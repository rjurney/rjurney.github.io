[{"body": "<p>My latest book, Agile Data Science v2.0 is out in early release by O'Reilly! The book is rewritten using PySpark, and many latest and greatest tools like scikit-learn, word2vec, Spark SQL, d3.js and many more. In addition, much new content has been added to make the book a great introduction to predictive analytics in theory and practice.</p> \n\n<p>I&rsquo;m very proud of it :)</p>\n\n<a href=\"http://bit.ly/agile_data_science\">http://bit.ly/agile_data_science</a>\n\n<br/><br/><center><img src=\"http://akamaicovers.oreilly.com/images/0636920051619/rc_cat.gif\"/></center>", "liked": false, "followed": false, "reblog_key": "chjTtg5W", "reblog": {"comment": "<p><p>My latest book, Agile Data Science v2.0 is out in early release by O'Reilly! The book is rewritten using PySpark, and many latest and greatest tools like scikit-learn, word2vec, Spark SQL, d3.js and many more. In addition, much new content has been added to make the book a great introduction to predictive analytics in theory and practice.</p> \n\n<p>I\u2019m very proud of it :)</p>\n\n<a href=\"http://bit.ly/agile_data_science\">http://bit.ly/agile_data_science</a>\n\n<br><br><center><img src=\"http://akamaicovers.oreilly.com/images/0636920051619/rc_cat.gif\"></center></p>", "tree_html": ""}, "can_send_in_message": true, "id": 150513102419, "display_avatar": true, "can_reply": true, "can_like": false, "title": null, "tags": [], "post_url": "http://datasyndrome.com/post/150513102419/my-latest-book-agile-data-science-v20-is-out-in", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y2CBHwvJ", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1474069575, "note_count": 3, "trail": [{"content": "<p><p>My latest book, Agile Data Science v2.0 is out in early release by O'Reilly! The book is rewritten using PySpark, and many latest and greatest tools like scikit-learn, word2vec, Spark SQL, d3.js and many more. In addition, much new content has been added to make the book a great introduction to predictive analytics in theory and practice.</p> \n\n<p>I&rsquo;m very proud of it :)</p>\n\n<a href=\"http://bit.ly/agile_data_science\">http://bit.ly/agile_data_science</a>\n\n<br /><br /><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://akamaicovers.oreilly.com/images/0636920051619/rc_cat.gif\">External image</div></p>", "content_raw": "<p><p>My latest book, Agile Data Science v2.0 is out in early release by O'Reilly! The book is rewritten using PySpark, and many latest and greatest tools like scikit-learn, word2vec, Spark SQL, d3.js and many more. In addition, much new content has been added to make the book a great introduction to predictive analytics in theory and practice.</p> \n\n<p>I\u2019m very proud of it :)</p>\n\n<a href=\"http://bit.ly/agile_data_science\">http://bit.ly/agile_data_science</a>\n\n<br><br><center><img src=\"http://akamaicovers.oreilly.com/images/0636920051619/rc_cat.gif\"></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "150513102419"}}], "date": "2016-09-16 23:46:15 GMT", "slug": "my-latest-book-agile-data-science-v20-is-out-in", "blog_name": "rjurney", "summary": "My latest book, Agile Data Science v2.0 is out in early release by O'Reilly! The book is rewritten using PySpark, and many...", "can_reblog": true}, {"body": "<pre><code>alias photoshop=\"open -a /Applications/Adobe\\ Photoshop\\ Elements\\ 10\\ Editor.app\"\n\nphotoshop images/foobar.png\n</code></pre>", "liked": false, "followed": false, "reblog_key": "XXbnlJZc", "reblog": {"comment": "<p><pre><code>alias photoshop=\"open -a /Applications/Adobe\\ Photoshop\\ Elements\\ 10\\ Editor.app\"\n\nphotoshop images/foobar.png\n</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 141222446709, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Adobe Apps from OS X Command Line", "tags": [], "post_url": "http://datasyndrome.com/post/141222446709/adobe-apps-from-os-x-command-line", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y23XWuPr", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1458253427, "note_count": 0, "trail": [{"content": "<p><pre><code>alias photoshop=\"open -a /Applications/Adobe\\ Photoshop\\ Elements\\ 10\\ Editor.app\"\n\nphotoshop images/foobar.png\n</code></pre></p>", "content_raw": "<p><pre><code>alias photoshop=\"open -a /Applications/Adobe\\ Photoshop\\ Elements\\ 10\\ Editor.app\"\n\nphotoshop images/foobar.png\n</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "141222446709"}}], "date": "2016-03-17 22:23:47 GMT", "slug": "adobe-apps-from-os-x-command-line", "blog_name": "rjurney", "summary": "Adobe Apps from OS X Command Line", "can_reblog": true}, {"body": "<pre><code>#!/usr/bin/env bash\n\nif [ \"$(uname)\" == \"Darwin\" ]; then\n    ANADONCA_OS_NAME='MacOSX'      \nelif [ \"$(expr substr $(uname -s) 1 5)\" == \"Linux\" ]; then\n    ANADONCA_OS_NAME='Linux'\nelif [ \"$(expr substr $(uname -s) 1 10)\" == \"MINGW32_NT\" ]; then\n    ANADONCA_OS_NAME='Windows'\nfi\n\n# Download and install Anaconda\nwget -P /tmp/ \"http://repo.continuum.io/archive/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\"\nbash \"/tmp/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\" -b -p $HOME/anaconda\nexport PATH=\"$HOME/anaconda/bin:$PATH\"\necho 'export PATH=\"$HOME/anaconda/bin:$PATH\"' &gt;&gt; ~/.bash_profile</code></pre>\n\n<p>See\u00a0<a href=\"https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh\">https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh</a></p>", "liked": false, "followed": false, "reblog_key": "CBfDPpNu", "reblog": {"comment": "<pre><code>#!/usr/bin/env bash\n\nif [ \"$(uname)\" == \"Darwin\" ]; then\n    ANADONCA_OS_NAME='MacOSX'      \nelif [ \"$(expr substr $(uname -s) 1 5)\" == \"Linux\" ]; then\n    ANADONCA_OS_NAME='Linux'\nelif [ \"$(expr substr $(uname -s) 1 10)\" == \"MINGW32_NT\" ]; then\n    ANADONCA_OS_NAME='Windows'\nfi\n\n# Download and install Anaconda\nwget -P /tmp/ \"http://repo.continuum.io/archive/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\"\nbash \"/tmp/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\" -b -p $HOME/anaconda\nexport PATH=\"$HOME/anaconda/bin:$PATH\"\necho 'export PATH=\"$HOME/anaconda/bin:$PATH\"' &gt;&gt; ~/.bash_profile</code></pre>\n\n<p>See\u00a0<a href=\"https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh\">https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh</a></p>", "tree_html": ""}, "can_send_in_message": true, "id": 141220337084, "display_avatar": true, "can_reply": true, "can_like": false, "title": "HOWTO do a cross-platform, headless Anaconda install", "tags": [], "post_url": "http://datasyndrome.com/post/141220337084/howto-do-a-cross-platform-headless-anaconda", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y23XOrMy", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1458250793, "note_count": 0, "trail": [{"content": "<pre><code>#!/usr/bin/env bash\n\nif [ \"$(uname)\" == \"Darwin\" ]; then\n    ANADONCA_OS_NAME='MacOSX'      \nelif [ \"$(expr substr $(uname -s) 1 5)\" == \"Linux\" ]; then\n    ANADONCA_OS_NAME='Linux'\nelif [ \"$(expr substr $(uname -s) 1 10)\" == \"MINGW32_NT\" ]; then\n    ANADONCA_OS_NAME='Windows'\nfi\n\n# Download and install Anaconda\nwget -P /tmp/ \"http://repo.continuum.io/archive/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\"\nbash \"/tmp/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\" -b -p $HOME/anaconda\nexport PATH=\"$HOME/anaconda/bin:$PATH\"\necho 'export PATH=\"$HOME/anaconda/bin:$PATH\"' &gt;&gt; ~/.bash_profile</code></pre>\n\n<p>See&nbsp;<a href=\"https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh\">https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh</a></p>", "content_raw": "<pre><code>#!/usr/bin/env bash\n\nif [ \"$(uname)\" == \"Darwin\" ]; then\n    ANADONCA_OS_NAME='MacOSX'      \nelif [ \"$(expr substr $(uname -s) 1 5)\" == \"Linux\" ]; then\n    ANADONCA_OS_NAME='Linux'\nelif [ \"$(expr substr $(uname -s) 1 10)\" == \"MINGW32_NT\" ]; then\n    ANADONCA_OS_NAME='Windows'\nfi\n\n# Download and install Anaconda\nwget -P /tmp/ \"http://repo.continuum.io/archive/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\"\nbash \"/tmp/Anaconda2-2.5.0-${ANADONCA_OS_NAME}-x86_64.sh\" -b -p $HOME/anaconda\nexport PATH=\"$HOME/anaconda/bin:$PATH\"\necho 'export PATH=\"$HOME/anaconda/bin:$PATH\"' &gt;&gt; ~/.bash_profile</code></pre>\n\n<p>See\u00a0<a href=\"https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh\">https://github.com/rjurney/Agile_Data_Code_2/blob/master/ch03/install.sh</a></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "141220337084"}}], "date": "2016-03-17 21:39:53 GMT", "slug": "howto-do-a-cross-platform-headless-anaconda", "blog_name": "rjurney", "summary": "HOWTO do a cross-platform, headless Anaconda install", "can_reblog": true}, {"body": "<p>I am vectorizing some features in sklearn, and I have run into a problem. DictVectorizer works well if your data can be encoded into one dict per item. What if your items can have two values of the same column? \n\nFor instance, DictVectorizer works fine on an item like this one:\n\n<code><pre>{'a': 'b', 'b': 'c'}</pre></code>\n\nBut what about something like this, with more than one value per column? \n\n<code><pre>{\u2018a\u2019: [\u2018b\u2019,\u2019c\u2019], \u2018b\u2019: \u2018d\u2019}</pre></code>\n\nThe strategy of one-hot-encoding can still apply, you simply want two a columns\u2026 a=b and a=c. So far as I can tell, no such vectorizer exists!\n\nWhat is one supposed to do in this situation? Do I need to create my own MultiDictVectorizer?</p>\n\n<p>I just <a href=\"http://stackoverflow.com/questions/35421205/how-can-i-encode-features-with-more-than-one-value-per-column-multidictvectoriz\">posted this</a> to StackOverflow.</p>\n\n<p>To answer my own question, I am adding support for lists to DictVectorizer, or creating a new class MultiDictVectorizer that does so. From StackOverflow:</p>\n\n<bq>DictVectorizer can&rsquo;t handle multiple values per key, so I am adding this ability to it. If the pull is accepted, this will be a part of sklearn. If not, I will subclass DictVectorizer in MultiDictVectorizer and will release a package for this class.<br/><br/><a href=\"https://github.com/scikit-learn/scikit-learn/pull/6369\">Pull request at Github</a><br/><a href=\"https://github.com/scikit-learn/scikit-learn/issues/6368\">Issue in sklearn Github project</a></bq>", "liked": false, "followed": false, "reblog_key": "2hQNqPRZ", "reblog": {"comment": "<p><p>I am vectorizing some features in sklearn, and I have run into a problem. DictVectorizer works well if your data can be encoded into one dict per item. What if your items can have two values of the same column? \n\nFor instance, DictVectorizer works fine on an item like this one:\n\n<code><pre>{'a': 'b', 'b': 'c'}</pre></code>\n\nBut what about something like this, with more than one value per column? \n\n<code><pre>{\u2018a\u2019: [\u2018b\u2019,\u2019c\u2019], \u2018b\u2019: \u2018d\u2019}</pre></code>\n\nThe strategy of one-hot-encoding can still apply, you simply want two a columns\u2026 a=b and a=c. So far as I can tell, no such vectorizer exists!\n\nWhat is one supposed to do in this situation? Do I need to create my own MultiDictVectorizer?</p>\n\n<p>I just <a href=\"http://stackoverflow.com/questions/35421205/how-can-i-encode-features-with-more-than-one-value-per-column-multidictvectoriz\">posted this</a> to StackOverflow.</p>\n\n<p>To answer my own question, I am adding support for lists to DictVectorizer, or creating a new class MultiDictVectorizer that does so. From StackOverflow:</p>\n\n<bq>DictVectorizer can\u2019t handle multiple values per key, so I am adding this ability to it. If the pull is accepted, this will be a part of sklearn. If not, I will subclass DictVectorizer in MultiDictVectorizer and will release a package for this class.<br><br><a href=\"https://github.com/scikit-learn/scikit-learn/pull/6369\">Pull request at Github</a><br><a href=\"https://github.com/scikit-learn/scikit-learn/issues/6368\">Issue in sklearn Github project</a></bq></p>", "tree_html": ""}, "can_send_in_message": true, "id": 139386441969, "display_avatar": true, "can_reply": true, "can_like": false, "title": "MultiDictVectorizer for sklearn?", "tags": [], "post_url": "http://datasyndrome.com/post/139386441969/multidictvectorizer-for-sklearn", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y21q553n", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1455579322, "note_count": 0, "trail": [{"content": "<p><p>I am vectorizing some features in sklearn, and I have run into a problem. DictVectorizer works well if your data can be encoded into one dict per item. What if your items can have two values of the same column? \n\nFor instance, DictVectorizer works fine on an item like this one:\n\n<code>{'a': 'b', 'b': 'c'}</code>\n\nBut what about something like this, with more than one value per column? \n\n<code>{&lsquo;a&rsquo;: [&lsquo;b&rsquo;,&rsquo;c&rsquo;], &lsquo;b&rsquo;: &lsquo;d&rsquo;}</code>\n\nThe strategy of one-hot-encoding can still apply, you simply want two a columns&hellip; a=b and a=c. So far as I can tell, no such vectorizer exists!\n\nWhat is one supposed to do in this situation? Do I need to create my own MultiDictVectorizer?</p>\n\n<p>I just <a href=\"http://stackoverflow.com/questions/35421205/how-can-i-encode-features-with-more-than-one-value-per-column-multidictvectoriz\">posted this</a> to StackOverflow.</p>\n\n<p>To answer my own question, I am adding support for lists to DictVectorizer, or creating a new class MultiDictVectorizer that does so. From StackOverflow:</p>\n\nDictVectorizer can&rsquo;t handle multiple values per key, so I am adding this ability to it. If the pull is accepted, this will be a part of sklearn. If not, I will subclass DictVectorizer in MultiDictVectorizer and will release a package for this class.<br /><br /><a href=\"https://github.com/scikit-learn/scikit-learn/pull/6369\">Pull request at Github</a><br /><a href=\"https://github.com/scikit-learn/scikit-learn/issues/6368\">Issue in sklearn Github project</a></p>", "content_raw": "<p><p>I am vectorizing some features in sklearn, and I have run into a problem. DictVectorizer works well if your data can be encoded into one dict per item. What if your items can have two values of the same column? \n\nFor instance, DictVectorizer works fine on an item like this one:\n\n<code><pre>{'a': 'b', 'b': 'c'}</pre></code>\n\nBut what about something like this, with more than one value per column? \n\n<code><pre>{\u2018a\u2019: [\u2018b\u2019,\u2019c\u2019], \u2018b\u2019: \u2018d\u2019}</pre></code>\n\nThe strategy of one-hot-encoding can still apply, you simply want two a columns\u2026 a=b and a=c. So far as I can tell, no such vectorizer exists!\n\nWhat is one supposed to do in this situation? Do I need to create my own MultiDictVectorizer?</p>\n\n<p>I just <a href=\"http://stackoverflow.com/questions/35421205/how-can-i-encode-features-with-more-than-one-value-per-column-multidictvectoriz\">posted this</a> to StackOverflow.</p>\n\n<p>To answer my own question, I am adding support for lists to DictVectorizer, or creating a new class MultiDictVectorizer that does so. From StackOverflow:</p>\n\n<bq>DictVectorizer can\u2019t handle multiple values per key, so I am adding this ability to it. If the pull is accepted, this will be a part of sklearn. If not, I will subclass DictVectorizer in MultiDictVectorizer and will release a package for this class.<br><br><a href=\"https://github.com/scikit-learn/scikit-learn/pull/6369\">Pull request at Github</a><br><a href=\"https://github.com/scikit-learn/scikit-learn/issues/6368\">Issue in sklearn Github project</a></bq></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "139386441969"}}], "date": "2016-02-15 23:35:22 GMT", "slug": "multidictvectorizer-for-sklearn", "blog_name": "rjurney", "summary": "MultiDictVectorizer for sklearn?", "can_reblog": true}, {"body": "<p align=\"justify\"><b>I&rsquo;ve recently discovered an amazing new treatment for chronic pain called Cannabidiol</b>, also known as CBD, that I want to tell you about.</p>\n\n<p align=\"justify\"><blockqoute><p><i>Cannabidiol (CBD) is one of at least 85 active cannabinoids identified in cannabis.[4] It is a major phytocannabinoid, accounting for up to 40% of the plant&rsquo;s extract.[5] CBD is considered to have a wider scope of potential medical applications than tetrahydrocannabinol (THC).</i></p>\n<footer><cite><a href=\"https://en.wikipedia.org/wiki/Cannabidiol\">Wikipedia on CBD</a></cite></footer></blockqoute></p>\n\n<p align=\"justify\">It is strange to talk openly about medical marijuana/cannabis, even as a California resident, as there is a stigma associated with it. <i>After all, lets face it&hellip; most people with &lsquo;anxiety&rsquo; that consume medical cannabis just like to get high, and medical cannabis is simply a loophole for their recreational use or even dependence.</i></p>\n\n<img src=\"https://s3.amazonaws.com/rjurneyopen/CBD_Molecule.JPG\" width=\"400px\" align=\"right\"/><p align=\"justify\">That is why I want to talk openly about taking CBD. For a growing number of pain patients (and others), medical cannabis in the form of CBD represent an important new treatment that simply does not 'get you high,&rsquo; and yet relieves pain as effectively as any other treatment. I suffer from neck pain that is a nuisance, and CBD is a powerful new tool in my treatment of this pain.</p>\n\n<p align=\"justify\">To get concrete: for $60 at a local dispensary, I bought a hemp CBD 'vape pen&rsquo; that comes with a cartridge with 250mg of CBD dissolved in essential oils of hemp. Hemp being the legal form of cannabis without THC in it, used to make rope. The pen is standardized at 1mg of cannabinoids per hit. A 'hit&rsquo; is a pull or inhalation on the pen, which vaporizes (as opposed to burns) the oil and delivers it to your lungs. A working dose is several 'hits&rsquo; or inhalations.</p>\n\n<p>The effect? <b>All pain, even severe pain, melts away in 30 seconds.</b> This effect lasts about 15 minutes. There is nothing else like this available medically. No other treatment available so quickly addresses severe pain. Vaped CBD is simply amazing. I can&rsquo;t oversell how effective it is.</p>\n\n<p>But 15 minutes? If this were your only method of pain control, you would be vaping all day long. This is undesirable. For longer term pain control, turn to CBD sublingual drops. 10-20mg of CBD under the tongue (4-8 sprays of the drops I use) takes effect within 10 minutes and lasts for hours. A large-sized vial of drops goes for about $60 and has 90 sprays. The price of CBD has gotten much cheaper in the last couple of years and is likely to continue to decrease.</p>\n\n<p>Used together, drops and the pen can lead to a dramatic reduction in the use of other pain medications, which means far fewer unwanted side effects. Simply put: <b>if you&rsquo;re in pain and you&rsquo;re in a state where CBD is legal, you should try CBD</b>. It is a powerful new tool to combat chronic pain.</p>", "liked": false, "followed": false, "reblog_key": "l5B3CXFV", "reblog": {"comment": "<p align=\"justify\"><b>I\u2019ve recently discovered an amazing new treatment for chronic pain called Cannabidiol</b>, also known as CBD, that I want to tell you about.</p>\n\n<p align=\"justify\"><blockqoute><p><i>Cannabidiol (CBD) is one of at least 85 active cannabinoids identified in cannabis.[4] It is a major phytocannabinoid, accounting for up to 40% of the plant\u2019s extract.[5] CBD is considered to have a wider scope of potential medical applications than tetrahydrocannabinol (THC).</i></p>\n<footer><cite><a href=\"https://en.wikipedia.org/wiki/Cannabidiol\">Wikipedia on CBD</a></cite></footer></blockqoute></p>\n\n<p align=\"justify\">It is strange to talk openly about medical marijuana/cannabis, even as a California resident, as there is a stigma associated with it. <i>After all, lets face it\u2026 most people with \u2018anxiety\u2019 that consume medical cannabis just like to get high, and medical cannabis is simply a loophole for their recreational use or even dependence.</i></p>\n\n<img src=\"https://s3.amazonaws.com/rjurneyopen/CBD_Molecule.JPG\" width=\"400px\" align=\"right\"><p align=\"justify\">That is why I want to talk openly about taking CBD. For a growing number of pain patients (and others), medical cannabis in the form of CBD represent an important new treatment that simply does not 'get you high,\u2019 and yet relieves pain as effectively as any other treatment. I suffer from neck pain that is a nuisance, and CBD is a powerful new tool in my treatment of this pain.</p>\n\n<p align=\"justify\">To get concrete: for $60 at a local dispensary, I bought a hemp CBD 'vape pen\u2019 that comes with a cartridge with 250mg of CBD dissolved in essential oils of hemp. Hemp being the legal form of cannabis without THC in it, used to make rope. The pen is standardized at 1mg of cannabinoids per hit. A 'hit\u2019 is a pull or inhalation on the pen, which vaporizes (as opposed to burns) the oil and delivers it to your lungs. A working dose is several 'hits\u2019 or inhalations.</p>\n\n<p>The effect? <b>All pain, even severe pain, melts away in 30 seconds.</b> This effect lasts about 15 minutes. There is nothing else like this available medically. No other treatment available so quickly addresses severe pain. Vaped CBD is simply amazing. I can\u2019t oversell how effective it is.</p>\n\n<p>But 15 minutes? If this were your only method of pain control, you would be vaping all day long. This is undesirable. For longer term pain control, turn to CBD sublingual drops. 10-20mg of CBD under the tongue (4-8 sprays of the drops I use) takes effect within 10 minutes and lasts for hours. A large-sized vial of drops goes for about $60 and has 90 sprays. The price of CBD has gotten much cheaper in the last couple of years and is likely to continue to decrease.</p>\n\n<p>Used together, drops and the pen can lead to a dramatic reduction in the use of other pain medications, which means far fewer unwanted side effects. Simply put: <b>if you\u2019re in pain and you\u2019re in a state where CBD is legal, you should try CBD</b>. It is a powerful new tool to combat chronic pain.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 136697814849, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Cannabadiol (CBD) for Chronic Pain", "tags": [], "post_url": "http://datasyndrome.com/post/136697814849/cannabadiol-cbd-for-chronic-pain", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1-Jqnz1", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1452027731, "note_count": 0, "trail": [{"content": "<p><b>I&rsquo;ve recently discovered an amazing new treatment for chronic pain called Cannabidiol</b>, also known as CBD, that I want to tell you about.</p>\n\n<p><i>Cannabidiol (CBD) is one of at least 85 active cannabinoids identified in cannabis.[4] It is a major phytocannabinoid, accounting for up to 40% of the plant&rsquo;s extract.[5] CBD is considered to have a wider scope of potential medical applications than tetrahydrocannabinol (THC).</i></p>\n<a href=\"https://en.wikipedia.org/wiki/Cannabidiol\">Wikipedia on CBD</a>\n\n<p>It is strange to talk openly about medical marijuana/cannabis, even as a California resident, as there is a stigma associated with it. <i>After all, lets face it&hellip; most people with &lsquo;anxiety&rsquo; that consume medical cannabis just like to get high, and medical cannabis is simply a loophole for their recreational use or even dependence.</i></p>\n\n<div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/rjurneyopen/CBD_Molecule.JPG\">External image</div><p>That is why I want to talk openly about taking CBD. For a growing number of pain patients (and others), medical cannabis in the form of CBD represent an important new treatment that simply does not 'get you high,&rsquo; and yet relieves pain as effectively as any other treatment. I suffer from neck pain that is a nuisance, and CBD is a powerful new tool in my treatment of this pain.</p>\n\n<p>To get concrete: for $60 at a local dispensary, I bought a hemp CBD 'vape pen&rsquo; that comes with a cartridge with 250mg of CBD dissolved in essential oils of hemp. Hemp being the legal form of cannabis without THC in it, used to make rope. The pen is standardized at 1mg of cannabinoids per hit. A 'hit&rsquo; is a pull or inhalation on the pen, which vaporizes (as opposed to burns) the oil and delivers it to your lungs. A working dose is several 'hits&rsquo; or inhalations.</p>\n\n<p>The effect? <b>All pain, even severe pain, melts away in 30 seconds.</b> This effect lasts about 15 minutes. There is nothing else like this available medically. No other treatment available so quickly addresses severe pain. Vaped CBD is simply amazing. I can&rsquo;t oversell how effective it is.</p>\n\n<p>But 15 minutes? If this were your only method of pain control, you would be vaping all day long. This is undesirable. For longer term pain control, turn to CBD sublingual drops. 10-20mg of CBD under the tongue (4-8 sprays of the drops I use) takes effect within 10 minutes and lasts for hours. A large-sized vial of drops goes for about $60 and has 90 sprays. The price of CBD has gotten much cheaper in the last couple of years and is likely to continue to decrease.</p>\n\n<p>Used together, drops and the pen can lead to a dramatic reduction in the use of other pain medications, which means far fewer unwanted side effects. Simply put: <b>if you&rsquo;re in pain and you&rsquo;re in a state where CBD is legal, you should try CBD</b>. It is a powerful new tool to combat chronic pain.</p>", "content_raw": "<p align=\"justify\"><b>I\u2019ve recently discovered an amazing new treatment for chronic pain called Cannabidiol</b>, also known as CBD, that I want to tell you about.</p>\n\n<p align=\"justify\"><blockqoute><p><i>Cannabidiol (CBD) is one of at least 85 active cannabinoids identified in cannabis.[4] It is a major phytocannabinoid, accounting for up to 40% of the plant\u2019s extract.[5] CBD is considered to have a wider scope of potential medical applications than tetrahydrocannabinol (THC).</i></p>\n<footer><cite><a href=\"https://en.wikipedia.org/wiki/Cannabidiol\">Wikipedia on CBD</a></cite></footer></blockqoute></p>\n\n<p align=\"justify\">It is strange to talk openly about medical marijuana/cannabis, even as a California resident, as there is a stigma associated with it. <i>After all, lets face it\u2026 most people with \u2018anxiety\u2019 that consume medical cannabis just like to get high, and medical cannabis is simply a loophole for their recreational use or even dependence.</i></p>\n\n<img src=\"https://s3.amazonaws.com/rjurneyopen/CBD_Molecule.JPG\" width=\"400px\" align=\"right\"><p align=\"justify\">That is why I want to talk openly about taking CBD. For a growing number of pain patients (and others), medical cannabis in the form of CBD represent an important new treatment that simply does not 'get you high,\u2019 and yet relieves pain as effectively as any other treatment. I suffer from neck pain that is a nuisance, and CBD is a powerful new tool in my treatment of this pain.</p>\n\n<p align=\"justify\">To get concrete: for $60 at a local dispensary, I bought a hemp CBD 'vape pen\u2019 that comes with a cartridge with 250mg of CBD dissolved in essential oils of hemp. Hemp being the legal form of cannabis without THC in it, used to make rope. The pen is standardized at 1mg of cannabinoids per hit. A 'hit\u2019 is a pull or inhalation on the pen, which vaporizes (as opposed to burns) the oil and delivers it to your lungs. A working dose is several 'hits\u2019 or inhalations.</p>\n\n<p>The effect? <b>All pain, even severe pain, melts away in 30 seconds.</b> This effect lasts about 15 minutes. There is nothing else like this available medically. No other treatment available so quickly addresses severe pain. Vaped CBD is simply amazing. I can\u2019t oversell how effective it is.</p>\n\n<p>But 15 minutes? If this were your only method of pain control, you would be vaping all day long. This is undesirable. For longer term pain control, turn to CBD sublingual drops. 10-20mg of CBD under the tongue (4-8 sprays of the drops I use) takes effect within 10 minutes and lasts for hours. A large-sized vial of drops goes for about $60 and has 90 sprays. The price of CBD has gotten much cheaper in the last couple of years and is likely to continue to decrease.</p>\n\n<p>Used together, drops and the pen can lead to a dramatic reduction in the use of other pain medications, which means far fewer unwanted side effects. Simply put: <b>if you\u2019re in pain and you\u2019re in a state where CBD is legal, you should try CBD</b>. It is a powerful new tool to combat chronic pain.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "136697814849"}}], "date": "2016-01-05 21:02:11 GMT", "slug": "cannabadiol-cbd-for-chronic-pain", "blog_name": "rjurney", "summary": "Cannabadiol (CBD) for Chronic Pain", "can_reblog": true}, {"body": "<p>When running iterative tasks on your machine, it is frustrating to have to start over if an exception is thrown. For this reason, I hacked this simple utility to resume. Enjoy!</p>\n\n\n<p>Utility functions:</p>\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\"># util.py</span>\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">log_place</span>(filename, record):\n  f <span style=\"color: #333333\">=</span> codecs<span style=\"color: #333333\">.</span>open(filename, <span style=\"background-color: #fff0f0\">'w'</span>, <span style=\"background-color: #fff0f0\">'utf8'</span>)\n  f<span style=\"color: #333333\">.</span>write(json<span style=\"color: #333333\">.</span>dumps(record))\n  f<span style=\"color: #333333\">.</span>close()\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">True</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">load_place</span>(filename):\n  <span style=\"color: #008800; font-weight: bold\">if</span> os<span style=\"color: #333333\">.</span>path<span style=\"color: #333333\">.</span>isfile(filename): \n    f <span style=\"color: #333333\">=</span> codecs<span style=\"color: #333333\">.</span>open(filename, <span style=\"background-color: #fff0f0\">'r'</span>, <span style=\"background-color: #fff0f0\">'utf8'</span>)\n    record <span style=\"color: #333333\">=</span> json<span style=\"color: #333333\">.</span>loads(f<span style=\"color: #333333\">.</span>read())\n    f<span style=\"color: #333333\">.</span>close()\n    <span style=\"color: #008800; font-weight: bold\">return</span> record\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">False</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">resume_place_in_list</span>(record, a_list):\n  <span style=\"color: #008800; font-weight: bold\">for</span> i, item <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">enumerate</span>(a_list):\n    <span style=\"color: #008800; font-weight: bold\">if</span> dicts_are_equal(item, record):\n      <span style=\"color: #008800; font-weight: bold\">return</span> i\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">dicts_are_equal</span>(dict_1, dict_2):\n  unmatched_item <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">set</span>(dict_1<span style=\"color: #333333\">.</span>items()) <span style=\"color: #333333\">^</span> <span style=\"color: #007020\">set</span>(dict_2<span style=\"color: #333333\">.</span>items())\n  <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #007020\">len</span>(unmatched_item) <span style=\"color: #333333\">==</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>:\n    <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">True</span>\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">False</span>\n</pre></div>\n\n<br/><p>Using this utility in your main loop is easy:</p>\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\"># main.py</span>\nrecords <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>json_cr_file_2_array(args<span style=\"color: #333333\">.</span>file)\n  \n<span style=\"color: #888888\"># Load our place</span>\nstarting_place <span style=\"color: #333333\">=</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>\nplace_record <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>load_place(PLACE_LOG_FILENAME)\n<span style=\"color: #008800; font-weight: bold\">if</span> place_record:\n  starting_place <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>resume_place_in_list(place_record, records)\n  \n<span style=\"color: #008800; font-weight: bold\">for</span> i, record <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">enumerate</span>(records):\n  <span style=\"color: #008800; font-weight: bold\">if</span> i <span style=\"color: #333333\">&lt;=</span> starting_place <span style=\"color: #000000; font-weight: bold\">and</span> starting_place <span style=\"color: #333333\">&gt;</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>:\n    <span style=\"color: #008800; font-weight: bold\">continue</span>\n  <span style=\"color: #333333\">...</span>\n  util<span style=\"color: #333333\">.</span>log_place(PLACE_LOG_FILENAME, record)\n</pre></div>", "liked": false, "followed": false, "reblog_key": "Ib9dOPMO", "reblog": {"comment": "<p><p>When running iterative tasks on your machine, it is frustrating to have to start over if an exception is thrown. For this reason, I hacked this simple utility to resume. Enjoy!</p>\n\n\n<p>Utility functions:</p>\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\"># util.py</span>\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">log_place</span>(filename, record):\n  f <span style=\"color: #333333\">=</span> codecs<span style=\"color: #333333\">.</span>open(filename, <span style=\"background-color: #fff0f0\">'w'</span>, <span style=\"background-color: #fff0f0\">'utf8'</span>)\n  f<span style=\"color: #333333\">.</span>write(json<span style=\"color: #333333\">.</span>dumps(record))\n  f<span style=\"color: #333333\">.</span>close()\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">True</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">load_place</span>(filename):\n  <span style=\"color: #008800; font-weight: bold\">if</span> os<span style=\"color: #333333\">.</span>path<span style=\"color: #333333\">.</span>isfile(filename): \n    f <span style=\"color: #333333\">=</span> codecs<span style=\"color: #333333\">.</span>open(filename, <span style=\"background-color: #fff0f0\">'r'</span>, <span style=\"background-color: #fff0f0\">'utf8'</span>)\n    record <span style=\"color: #333333\">=</span> json<span style=\"color: #333333\">.</span>loads(f<span style=\"color: #333333\">.</span>read())\n    f<span style=\"color: #333333\">.</span>close()\n    <span style=\"color: #008800; font-weight: bold\">return</span> record\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">False</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">resume_place_in_list</span>(record, a_list):\n  <span style=\"color: #008800; font-weight: bold\">for</span> i, item <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">enumerate</span>(a_list):\n    <span style=\"color: #008800; font-weight: bold\">if</span> dicts_are_equal(item, record):\n      <span style=\"color: #008800; font-weight: bold\">return</span> i\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">dicts_are_equal</span>(dict_1, dict_2):\n  unmatched_item <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">set</span>(dict_1<span style=\"color: #333333\">.</span>items()) <span style=\"color: #333333\">^</span> <span style=\"color: #007020\">set</span>(dict_2<span style=\"color: #333333\">.</span>items())\n  <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #007020\">len</span>(unmatched_item) <span style=\"color: #333333\">==</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>:\n    <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">True</span>\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">False</span>\n</pre></div>\n\n<br><p>Using this utility in your main loop is easy:</p>\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\"># main.py</span>\nrecords <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>json_cr_file_2_array(args<span style=\"color: #333333\">.</span>file)\n  \n<span style=\"color: #888888\"># Load our place</span>\nstarting_place <span style=\"color: #333333\">=</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>\nplace_record <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>load_place(PLACE_LOG_FILENAME)\n<span style=\"color: #008800; font-weight: bold\">if</span> place_record:\n  starting_place <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>resume_place_in_list(place_record, records)\n  \n<span style=\"color: #008800; font-weight: bold\">for</span> i, record <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">enumerate</span>(records):\n  <span style=\"color: #008800; font-weight: bold\">if</span> i <span style=\"color: #333333\"><=</span> starting_place <span style=\"color: #000000; font-weight: bold\">and</span> starting_place <span style=\"color: #333333\">></span> <span style=\"color: #0000DD; font-weight: bold\">0</span>:\n    <span style=\"color: #008800; font-weight: bold\">continue</span>\n  <span style=\"color: #333333\">...</span>\n  util<span style=\"color: #333333\">.</span>log_place(PLACE_LOG_FILENAME, record)\n</pre></div></p>", "tree_html": ""}, "can_send_in_message": true, "id": 134024305544, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Resuming a job in Python", "tags": [], "post_url": "http://datasyndrome.com/post/134024305544/resuming-a-job-in-python", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1yqU9k8", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1448581293, "note_count": 0, "trail": [{"content": "<p><p>When running iterative tasks on your machine, it is frustrating to have to start over if an exception is thrown. For this reason, I hacked this simple utility to resume. Enjoy!</p>\n\n\n<p>Utility functions:</p>\n\n<pre># util.py\ndef log_place(filename, record):\n  f = codecs.open(filename, 'w', 'utf8')\n  f.write(json.dumps(record))\n  f.close()\n  return True\n\ndef load_place(filename):\n  if os.path.isfile(filename): \n    f = codecs.open(filename, 'r', 'utf8')\n    record = json.loads(f.read())\n    f.close()\n    return record\n  return False\n\ndef resume_place_in_list(record, a_list):\n  for i, item in enumerate(a_list):\n    if dicts_are_equal(item, record):\n      return i\n  return 0\n\ndef dicts_are_equal(dict_1, dict_2):\n  unmatched_item = set(dict_1.items()) ^ set(dict_2.items())\n  if len(unmatched_item) == 0:\n    return True\n  return False\n</pre>\n\n<br /><p>Using this utility in your main loop is easy:</p>\n\n<pre># main.py\nrecords = util.json_cr_file_2_array(args.file)\n  \n# Load our place\nstarting_place = 0\nplace_record = util.load_place(PLACE_LOG_FILENAME)\nif place_record:\n  starting_place = util.resume_place_in_list(place_record, records)\n  \nfor i, record in enumerate(records):\n  if i  starting_place and starting_place &gt; 0:\n    continue\n  ...\n  util.log_place(PLACE_LOG_FILENAME, record)\n</pre></p>", "content_raw": "<p><p>When running iterative tasks on your machine, it is frustrating to have to start over if an exception is thrown. For this reason, I hacked this simple utility to resume. Enjoy!</p>\n\n\n<p>Utility functions:</p>\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\"># util.py</span>\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">log_place</span>(filename, record):\n  f <span style=\"color: #333333\">=</span> codecs<span style=\"color: #333333\">.</span>open(filename, <span style=\"background-color: #fff0f0\">'w'</span>, <span style=\"background-color: #fff0f0\">'utf8'</span>)\n  f<span style=\"color: #333333\">.</span>write(json<span style=\"color: #333333\">.</span>dumps(record))\n  f<span style=\"color: #333333\">.</span>close()\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">True</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">load_place</span>(filename):\n  <span style=\"color: #008800; font-weight: bold\">if</span> os<span style=\"color: #333333\">.</span>path<span style=\"color: #333333\">.</span>isfile(filename): \n    f <span style=\"color: #333333\">=</span> codecs<span style=\"color: #333333\">.</span>open(filename, <span style=\"background-color: #fff0f0\">'r'</span>, <span style=\"background-color: #fff0f0\">'utf8'</span>)\n    record <span style=\"color: #333333\">=</span> json<span style=\"color: #333333\">.</span>loads(f<span style=\"color: #333333\">.</span>read())\n    f<span style=\"color: #333333\">.</span>close()\n    <span style=\"color: #008800; font-weight: bold\">return</span> record\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">False</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">resume_place_in_list</span>(record, a_list):\n  <span style=\"color: #008800; font-weight: bold\">for</span> i, item <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">enumerate</span>(a_list):\n    <span style=\"color: #008800; font-weight: bold\">if</span> dicts_are_equal(item, record):\n      <span style=\"color: #008800; font-weight: bold\">return</span> i\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">dicts_are_equal</span>(dict_1, dict_2):\n  unmatched_item <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">set</span>(dict_1<span style=\"color: #333333\">.</span>items()) <span style=\"color: #333333\">^</span> <span style=\"color: #007020\">set</span>(dict_2<span style=\"color: #333333\">.</span>items())\n  <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #007020\">len</span>(unmatched_item) <span style=\"color: #333333\">==</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>:\n    <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">True</span>\n  <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">False</span>\n</pre></div>\n\n<br><p>Using this utility in your main loop is easy:</p>\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\"># main.py</span>\nrecords <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>json_cr_file_2_array(args<span style=\"color: #333333\">.</span>file)\n  \n<span style=\"color: #888888\"># Load our place</span>\nstarting_place <span style=\"color: #333333\">=</span> <span style=\"color: #0000DD; font-weight: bold\">0</span>\nplace_record <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>load_place(PLACE_LOG_FILENAME)\n<span style=\"color: #008800; font-weight: bold\">if</span> place_record:\n  starting_place <span style=\"color: #333333\">=</span> util<span style=\"color: #333333\">.</span>resume_place_in_list(place_record, records)\n  \n<span style=\"color: #008800; font-weight: bold\">for</span> i, record <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">enumerate</span>(records):\n  <span style=\"color: #008800; font-weight: bold\">if</span> i <span style=\"color: #333333\"><=</span> starting_place <span style=\"color: #000000; font-weight: bold\">and</span> starting_place <span style=\"color: #333333\">></span> <span style=\"color: #0000DD; font-weight: bold\">0</span>:\n    <span style=\"color: #008800; font-weight: bold\">continue</span>\n  <span style=\"color: #333333\">...</span>\n  util<span style=\"color: #333333\">.</span>log_place(PLACE_LOG_FILENAME, record)\n</pre></div></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "134024305544"}}], "date": "2015-11-26 23:41:33 GMT", "slug": "resuming-a-job-in-python", "blog_name": "rjurney", "summary": "Resuming a job in Python", "can_reblog": true}, {"body": "Below is a utility script for turning an array of json objects into Tab-Separated-Value (TSV) format. I got tired of doing this in throwaway scripts and finally wrote a utility, and I gift it unto thee!\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\">#!/usr/bin/env python</span>\n\n<span style=\"color: #008800; font-weight: bold\">import</span> <span style=\"color: #0e84b5; font-weight: bold\">sys</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">os</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">re</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">json</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">argparse</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">json_file_2_array</span>(path):\n  text <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">open</span>(path)<span style=\"color: #333333\">.</span>read()\n  <span style=\"color: #008800; font-weight: bold\">return</span> json<span style=\"color: #333333\">.</span>loads(text)\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">json_cr_file_2_array</span>(path):\n  ary <span style=\"color: #333333\">=</span> []\n  f <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">open</span>(path)\n  <span style=\"color: #008800; font-weight: bold\">for</span> line <span style=\"color: #000000; font-weight: bold\">in</span> f:\n    record <span style=\"color: #333333\">=</span> json<span style=\"color: #333333\">.</span>loads(line<span style=\"color: #333333\">.</span>rstrip(<span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\n</span><span style=\"background-color: #fff0f0\">|</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\r</span><span style=\"background-color: #fff0f0\">\"</span>))\n    ary<span style=\"color: #333333\">.</span>append(record)\n  <span style=\"color: #008800; font-weight: bold\">return</span> ary\n\nparser <span style=\"color: #333333\">=</span> argparse<span style=\"color: #333333\">.</span>ArgumentParser(description<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">'This is a script to turn JSON to TSV with a header row.'</span>)\nparser<span style=\"color: #333333\">.</span>add_argument(<span style=\"background-color: #fff0f0\">'-f'</span>,<span style=\"background-color: #fff0f0\">'--file'</span>, help<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"File to convert.\"</span>, required<span style=\"color: #333333\">=</span><span style=\"color: #007020\">True</span>)\nparser<span style=\"color: #333333\">.</span>add_argument(<span style=\"background-color: #fff0f0\">'-j'</span>,<span style=\"background-color: #fff0f0\">'--json'</span>, help<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"Read the entire file as a json array.\"</span>, required<span style=\"color: #333333\">=</span><span style=\"color: #007020\">False</span>, action<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"store_true\"</span>)\nargs <span style=\"color: #333333\">=</span> parser<span style=\"color: #333333\">.</span>parse_args()\n\ndata <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">None</span>\n<span style=\"color: #008800; font-weight: bold\">if</span> args<span style=\"color: #333333\">.</span>json:\n  data <span style=\"color: #333333\">=</span> json_file_2_array(args<span style=\"color: #333333\">.</span>file)\n<span style=\"color: #008800; font-weight: bold\">else</span>:\n  data <span style=\"color: #333333\">=</span> json_cr_file_2_array(args<span style=\"color: #333333\">.</span>file)\n\n<span style=\"color: #888888\"># Get the set of field names occurring in any records</span>\nkeyset <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">set</span>()\n<span style=\"color: #008800; font-weight: bold\">for</span> d <span style=\"color: #000000; font-weight: bold\">in</span> data:\n  keys <span style=\"color: #333333\">=</span> d<span style=\"color: #333333\">.</span>keys()\n  <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> keys:\n    keyset<span style=\"color: #333333\">.</span>add(key)\n\n<span style=\"color: #888888\"># Print header</span>\n<span style=\"color: #008800; font-weight: bold\">print</span> <span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\t</span><span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #333333\">.</span>join(keyset)\n\n<span style=\"color: #008800; font-weight: bold\">for</span> d <span style=\"color: #000000; font-weight: bold\">in</span> data:\n  row <span style=\"color: #333333\">=</span> []\n  <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> keyset:\n    key_or_empty <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">str</span>(d[key]) <span style=\"color: #008800; font-weight: bold\">if</span> key <span style=\"color: #000000; font-weight: bold\">in</span> d <span style=\"color: #008800; font-weight: bold\">else</span> <span style=\"background-color: #fff0f0\">''</span>\n    row<span style=\"color: #333333\">.</span>append(key_or_empty)\n  <span style=\"color: #008800; font-weight: bold\">print</span> <span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\t</span><span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #333333\">.</span>join(row)\n</pre></div>", "liked": false, "followed": false, "reblog_key": "QlRsO3xY", "reblog": {"comment": "<p>Below is a utility script for turning an array of json objects into Tab-Separated-Value (TSV) format. I got tired of doing this in throwaway scripts and finally wrote a utility, and I gift it unto thee!\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\">#!/usr/bin/env python</span>\n\n<span style=\"color: #008800; font-weight: bold\">import</span> <span style=\"color: #0e84b5; font-weight: bold\">sys</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">os</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">re</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">json</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">argparse</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">json_file_2_array</span>(path):\n  text <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">open</span>(path)<span style=\"color: #333333\">.</span>read()\n  <span style=\"color: #008800; font-weight: bold\">return</span> json<span style=\"color: #333333\">.</span>loads(text)\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">json_cr_file_2_array</span>(path):\n  ary <span style=\"color: #333333\">=</span> []\n  f <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">open</span>(path)\n  <span style=\"color: #008800; font-weight: bold\">for</span> line <span style=\"color: #000000; font-weight: bold\">in</span> f:\n    record <span style=\"color: #333333\">=</span> json<span style=\"color: #333333\">.</span>loads(line<span style=\"color: #333333\">.</span>rstrip(<span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\n</span><span style=\"background-color: #fff0f0\">|</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\r</span><span style=\"background-color: #fff0f0\">\"</span>))\n    ary<span style=\"color: #333333\">.</span>append(record)\n  <span style=\"color: #008800; font-weight: bold\">return</span> ary\n\nparser <span style=\"color: #333333\">=</span> argparse<span style=\"color: #333333\">.</span>ArgumentParser(description<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">'This is a script to turn JSON to TSV with a header row.'</span>)\nparser<span style=\"color: #333333\">.</span>add_argument(<span style=\"background-color: #fff0f0\">'-f'</span>,<span style=\"background-color: #fff0f0\">'--file'</span>, help<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"File to convert.\"</span>, required<span style=\"color: #333333\">=</span><span style=\"color: #007020\">True</span>)\nparser<span style=\"color: #333333\">.</span>add_argument(<span style=\"background-color: #fff0f0\">'-j'</span>,<span style=\"background-color: #fff0f0\">'--json'</span>, help<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"Read the entire file as a json array.\"</span>, required<span style=\"color: #333333\">=</span><span style=\"color: #007020\">False</span>, action<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"store_true\"</span>)\nargs <span style=\"color: #333333\">=</span> parser<span style=\"color: #333333\">.</span>parse_args()\n\ndata <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">None</span>\n<span style=\"color: #008800; font-weight: bold\">if</span> args<span style=\"color: #333333\">.</span>json:\n  data <span style=\"color: #333333\">=</span> json_file_2_array(args<span style=\"color: #333333\">.</span>file)\n<span style=\"color: #008800; font-weight: bold\">else</span>:\n  data <span style=\"color: #333333\">=</span> json_cr_file_2_array(args<span style=\"color: #333333\">.</span>file)\n\n<span style=\"color: #888888\"># Get the set of field names occurring in any records</span>\nkeyset <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">set</span>()\n<span style=\"color: #008800; font-weight: bold\">for</span> d <span style=\"color: #000000; font-weight: bold\">in</span> data:\n  keys <span style=\"color: #333333\">=</span> d<span style=\"color: #333333\">.</span>keys()\n  <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> keys:\n    keyset<span style=\"color: #333333\">.</span>add(key)\n\n<span style=\"color: #888888\"># Print header</span>\n<span style=\"color: #008800; font-weight: bold\">print</span> <span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\t</span><span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #333333\">.</span>join(keyset)\n\n<span style=\"color: #008800; font-weight: bold\">for</span> d <span style=\"color: #000000; font-weight: bold\">in</span> data:\n  row <span style=\"color: #333333\">=</span> []\n  <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> keyset:\n    key_or_empty <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">str</span>(d[key]) <span style=\"color: #008800; font-weight: bold\">if</span> key <span style=\"color: #000000; font-weight: bold\">in</span> d <span style=\"color: #008800; font-weight: bold\">else</span> <span style=\"background-color: #fff0f0\">''</span>\n    row<span style=\"color: #333333\">.</span>append(key_or_empty)\n  <span style=\"color: #008800; font-weight: bold\">print</span> <span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\t</span><span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #333333\">.</span>join(row)\n</pre></div></p>", "tree_html": ""}, "can_send_in_message": true, "id": 131593181809, "display_avatar": true, "can_reply": true, "can_like": false, "title": "json_to_tsv", "tags": ["python json tsv data"], "post_url": "http://datasyndrome.com/post/131593181809/jsontotsv", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1wZa9fn", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1445393287, "note_count": 0, "trail": [{"content": "<p><p>Below is a utility script for turning an array of json objects into Tab-Separated-Value (TSV) format. I got tired of doing this in throwaway scripts and finally wrote a utility, and I gift it unto thee!\n\n</p><pre>#!/usr/bin/env python\n\nimport sys, os, re, json, argparse\n\ndef json_file_2_array(path):\n  text = open(path).read()\n  return json.loads(text)\n\ndef json_cr_file_2_array(path):\n  ary = []\n  f = open(path)\n  for line in f:\n    record = json.loads(line.rstrip(\"\\n|\\r\"))\n    ary.append(record)\n  return ary\n\nparser = argparse.ArgumentParser(description='This is a script to turn JSON to TSV with a header row.')\nparser.add_argument('-f','--file', help=\"File to convert.\", required=True)\nparser.add_argument('-j','--json', help=\"Read the entire file as a json array.\", required=False, action=\"store_true\")\nargs = parser.parse_args()\n\ndata = None\nif args.json:\n  data = json_file_2_array(args.file)\nelse:\n  data = json_cr_file_2_array(args.file)\n\n# Get the set of field names occurring in any records\nkeyset = set()\nfor d in data:\n  keys = d.keys()\n  for key in keys:\n    keyset.add(key)\n\n# Print header\nprint \"\\t\".join(keyset)\n\nfor d in data:\n  row = []\n  for key in keyset:\n    key_or_empty = str(d[key]) if key in d else ''\n    row.append(key_or_empty)\n  print \"\\t\".join(row)\n</pre></p>", "content_raw": "<p>Below is a utility script for turning an array of json objects into Tab-Separated-Value (TSV) format. I got tired of doing this in throwaway scripts and finally wrote a utility, and I gift it unto thee!\n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #888888\">#!/usr/bin/env python</span>\n\n<span style=\"color: #008800; font-weight: bold\">import</span> <span style=\"color: #0e84b5; font-weight: bold\">sys</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">os</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">re</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">json</span><span style=\"color: #333333\">,</span> <span style=\"color: #0e84b5; font-weight: bold\">argparse</span>\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">json_file_2_array</span>(path):\n  text <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">open</span>(path)<span style=\"color: #333333\">.</span>read()\n  <span style=\"color: #008800; font-weight: bold\">return</span> json<span style=\"color: #333333\">.</span>loads(text)\n\n<span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">json_cr_file_2_array</span>(path):\n  ary <span style=\"color: #333333\">=</span> []\n  f <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">open</span>(path)\n  <span style=\"color: #008800; font-weight: bold\">for</span> line <span style=\"color: #000000; font-weight: bold\">in</span> f:\n    record <span style=\"color: #333333\">=</span> json<span style=\"color: #333333\">.</span>loads(line<span style=\"color: #333333\">.</span>rstrip(<span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\n</span><span style=\"background-color: #fff0f0\">|</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\r</span><span style=\"background-color: #fff0f0\">\"</span>))\n    ary<span style=\"color: #333333\">.</span>append(record)\n  <span style=\"color: #008800; font-weight: bold\">return</span> ary\n\nparser <span style=\"color: #333333\">=</span> argparse<span style=\"color: #333333\">.</span>ArgumentParser(description<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">'This is a script to turn JSON to TSV with a header row.'</span>)\nparser<span style=\"color: #333333\">.</span>add_argument(<span style=\"background-color: #fff0f0\">'-f'</span>,<span style=\"background-color: #fff0f0\">'--file'</span>, help<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"File to convert.\"</span>, required<span style=\"color: #333333\">=</span><span style=\"color: #007020\">True</span>)\nparser<span style=\"color: #333333\">.</span>add_argument(<span style=\"background-color: #fff0f0\">'-j'</span>,<span style=\"background-color: #fff0f0\">'--json'</span>, help<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"Read the entire file as a json array.\"</span>, required<span style=\"color: #333333\">=</span><span style=\"color: #007020\">False</span>, action<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">\"store_true\"</span>)\nargs <span style=\"color: #333333\">=</span> parser<span style=\"color: #333333\">.</span>parse_args()\n\ndata <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">None</span>\n<span style=\"color: #008800; font-weight: bold\">if</span> args<span style=\"color: #333333\">.</span>json:\n  data <span style=\"color: #333333\">=</span> json_file_2_array(args<span style=\"color: #333333\">.</span>file)\n<span style=\"color: #008800; font-weight: bold\">else</span>:\n  data <span style=\"color: #333333\">=</span> json_cr_file_2_array(args<span style=\"color: #333333\">.</span>file)\n\n<span style=\"color: #888888\"># Get the set of field names occurring in any records</span>\nkeyset <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">set</span>()\n<span style=\"color: #008800; font-weight: bold\">for</span> d <span style=\"color: #000000; font-weight: bold\">in</span> data:\n  keys <span style=\"color: #333333\">=</span> d<span style=\"color: #333333\">.</span>keys()\n  <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> keys:\n    keyset<span style=\"color: #333333\">.</span>add(key)\n\n<span style=\"color: #888888\"># Print header</span>\n<span style=\"color: #008800; font-weight: bold\">print</span> <span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\t</span><span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #333333\">.</span>join(keyset)\n\n<span style=\"color: #008800; font-weight: bold\">for</span> d <span style=\"color: #000000; font-weight: bold\">in</span> data:\n  row <span style=\"color: #333333\">=</span> []\n  <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> keyset:\n    key_or_empty <span style=\"color: #333333\">=</span> <span style=\"color: #007020\">str</span>(d[key]) <span style=\"color: #008800; font-weight: bold\">if</span> key <span style=\"color: #000000; font-weight: bold\">in</span> d <span style=\"color: #008800; font-weight: bold\">else</span> <span style=\"background-color: #fff0f0\">''</span>\n    row<span style=\"color: #333333\">.</span>append(key_or_empty)\n  <span style=\"color: #008800; font-weight: bold\">print</span> <span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #666666; font-weight: bold; background-color: #fff0f0\">\\t</span><span style=\"background-color: #fff0f0\">\"</span><span style=\"color: #333333\">.</span>join(row)\n</pre></div></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "131593181809"}}], "date": "2015-10-21 02:08:07 GMT", "slug": "jsontotsv", "blog_name": "rjurney", "summary": "json_to_tsv", "can_reblog": true}, {"body": "<pre style=\"color:#000000;background:#ffffff;\"><span style=\"color:#696969; \"># What I really want to see is... un-reciprocal links. Lots of to/not a lot of to back &amp; vice versa</span>\nto_from_ratios <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">]</span>\n<span style=\"color:#800000; font-weight:bold; \">for</span> key<span style=\"color:#808030; \">,</span> group <span style=\"color:#800000; font-weight:bold; \">in</span> groupby<span style=\"color:#808030; \">(</span>relative_links<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> <span style=\"color:#808030; \">(</span>x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\n    <span style=\"color:#800000; font-weight:bold; \">for</span> key2<span style=\"color:#808030; \">,</span> group2 <span style=\"color:#800000; font-weight:bold; \">in</span> groupby<span style=\"color:#808030; \">(</span>relative_links<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> <span style=\"color:#808030; \">(</span>x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\n        <span style=\"color:#800000; font-weight:bold; \">if</span> key <span style=\"color:#44aadd; \">==</span> key2<span style=\"color:#808030; \">:</span>\n            to_from_ratios<span style=\"color:#808030; \">.</span>append<span style=\"color:#808030; \">(</span><span style=\"color:#808030; \">(</span>key<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">1</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> <span style=\"color:#400000; \">list</span><span style=\"color:#808030; \">(</span>group<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">3</span><span style=\"color:#808030; \">]</span><span style=\"color:#44aadd; \">/</span><span style=\"color:#400000; \">list</span><span style=\"color:#808030; \">(</span>group2<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">3</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\n\nsorted_to_from_ratios <span style=\"color:#808030; \">=</span> <span style=\"color:#400000; \">sorted</span><span style=\"color:#808030; \">(</span>to_from_ratios<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span> <span style=\"color:#44aadd; \">*</span> <span style=\"color:#44aadd; \">-</span><span style=\"color:#008c00; \">1</span><span style=\"color:#808030; \">)</span>\n<span style=\"color:#800000; font-weight:bold; \">print</span> Table<span style=\"color:#808030; \">(</span><span style=\"color:#808030; \">[</span><span style=\"color:#0000e6; \">\"From\"</span><span style=\"color:#808030; \">,</span> <span style=\"color:#0000e6; \">\"To\"</span><span style=\"color:#808030; \">,</span> <span style=\"color:#0000e6; \">\"Ratio\"</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span>sorted_to_from_ratios<span style=\"color:#808030; \">)</span>\n</pre>", "liked": false, "followed": false, "reblog_key": "6exLC7Wr", "reblog": {"comment": "<p><pre style=\"color:#000000;background:#ffffff;\"><span style=\"color:#696969; \"># What I really want to see is... un-reciprocal links. Lots of to/not a lot of to back & vice versa</span>\nto_from_ratios <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">]</span>\n<span style=\"color:#800000; font-weight:bold; \">for</span> key<span style=\"color:#808030; \">,</span> group <span style=\"color:#800000; font-weight:bold; \">in</span> groupby<span style=\"color:#808030; \">(</span>relative_links<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> <span style=\"color:#808030; \">(</span>x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\n    <span style=\"color:#800000; font-weight:bold; \">for</span> key2<span style=\"color:#808030; \">,</span> group2 <span style=\"color:#800000; font-weight:bold; \">in</span> groupby<span style=\"color:#808030; \">(</span>relative_links<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> <span style=\"color:#808030; \">(</span>x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\n        <span style=\"color:#800000; font-weight:bold; \">if</span> key <span style=\"color:#44aadd; \">==</span> key2<span style=\"color:#808030; \">:</span>\n            to_from_ratios<span style=\"color:#808030; \">.</span>append<span style=\"color:#808030; \">(</span><span style=\"color:#808030; \">(</span>key<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">1</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> <span style=\"color:#400000; \">list</span><span style=\"color:#808030; \">(</span>group<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">3</span><span style=\"color:#808030; \">]</span><span style=\"color:#44aadd; \">/</span><span style=\"color:#400000; \">list</span><span style=\"color:#808030; \">(</span>group2<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">3</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\n\nsorted_to_from_ratios <span style=\"color:#808030; \">=</span> <span style=\"color:#400000; \">sorted</span><span style=\"color:#808030; \">(</span>to_from_ratios<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span> <span style=\"color:#44aadd; \">*</span> <span style=\"color:#44aadd; \">-</span><span style=\"color:#008c00; \">1</span><span style=\"color:#808030; \">)</span>\n<span style=\"color:#800000; font-weight:bold; \">print</span> Table<span style=\"color:#808030; \">(</span><span style=\"color:#808030; \">[</span><span style=\"color:#0000e6; \">\"From\"</span><span style=\"color:#808030; \">,</span> <span style=\"color:#0000e6; \">\"To\"</span><span style=\"color:#808030; \">,</span> <span style=\"color:#0000e6; \">\"Ratio\"</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span>sorted_to_from_ratios<span style=\"color:#808030; \">)</span>\n</pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 124870757299, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Using groupby and PrettyTable in Python", "tags": [], "post_url": "http://datasyndrome.com/post/124870757299/using-groupby-and-prettytable-in-python", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1qIu8kp", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1437692155, "note_count": 0, "trail": [{"content": "<p><pre># What I really want to see is... un-reciprocal links. Lots of to/not a lot of to back &amp; vice versa\nto_from_ratios = []\nfor key, group in groupby(relative_links, key=lambda x: (x[0], x[2])):\n    for key2, group2 in groupby(relative_links, key=lambda x: (x[2], x[0])):\n        if key == key2:\n            to_from_ratios.append((key[0], key[1], list(group)[0][3]/list(group2)[0][3]))\n\nsorted_to_from_ratios = sorted(to_from_ratios, key=lambda x: x[2] * -1)\nprint Table([\"From\", \"To\", \"Ratio\"],sorted_to_from_ratios)\n</pre></p>", "content_raw": "<p><pre style=\"color:#000000;background:#ffffff;\"><span style=\"color:#696969; \"># What I really want to see is... un-reciprocal links. Lots of to/not a lot of to back & vice versa</span>\nto_from_ratios <span style=\"color:#808030; \">=</span> <span style=\"color:#808030; \">[</span><span style=\"color:#808030; \">]</span>\n<span style=\"color:#800000; font-weight:bold; \">for</span> key<span style=\"color:#808030; \">,</span> group <span style=\"color:#800000; font-weight:bold; \">in</span> groupby<span style=\"color:#808030; \">(</span>relative_links<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> <span style=\"color:#808030; \">(</span>x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\n    <span style=\"color:#800000; font-weight:bold; \">for</span> key2<span style=\"color:#808030; \">,</span> group2 <span style=\"color:#800000; font-weight:bold; \">in</span> groupby<span style=\"color:#808030; \">(</span>relative_links<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> <span style=\"color:#808030; \">(</span>x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">:</span>\n        <span style=\"color:#800000; font-weight:bold; \">if</span> key <span style=\"color:#44aadd; \">==</span> key2<span style=\"color:#808030; \">:</span>\n            to_from_ratios<span style=\"color:#808030; \">.</span>append<span style=\"color:#808030; \">(</span><span style=\"color:#808030; \">(</span>key<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">1</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span> <span style=\"color:#400000; \">list</span><span style=\"color:#808030; \">(</span>group<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">3</span><span style=\"color:#808030; \">]</span><span style=\"color:#44aadd; \">/</span><span style=\"color:#400000; \">list</span><span style=\"color:#808030; \">(</span>group2<span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">0</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">3</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">)</span><span style=\"color:#808030; \">)</span>\n\nsorted_to_from_ratios <span style=\"color:#808030; \">=</span> <span style=\"color:#400000; \">sorted</span><span style=\"color:#808030; \">(</span>to_from_ratios<span style=\"color:#808030; \">,</span> key<span style=\"color:#808030; \">=</span><span style=\"color:#800000; font-weight:bold; \">lambda</span> x<span style=\"color:#808030; \">:</span> x<span style=\"color:#808030; \">[</span><span style=\"color:#008c00; \">2</span><span style=\"color:#808030; \">]</span> <span style=\"color:#44aadd; \">*</span> <span style=\"color:#44aadd; \">-</span><span style=\"color:#008c00; \">1</span><span style=\"color:#808030; \">)</span>\n<span style=\"color:#800000; font-weight:bold; \">print</span> Table<span style=\"color:#808030; \">(</span><span style=\"color:#808030; \">[</span><span style=\"color:#0000e6; \">\"From\"</span><span style=\"color:#808030; \">,</span> <span style=\"color:#0000e6; \">\"To\"</span><span style=\"color:#808030; \">,</span> <span style=\"color:#0000e6; \">\"Ratio\"</span><span style=\"color:#808030; \">]</span><span style=\"color:#808030; \">,</span>sorted_to_from_ratios<span style=\"color:#808030; \">)</span>\n</pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "124870757299"}}], "date": "2015-07-23 22:55:55 GMT", "slug": "using-groupby-and-prettytable-in-python", "blog_name": "rjurney", "summary": "Using groupby and PrettyTable in Python", "can_reblog": true}, {"body": "One-liner pretty tables in Python: print Table([&ldquo;Column 1&rdquo;,&ldquo;Column 2&rdquo;, &hellip;],[[&ldquo;Row 1&rdquo;, 1.0, &hellip;],&hellip;]) \n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><table><tr><td><pre style=\"margin: 0; line-height: 125%\"> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22</pre></td><td><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #008800; font-weight: bold\">from</span> <span style=\"color: #0e84b5; font-weight: bold\">prettytable</span> <span style=\"color: #008800; font-weight: bold\">import</span> PrettyTable\n\n<span style=\"color: #008800; font-weight: bold\">class</span> <span style=\"color: #BB0066; font-weight: bold\">Table</span>:\n  <span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">__init__</span>(<span style=\"color: #007020\">self</span>, columns, data):\n    <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #000000; font-weight: bold\">not</span> <span style=\"color: #007020\">len</span>(columns):\n      <span style=\"color: #008800; font-weight: bold\">raise</span> <span style=\"background-color: #fff0f0\">\"Table must have at least one column\"</span>\n    <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #000000; font-weight: bold\">not</span> <span style=\"color: #007020\">len</span>(data):\n      <span style=\"color: #008800; font-weight: bold\">raise</span> <span style=\"background-color: #fff0f0\">\"Table must have at least one row\"</span>\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_columns <span style=\"color: #333333\">=</span> columns\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_data <span style=\"color: #333333\">=</span> data    \n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p <span style=\"color: #333333\">=</span> PrettyTable(<span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_columns)\n    \n    <span style=\"color: #008800; font-weight: bold\">for</span> row <span style=\"color: #000000; font-weight: bold\">in</span> data:\n      <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>add_row(row)\n  \n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>padding_width <span style=\"color: #333333\">=</span> <span style=\"color: #0000DD; font-weight: bold\">1</span>\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>float_format<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">'.2f'</span>\n    <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>align<span style=\"color: #333333\">.</span>keys():\n      <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>align[key] <span style=\"color: #333333\">=</span> <span style=\"background-color: #fff0f0\">'r'</span>\n  \n  <span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">__str__</span>(<span style=\"color: #007020\">self</span>):\n    <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">str</span>(<span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p)\n</pre></td></tr></table></div>", "liked": false, "followed": false, "reblog_key": "04iiJkU8", "reblog": {"comment": "<p>One-liner pretty tables in Python: print Table([\u201cColumn 1\u201d,\u201cColumn 2\u201d, \u2026],[[\u201cRow 1\u201d, 1.0, \u2026],\u2026]) \n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><table><tr><td><pre style=\"margin: 0; line-height: 125%\"> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22</pre></td><td><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #008800; font-weight: bold\">from</span> <span style=\"color: #0e84b5; font-weight: bold\">prettytable</span> <span style=\"color: #008800; font-weight: bold\">import</span> PrettyTable\n\n<span style=\"color: #008800; font-weight: bold\">class</span> <span style=\"color: #BB0066; font-weight: bold\">Table</span>:\n  <span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">__init__</span>(<span style=\"color: #007020\">self</span>, columns, data):\n    <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #000000; font-weight: bold\">not</span> <span style=\"color: #007020\">len</span>(columns):\n      <span style=\"color: #008800; font-weight: bold\">raise</span> <span style=\"background-color: #fff0f0\">\"Table must have at least one column\"</span>\n    <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #000000; font-weight: bold\">not</span> <span style=\"color: #007020\">len</span>(data):\n      <span style=\"color: #008800; font-weight: bold\">raise</span> <span style=\"background-color: #fff0f0\">\"Table must have at least one row\"</span>\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_columns <span style=\"color: #333333\">=</span> columns\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_data <span style=\"color: #333333\">=</span> data    \n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p <span style=\"color: #333333\">=</span> PrettyTable(<span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_columns)\n    \n    <span style=\"color: #008800; font-weight: bold\">for</span> row <span style=\"color: #000000; font-weight: bold\">in</span> data:\n      <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>add_row(row)\n  \n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>padding_width <span style=\"color: #333333\">=</span> <span style=\"color: #0000DD; font-weight: bold\">1</span>\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>float_format<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">'.2f'</span>\n    <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>align<span style=\"color: #333333\">.</span>keys():\n      <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>align[key] <span style=\"color: #333333\">=</span> <span style=\"background-color: #fff0f0\">'r'</span>\n  \n  <span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">__str__</span>(<span style=\"color: #007020\">self</span>):\n    <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">str</span>(<span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p)\n</pre></td></tr></table></div></p>", "tree_html": ""}, "can_send_in_message": true, "id": 124803464429, "display_avatar": true, "can_reply": true, "can_like": false, "title": "One-Liner PrettyTables in Python", "tags": [], "post_url": "http://datasyndrome.com/post/124803464429/one-liner-prettytables-in-python", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1qEtRpj", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1437621421, "note_count": 0, "trail": [{"content": "<p>One-liner pretty tables in Python: print Table([&ldquo;Column 1&rdquo;,&ldquo;Column 2&rdquo;, &hellip;],[[&ldquo;Row 1&rdquo;, 1.0, &hellip;],&hellip;]) \n\n</p><p><a href=\"#\"><img src=\"http://assets.tumblr.com/images/inline_placeholder.png\" width=\"18\" height=\"14\"/></a></p>", "content_raw": "<p>One-liner pretty tables in Python: print Table([\u201cColumn 1\u201d,\u201cColumn 2\u201d, \u2026],[[\u201cRow 1\u201d, 1.0, \u2026],\u2026]) \n\n<!-- HTML generated using hilite.me --><div style=\"background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;\"><table><tr><td><pre style=\"margin: 0; line-height: 125%\"> 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22</pre></td><td><pre style=\"margin: 0; line-height: 125%\"><span style=\"color: #008800; font-weight: bold\">from</span> <span style=\"color: #0e84b5; font-weight: bold\">prettytable</span> <span style=\"color: #008800; font-weight: bold\">import</span> PrettyTable\n\n<span style=\"color: #008800; font-weight: bold\">class</span> <span style=\"color: #BB0066; font-weight: bold\">Table</span>:\n  <span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">__init__</span>(<span style=\"color: #007020\">self</span>, columns, data):\n    <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #000000; font-weight: bold\">not</span> <span style=\"color: #007020\">len</span>(columns):\n      <span style=\"color: #008800; font-weight: bold\">raise</span> <span style=\"background-color: #fff0f0\">\"Table must have at least one column\"</span>\n    <span style=\"color: #008800; font-weight: bold\">if</span> <span style=\"color: #000000; font-weight: bold\">not</span> <span style=\"color: #007020\">len</span>(data):\n      <span style=\"color: #008800; font-weight: bold\">raise</span> <span style=\"background-color: #fff0f0\">\"Table must have at least one row\"</span>\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_columns <span style=\"color: #333333\">=</span> columns\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_data <span style=\"color: #333333\">=</span> data    \n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p <span style=\"color: #333333\">=</span> PrettyTable(<span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_columns)\n    \n    <span style=\"color: #008800; font-weight: bold\">for</span> row <span style=\"color: #000000; font-weight: bold\">in</span> data:\n      <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>add_row(row)\n  \n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>padding_width <span style=\"color: #333333\">=</span> <span style=\"color: #0000DD; font-weight: bold\">1</span>\n    <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>float_format<span style=\"color: #333333\">=</span><span style=\"background-color: #fff0f0\">'.2f'</span>\n    <span style=\"color: #008800; font-weight: bold\">for</span> key <span style=\"color: #000000; font-weight: bold\">in</span> <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>align<span style=\"color: #333333\">.</span>keys():\n      <span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p<span style=\"color: #333333\">.</span>align[key] <span style=\"color: #333333\">=</span> <span style=\"background-color: #fff0f0\">'r'</span>\n  \n  <span style=\"color: #008800; font-weight: bold\">def</span> <span style=\"color: #0066BB; font-weight: bold\">__str__</span>(<span style=\"color: #007020\">self</span>):\n    <span style=\"color: #008800; font-weight: bold\">return</span> <span style=\"color: #007020\">str</span>(<span style=\"color: #007020\">self</span><span style=\"color: #333333\">.</span>_p)\n</pre></td></tr></table></div></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "124803464429"}}], "date": "2015-07-23 03:17:01 GMT", "slug": "one-liner-prettytables-in-python", "blog_name": "rjurney", "summary": "One-Liner PrettyTables in Python", "can_reblog": true}, {"body": "<img src=\"https://s3.amazonaws.com/relato.public/Atlanta_Security_Cluster.png\" width=\"600px\"/><p align=\"justify\">Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I&rsquo;m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p align=\"justify\">The map shows the degree to which apprenticeship is essential to the growth of markets. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p align=\"justify\">And I wonder&hellip; what has happened between 2010 and 2015? Has the network grown? Is the network effect still happening?</p>\n    \n    <p align=\"justify\">Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I&rsquo;m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p align=\"justify\">The map shows the degree to which apprenticeship is essential to the growth of startup clusters. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p align=\"justify\">And I wonder&hellip; what has happened between 2010 and 2015? Has the network grown? Is the network effect still working?</p>\n    \n    <p align=\"justify\">So, <b>I&rsquo;m calling on you to find out!</b> I created a <a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Google Form</a> to collect the latest data. Please enter new startups that are offshoots of any of the companies in the 2010 map.</p>\n    \n    <p align=\"justify\"><a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Checkout the Google Form!</a></p>", "liked": false, "followed": false, "reblog_key": "uywWhg9c", "reblog": {"comment": "<p><img src=\"https://s3.amazonaws.com/relato.public/Atlanta_Security_Cluster.png\" width=\"600px\"><p align=\"justify\">Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I\u2019m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p align=\"justify\">The map shows the degree to which apprenticeship is essential to the growth of markets. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p align=\"justify\">And I wonder\u2026 what has happened between 2010 and 2015? Has the network grown? Is the network effect still happening?</p>\n    \n    <p align=\"justify\">Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I\u2019m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p align=\"justify\">The map shows the degree to which apprenticeship is essential to the growth of startup clusters. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p align=\"justify\">And I wonder\u2026 what has happened between 2010 and 2015? Has the network grown? Is the network effect still working?</p>\n    \n    <p align=\"justify\">So, <b>I\u2019m calling on you to find out!</b> I created a <a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Google Form</a> to collect the latest data. Please enter new startups that are offshoots of any of the companies in the 2010 map.</p>\n    \n    <p align=\"justify\"><a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Checkout the Google Form!</a></p></p>", "tree_html": ""}, "can_send_in_message": true, "id": 119922486144, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Atlanta Security Ecosystem Revisited: 2015 Update", "tags": [], "post_url": "http://datasyndrome.com/post/119922486144/atlanta-security-ecosystem-revisited-2015-update", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1lhx_k0", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1432625520, "note_count": 3, "trail": [{"content": "<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/relato.public/Atlanta_Security_Cluster.png\">External image</div></p><p>Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I&rsquo;m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p>The map shows the degree to which apprenticeship is essential to the growth of markets. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p>And I wonder&hellip; what has happened between 2010 and 2015? Has the network grown? Is the network effect still happening?</p>\n    \n    <p>Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I&rsquo;m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p>The map shows the degree to which apprenticeship is essential to the growth of startup clusters. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p>And I wonder&hellip; what has happened between 2010 and 2015? Has the network grown? Is the network effect still working?</p>\n    \n    <p>So, <b>I&rsquo;m calling on you to find out!</b> I created a <a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Google Form</a> to collect the latest data. Please enter new startups that are offshoots of any of the companies in the 2010 map.</p>\n    \n    <p><a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Checkout the Google Form!</a></p>", "content_raw": "<p><img src=\"https://s3.amazonaws.com/relato.public/Atlanta_Security_Cluster.png\" width=\"600px\"><p align=\"justify\">Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I\u2019m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p align=\"justify\">The map shows the degree to which apprenticeship is essential to the growth of markets. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p align=\"justify\">And I wonder\u2026 what has happened between 2010 and 2015? Has the network grown? Is the network effect still happening?</p>\n    \n    <p align=\"justify\">Back in 2010 - with help from the startup community in Atlanta - I created a social network representation of the security startup cluster in Atlanta. Nowadays I\u2019m <a href=\"http://www.relato.io/\">working on</a> networks in the economy full time, so this map has been on my mind.</p>\n    \n    <p align=\"justify\">The map shows the degree to which apprenticeship is essential to the growth of startup clusters. The best way to be a successful founder is to work for a hot startup, make your seed money from stock options, and start you own company with coworkers as founders. Then hire more former coworkers.</p>\n    \n    <p align=\"justify\">And I wonder\u2026 what has happened between 2010 and 2015? Has the network grown? Is the network effect still working?</p>\n    \n    <p align=\"justify\">So, <b>I\u2019m calling on you to find out!</b> I created a <a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Google Form</a> to collect the latest data. Please enter new startups that are offshoots of any of the companies in the 2010 map.</p>\n    \n    <p align=\"justify\"><a href=\"https://docs.google.com/forms/d/1DTYhILyuSBhwZetMI_9PI-x39q4hEVvC6DE2D3z0lb8/viewform?usp=send_form\">Checkout the Google Form!</a></p></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "119922486144"}}], "date": "2015-05-26 07:32:00 GMT", "slug": "atlanta-security-ecosystem-revisited-2015-update", "blog_name": "rjurney", "summary": "Atlanta Security Ecosystem Revisited: 2015 Update", "can_reblog": true}, {"body": "<style>\n    blockquote {\n        font: 14px/22px normal helvetica, sans-serif;\n        margin-top: 10px;\n        margin-bottom: 10px;\n        margin-left: 50px;\n        padding-left: 15px;\n        border-left: 3px solid #ccc;\n    } \n  \t</style><center><a href=\"https://s3.amazonaws.com/relato.public/Atlanta_Security_Cluster.png\"><img src=\"https://s3.amazonaws.com/relato.public/atlanta_security_cluster_700.png\" width=\"600px\" align=\"top\"/></a></center>\n\n\t<h1>The Networked Economy</h1>\n\n\t<p>In this post we&rsquo;ll survey some adventures in networks, starting with startup ecosystems and ending in network-driven marketing.</p>\n\n\t<h2>Networks of Success</h2>\n\n    <p>Above is a map of the security sector of the startup ecosystem in Atlanta as of 2010. Each node (circle) is a company. Each link between nodes represents a founder who worked at the originating company and went on to found the destination company. If you look, Internet Security Systems (ISS) and SecureIT (which sold the Internet Scanner by ISS) spawned most of the other companies in the cluster.</p>\n    \n    <p>This simple chart illustrates the network-centric process underlying the emergence of startup ecosystems. Groups of companies emerge together via &lsquo;Networks of Success,&rsquo; groups of individuals who work together and develop an abundance of skills, social capital and cash.</p>\n    \n    <p>This network is similar to others that are better known, like the Fairchildren or the PayPal Mafia:</p>\n    \n    <center>\n      <a style=\"margin: 10px;\" href=\"https://s3.amazonaws.com/relato.public/paypal_mafia.jpg\"><img src=\"https://s3.amazonaws.com/relato.public/paypal_mafia_icon.gif\" width=\"200px\"/></a>\n      <a style=\"margin: 10px;\" href=\"https://s3.amazonaws.com/relato.public/fairchildren.jpg\"><img src=\"https://s3.amazonaws.com/relato.public/fairchildren_400.png\" width=\"400px\"/></a>\n    </center>\n    \n    <p>This was my first social network research, a domain typically limited to social scientists and PhD candidates. When I say <i>social network</i>, I don&rsquo;t mean Facebook, I mean <i>social network</i> as in <a href=\"http://en.wikipedia.org/wiki/Social_network_analysis\">Social Network Analysis</a>:</p>\n    \n    <blockquote>Social network analysis (SNA) is a strategy for investigating social structures through the use of network and graph theories. It characterizes networked structures in terms of nodes (individual actors, people, or things within the network) and the ties or edges (relationships or interactions) that connect them.</blockquote>\n    \n    <p>The Atlanta startup map shows the importance of apprenticeship in building startups and ecosystems. Participating in a solid IPO is equivalent to seed funding for every early employee. This is what is missing from startup ecosystems in provincial places\u2026 collectively, there isn\u2019t enough success and capital for the employees of successful companies to have enough skills and capital to start their own ventures.</p>\n    \n    <p>Once that tipping point occurs, though, where startups beget startups, startup ecosystems self-sustain. They grow on their own. Older generations of entrepreneurs invest in and mentor younger entrepreneurs, with each cohort becoming increasingly wealthy and well connected. Atlanta has a cycle of wealth occurring in the security sector, making it a great place to start a security company.</p>\n    \n    <p>My hope with this map was to affect policy - to encourage the state to redirect stimulus money towards economic clusters that <b>work</b> as this one does. This remains a hope.</p>\n        \n    <p>In any case&hellip; thats a lot to learn from a simple map, but thats the kind of insight collecting and analyzing social networks can provide.</p>\n    \n    <h2>Inbox Networks</h2>\n    \n    <img src=\"https://s3.amazonaws.com/relato.public/russell_jurney_inbox.png\" width=\"600px\"/>\n    \n    After discovering the Enron dataset, I set my eyes on email: extracting clusters of networks of people and their relationships. \n    \n    <br/><img src=\"https://s3.amazonaws.com/relato.public/union_inboxes.png\" width=\"600px\"/>", "liked": false, "followed": false, "reblog_key": "An8mqarJ", "reblog": {"comment": "<p><style>\n    blockquote {\n        font: 14px/22px normal helvetica, sans-serif;\n        margin-top: 10px;\n        margin-bottom: 10px;\n        margin-left: 50px;\n        padding-left: 15px;\n        border-left: 3px solid #ccc;\n    } \n  \t</style><center><a href=\"https://s3.amazonaws.com/relato.public/Atlanta_Security_Cluster.png\"><img src=\"https://s3.amazonaws.com/relato.public/atlanta_security_cluster_700.png\" width=\"600px\" align=\"top\"></a></center>\n\n\t<h1>The Networked Economy</h1>\n\n\t<p>In this post we\u2019ll survey some adventures in networks, starting with startup ecosystems and ending in network-driven marketing.</p>\n\n\t<h2>Networks of Success</h2>\n\n    <p>Above is a map of the security sector of the startup ecosystem in Atlanta as of 2010. Each node (circle) is a company. Each link between nodes represents a founder who worked at the originating company and went on to found the destination company. If you look, Internet Security Systems (ISS) and SecureIT (which sold the Internet Scanner by ISS) spawned most of the other companies in the cluster.</p>\n    \n    <p>This simple chart illustrates the network-centric process underlying the emergence of startup ecosystems. Groups of companies emerge together via \u2018Networks of Success,\u2019 groups of individuals who work together and develop an abundance of skills, social capital and cash.</p>\n    \n    <p>This network is similar to others that are better known, like the Fairchildren or the PayPal Mafia:</p>\n    \n    <center>\n      <a style=\"margin: 10px;\" href=\"https://s3.amazonaws.com/relato.public/paypal_mafia.jpg\"><img src=\"https://s3.amazonaws.com/relato.public/paypal_mafia_icon.gif\" width=\"200px\"></a>\n      <a style=\"margin: 10px;\" href=\"https://s3.amazonaws.com/relato.public/fairchildren.jpg\"><img src=\"https://s3.amazonaws.com/relato.public/fairchildren_400.png\" width=\"400px\"></a>\n    </center>\n    \n    <p>This was my first social network research, a domain typically limited to social scientists and PhD candidates. When I say <i>social network</i>, I don\u2019t mean Facebook, I mean <i>social network</i> as in <a href=\"http://en.wikipedia.org/wiki/Social_network_analysis\">Social Network Analysis</a>:</p>\n    \n    <blockquote>Social network analysis (SNA) is a strategy for investigating social structures through the use of network and graph theories. It characterizes networked structures in terms of nodes (individual actors, people, or things within the network) and the ties or edges (relationships or interactions) that connect them.</blockquote>\n    \n    <p>The Atlanta startup map shows the importance of apprenticeship in building startups and ecosystems. Participating in a solid IPO is equivalent to seed funding for every early employee. This is what is missing from startup ecosystems in provincial places\u2026 collectively, there isn\u2019t enough success and capital for the employees of successful companies to have enough skills and capital to start their own ventures.</p>\n    \n    <p>Once that tipping point occurs, though, where startups beget startups, startup ecosystems self-sustain. They grow on their own. Older generations of entrepreneurs invest in and mentor younger entrepreneurs, with each cohort becoming increasingly wealthy and well connected. Atlanta has a cycle of wealth occurring in the security sector, making it a great place to start a security company.</p>\n    \n    <p>My hope with this map was to affect policy - to encourage the state to redirect stimulus money towards economic clusters that <b>work</b> as this one does. This remains a hope.</p>\n        \n    <p>In any case\u2026 thats a lot to learn from a simple map, but thats the kind of insight collecting and analyzing social networks can provide.</p>\n    \n    <h2>Inbox Networks</h2>\n    \n    <img src=\"https://s3.amazonaws.com/relato.public/russell_jurney_inbox.png\" width=\"600px\">\n    \n    After discovering the Enron dataset, I set my eyes on email: extracting clusters of networks of people and their relationships. \n    \n    <br><img src=\"https://s3.amazonaws.com/relato.public/union_inboxes.png\" width=\"600px\"></p>", "tree_html": ""}, "can_send_in_message": false, "id": 118815783544, "display_avatar": true, "can_reply": true, "can_like": false, "title": null, "tags": [], "post_url": "http://datasyndrome.com/post/118815783544/blockquote-font-14px22px-normal", "recommended_source": null, "state": "private", "short_url": "https://tmblr.co/ZbIO5y1kf_Ffu", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1431471671, "note_count": 0, "trail": [{"content": "<p><p>\n    blockquote {\n        font: 14px/22px normal helvetica, sans-serif;\n        margin-top: 10px;\n        margin-bottom: 10px;\n        margin-left: 50px;\n        padding-left: 15px;\n        border-left: 3px solid #ccc;\n    } \n  \t</p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/relato.public/atlanta_security_cluster_700.png\">External image</div>\n\n\t<h1>The Networked Economy</h1>\n\n\t<p>In this post we&rsquo;ll survey some adventures in networks, starting with startup ecosystems and ending in network-driven marketing.</p>\n\n\t<h2>Networks of Success</h2>\n\n    <p>Above is a map of the security sector of the startup ecosystem in Atlanta as of 2010. Each node (circle) is a company. Each link between nodes represents a founder who worked at the originating company and went on to found the destination company. If you look, Internet Security Systems (ISS) and SecureIT (which sold the Internet Scanner by ISS) spawned most of the other companies in the cluster.</p>\n    \n    <p>This simple chart illustrates the network-centric process underlying the emergence of startup ecosystems. Groups of companies emerge together via &lsquo;Networks of Success,&rsquo; groups of individuals who work together and develop an abundance of skills, social capital and cash.</p>\n    \n    <p>This network is similar to others that are better known, like the Fairchildren or the PayPal Mafia:</p>\n    \n    \n      <div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/relato.public/paypal_mafia_icon.gif\">External image</div>\n      <div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/relato.public/fairchildren_400.png\">External image</div>\n    \n    \n    <p>This was my first social network research, a domain typically limited to social scientists and PhD candidates. When I say <i>social network</i>, I don&rsquo;t mean Facebook, I mean <i>social network</i> as in <a href=\"http://en.wikipedia.org/wiki/Social_network_analysis\">Social Network Analysis</a>:</p>\n    \n    <blockquote><p>Social network analysis (SNA) is a strategy for investigating social structures through the use of network and graph theories. It characterizes networked structures in terms of nodes (individual actors, people, or things within the network) and the ties or edges (relationships or interactions) that connect them.</p></blockquote>\n    \n    <p>The Atlanta startup map shows the importance of apprenticeship in building startups and ecosystems. Participating in a solid IPO is equivalent to seed funding for every early employee. This is what is missing from startup ecosystems in provincial places&hellip; collectively, there isn&rsquo;t enough success and capital for the employees of successful companies to have enough skills and capital to start their own ventures.</p>\n    \n    <p>Once that tipping point occurs, though, where startups beget startups, startup ecosystems self-sustain. They grow on their own. Older generations of entrepreneurs invest in and mentor younger entrepreneurs, with each cohort becoming increasingly wealthy and well connected. Atlanta has a cycle of wealth occurring in the security sector, making it a great place to start a security company.</p>\n    \n    <p>My hope with this map was to affect policy - to encourage the state to redirect stimulus money towards economic clusters that <b>work</b> as this one does. This remains a hope.</p>\n        \n    <p>In any case&hellip; thats a lot to learn from a simple map, but thats the kind of insight collecting and analyzing social networks can provide.</p>\n    \n    <h2>Inbox Networks</h2>\n    \n    <div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/relato.public/russell_jurney_inbox.png\">External image</div>\n    \n    After discovering the Enron dataset, I set my eyes on email: extracting clusters of networks of people and their relationships. \n    \n    <br /><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/relato.public/union_inboxes.png\">External image</div></p>", "content_raw": "<p><style>\n    blockquote {\n        font: 14px/22px normal helvetica, sans-serif;\n        margin-top: 10px;\n        margin-bottom: 10px;\n        margin-left: 50px;\n        padding-left: 15px;\n        border-left: 3px solid #ccc;\n    } \n  \t</style><center><a href=\"https://s3.amazonaws.com/relato.public/Atlanta_Security_Cluster.png\"><img src=\"https://s3.amazonaws.com/relato.public/atlanta_security_cluster_700.png\" width=\"600px\" align=\"top\"></a></center>\n\n\t<h1>The Networked Economy</h1>\n\n\t<p>In this post we\u2019ll survey some adventures in networks, starting with startup ecosystems and ending in network-driven marketing.</p>\n\n\t<h2>Networks of Success</h2>\n\n    <p>Above is a map of the security sector of the startup ecosystem in Atlanta as of 2010. Each node (circle) is a company. Each link between nodes represents a founder who worked at the originating company and went on to found the destination company. If you look, Internet Security Systems (ISS) and SecureIT (which sold the Internet Scanner by ISS) spawned most of the other companies in the cluster.</p>\n    \n    <p>This simple chart illustrates the network-centric process underlying the emergence of startup ecosystems. Groups of companies emerge together via \u2018Networks of Success,\u2019 groups of individuals who work together and develop an abundance of skills, social capital and cash.</p>\n    \n    <p>This network is similar to others that are better known, like the Fairchildren or the PayPal Mafia:</p>\n    \n    <center>\n      <a style=\"margin: 10px;\" href=\"https://s3.amazonaws.com/relato.public/paypal_mafia.jpg\"><img src=\"https://s3.amazonaws.com/relato.public/paypal_mafia_icon.gif\" width=\"200px\"></a>\n      <a style=\"margin: 10px;\" href=\"https://s3.amazonaws.com/relato.public/fairchildren.jpg\"><img src=\"https://s3.amazonaws.com/relato.public/fairchildren_400.png\" width=\"400px\"></a>\n    </center>\n    \n    <p>This was my first social network research, a domain typically limited to social scientists and PhD candidates. When I say <i>social network</i>, I don\u2019t mean Facebook, I mean <i>social network</i> as in <a href=\"http://en.wikipedia.org/wiki/Social_network_analysis\">Social Network Analysis</a>:</p>\n    \n    <blockquote>Social network analysis (SNA) is a strategy for investigating social structures through the use of network and graph theories. It characterizes networked structures in terms of nodes (individual actors, people, or things within the network) and the ties or edges (relationships or interactions) that connect them.</blockquote>\n    \n    <p>The Atlanta startup map shows the importance of apprenticeship in building startups and ecosystems. Participating in a solid IPO is equivalent to seed funding for every early employee. This is what is missing from startup ecosystems in provincial places\u2026 collectively, there isn\u2019t enough success and capital for the employees of successful companies to have enough skills and capital to start their own ventures.</p>\n    \n    <p>Once that tipping point occurs, though, where startups beget startups, startup ecosystems self-sustain. They grow on their own. Older generations of entrepreneurs invest in and mentor younger entrepreneurs, with each cohort becoming increasingly wealthy and well connected. Atlanta has a cycle of wealth occurring in the security sector, making it a great place to start a security company.</p>\n    \n    <p>My hope with this map was to affect policy - to encourage the state to redirect stimulus money towards economic clusters that <b>work</b> as this one does. This remains a hope.</p>\n        \n    <p>In any case\u2026 thats a lot to learn from a simple map, but thats the kind of insight collecting and analyzing social networks can provide.</p>\n    \n    <h2>Inbox Networks</h2>\n    \n    <img src=\"https://s3.amazonaws.com/relato.public/russell_jurney_inbox.png\" width=\"600px\">\n    \n    After discovering the Enron dataset, I set my eyes on email: extracting clusters of networks of people and their relationships. \n    \n    <br><img src=\"https://s3.amazonaws.com/relato.public/union_inboxes.png\" width=\"600px\"></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "118815783544"}}], "date": "2015-05-12 23:01:11 GMT", "slug": "blockquote-font-14px22px-normal", "blog_name": "rjurney", "summary": "blockquote {\n        font: 14px/22px normal helvetica, sans-serif;\n        margin-top: 10px;\n        margin-bottom: 10px;\n      ...", "can_reblog": false}, {"body": "<p>If you&rsquo;re like me, even though you code daily - you can hardly remember how to program anymore. I don&rsquo;t know the language I use daily (more than any other) - Python - very well at all. I can&rsquo;t even remember HTML, and I&rsquo;ve been writing it for 15 years.</p>\n\n<p>And yet I don&rsquo;t think I&rsquo;m a blathering idiot (for this shortcoming, anyway). Like most everyone else - I don&rsquo;t much program anymore. Rather, I piece together other people&rsquo;s code exclusively - adapting it to my needs. Put another way, my memory has become externalized. Sites like Stack Overflow, handily indexed by Google, are there to help me remember any basic operation, and many complex operations.</p>\n\n<p>The upside: I am &lsquo;fluent&rsquo; in a dozen languages. Isolated from the internet, I can&rsquo;t remember any of them, but I can code at a pretty good rate in any of them thanks to the web.</p>\n\n<p>But there&rsquo;s an artifact of this system, and its been going to waste. At the end of any program I&rsquo;m editing - when the file(s) do what I need them to do, there is a browser window with an ordered list of each problem I encountered, and the solution to it. And generally, this goes away when I close all the tabs.</p>\n\n<p>So from now on, I&rsquo;m using <a href=\"https://www.one-tab.com/\">OneTab</a>, a Chrome Plugin, to persist these tabs as comments in a README. I figure it will make the code I write self documenting.</p>", "liked": false, "followed": false, "reblog_key": "QgDGjE3J", "reblog": {"comment": "<p>If you\u2019re like me, even though you code daily - you can hardly remember how to program anymore. I don\u2019t know the language I use daily (more than any other) - Python - very well at all. I can\u2019t even remember HTML, and I\u2019ve been writing it for 15 years.</p>\n\n<p>And yet I don\u2019t think I\u2019m a blathering idiot (for this shortcoming, anyway). Like most everyone else - I don\u2019t much program anymore. Rather, I piece together other people\u2019s code exclusively - adapting it to my needs. Put another way, my memory has become externalized. Sites like Stack Overflow, handily indexed by Google, are there to help me remember any basic operation, and many complex operations.</p>\n\n<p>The upside: I am \u2018fluent\u2019 in a dozen languages. Isolated from the internet, I can\u2019t remember any of them, but I can code at a pretty good rate in any of them thanks to the web.</p>\n\n<p>But there\u2019s an artifact of this system, and its been going to waste. At the end of any program I\u2019m editing - when the file(s) do what I need them to do, there is a browser window with an ordered list of each problem I encountered, and the solution to it. And generally, this goes away when I close all the tabs.</p>\n\n<p>So from now on, I\u2019m using <a href=\"https://www.one-tab.com/\">OneTab</a>, a Chrome Plugin, to persist these tabs as comments in a README. I figure it will make the code I write self documenting.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 106761986894, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Self-Documenting Code with OneTab", "tags": [], "post_url": "http://datasyndrome.com/post/106761986894/self-documenting-code-with-onetab", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1ZRWgDE", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1420080787, "note_count": 3, "trail": [{"content": "<p>If you&rsquo;re like me, even though you code daily - you can hardly remember how to program anymore. I don&rsquo;t know the language I use daily (more than any other) - Python - very well at all. I can&rsquo;t even remember HTML, and I&rsquo;ve been writing it for 15 years.</p>\n\n<p>And yet I don&rsquo;t think I&rsquo;m a blathering idiot (for this shortcoming, anyway). Like most everyone else - I don&rsquo;t much program anymore. Rather, I piece together other people&rsquo;s code exclusively - adapting it to my needs. Put another way, my memory has become externalized. Sites like Stack Overflow, handily indexed by Google, are there to help me remember any basic operation, and many complex operations.</p>\n\n<p>The upside: I am &lsquo;fluent&rsquo; in a dozen languages. Isolated from the internet, I can&rsquo;t remember any of them, but I can code at a pretty good rate in any of them thanks to the web.</p>\n\n<p>But there&rsquo;s an artifact of this system, and its been going to waste. At the end of any program I&rsquo;m editing - when the file(s) do what I need them to do, there is a browser window with an ordered list of each problem I encountered, and the solution to it. And generally, this goes away when I close all the tabs.</p>\n\n<p>So from now on, I&rsquo;m using <a href=\"https://www.one-tab.com/\">OneTab</a>, a Chrome Plugin, to persist these tabs as comments in a README. I figure it will make the code I write self documenting.</p>", "content_raw": "<p>If you\u2019re like me, even though you code daily - you can hardly remember how to program anymore. I don\u2019t know the language I use daily (more than any other) - Python - very well at all. I can\u2019t even remember HTML, and I\u2019ve been writing it for 15 years.</p>\n\n<p>And yet I don\u2019t think I\u2019m a blathering idiot (for this shortcoming, anyway). Like most everyone else - I don\u2019t much program anymore. Rather, I piece together other people\u2019s code exclusively - adapting it to my needs. Put another way, my memory has become externalized. Sites like Stack Overflow, handily indexed by Google, are there to help me remember any basic operation, and many complex operations.</p>\n\n<p>The upside: I am \u2018fluent\u2019 in a dozen languages. Isolated from the internet, I can\u2019t remember any of them, but I can code at a pretty good rate in any of them thanks to the web.</p>\n\n<p>But there\u2019s an artifact of this system, and its been going to waste. At the end of any program I\u2019m editing - when the file(s) do what I need them to do, there is a browser window with an ordered list of each problem I encountered, and the solution to it. And generally, this goes away when I close all the tabs.</p>\n\n<p>So from now on, I\u2019m using <a href=\"https://www.one-tab.com/\">OneTab</a>, a Chrome Plugin, to persist these tabs as comments in a README. I figure it will make the code I write self documenting.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "106761986894"}}], "date": "2015-01-01 02:53:07 GMT", "slug": "self-documenting-code-with-onetab", "blog_name": "rjurney", "summary": "Self-Documenting Code with OneTab", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "eNWjLXaZ", "short_url": "https://tmblr.co/ZbIO5y1Yz2vTo", "can_send_in_message": true, "id": 106250868594, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/106250868594", "tags": [], "post_url": "http://datasyndrome.com/post/106250868594/now-seems-a-good-time-to-tell-people-that-im", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Now seems a good time to tell people that I\u2019m currently crunching on finishing my next book, <a href=\"http://shop.oreilly.com/product/0636920026372.do?sortby=bestSellers\">Big Data for Chimps</a>, with Flip Kromer of Infochimps. It will be out in the next few months. The book covers analytic design patterns in Pig :)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1419624129, "note_count": 2, "trail": [{"content": "<p>Now seems a good time to tell people that I&rsquo;m currently crunching on finishing my next book, <a href=\"http://shop.oreilly.com/product/0636920026372.do?sortby=bestSellers\">Big Data for Chimps</a>, with Flip Kromer of Infochimps. It will be out in the next few months. The book covers analytic design patterns in Pig :)</p>", "content_raw": "<p>Now seems a good time to tell people that I\u2019m currently crunching on finishing my next book, <a href=\"http://shop.oreilly.com/product/0636920026372.do?sortby=bestSellers\">Big Data for Chimps</a>, with Flip Kromer of Infochimps. It will be out in the next few months. The book covers analytic design patterns in Pig :)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "106250868594"}}], "date": "2014-12-26 20:02:09 GMT", "slug": "now-seems-a-good-time-to-tell-people-that-im", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/8b6214e18aaa9bbca91bde5ec48164de/tumblr_nh7gzlAEK41qe7pymo2_r1_1280.png", "width": 600, "height": 787}, "alt_sizes": [{"url": "https://68.media.tumblr.com/8b6214e18aaa9bbca91bde5ec48164de/tumblr_nh7gzlAEK41qe7pymo2_r1_1280.png", "width": 600, "height": 787}, {"url": "https://68.media.tumblr.com/8b6214e18aaa9bbca91bde5ec48164de/tumblr_nh7gzlAEK41qe7pymo2_r1_500.png", "width": 500, "height": 656}, {"url": "https://68.media.tumblr.com/8b6214e18aaa9bbca91bde5ec48164de/tumblr_nh7gzlAEK41qe7pymo2_r1_400.png", "width": 400, "height": 525}, {"url": "https://68.media.tumblr.com/8b6214e18aaa9bbca91bde5ec48164de/tumblr_nh7gzlAEK41qe7pymo2_r1_250.png", "width": 250, "height": 328}, {"url": "https://68.media.tumblr.com/8b6214e18aaa9bbca91bde5ec48164de/tumblr_nh7gzlAEK41qe7pymo2_r1_100.png", "width": 100, "height": 131}, {"url": "https://68.media.tumblr.com/8b6214e18aaa9bbca91bde5ec48164de/tumblr_nh7gzlAEK41qe7pymo2_r1_75sq.png", "width": 75, "height": 75}]}], "summary": "Now seems a good time to tell people that I'm currently crunching on finishing my next book, Big Data for Chimps, with Flip...", "caption": "<p>Now seems a good time to tell people that I&rsquo;m currently crunching on finishing my next book, <a href=\"http://shop.oreilly.com/product/0636920026372.do?sortby=bestSellers\">Big Data for Chimps</a>, with Flip Kromer of Infochimps. It will be out in the next few months. The book covers analytic design patterns in Pig :)</p>", "can_reblog": true}, {"body": "<p><img width=\"200px\" align=\"right\" src=\"https://68.media.tumblr.com/a08357d4d5f875d24bb57b59199b6b4d/tumblr_inline_nfhixlyQXQ1qdyhha.gif\"/></p>\n\n<p>This month I&rsquo;m introducing myself to Japanese tea - which is nearly always green. I&rsquo;ve been introduced to other kinds of tea with expensive grades, and it has me wondering if I really know what to appreciate about &lsquo;fine&rsquo; tea.</p>\n\n<p>So this time, with Japanese green tea, I&rsquo;m learning from the bottom up. I&rsquo;ve ordered three 'crude&rsquo; or cheap teas from <a href=\"http://yunomi.us\">Yunomi.us</a>: <a href=\"https://yunomi.us/shop/7361/morita-04-sayama-karigane-premium-stem-tea-id-7361/\">Kukicha</a>, <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">Konacha</a> and <a href=\"https://yunomi.us/shop/8053/morita-03-aracha-hoju-%E5%AE%9D%E7%8F%A0-id-8053/\">Aracha</a>.</p>\n\n<p><a href=\"http://en.wikipedia.org/wiki/Kukicha\"><b>Kukicha</b></a> or twig tea, also known as b\u014dcha (\u68d2\u8336), is a Japanese blend made of stems, stalks, and twigs. </p>\n\n<p>Kukicha has a nutty, slightly grassy, intensely <a href=\"http://en.wikipedia.org/wiki/Umami\">umami</a> flavor like no other tea I&rsquo;ve had. It is said to have less caffeine than other teas, although this varies significantly.</p>\n\n<p>I don&rsquo;t know much about green tea, but when I read descriptions like &ldquo;&hellip;being composed of parts of the tea plant that are excluded from most other teas,&rdquo; I start rooting for the underdog. </p>\n\n<p>Kukicha is my favorite green tea so far.</p>\n\n<p><img width=\"200px\" align=\"left\" src=\"https://68.media.tumblr.com/1f810700622a6037dd61207533cb790c/tumblr_inline_nfhizdSDpn1qdyhha.gif\"/><a href=\"http://en.wikipedia.org/wiki/Aracha\"><b>Aracha</b></a> is processed green tea before it is split and refined into different grades. Called &ldquo;farmers tea,&rdquo; aracha isn&rsquo;t commonly available in stores. It has a wild, complex taste. I only bought 10 grams of Aracha - enough for about 3 cups, the way I brew it. </p>\n\n<p>Aracha is salty. It has a complex taste with a salty ending. It is far gentler than Konacha, but the aftertaste reminds me of it. This Aracha is very interesting, seems to have two natures - the up front taste and the tail. I&rsquo;m definitely going to buy some more and learn more about it.</p>\n\n<p><img width=\"200px\" align=\"right\" src=\"https://68.media.tumblr.com/5d2f3e46355d73ac1fcb77d455d3a27a/tumblr_inline_nfhj2gfvHj1qdyhha.png\"/><a href=\"http://en.wikipedia.org/wiki/Konacha\"><b>Konacha</b></a> is composed of leftover bits of leaves, buds and stems after tea is processed and separated into different grades. You&rsquo;ve probably had Konacha before, as it is served in sushi restaurants to erase the aftertaste of raw fish. </p>\n\n<p>Konacha has a thick texture with lots of particles in the bottom of the cup. Its taste is complex, even overpowering, with a taste similar to kelp. It becomes bitter fast when over-brewed, so don&rsquo;t do that. </p>\n\n<p>Konacha definitely goes well with food. It clears the palette with every sip. It is cheap, too. Fifty grams was <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">$4.51 from Yunomi.us</a>.</p>\n\n<p>Bottom line: Konacha is a tea I&rsquo;m likely to drink often. </p>\n\n<p>All in all I enjoyed these three teas, and I&rsquo;m likely to try them again.</p>", "liked": false, "followed": false, "reblog_key": "d6QPV1iG", "reblog": {"comment": "<p><img width=\"200px\" align=\"right\" src=\"https://68.media.tumblr.com/a08357d4d5f875d24bb57b59199b6b4d/tumblr_inline_nfhixlyQXQ1qdyhha.gif\"></p>\n\n<p>This month I\u2019m introducing myself to Japanese tea - which is nearly always green. I\u2019ve been introduced to other kinds of tea with expensive grades, and it has me wondering if I really know what to appreciate about \u2018fine\u2019 tea.</p>\n\n<p>So this time, with Japanese green tea, I\u2019m learning from the bottom up. I\u2019ve ordered three 'crude\u2019 or cheap teas from <a href=\"http://yunomi.us\">Yunomi.us</a>: <a href=\"https://yunomi.us/shop/7361/morita-04-sayama-karigane-premium-stem-tea-id-7361/\">Kukicha</a>, <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">Konacha</a> and <a href=\"https://yunomi.us/shop/8053/morita-03-aracha-hoju-%E5%AE%9D%E7%8F%A0-id-8053/\">Aracha</a>.</p>\n\n<p><a href=\"http://en.wikipedia.org/wiki/Kukicha\"><b>Kukicha</b></a> or twig tea, also known as b\u014dcha (\u68d2\u8336), is a Japanese blend made of stems, stalks, and twigs. </p>\n\n<p>Kukicha has a nutty, slightly grassy, intensely <a href=\"http://en.wikipedia.org/wiki/Umami\">umami</a> flavor like no other tea I\u2019ve had. It is said to have less caffeine than other teas, although this varies significantly.</p>\n\n<p>I don\u2019t know much about green tea, but when I read descriptions like \u201c\u2026being composed of parts of the tea plant that are excluded from most other teas,\u201d I start rooting for the underdog. </p>\n\n<p>Kukicha is my favorite green tea so far.</p>\n\n<p><img width=\"200px\" align=\"left\" src=\"https://68.media.tumblr.com/1f810700622a6037dd61207533cb790c/tumblr_inline_nfhizdSDpn1qdyhha.gif\"><a href=\"http://en.wikipedia.org/wiki/Aracha\"><b>Aracha</b></a> is processed green tea before it is split and refined into different grades. Called \u201cfarmers tea,\u201d aracha isn\u2019t commonly available in stores. It has a wild, complex taste. I only bought 10 grams of Aracha - enough for about 3 cups, the way I brew it. </p>\n\n<p>Aracha is salty. It has a complex taste with a salty ending. It is far gentler than Konacha, but the aftertaste reminds me of it. This Aracha is very interesting, seems to have two natures - the up front taste and the tail. I\u2019m definitely going to buy some more and learn more about it.</p>\n\n<p><img width=\"200px\" align=\"right\" src=\"https://68.media.tumblr.com/5d2f3e46355d73ac1fcb77d455d3a27a/tumblr_inline_nfhj2gfvHj1qdyhha.png\"><a href=\"http://en.wikipedia.org/wiki/Konacha\"><b>Konacha</b></a> is composed of leftover bits of leaves, buds and stems after tea is processed and separated into different grades. You\u2019ve probably had Konacha before, as it is served in sushi restaurants to erase the aftertaste of raw fish. </p>\n\n<p>Konacha has a thick texture with lots of particles in the bottom of the cup. Its taste is complex, even overpowering, with a taste similar to kelp. It becomes bitter fast when over-brewed, so don\u2019t do that. </p>\n\n<p>Konacha definitely goes well with food. It clears the palette with every sip. It is cheap, too. Fifty grams was <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">$4.51 from Yunomi.us</a>.</p>\n\n<p>Bottom line: Konacha is a tea I\u2019m likely to drink often. </p>\n\n<p>All in all I enjoyed these three teas, and I\u2019m likely to try them again.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 103597818569, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Japanese Tea Bottom Up: Kukicha, Aracha, Konacha", "tags": [], "post_url": "http://datasyndrome.com/post/103597818569/japanese-tea-bottom-up-kukicha-aracha-konacha", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1WUwKB9", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1416964260, "note_count": 0, "trail": [{"content": "<p><img src=\"https://68.media.tumblr.com/a08357d4d5f875d24bb57b59199b6b4d/tumblr_inline_nfhixlyQXQ1qdyhha.gif\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\n<p>This month I&rsquo;m introducing myself to Japanese tea - which is nearly always green. I&rsquo;ve been introduced to other kinds of tea with expensive grades, and it has me wondering if I really know what to appreciate about &lsquo;fine&rsquo; tea.</p>\n\n<p>So this time, with Japanese green tea, I&rsquo;m learning from the bottom up. I&rsquo;ve ordered three 'crude&rsquo; or cheap teas from <a href=\"http://yunomi.us\">Yunomi.us</a>: <a href=\"https://yunomi.us/shop/7361/morita-04-sayama-karigane-premium-stem-tea-id-7361/\">Kukicha</a>, <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">Konacha</a> and <a href=\"https://yunomi.us/shop/8053/morita-03-aracha-hoju-%E5%AE%9D%E7%8F%A0-id-8053/\">Aracha</a>.</p>\n\n<p><a href=\"http://en.wikipedia.org/wiki/Kukicha\"><b>Kukicha</b></a> or twig tea, also known as b&#333;cha (&#26834;&#33590;), is a Japanese blend made of stems, stalks, and twigs. </p>\n\n<p>Kukicha has a nutty, slightly grassy, intensely <a href=\"http://en.wikipedia.org/wiki/Umami\">umami</a> flavor like no other tea I&rsquo;ve had. It is said to have less caffeine than other teas, although this varies significantly.</p>\n\n<p>I don&rsquo;t know much about green tea, but when I read descriptions like &ldquo;&hellip;being composed of parts of the tea plant that are excluded from most other teas,&rdquo; I start rooting for the underdog. </p>\n\n<p>Kukicha is my favorite green tea so far.</p>\n\n<p><img src=\"https://68.media.tumblr.com/1f810700622a6037dd61207533cb790c/tumblr_inline_nfhizdSDpn1qdyhha.gif\" class=\"toggle_inline_image inline_image constrained_image\"/><a href=\"http://en.wikipedia.org/wiki/Aracha\"><b>Aracha</b></a> is processed green tea before it is split and refined into different grades. Called &ldquo;farmers tea,&rdquo; aracha isn&rsquo;t commonly available in stores. It has a wild, complex taste. I only bought 10 grams of Aracha - enough for about 3 cups, the way I brew it. </p>\n\n<p>Aracha is salty. It has a complex taste with a salty ending. It is far gentler than Konacha, but the aftertaste reminds me of it. This Aracha is very interesting, seems to have two natures - the up front taste and the tail. I&rsquo;m definitely going to buy some more and learn more about it.</p>\n\n<p><img src=\"https://68.media.tumblr.com/5d2f3e46355d73ac1fcb77d455d3a27a/tumblr_inline_nfhj2gfvHj1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/><a href=\"http://en.wikipedia.org/wiki/Konacha\"><b>Konacha</b></a> is composed of leftover bits of leaves, buds and stems after tea is processed and separated into different grades. You&rsquo;ve probably had Konacha before, as it is served in sushi restaurants to erase the aftertaste of raw fish. </p>\n\n<p>Konacha has a thick texture with lots of particles in the bottom of the cup. Its taste is complex, even overpowering, with a taste similar to kelp. It becomes bitter fast when over-brewed, so don&rsquo;t do that. </p>\n\n<p>Konacha definitely goes well with food. It clears the palette with every sip. It is cheap, too. Fifty grams was <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">$4.51 from Yunomi.us</a>.</p>\n\n<p>Bottom line: Konacha is a tea I&rsquo;m likely to drink often. </p>\n\n<p>All in all I enjoyed these three teas, and I&rsquo;m likely to try them again.</p>", "content_raw": "<p><img width=\"200px\" align=\"right\" src=\"https://68.media.tumblr.com/a08357d4d5f875d24bb57b59199b6b4d/tumblr_inline_nfhixlyQXQ1qdyhha.gif\"></p>\n\n<p>This month I\u2019m introducing myself to Japanese tea - which is nearly always green. I\u2019ve been introduced to other kinds of tea with expensive grades, and it has me wondering if I really know what to appreciate about \u2018fine\u2019 tea.</p>\n\n<p>So this time, with Japanese green tea, I\u2019m learning from the bottom up. I\u2019ve ordered three 'crude\u2019 or cheap teas from <a href=\"http://yunomi.us\">Yunomi.us</a>: <a href=\"https://yunomi.us/shop/7361/morita-04-sayama-karigane-premium-stem-tea-id-7361/\">Kukicha</a>, <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">Konacha</a> and <a href=\"https://yunomi.us/shop/8053/morita-03-aracha-hoju-%E5%AE%9D%E7%8F%A0-id-8053/\">Aracha</a>.</p>\n\n<p><a href=\"http://en.wikipedia.org/wiki/Kukicha\"><b>Kukicha</b></a> or twig tea, also known as b\u014dcha (\u68d2\u8336), is a Japanese blend made of stems, stalks, and twigs. </p>\n\n<p>Kukicha has a nutty, slightly grassy, intensely <a href=\"http://en.wikipedia.org/wiki/Umami\">umami</a> flavor like no other tea I\u2019ve had. It is said to have less caffeine than other teas, although this varies significantly.</p>\n\n<p>I don\u2019t know much about green tea, but when I read descriptions like \u201c\u2026being composed of parts of the tea plant that are excluded from most other teas,\u201d I start rooting for the underdog. </p>\n\n<p>Kukicha is my favorite green tea so far.</p>\n\n<p><img width=\"200px\" align=\"left\" src=\"https://68.media.tumblr.com/1f810700622a6037dd61207533cb790c/tumblr_inline_nfhizdSDpn1qdyhha.gif\"><a href=\"http://en.wikipedia.org/wiki/Aracha\"><b>Aracha</b></a> is processed green tea before it is split and refined into different grades. Called \u201cfarmers tea,\u201d aracha isn\u2019t commonly available in stores. It has a wild, complex taste. I only bought 10 grams of Aracha - enough for about 3 cups, the way I brew it. </p>\n\n<p>Aracha is salty. It has a complex taste with a salty ending. It is far gentler than Konacha, but the aftertaste reminds me of it. This Aracha is very interesting, seems to have two natures - the up front taste and the tail. I\u2019m definitely going to buy some more and learn more about it.</p>\n\n<p><img width=\"200px\" align=\"right\" src=\"https://68.media.tumblr.com/5d2f3e46355d73ac1fcb77d455d3a27a/tumblr_inline_nfhj2gfvHj1qdyhha.png\"><a href=\"http://en.wikipedia.org/wiki/Konacha\"><b>Konacha</b></a> is composed of leftover bits of leaves, buds and stems after tea is processed and separated into different grades. You\u2019ve probably had Konacha before, as it is served in sushi restaurants to erase the aftertaste of raw fish. </p>\n\n<p>Konacha has a thick texture with lots of particles in the bottom of the cup. Its taste is complex, even overpowering, with a taste similar to kelp. It becomes bitter fast when over-brewed, so don\u2019t do that. </p>\n\n<p>Konacha definitely goes well with food. It clears the palette with every sip. It is cheap, too. Fifty grams was <a href=\"https://yunomi.us/shop/6016/takeo-tea-farm-spring-konacha-ichiban-50g-id-6016/\">$4.51 from Yunomi.us</a>.</p>\n\n<p>Bottom line: Konacha is a tea I\u2019m likely to drink often. </p>\n\n<p>All in all I enjoyed these three teas, and I\u2019m likely to try them again.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "103597818569"}}], "date": "2014-11-26 01:11:00 GMT", "slug": "japanese-tea-bottom-up-kukicha-aracha-konacha", "blog_name": "rjurney", "summary": "Japanese Tea Bottom Up: Kukicha, Aracha, Konacha", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "fVul72VK", "short_url": "https://tmblr.co/ZbIO5y1Ndc4hT", "can_send_in_message": true, "id": 94079830749, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/94079830749", "tags": [], "post_url": "http://datasyndrome.com/post/94079830749/lebowski-on-screen-at-century-20-daly-city", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Lebowski on screen (at Century 20 Daly City)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1407433166, "note_count": 0, "trail": [{"content": "<p>Lebowski on screen (at Century 20 Daly City)</p>", "content_raw": "<p>Lebowski on screen (at Century 20 Daly City)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "94079830749"}}], "date": "2014-08-07 17:39:26 GMT", "slug": "lebowski-on-screen-at-century-20-daly-city", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/d03bf03ba8c03ee15cedc6a44fa733b4/tumblr_n9y6drKzaG1qe7pymo1_1280.jpg", "width": 640, "height": 640}, "alt_sizes": [{"url": "https://68.media.tumblr.com/d03bf03ba8c03ee15cedc6a44fa733b4/tumblr_n9y6drKzaG1qe7pymo1_1280.jpg", "width": 640, "height": 640}, {"url": "https://68.media.tumblr.com/d03bf03ba8c03ee15cedc6a44fa733b4/tumblr_n9y6drKzaG1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/d03bf03ba8c03ee15cedc6a44fa733b4/tumblr_n9y6drKzaG1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/d03bf03ba8c03ee15cedc6a44fa733b4/tumblr_n9y6drKzaG1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/d03bf03ba8c03ee15cedc6a44fa733b4/tumblr_n9y6drKzaG1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/d03bf03ba8c03ee15cedc6a44fa733b4/tumblr_n9y6drKzaG1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/rZ99nvRT65/", "summary": "Lebowski on screen (at Century 20 Daly City)", "caption": "<p>Lebowski on screen (at Century 20 Daly City)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "vF45xz0w", "short_url": "https://tmblr.co/ZbIO5y1N3_4BW", "can_send_in_message": true, "id": 93482140384, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/93482140384", "tags": [], "post_url": "http://datasyndrome.com/post/93482140384/most-secret-war-is-an-amazing-read-about-the-power", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Most Secret War is an amazing read about the power and consequence of good analytics. (at Pacifica Ocean Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1406879160, "note_count": 0, "trail": [{"content": "<p>Most Secret War is an amazing read about the power and consequence of good analytics. (at Pacifica Ocean Beach)</p>", "content_raw": "<p>Most Secret War is an amazing read about the power and consequence of good analytics. (at Pacifica Ocean Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "93482140384"}}], "date": "2014-08-01 07:46:00 GMT", "slug": "most-secret-war-is-an-amazing-read-about-the-power", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/e8a2d0ed0fb2211bfd7b56dbbf50a946/tumblr_n9mawouHkm1qe7pymo1_1280.jpg", "width": 640, "height": 640}, "alt_sizes": [{"url": "https://68.media.tumblr.com/e8a2d0ed0fb2211bfd7b56dbbf50a946/tumblr_n9mawouHkm1qe7pymo1_1280.jpg", "width": 640, "height": 640}, {"url": "https://68.media.tumblr.com/e8a2d0ed0fb2211bfd7b56dbbf50a946/tumblr_n9mawouHkm1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/e8a2d0ed0fb2211bfd7b56dbbf50a946/tumblr_n9mawouHkm1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/e8a2d0ed0fb2211bfd7b56dbbf50a946/tumblr_n9mawouHkm1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/e8a2d0ed0fb2211bfd7b56dbbf50a946/tumblr_n9mawouHkm1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/e8a2d0ed0fb2211bfd7b56dbbf50a946/tumblr_n9mawouHkm1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/rJdR5cRT4W/", "summary": "Most Secret War is an amazing read about the power and consequence of good analytics. (at Pacifica Ocean Beach)", "caption": "<p>Most Secret War is an amazing read about the power and consequence of good analytics. (at Pacifica Ocean Beach)</p>", "can_reblog": true}, {"body": "<pre><code>[\n    \"0xdata\",\n    \"10gen\",\n    \"A-TRAC\",\n    \"A3 Data\",\n    \"ABYRES Enterprise Technologies\",\n    \"AE Business Solutions\",\n    \"AMD\",\n    \"APEXCNS\",\n    \"ASD TECH\",\n    \"Ab Initio\",\n    \"Abitech Software\",\n    \"Accenture\",\n    \"Acentrix\",\n    \"Actian\",\n    \"Active Network\",\n    \"Actuate\",\n    \"Adastra\",\n    \"Admatic\",\n    \"Advanced Analytic Services\",\n    \"Advanced Micro Devices\",\n    \"Advizor\",\n    \"Aeronomy\",\n    \"Aeverie Inc.\",\n    \"Affini-Tech\",\n    \"Agile Bay\",\n    \"Aha! Software\",\n    \"Aleron\",\n    \"AllianceONE\",\n    \"AlphaSix Corporation\",\n    \"Alpine Data Labs\",\n    \"Alteryx\",\n    \"Altic\",\n    \"Altior Inc\",\n    \"Altiscale\",\n    \"Altoros\",\n    \"Amazon Elastic MapReduce\",\n    \"Amdocs\",\n    \"Anji Technologies\",\n    \"Apara Solutions\",\n    \"Apervi\",\n    \"AppFluent\",\n    \"Appcara\",\n    \"Appfluent\",\n    \"Appnovation\",\n    \"AquaFold\",\n    \"Archius\",\n    \"Argil Data\",\n    \"Aricent\",\n    \"Arieso\",\n    \"Arista Networks\",\n    \"Artis Consulting\",\n    \"Assembly Data System\",\n    \"Atigeo\",\n    \"Attivio\",\n    \"Attunity\",\n    \"Audaque Data Technology\",\n    \"AugmentIQ Data Sciences\",\n    \"Aurelius\",\n    \"Avalon Consulting\",\n    \"Avenues International\",\n    \"Axeldata Systems FZ-LLC\",\n    \"Ayasdi\",\n    \"Aziksa\",\n    \"Azul Systems\",\n    \"Azuris\",\n    \"B1 Systems GmbH\",\n    \"BC Cloud\",\n    \"BDI Systems\",\n    \"BI Acuity\",\n    \"BMC Software\",\n    \"BPM-Conseil\",\n    \"Basis Technology\",\n    \"BeagleData\",\n    \"Big Data Elephants, Inc.\",\n    \"Big Data Partnership\",\n    \"Big Switch Networks\",\n    \"BigDataStrategies\",\n    \"Bilginc IT Academy\",\n    \"Bilot\",\n    \"BioDatomics\",\n    \"Birst\",\n    \"Bit Stew Systems\",\n    \"BizData\",\n    \"Blue Canopy Group, LLC\",\n    \"BlueData Software\",\n    \"BlueGranite\",\n    \"BlueMetal Architects\",\n    \"BluePatagon\",\n    \"Booz Allen Hamilton\",\n    \"Boundary\",\n    \"BrainPad Inc.\",\n    \"Bright Computing \",\n    \"Brillio\",\n    \"Brocade\",\n    \"Bruhati\",\n    \"Bull\",\n    \"Business Objects\",\n    \"CAS\",\n    \"COMAT Training Services Pte Ltd\",\n    \"CR-X\",\n    \"CS InIT\",\n    \"CSC\",\n    \"Calpont Corporation\",\n    \"Calxeda\",\n    \"Canonical\",\n    \"Capgemini\",\n    \"Carahsoft\",\n    \"Caserta Concepts\",\n    \"Celer Technologies\",\n    \"Centric Consulting\",\n    \"CenturyLink Technology Solutions\",\n    \"Chicago Business Intelligence Group\",\n    \"Ciber\",\n    \"Cirro\",\n    \"Cisco\",\n    \"Clarity Solution Group\",\n    \"ClearDATA\",\n    \"Cleo\",\n    \"ClickFox\",\n    \"Cloud A\",\n    \"Cloud Front Group\",\n    \"Cloud Partners\",\n    \"Cloudera\",\n    \"Cloudwick\",\n    \"Coeo\",\n    \"Cognizant\",\n    \"Cognos\",\n    \"Collier IT\",\n    \"Compegence\",\n    \"Composite Software\",\n    \"Compsesa\",\n    \"Computertekk\",\n    \"Compuware\",\n    \"Concurrent\",\n    \"Contexti\",\n    \"Continuent\",\n    \"Continuuity\",\n    \"Cotran Technologies\",\n    \"Cross Point Solutions\",\n    \"DFHeinz\",\n    \"Data Center Warehouse\",\n    \"Data Tactics\",\n    \"DataLayer\",\n    \"DataStax\",\n    \"DataTorrent\",\n    \"Databricks\",\n    \"Dataguise\",\n    \"Datalakes\",\n    \"Datameer\",\n    \"Daxpy\",\n    \"Decision Patterns\",\n    \"Dell\",\n    \"DiYOTTA\",\n    \"Digital Reasoning\",\n    \"DigitalRoute\",\n    \"Discovix\",\n    \"Dragonfly Data Factory\",\n    \"EMC\",\n    \"EOIR Technologies\",\n    \"Ecube\",\n    \"Elastacloud\",\n    \"Elasticsearch\",\n    \"EmergiNet\",\n    \"Eminent Software Services\",\n    \"Enfathom North Highland\",\n    \"Enterprise MapReduce\",\n    \"EnterpriseDB\",\n    \"Envision IT Group \",\n    \"Evolver\",\n    \"Exar\",\n    \"Excedis\",\n    \"Excel Big Data\",\n    \"Exilant\",\n    \"FDM Group\",\n    \"FORMCEPT\",\n    \"Factual\",\n    \"Fast Data Connect\",\n    \"Fingerprint Consultancy\",\n    \"Fino Consulting\",\n    \"First Light Technologies\",\n    \"Force10\",\n    \"Fusion-io\",\n    \"Fusionex\",\n    \"GCA Technology Services\",\n    \"GNS Healthcare\",\n    \"GTRI\",\n    \"Gazzang\",\n    \"Globalscape\",\n    \"Globant\",\n    \"Gnip\",\n    \"GoGrid\",\n    \"Google Compute Engine\",\n    \"GrayMatter\",\n    \"Guavus\",\n    \"H2O\",\n    \"HVR Software\",\n    \"Hadapt\",\n    \"Hadoop Illuminated\",\n    \"Happiest Minds\",\n    \"Heerbod Corp.\",\n    \"Hewlett Packard\",\n    \"Hortonworks\",\n    \"Hstreaming\",\n    \"IBM\",\n    \"ICC\",\n    \"IDA Solutions\",\n    \"IIS Technology\",\n    \"IKANOW\",\n    \"ITC Infotech\",\n    \"Ideas2IT\",\n    \"Ideation816 Corporation\",\n    \"Impetus\",\n    \"Impetus Technologies\",\n    \"Indigo New Zealand Limited\",\n    \"InfiniDB\",\n    \"InfoCentric\",\n    \"InfoObjects\",\n    \"InfoTrellis\",\n    \"Informatica\",\n    \"Information Builders\",\n    \"InsightsOne\",\n    \"Integrated Cyber Solutions\",\n    \"IntegriChain\",\n    \"Intel\",\n    \"Intelent\",\n    \"InterSys Consulting\",\n    \"Interactive Algorithms Inc. \",\n    \"IronBrick\",\n    \"Isilon\",\n    \"Ispirer\",\n    \"Jaspersoft\",\n    \"Joyent\",\n    \"KPI Partners Inc.\",\n    \"KPO Partners\",\n    \"Kaggle\",\n    \"KarmaSphere\",\n    \"Karmasphere\",\n    \"Keylink Technology\",\n    \"Keymobile Software\",\n    \"Kinney Group\",\n    \"KloudData\",\n    \"Knowledge Solutions\",\n    \"Knowledgent\",\n    \"Kognitio\",\n    \"Koverser\",\n    \"L&amp;T Infotech\",\n    \"LG CNS \",\n    \"LOOK Innovative\",\n    \"LSI\",\n    \"Latta Partners\",\n    \"Lericon Informatics\",\n    \"Likya Teknoloji\",\n    \"Linux Polska\",\n    \"Logi Analytics\",\n    \"LogiAnalytics\",\n    \"London Consulting Ltd.\",\n    \"Looker\",\n    \"LucidWorks\",\n    \"MZMTechnologies\",\n    \"ManTech\",\n    \"MapR\",\n    \"MarkLogic\",\n    \"Maxonic\",\n    \"McKnight Consulting Group\",\n    \"Mellanox Technologies\",\n    \"MetaScale\",\n    \"Metric Insights\",\n    \"MicroStrategy\",\n    \"Micron\",\n    \"Microsoft\",\n    \"Mikan Associates\",\n    \"Miri InfoTech\",\n    \"MisOne Solution\",\n    \"Mission First\",\n    \"MongoDB\",\n    \"Moser Consulting\",\n    \"Mund Consulting\",\n    \"Myers-Holum\",\n    \"NFLabs\",\n    \"NGData\",\n    \"NS Solutions\",\n    \"NTC Vulkan\",\n    \"NYSE\",\n    \"Narus\",\n    \"Nautilus Technologies\",\n    \"NectarGlobe Technology Solutions\",\n    \"NetApp\",\n    \"Netmind\",\n    \"New Era Technologies\",\n    \"NimbleScale\",\n    \"NorCom\",\n    \"Nous Infosystems\",\n    \"Novetta Solutions\",\n    \"Nutanix\",\n    \"OCTO\",\n    \"OnX Enterprise Solutions\",\n    \"Onepoint IQ\",\n    \"Onramp Corporation\",\n    \"Open Software Integrators\",\n    \"OpenBI\",\n    \"OpenOsmium\",\n    \"Opex Software\",\n    \"Options I/O\",\n    \"Oran Technology\",\n    \"Orzota\",\n    \"PRECOGNX\",\n    \"PSSC Labs\",\n    \"Pactera\",\n    \"Panasas\",\n    \"Panorama\",\n    \"Pentaho\",\n    \"Pepperdata\",\n    \"Perficient\",\n    \"Persistent Systems\",\n    \"Pervasive Big Data &amp; Analytics\",\n    \"Pervasive Data Innovation\",\n    \"PiTech Solutions\",\n    \"Platfora\",\n    \"Polyform Labs\",\n    \"PrediGO!\",\n    \"Predictive Analytics Corporation\",\n    \"Predixion\",\n    \"Prime Dimensions, LLC\",\n    \"Procima Experts\",\n    \"Progress\",\n    \"Propus\",\n    \"Prosys\",\n    \"Protegrity\",\n    \"QA\",\n    \"QLogic\",\n    \"Qlik\",\n    \"QlikView\",\n    \"Qubole\",\n    \"QuickLogix LLC\",\n    \"RCS Education\",\n    \"RTTS\",\n    \"Rackspace\",\n    \"Radoop\",\n    \"RailsFactory\",\n    \"RainStor\",\n    \"Recombinant by Deloitte\",\n    \"Red Gate\",\n    \"Red Hat\",\n    \"RedPoint Global\",\n    \"Revelytix\",\n    \"Revolution Analytics\",\n    \"Revolutionary Machines\",\n    \"SAP\",\n    \"SAS\",\n    \"SCG Solutions\",\n    \"SEED Infotech\",\n    \"SELA\",\n    \"SGI\",\n    \"SHMsoft\",\n    \"SHS-Viveon\",\n    \"SUN Microsystems\",\n    \"SUSE\",\n    \"SYNTASA\",\n    \"Saama Technologies\",\n    \"Sakura Sky Media\",\n    \"Savvis\",\n    \"Scale Abilities\",\n    \"ScaleOut Software\",\n    \"Scaled Risk\",\n    \"Scorecard Systems\",\n    \"Seagate\",\n    \"Sematext\",\n    \"Sendero Business Services\",\n    \"Serendio\",\n    \"Seynur\",\n    \"Sierra Technology\",\n    \"SilverSpring Networks\",\n    \"Simba\",\n    \"Sinergy\",\n    \"Skytree\",\n    \"SnapLogic\",\n    \"SoftNet Solutions\",\n    \"Solarflare\",\n    \"SolidQ\",\n    \"Solus Group\",\n    \"Sophias\",\n    \"Space-Time Insight\",\n    \"Spectra Logic\",\n    \"SpectraMind Solutions\",\n    \"Splunk\",\n    \"Spring\",\n    \"Spry\",\n    \"Sqrrl\",\n    \"Squid Solutions\",\n    \"StackIQ\",\n    \"Strategic IT Security\",\n    \"Strategix Solutions\",\n    \"Streambase\",\n    \"Sunset Learning Institute\",\n    \"Supermicro\",\n    \"Switch NAP\",\n    \"Symantec\",\n    \"Syncsort\",\n    \"Syncwork\",\n    \"Syntel\",\n    \"Systematix Infotech\",\n    \"T4G\",\n    \"TCloud Computing\",\n    \"TDK Technologies\",\n    \"TIBCO Software\",\n    \"Tableau Software\",\n    \"Talend\",\n    \"Tamr\",\n    \"Tata Consultancy Services\",\n    \"Teradata\",\n    \"The Principal Consulting\",\n    \"Think Big Analytics\",\n    \"Third Eye Consulting Services &amp; Solutions\",\n    \"ThrivOn\",\n    \"Tibco Spotfire\",\n    \"TipDM Intelligent Technology\",\n    \"Tissow\",\n    \"Trace3\",\n    \"Transcend Business Intelligence\",\n    \"Trendwise Analytics\",\n    \"Tresata\",\n    \"Tri-IT Solutions\",\n    \"Trifacta\",\n    \"Twingo\",\n    \"UL Environment\",\n    \"Ubeeko\",\n    \"Univa\",\n    \"VCE\",\n    \"VLDB Solutions\",\n    \"VMWare\",\n    \"VRV Solutions\",\n    \"Vanilla\",\n    \"Vector Technology Solutions\",\n    \"Veristorm\",\n    \"Vertascale\",\n    \"Vertica\",\n    \"Vinnox Technologies\",\n    \"Violin Memory\",\n    \"Virtual Infotech\",\n    \"VirtualScale\",\n    \"Viscosity North America\",\n    \"VoltDB\",\n    \"Voltage Security\",\n    \"WANdisco\",\n    \"WE-Ankor\",\n    \"WHIPTAIL\",\n    \"West Monroe Partners\",\n    \"WhiteKlay\",\n    \"Wipro Technologies\",\n    \"World Wide Technology\",\n    \"XCentium\",\n    \"XOR Security\",\n    \"Xenolytics\",\n    \"Xplenty\",\n    \"Xtreme Insights\",\n    \"Yeswici LLC\",\n    \"Z Data Inc.\",\n    \"ZData\",\n    \"Zaloni\",\n    \"Zementis\",\n    \"Zettaset\",\n    \"Zuhlke Engineering\",\n    \"acentrix\",\n    \"adesso AG\",\n    \"cimt AG\",\n    \"codecentric\",\n    \"comSysto\",\n    \"eCapital Advisors\",\n    \"eHire Labs\",\n    \"eSage Group\",\n    \"eTouch Systems\",\n    \"iQuest\",\n    \"iTalent Corporation\",\n    \"iTrend\",\n    \"immixGroup\",\n    \"is-land Systems Inc.\",\n    \"Pivotal\"\n]</code></pre>", "liked": false, "followed": false, "reblog_key": "37pVpQdr", "reblog": {"comment": "<p><pre><code>[\n    \"0xdata\",\n    \"10gen\",\n    \"A-TRAC\",\n    \"A3 Data\",\n    \"ABYRES Enterprise Technologies\",\n    \"AE Business Solutions\",\n    \"AMD\",\n    \"APEXCNS\",\n    \"ASD TECH\",\n    \"Ab Initio\",\n    \"Abitech Software\",\n    \"Accenture\",\n    \"Acentrix\",\n    \"Actian\",\n    \"Active Network\",\n    \"Actuate\",\n    \"Adastra\",\n    \"Admatic\",\n    \"Advanced Analytic Services\",\n    \"Advanced Micro Devices\",\n    \"Advizor\",\n    \"Aeronomy\",\n    \"Aeverie Inc.\",\n    \"Affini-Tech\",\n    \"Agile Bay\",\n    \"Aha! Software\",\n    \"Aleron\",\n    \"AllianceONE\",\n    \"AlphaSix Corporation\",\n    \"Alpine Data Labs\",\n    \"Alteryx\",\n    \"Altic\",\n    \"Altior Inc\",\n    \"Altiscale\",\n    \"Altoros\",\n    \"Amazon Elastic MapReduce\",\n    \"Amdocs\",\n    \"Anji Technologies\",\n    \"Apara Solutions\",\n    \"Apervi\",\n    \"AppFluent\",\n    \"Appcara\",\n    \"Appfluent\",\n    \"Appnovation\",\n    \"AquaFold\",\n    \"Archius\",\n    \"Argil Data\",\n    \"Aricent\",\n    \"Arieso\",\n    \"Arista Networks\",\n    \"Artis Consulting\",\n    \"Assembly Data System\",\n    \"Atigeo\",\n    \"Attivio\",\n    \"Attunity\",\n    \"Audaque Data Technology\",\n    \"AugmentIQ Data Sciences\",\n    \"Aurelius\",\n    \"Avalon Consulting\",\n    \"Avenues International\",\n    \"Axeldata Systems FZ-LLC\",\n    \"Ayasdi\",\n    \"Aziksa\",\n    \"Azul Systems\",\n    \"Azuris\",\n    \"B1 Systems GmbH\",\n    \"BC Cloud\",\n    \"BDI Systems\",\n    \"BI Acuity\",\n    \"BMC Software\",\n    \"BPM-Conseil\",\n    \"Basis Technology\",\n    \"BeagleData\",\n    \"Big Data Elephants, Inc.\",\n    \"Big Data Partnership\",\n    \"Big Switch Networks\",\n    \"BigDataStrategies\",\n    \"Bilginc IT Academy\",\n    \"Bilot\",\n    \"BioDatomics\",\n    \"Birst\",\n    \"Bit Stew Systems\",\n    \"BizData\",\n    \"Blue Canopy Group, LLC\",\n    \"BlueData Software\",\n    \"BlueGranite\",\n    \"BlueMetal Architects\",\n    \"BluePatagon\",\n    \"Booz Allen Hamilton\",\n    \"Boundary\",\n    \"BrainPad Inc.\",\n    \"Bright Computing \",\n    \"Brillio\",\n    \"Brocade\",\n    \"Bruhati\",\n    \"Bull\",\n    \"Business Objects\",\n    \"CAS\",\n    \"COMAT Training Services Pte Ltd\",\n    \"CR-X\",\n    \"CS InIT\",\n    \"CSC\",\n    \"Calpont Corporation\",\n    \"Calxeda\",\n    \"Canonical\",\n    \"Capgemini\",\n    \"Carahsoft\",\n    \"Caserta Concepts\",\n    \"Celer Technologies\",\n    \"Centric Consulting\",\n    \"CenturyLink Technology Solutions\",\n    \"Chicago Business Intelligence Group\",\n    \"Ciber\",\n    \"Cirro\",\n    \"Cisco\",\n    \"Clarity Solution Group\",\n    \"ClearDATA\",\n    \"Cleo\",\n    \"ClickFox\",\n    \"Cloud A\",\n    \"Cloud Front Group\",\n    \"Cloud Partners\",\n    \"Cloudera\",\n    \"Cloudwick\",\n    \"Coeo\",\n    \"Cognizant\",\n    \"Cognos\",\n    \"Collier IT\",\n    \"Compegence\",\n    \"Composite Software\",\n    \"Compsesa\",\n    \"Computertekk\",\n    \"Compuware\",\n    \"Concurrent\",\n    \"Contexti\",\n    \"Continuent\",\n    \"Continuuity\",\n    \"Cotran Technologies\",\n    \"Cross Point Solutions\",\n    \"DFHeinz\",\n    \"Data Center Warehouse\",\n    \"Data Tactics\",\n    \"DataLayer\",\n    \"DataStax\",\n    \"DataTorrent\",\n    \"Databricks\",\n    \"Dataguise\",\n    \"Datalakes\",\n    \"Datameer\",\n    \"Daxpy\",\n    \"Decision Patterns\",\n    \"Dell\",\n    \"DiYOTTA\",\n    \"Digital Reasoning\",\n    \"DigitalRoute\",\n    \"Discovix\",\n    \"Dragonfly Data Factory\",\n    \"EMC\",\n    \"EOIR Technologies\",\n    \"Ecube\",\n    \"Elastacloud\",\n    \"Elasticsearch\",\n    \"EmergiNet\",\n    \"Eminent Software Services\",\n    \"Enfathom North Highland\",\n    \"Enterprise MapReduce\",\n    \"EnterpriseDB\",\n    \"Envision IT Group \",\n    \"Evolver\",\n    \"Exar\",\n    \"Excedis\",\n    \"Excel Big Data\",\n    \"Exilant\",\n    \"FDM Group\",\n    \"FORMCEPT\",\n    \"Factual\",\n    \"Fast Data Connect\",\n    \"Fingerprint Consultancy\",\n    \"Fino Consulting\",\n    \"First Light Technologies\",\n    \"Force10\",\n    \"Fusion-io\",\n    \"Fusionex\",\n    \"GCA Technology Services\",\n    \"GNS Healthcare\",\n    \"GTRI\",\n    \"Gazzang\",\n    \"Globalscape\",\n    \"Globant\",\n    \"Gnip\",\n    \"GoGrid\",\n    \"Google Compute Engine\",\n    \"GrayMatter\",\n    \"Guavus\",\n    \"H2O\",\n    \"HVR Software\",\n    \"Hadapt\",\n    \"Hadoop Illuminated\",\n    \"Happiest Minds\",\n    \"Heerbod Corp.\",\n    \"Hewlett Packard\",\n    \"Hortonworks\",\n    \"Hstreaming\",\n    \"IBM\",\n    \"ICC\",\n    \"IDA Solutions\",\n    \"IIS Technology\",\n    \"IKANOW\",\n    \"ITC Infotech\",\n    \"Ideas2IT\",\n    \"Ideation816 Corporation\",\n    \"Impetus\",\n    \"Impetus Technologies\",\n    \"Indigo New Zealand Limited\",\n    \"InfiniDB\",\n    \"InfoCentric\",\n    \"InfoObjects\",\n    \"InfoTrellis\",\n    \"Informatica\",\n    \"Information Builders\",\n    \"InsightsOne\",\n    \"Integrated Cyber Solutions\",\n    \"IntegriChain\",\n    \"Intel\",\n    \"Intelent\",\n    \"InterSys Consulting\",\n    \"Interactive Algorithms Inc. \",\n    \"IronBrick\",\n    \"Isilon\",\n    \"Ispirer\",\n    \"Jaspersoft\",\n    \"Joyent\",\n    \"KPI Partners Inc.\",\n    \"KPO Partners\",\n    \"Kaggle\",\n    \"KarmaSphere\",\n    \"Karmasphere\",\n    \"Keylink Technology\",\n    \"Keymobile Software\",\n    \"Kinney Group\",\n    \"KloudData\",\n    \"Knowledge Solutions\",\n    \"Knowledgent\",\n    \"Kognitio\",\n    \"Koverser\",\n    \"L&T Infotech\",\n    \"LG CNS \",\n    \"LOOK Innovative\",\n    \"LSI\",\n    \"Latta Partners\",\n    \"Lericon Informatics\",\n    \"Likya Teknoloji\",\n    \"Linux Polska\",\n    \"Logi Analytics\",\n    \"LogiAnalytics\",\n    \"London Consulting Ltd.\",\n    \"Looker\",\n    \"LucidWorks\",\n    \"MZMTechnologies\",\n    \"ManTech\",\n    \"MapR\",\n    \"MarkLogic\",\n    \"Maxonic\",\n    \"McKnight Consulting Group\",\n    \"Mellanox Technologies\",\n    \"MetaScale\",\n    \"Metric Insights\",\n    \"MicroStrategy\",\n    \"Micron\",\n    \"Microsoft\",\n    \"Mikan Associates\",\n    \"Miri InfoTech\",\n    \"MisOne Solution\",\n    \"Mission First\",\n    \"MongoDB\",\n    \"Moser Consulting\",\n    \"Mund Consulting\",\n    \"Myers-Holum\",\n    \"NFLabs\",\n    \"NGData\",\n    \"NS Solutions\",\n    \"NTC Vulkan\",\n    \"NYSE\",\n    \"Narus\",\n    \"Nautilus Technologies\",\n    \"NectarGlobe Technology Solutions\",\n    \"NetApp\",\n    \"Netmind\",\n    \"New Era Technologies\",\n    \"NimbleScale\",\n    \"NorCom\",\n    \"Nous Infosystems\",\n    \"Novetta Solutions\",\n    \"Nutanix\",\n    \"OCTO\",\n    \"OnX Enterprise Solutions\",\n    \"Onepoint IQ\",\n    \"Onramp Corporation\",\n    \"Open Software Integrators\",\n    \"OpenBI\",\n    \"OpenOsmium\",\n    \"Opex Software\",\n    \"Options I/O\",\n    \"Oran Technology\",\n    \"Orzota\",\n    \"PRECOGNX\",\n    \"PSSC Labs\",\n    \"Pactera\",\n    \"Panasas\",\n    \"Panorama\",\n    \"Pentaho\",\n    \"Pepperdata\",\n    \"Perficient\",\n    \"Persistent Systems\",\n    \"Pervasive Big Data & Analytics\",\n    \"Pervasive Data Innovation\",\n    \"PiTech Solutions\",\n    \"Platfora\",\n    \"Polyform Labs\",\n    \"PrediGO!\",\n    \"Predictive Analytics Corporation\",\n    \"Predixion\",\n    \"Prime Dimensions, LLC\",\n    \"Procima Experts\",\n    \"Progress\",\n    \"Propus\",\n    \"Prosys\",\n    \"Protegrity\",\n    \"QA\",\n    \"QLogic\",\n    \"Qlik\",\n    \"QlikView\",\n    \"Qubole\",\n    \"QuickLogix LLC\",\n    \"RCS Education\",\n    \"RTTS\",\n    \"Rackspace\",\n    \"Radoop\",\n    \"RailsFactory\",\n    \"RainStor\",\n    \"Recombinant by Deloitte\",\n    \"Red Gate\",\n    \"Red Hat\",\n    \"RedPoint Global\",\n    \"Revelytix\",\n    \"Revolution Analytics\",\n    \"Revolutionary Machines\",\n    \"SAP\",\n    \"SAS\",\n    \"SCG Solutions\",\n    \"SEED Infotech\",\n    \"SELA\",\n    \"SGI\",\n    \"SHMsoft\",\n    \"SHS-Viveon\",\n    \"SUN Microsystems\",\n    \"SUSE\",\n    \"SYNTASA\",\n    \"Saama Technologies\",\n    \"Sakura Sky Media\",\n    \"Savvis\",\n    \"Scale Abilities\",\n    \"ScaleOut Software\",\n    \"Scaled Risk\",\n    \"Scorecard Systems\",\n    \"Seagate\",\n    \"Sematext\",\n    \"Sendero Business Services\",\n    \"Serendio\",\n    \"Seynur\",\n    \"Sierra Technology\",\n    \"SilverSpring Networks\",\n    \"Simba\",\n    \"Sinergy\",\n    \"Skytree\",\n    \"SnapLogic\",\n    \"SoftNet Solutions\",\n    \"Solarflare\",\n    \"SolidQ\",\n    \"Solus Group\",\n    \"Sophias\",\n    \"Space-Time Insight\",\n    \"Spectra Logic\",\n    \"SpectraMind Solutions\",\n    \"Splunk\",\n    \"Spring\",\n    \"Spry\",\n    \"Sqrrl\",\n    \"Squid Solutions\",\n    \"StackIQ\",\n    \"Strategic IT Security\",\n    \"Strategix Solutions\",\n    \"Streambase\",\n    \"Sunset Learning Institute\",\n    \"Supermicro\",\n    \"Switch NAP\",\n    \"Symantec\",\n    \"Syncsort\",\n    \"Syncwork\",\n    \"Syntel\",\n    \"Systematix Infotech\",\n    \"T4G\",\n    \"TCloud Computing\",\n    \"TDK Technologies\",\n    \"TIBCO Software\",\n    \"Tableau Software\",\n    \"Talend\",\n    \"Tamr\",\n    \"Tata Consultancy Services\",\n    \"Teradata\",\n    \"The Principal Consulting\",\n    \"Think Big Analytics\",\n    \"Third Eye Consulting Services & Solutions\",\n    \"ThrivOn\",\n    \"Tibco Spotfire\",\n    \"TipDM Intelligent Technology\",\n    \"Tissow\",\n    \"Trace3\",\n    \"Transcend Business Intelligence\",\n    \"Trendwise Analytics\",\n    \"Tresata\",\n    \"Tri-IT Solutions\",\n    \"Trifacta\",\n    \"Twingo\",\n    \"UL Environment\",\n    \"Ubeeko\",\n    \"Univa\",\n    \"VCE\",\n    \"VLDB Solutions\",\n    \"VMWare\",\n    \"VRV Solutions\",\n    \"Vanilla\",\n    \"Vector Technology Solutions\",\n    \"Veristorm\",\n    \"Vertascale\",\n    \"Vertica\",\n    \"Vinnox Technologies\",\n    \"Violin Memory\",\n    \"Virtual Infotech\",\n    \"VirtualScale\",\n    \"Viscosity North America\",\n    \"VoltDB\",\n    \"Voltage Security\",\n    \"WANdisco\",\n    \"WE-Ankor\",\n    \"WHIPTAIL\",\n    \"West Monroe Partners\",\n    \"WhiteKlay\",\n    \"Wipro Technologies\",\n    \"World Wide Technology\",\n    \"XCentium\",\n    \"XOR Security\",\n    \"Xenolytics\",\n    \"Xplenty\",\n    \"Xtreme Insights\",\n    \"Yeswici LLC\",\n    \"Z Data Inc.\",\n    \"ZData\",\n    \"Zaloni\",\n    \"Zementis\",\n    \"Zettaset\",\n    \"Zuhlke Engineering\",\n    \"acentrix\",\n    \"adesso AG\",\n    \"cimt AG\",\n    \"codecentric\",\n    \"comSysto\",\n    \"eCapital Advisors\",\n    \"eHire Labs\",\n    \"eSage Group\",\n    \"eTouch Systems\",\n    \"iQuest\",\n    \"iTalent Corporation\",\n    \"iTrend\",\n    \"immixGroup\",\n    \"is-land Systems Inc.\",\n    \"Pivotal\"\n]</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 93271562269, "display_avatar": true, "can_reply": true, "can_like": false, "title": "A List of Hadoop Vendors", "tags": [], "post_url": "http://datasyndrome.com/post/93271562269/a-list-of-hadoop-vendors", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1MtQnWT", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1406689800, "note_count": 2, "trail": [{"content": "<p><pre><code>[\n    \"0xdata\",\n    \"10gen\",\n    \"A-TRAC\",\n    \"A3 Data\",\n    \"ABYRES Enterprise Technologies\",\n    \"AE Business Solutions\",\n    \"AMD\",\n    \"APEXCNS\",\n    \"ASD TECH\",\n    \"Ab Initio\",\n    \"Abitech Software\",\n    \"Accenture\",\n    \"Acentrix\",\n    \"Actian\",\n    \"Active Network\",\n    \"Actuate\",\n    \"Adastra\",\n    \"Admatic\",\n    \"Advanced Analytic Services\",\n    \"Advanced Micro Devices\",\n    \"Advizor\",\n    \"Aeronomy\",\n    \"Aeverie Inc.\",\n    \"Affini-Tech\",\n    \"Agile Bay\",\n    \"Aha! Software\",\n    \"Aleron\",\n    \"AllianceONE\",\n    \"AlphaSix Corporation\",\n    \"Alpine Data Labs\",\n    \"Alteryx\",\n    \"Altic\",\n    \"Altior Inc\",\n    \"Altiscale\",\n    \"Altoros\",\n    \"Amazon Elastic MapReduce\",\n    \"Amdocs\",\n    \"Anji Technologies\",\n    \"Apara Solutions\",\n    \"Apervi\",\n    \"AppFluent\",\n    \"Appcara\",\n    \"Appfluent\",\n    \"Appnovation\",\n    \"AquaFold\",\n    \"Archius\",\n    \"Argil Data\",\n    \"Aricent\",\n    \"Arieso\",\n    \"Arista Networks\",\n    \"Artis Consulting\",\n    \"Assembly Data System\",\n    \"Atigeo\",\n    \"Attivio\",\n    \"Attunity\",\n    \"Audaque Data Technology\",\n    \"AugmentIQ Data Sciences\",\n    \"Aurelius\",\n    \"Avalon Consulting\",\n    \"Avenues International\",\n    \"Axeldata Systems FZ-LLC\",\n    \"Ayasdi\",\n    \"Aziksa\",\n    \"Azul Systems\",\n    \"Azuris\",\n    \"B1 Systems GmbH\",\n    \"BC Cloud\",\n    \"BDI Systems\",\n    \"BI Acuity\",\n    \"BMC Software\",\n    \"BPM-Conseil\",\n    \"Basis Technology\",\n    \"BeagleData\",\n    \"Big Data Elephants, Inc.\",\n    \"Big Data Partnership\",\n    \"Big Switch Networks\",\n    \"BigDataStrategies\",\n    \"Bilginc IT Academy\",\n    \"Bilot\",\n    \"BioDatomics\",\n    \"Birst\",\n    \"Bit Stew Systems\",\n    \"BizData\",\n    \"Blue Canopy Group, LLC\",\n    \"BlueData Software\",\n    \"BlueGranite\",\n    \"BlueMetal Architects\",\n    \"BluePatagon\",\n    \"Booz Allen Hamilton\",\n    \"Boundary\",\n    \"BrainPad Inc.\",\n    \"Bright Computing \",\n    \"Brillio\",\n    \"Brocade\",\n    \"Bruhati\",\n    \"Bull\",\n    \"Business Objects\",\n    \"CAS\",\n    \"COMAT Training Services Pte Ltd\",\n    \"CR-X\",\n    \"CS InIT\",\n    \"CSC\",\n    \"Calpont Corporation\",\n    \"Calxeda\",\n    \"Canonical\",\n    \"Capgemini\",\n    \"Carahsoft\",\n    \"Caserta Concepts\",\n    \"Celer Technologies\",\n    \"Centric Consulting\",\n    \"CenturyLink Technology Solutions\",\n    \"Chicago Business Intelligence Group\",\n    \"Ciber\",\n    \"Cirro\",\n    \"Cisco\",\n    \"Clarity Solution Group\",\n    \"ClearDATA\",\n    \"Cleo\",\n    \"ClickFox\",\n    \"Cloud A\",\n    \"Cloud Front Group\",\n    \"Cloud Partners\",\n    \"Cloudera\",\n    \"Cloudwick\",\n    \"Coeo\",\n    \"Cognizant\",\n    \"Cognos\",\n    \"Collier IT\",\n    \"Compegence\",\n    \"Composite Software\",\n    \"Compsesa\",\n    \"Computertekk\",\n    \"Compuware\",\n    \"Concurrent\",\n    \"Contexti\",\n    \"Continuent\",\n    \"Continuuity\",\n    \"Cotran Technologies\",\n    \"Cross Point Solutions\",\n    \"DFHeinz\",\n    \"Data Center Warehouse\",\n    \"Data Tactics\",\n    \"DataLayer\",\n    \"DataStax\",\n    \"DataTorrent\",\n    \"Databricks\",\n    \"Dataguise\",\n    \"Datalakes\",\n    \"Datameer\",\n    \"Daxpy\",\n    \"Decision Patterns\",\n    \"Dell\",\n    \"DiYOTTA\",\n    \"Digital Reasoning\",\n    \"DigitalRoute\",\n    \"Discovix\",\n    \"Dragonfly Data Factory\",\n    \"EMC\",\n    \"EOIR Technologies\",\n    \"Ecube\",\n    \"Elastacloud\",\n    \"Elasticsearch\",\n    \"EmergiNet\",\n    \"Eminent Software Services\",\n    \"Enfathom North Highland\",\n    \"Enterprise MapReduce\",\n    \"EnterpriseDB\",\n    \"Envision IT Group \",\n    \"Evolver\",\n    \"Exar\",\n    \"Excedis\",\n    \"Excel Big Data\",\n    \"Exilant\",\n    \"FDM Group\",\n    \"FORMCEPT\",\n    \"Factual\",\n    \"Fast Data Connect\",\n    \"Fingerprint Consultancy\",\n    \"Fino Consulting\",\n    \"First Light Technologies\",\n    \"Force10\",\n    \"Fusion-io\",\n    \"Fusionex\",\n    \"GCA Technology Services\",\n    \"GNS Healthcare\",\n    \"GTRI\",\n    \"Gazzang\",\n    \"Globalscape\",\n    \"Globant\",\n    \"Gnip\",\n    \"GoGrid\",\n    \"Google Compute Engine\",\n    \"GrayMatter\",\n    \"Guavus\",\n    \"H2O\",\n    \"HVR Software\",\n    \"Hadapt\",\n    \"Hadoop Illuminated\",\n    \"Happiest Minds\",\n    \"Heerbod Corp.\",\n    \"Hewlett Packard\",\n    \"Hortonworks\",\n    \"Hstreaming\",\n    \"IBM\",\n    \"ICC\",\n    \"IDA Solutions\",\n    \"IIS Technology\",\n    \"IKANOW\",\n    \"ITC Infotech\",\n    \"Ideas2IT\",\n    \"Ideation816 Corporation\",\n    \"Impetus\",\n    \"Impetus Technologies\",\n    \"Indigo New Zealand Limited\",\n    \"InfiniDB\",\n    \"InfoCentric\",\n    \"InfoObjects\",\n    \"InfoTrellis\",\n    \"Informatica\",\n    \"Information Builders\",\n    \"InsightsOne\",\n    \"Integrated Cyber Solutions\",\n    \"IntegriChain\",\n    \"Intel\",\n    \"Intelent\",\n    \"InterSys Consulting\",\n    \"Interactive Algorithms Inc. \",\n    \"IronBrick\",\n    \"Isilon\",\n    \"Ispirer\",\n    \"Jaspersoft\",\n    \"Joyent\",\n    \"KPI Partners Inc.\",\n    \"KPO Partners\",\n    \"Kaggle\",\n    \"KarmaSphere\",\n    \"Karmasphere\",\n    \"Keylink Technology\",\n    \"Keymobile Software\",\n    \"Kinney Group\",\n    \"KloudData\",\n    \"Knowledge Solutions\",\n    \"Knowledgent\",\n    \"Kognitio\",\n    \"Koverser\",\n    \"L&amp;T Infotech\",\n    \"LG CNS \",\n    \"LOOK Innovative\",\n    \"LSI\",\n    \"Latta Partners\",\n    \"Lericon Informatics\",\n    \"Likya Teknoloji\",\n    \"Linux Polska\",\n    \"Logi Analytics\",\n    \"LogiAnalytics\",\n    \"London Consulting Ltd.\",\n    \"Looker\",\n    \"LucidWorks\",\n    \"MZMTechnologies\",\n    \"ManTech\",\n    \"MapR\",\n    \"MarkLogic\",\n    \"Maxonic\",\n    \"McKnight Consulting Group\",\n    \"Mellanox Technologies\",\n    \"MetaScale\",\n    \"Metric Insights\",\n    \"MicroStrategy\",\n    \"Micron\",\n    \"Microsoft\",\n    \"Mikan Associates\",\n    \"Miri InfoTech\",\n    \"MisOne Solution\",\n    \"Mission First\",\n    \"MongoDB\",\n    \"Moser Consulting\",\n    \"Mund Consulting\",\n    \"Myers-Holum\",\n    \"NFLabs\",\n    \"NGData\",\n    \"NS Solutions\",\n    \"NTC Vulkan\",\n    \"NYSE\",\n    \"Narus\",\n    \"Nautilus Technologies\",\n    \"NectarGlobe Technology Solutions\",\n    \"NetApp\",\n    \"Netmind\",\n    \"New Era Technologies\",\n    \"NimbleScale\",\n    \"NorCom\",\n    \"Nous Infosystems\",\n    \"Novetta Solutions\",\n    \"Nutanix\",\n    \"OCTO\",\n    \"OnX Enterprise Solutions\",\n    \"Onepoint IQ\",\n    \"Onramp Corporation\",\n    \"Open Software Integrators\",\n    \"OpenBI\",\n    \"OpenOsmium\",\n    \"Opex Software\",\n    \"Options I/O\",\n    \"Oran Technology\",\n    \"Orzota\",\n    \"PRECOGNX\",\n    \"PSSC Labs\",\n    \"Pactera\",\n    \"Panasas\",\n    \"Panorama\",\n    \"Pentaho\",\n    \"Pepperdata\",\n    \"Perficient\",\n    \"Persistent Systems\",\n    \"Pervasive Big Data &amp; Analytics\",\n    \"Pervasive Data Innovation\",\n    \"PiTech Solutions\",\n    \"Platfora\",\n    \"Polyform Labs\",\n    \"PrediGO!\",\n    \"Predictive Analytics Corporation\",\n    \"Predixion\",\n    \"Prime Dimensions, LLC\",\n    \"Procima Experts\",\n    \"Progress\",\n    \"Propus\",\n    \"Prosys\",\n    \"Protegrity\",\n    \"QA\",\n    \"QLogic\",\n    \"Qlik\",\n    \"QlikView\",\n    \"Qubole\",\n    \"QuickLogix LLC\",\n    \"RCS Education\",\n    \"RTTS\",\n    \"Rackspace\",\n    \"Radoop\",\n    \"RailsFactory\",\n    \"RainStor\",\n    \"Recombinant by Deloitte\",\n    \"Red Gate\",\n    \"Red Hat\",\n    \"RedPoint Global\",\n    \"Revelytix\",\n    \"Revolution Analytics\",\n    \"Revolutionary Machines\",\n    \"SAP\",\n    \"SAS\",\n    \"SCG Solutions\",\n    \"SEED Infotech\",\n    \"SELA\",\n    \"SGI\",\n    \"SHMsoft\",\n    \"SHS-Viveon\",\n    \"SUN Microsystems\",\n    \"SUSE\",\n    \"SYNTASA\",\n    \"Saama Technologies\",\n    \"Sakura Sky Media\",\n    \"Savvis\",\n    \"Scale Abilities\",\n    \"ScaleOut Software\",\n    \"Scaled Risk\",\n    \"Scorecard Systems\",\n    \"Seagate\",\n    \"Sematext\",\n    \"Sendero Business Services\",\n    \"Serendio\",\n    \"Seynur\",\n    \"Sierra Technology\",\n    \"SilverSpring Networks\",\n    \"Simba\",\n    \"Sinergy\",\n    \"Skytree\",\n    \"SnapLogic\",\n    \"SoftNet Solutions\",\n    \"Solarflare\",\n    \"SolidQ\",\n    \"Solus Group\",\n    \"Sophias\",\n    \"Space-Time Insight\",\n    \"Spectra Logic\",\n    \"SpectraMind Solutions\",\n    \"Splunk\",\n    \"Spring\",\n    \"Spry\",\n    \"Sqrrl\",\n    \"Squid Solutions\",\n    \"StackIQ\",\n    \"Strategic IT Security\",\n    \"Strategix Solutions\",\n    \"Streambase\",\n    \"Sunset Learning Institute\",\n    \"Supermicro\",\n    \"Switch NAP\",\n    \"Symantec\",\n    \"Syncsort\",\n    \"Syncwork\",\n    \"Syntel\",\n    \"Systematix Infotech\",\n    \"T4G\",\n    \"TCloud Computing\",\n    \"TDK Technologies\",\n    \"TIBCO Software\",\n    \"Tableau Software\",\n    \"Talend\",\n    \"Tamr\",\n    \"Tata Consultancy Services\",\n    \"Teradata\",\n    \"The Principal Consulting\",\n    \"Think Big Analytics\",\n    \"Third Eye Consulting Services &amp; Solutions\",\n    \"ThrivOn\",\n    \"Tibco Spotfire\",\n    \"TipDM Intelligent Technology\",\n    \"Tissow\",\n    \"Trace3\",\n    \"Transcend Business Intelligence\",\n    \"Trendwise Analytics\",\n    \"Tresata\",\n    \"Tri-IT Solutions\",\n    \"Trifacta\",\n    \"Twingo\",\n    \"UL Environment\",\n    \"Ubeeko\",\n    \"Univa\",\n    \"VCE\",\n    \"VLDB Solutions\",\n    \"VMWare\",\n    \"VRV Solutions\",\n    \"Vanilla\",\n    \"Vector Technology Solutions\",\n    \"Veristorm\",\n    \"Vertascale\",\n    \"Vertica\",\n    \"Vinnox Technologies\",\n    \"Violin Memory\",\n    \"Virtual Infotech\",\n    \"VirtualScale\",\n    \"Viscosity North America\",\n    \"VoltDB\",\n    \"Voltage Security\",\n    \"WANdisco\",\n    \"WE-Ankor\",\n    \"WHIPTAIL\",\n    \"West Monroe Partners\",\n    \"WhiteKlay\",\n    \"Wipro Technologies\",\n    \"World Wide Technology\",\n    \"XCentium\",\n    \"XOR Security\",\n    \"Xenolytics\",\n    \"Xplenty\",\n    \"Xtreme Insights\",\n    \"Yeswici LLC\",\n    \"Z Data Inc.\",\n    \"ZData\",\n    \"Zaloni\",\n    \"Zementis\",\n    \"Zettaset\",\n    \"Zuhlke Engineering\",\n    \"acentrix\",\n    \"adesso AG\",\n    \"cimt AG\",\n    \"codecentric\",\n    \"comSysto\",\n    \"eCapital Advisors\",\n    \"eHire Labs\",\n    \"eSage Group\",\n    \"eTouch Systems\",\n    \"iQuest\",\n    \"iTalent Corporation\",\n    \"iTrend\",\n    \"immixGroup\",\n    \"is-land Systems Inc.\",\n    \"Pivotal\"\n]</code></pre></p>", "content_raw": "<p><pre><code>[\n    \"0xdata\",\n    \"10gen\",\n    \"A-TRAC\",\n    \"A3 Data\",\n    \"ABYRES Enterprise Technologies\",\n    \"AE Business Solutions\",\n    \"AMD\",\n    \"APEXCNS\",\n    \"ASD TECH\",\n    \"Ab Initio\",\n    \"Abitech Software\",\n    \"Accenture\",\n    \"Acentrix\",\n    \"Actian\",\n    \"Active Network\",\n    \"Actuate\",\n    \"Adastra\",\n    \"Admatic\",\n    \"Advanced Analytic Services\",\n    \"Advanced Micro Devices\",\n    \"Advizor\",\n    \"Aeronomy\",\n    \"Aeverie Inc.\",\n    \"Affini-Tech\",\n    \"Agile Bay\",\n    \"Aha! Software\",\n    \"Aleron\",\n    \"AllianceONE\",\n    \"AlphaSix Corporation\",\n    \"Alpine Data Labs\",\n    \"Alteryx\",\n    \"Altic\",\n    \"Altior Inc\",\n    \"Altiscale\",\n    \"Altoros\",\n    \"Amazon Elastic MapReduce\",\n    \"Amdocs\",\n    \"Anji Technologies\",\n    \"Apara Solutions\",\n    \"Apervi\",\n    \"AppFluent\",\n    \"Appcara\",\n    \"Appfluent\",\n    \"Appnovation\",\n    \"AquaFold\",\n    \"Archius\",\n    \"Argil Data\",\n    \"Aricent\",\n    \"Arieso\",\n    \"Arista Networks\",\n    \"Artis Consulting\",\n    \"Assembly Data System\",\n    \"Atigeo\",\n    \"Attivio\",\n    \"Attunity\",\n    \"Audaque Data Technology\",\n    \"AugmentIQ Data Sciences\",\n    \"Aurelius\",\n    \"Avalon Consulting\",\n    \"Avenues International\",\n    \"Axeldata Systems FZ-LLC\",\n    \"Ayasdi\",\n    \"Aziksa\",\n    \"Azul Systems\",\n    \"Azuris\",\n    \"B1 Systems GmbH\",\n    \"BC Cloud\",\n    \"BDI Systems\",\n    \"BI Acuity\",\n    \"BMC Software\",\n    \"BPM-Conseil\",\n    \"Basis Technology\",\n    \"BeagleData\",\n    \"Big Data Elephants, Inc.\",\n    \"Big Data Partnership\",\n    \"Big Switch Networks\",\n    \"BigDataStrategies\",\n    \"Bilginc IT Academy\",\n    \"Bilot\",\n    \"BioDatomics\",\n    \"Birst\",\n    \"Bit Stew Systems\",\n    \"BizData\",\n    \"Blue Canopy Group, LLC\",\n    \"BlueData Software\",\n    \"BlueGranite\",\n    \"BlueMetal Architects\",\n    \"BluePatagon\",\n    \"Booz Allen Hamilton\",\n    \"Boundary\",\n    \"BrainPad Inc.\",\n    \"Bright Computing \",\n    \"Brillio\",\n    \"Brocade\",\n    \"Bruhati\",\n    \"Bull\",\n    \"Business Objects\",\n    \"CAS\",\n    \"COMAT Training Services Pte Ltd\",\n    \"CR-X\",\n    \"CS InIT\",\n    \"CSC\",\n    \"Calpont Corporation\",\n    \"Calxeda\",\n    \"Canonical\",\n    \"Capgemini\",\n    \"Carahsoft\",\n    \"Caserta Concepts\",\n    \"Celer Technologies\",\n    \"Centric Consulting\",\n    \"CenturyLink Technology Solutions\",\n    \"Chicago Business Intelligence Group\",\n    \"Ciber\",\n    \"Cirro\",\n    \"Cisco\",\n    \"Clarity Solution Group\",\n    \"ClearDATA\",\n    \"Cleo\",\n    \"ClickFox\",\n    \"Cloud A\",\n    \"Cloud Front Group\",\n    \"Cloud Partners\",\n    \"Cloudera\",\n    \"Cloudwick\",\n    \"Coeo\",\n    \"Cognizant\",\n    \"Cognos\",\n    \"Collier IT\",\n    \"Compegence\",\n    \"Composite Software\",\n    \"Compsesa\",\n    \"Computertekk\",\n    \"Compuware\",\n    \"Concurrent\",\n    \"Contexti\",\n    \"Continuent\",\n    \"Continuuity\",\n    \"Cotran Technologies\",\n    \"Cross Point Solutions\",\n    \"DFHeinz\",\n    \"Data Center Warehouse\",\n    \"Data Tactics\",\n    \"DataLayer\",\n    \"DataStax\",\n    \"DataTorrent\",\n    \"Databricks\",\n    \"Dataguise\",\n    \"Datalakes\",\n    \"Datameer\",\n    \"Daxpy\",\n    \"Decision Patterns\",\n    \"Dell\",\n    \"DiYOTTA\",\n    \"Digital Reasoning\",\n    \"DigitalRoute\",\n    \"Discovix\",\n    \"Dragonfly Data Factory\",\n    \"EMC\",\n    \"EOIR Technologies\",\n    \"Ecube\",\n    \"Elastacloud\",\n    \"Elasticsearch\",\n    \"EmergiNet\",\n    \"Eminent Software Services\",\n    \"Enfathom North Highland\",\n    \"Enterprise MapReduce\",\n    \"EnterpriseDB\",\n    \"Envision IT Group \",\n    \"Evolver\",\n    \"Exar\",\n    \"Excedis\",\n    \"Excel Big Data\",\n    \"Exilant\",\n    \"FDM Group\",\n    \"FORMCEPT\",\n    \"Factual\",\n    \"Fast Data Connect\",\n    \"Fingerprint Consultancy\",\n    \"Fino Consulting\",\n    \"First Light Technologies\",\n    \"Force10\",\n    \"Fusion-io\",\n    \"Fusionex\",\n    \"GCA Technology Services\",\n    \"GNS Healthcare\",\n    \"GTRI\",\n    \"Gazzang\",\n    \"Globalscape\",\n    \"Globant\",\n    \"Gnip\",\n    \"GoGrid\",\n    \"Google Compute Engine\",\n    \"GrayMatter\",\n    \"Guavus\",\n    \"H2O\",\n    \"HVR Software\",\n    \"Hadapt\",\n    \"Hadoop Illuminated\",\n    \"Happiest Minds\",\n    \"Heerbod Corp.\",\n    \"Hewlett Packard\",\n    \"Hortonworks\",\n    \"Hstreaming\",\n    \"IBM\",\n    \"ICC\",\n    \"IDA Solutions\",\n    \"IIS Technology\",\n    \"IKANOW\",\n    \"ITC Infotech\",\n    \"Ideas2IT\",\n    \"Ideation816 Corporation\",\n    \"Impetus\",\n    \"Impetus Technologies\",\n    \"Indigo New Zealand Limited\",\n    \"InfiniDB\",\n    \"InfoCentric\",\n    \"InfoObjects\",\n    \"InfoTrellis\",\n    \"Informatica\",\n    \"Information Builders\",\n    \"InsightsOne\",\n    \"Integrated Cyber Solutions\",\n    \"IntegriChain\",\n    \"Intel\",\n    \"Intelent\",\n    \"InterSys Consulting\",\n    \"Interactive Algorithms Inc. \",\n    \"IronBrick\",\n    \"Isilon\",\n    \"Ispirer\",\n    \"Jaspersoft\",\n    \"Joyent\",\n    \"KPI Partners Inc.\",\n    \"KPO Partners\",\n    \"Kaggle\",\n    \"KarmaSphere\",\n    \"Karmasphere\",\n    \"Keylink Technology\",\n    \"Keymobile Software\",\n    \"Kinney Group\",\n    \"KloudData\",\n    \"Knowledge Solutions\",\n    \"Knowledgent\",\n    \"Kognitio\",\n    \"Koverser\",\n    \"L&T Infotech\",\n    \"LG CNS \",\n    \"LOOK Innovative\",\n    \"LSI\",\n    \"Latta Partners\",\n    \"Lericon Informatics\",\n    \"Likya Teknoloji\",\n    \"Linux Polska\",\n    \"Logi Analytics\",\n    \"LogiAnalytics\",\n    \"London Consulting Ltd.\",\n    \"Looker\",\n    \"LucidWorks\",\n    \"MZMTechnologies\",\n    \"ManTech\",\n    \"MapR\",\n    \"MarkLogic\",\n    \"Maxonic\",\n    \"McKnight Consulting Group\",\n    \"Mellanox Technologies\",\n    \"MetaScale\",\n    \"Metric Insights\",\n    \"MicroStrategy\",\n    \"Micron\",\n    \"Microsoft\",\n    \"Mikan Associates\",\n    \"Miri InfoTech\",\n    \"MisOne Solution\",\n    \"Mission First\",\n    \"MongoDB\",\n    \"Moser Consulting\",\n    \"Mund Consulting\",\n    \"Myers-Holum\",\n    \"NFLabs\",\n    \"NGData\",\n    \"NS Solutions\",\n    \"NTC Vulkan\",\n    \"NYSE\",\n    \"Narus\",\n    \"Nautilus Technologies\",\n    \"NectarGlobe Technology Solutions\",\n    \"NetApp\",\n    \"Netmind\",\n    \"New Era Technologies\",\n    \"NimbleScale\",\n    \"NorCom\",\n    \"Nous Infosystems\",\n    \"Novetta Solutions\",\n    \"Nutanix\",\n    \"OCTO\",\n    \"OnX Enterprise Solutions\",\n    \"Onepoint IQ\",\n    \"Onramp Corporation\",\n    \"Open Software Integrators\",\n    \"OpenBI\",\n    \"OpenOsmium\",\n    \"Opex Software\",\n    \"Options I/O\",\n    \"Oran Technology\",\n    \"Orzota\",\n    \"PRECOGNX\",\n    \"PSSC Labs\",\n    \"Pactera\",\n    \"Panasas\",\n    \"Panorama\",\n    \"Pentaho\",\n    \"Pepperdata\",\n    \"Perficient\",\n    \"Persistent Systems\",\n    \"Pervasive Big Data & Analytics\",\n    \"Pervasive Data Innovation\",\n    \"PiTech Solutions\",\n    \"Platfora\",\n    \"Polyform Labs\",\n    \"PrediGO!\",\n    \"Predictive Analytics Corporation\",\n    \"Predixion\",\n    \"Prime Dimensions, LLC\",\n    \"Procima Experts\",\n    \"Progress\",\n    \"Propus\",\n    \"Prosys\",\n    \"Protegrity\",\n    \"QA\",\n    \"QLogic\",\n    \"Qlik\",\n    \"QlikView\",\n    \"Qubole\",\n    \"QuickLogix LLC\",\n    \"RCS Education\",\n    \"RTTS\",\n    \"Rackspace\",\n    \"Radoop\",\n    \"RailsFactory\",\n    \"RainStor\",\n    \"Recombinant by Deloitte\",\n    \"Red Gate\",\n    \"Red Hat\",\n    \"RedPoint Global\",\n    \"Revelytix\",\n    \"Revolution Analytics\",\n    \"Revolutionary Machines\",\n    \"SAP\",\n    \"SAS\",\n    \"SCG Solutions\",\n    \"SEED Infotech\",\n    \"SELA\",\n    \"SGI\",\n    \"SHMsoft\",\n    \"SHS-Viveon\",\n    \"SUN Microsystems\",\n    \"SUSE\",\n    \"SYNTASA\",\n    \"Saama Technologies\",\n    \"Sakura Sky Media\",\n    \"Savvis\",\n    \"Scale Abilities\",\n    \"ScaleOut Software\",\n    \"Scaled Risk\",\n    \"Scorecard Systems\",\n    \"Seagate\",\n    \"Sematext\",\n    \"Sendero Business Services\",\n    \"Serendio\",\n    \"Seynur\",\n    \"Sierra Technology\",\n    \"SilverSpring Networks\",\n    \"Simba\",\n    \"Sinergy\",\n    \"Skytree\",\n    \"SnapLogic\",\n    \"SoftNet Solutions\",\n    \"Solarflare\",\n    \"SolidQ\",\n    \"Solus Group\",\n    \"Sophias\",\n    \"Space-Time Insight\",\n    \"Spectra Logic\",\n    \"SpectraMind Solutions\",\n    \"Splunk\",\n    \"Spring\",\n    \"Spry\",\n    \"Sqrrl\",\n    \"Squid Solutions\",\n    \"StackIQ\",\n    \"Strategic IT Security\",\n    \"Strategix Solutions\",\n    \"Streambase\",\n    \"Sunset Learning Institute\",\n    \"Supermicro\",\n    \"Switch NAP\",\n    \"Symantec\",\n    \"Syncsort\",\n    \"Syncwork\",\n    \"Syntel\",\n    \"Systematix Infotech\",\n    \"T4G\",\n    \"TCloud Computing\",\n    \"TDK Technologies\",\n    \"TIBCO Software\",\n    \"Tableau Software\",\n    \"Talend\",\n    \"Tamr\",\n    \"Tata Consultancy Services\",\n    \"Teradata\",\n    \"The Principal Consulting\",\n    \"Think Big Analytics\",\n    \"Third Eye Consulting Services & Solutions\",\n    \"ThrivOn\",\n    \"Tibco Spotfire\",\n    \"TipDM Intelligent Technology\",\n    \"Tissow\",\n    \"Trace3\",\n    \"Transcend Business Intelligence\",\n    \"Trendwise Analytics\",\n    \"Tresata\",\n    \"Tri-IT Solutions\",\n    \"Trifacta\",\n    \"Twingo\",\n    \"UL Environment\",\n    \"Ubeeko\",\n    \"Univa\",\n    \"VCE\",\n    \"VLDB Solutions\",\n    \"VMWare\",\n    \"VRV Solutions\",\n    \"Vanilla\",\n    \"Vector Technology Solutions\",\n    \"Veristorm\",\n    \"Vertascale\",\n    \"Vertica\",\n    \"Vinnox Technologies\",\n    \"Violin Memory\",\n    \"Virtual Infotech\",\n    \"VirtualScale\",\n    \"Viscosity North America\",\n    \"VoltDB\",\n    \"Voltage Security\",\n    \"WANdisco\",\n    \"WE-Ankor\",\n    \"WHIPTAIL\",\n    \"West Monroe Partners\",\n    \"WhiteKlay\",\n    \"Wipro Technologies\",\n    \"World Wide Technology\",\n    \"XCentium\",\n    \"XOR Security\",\n    \"Xenolytics\",\n    \"Xplenty\",\n    \"Xtreme Insights\",\n    \"Yeswici LLC\",\n    \"Z Data Inc.\",\n    \"ZData\",\n    \"Zaloni\",\n    \"Zementis\",\n    \"Zettaset\",\n    \"Zuhlke Engineering\",\n    \"acentrix\",\n    \"adesso AG\",\n    \"cimt AG\",\n    \"codecentric\",\n    \"comSysto\",\n    \"eCapital Advisors\",\n    \"eHire Labs\",\n    \"eSage Group\",\n    \"eTouch Systems\",\n    \"iQuest\",\n    \"iTalent Corporation\",\n    \"iTrend\",\n    \"immixGroup\",\n    \"is-land Systems Inc.\",\n    \"Pivotal\"\n]</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "93271562269"}}], "date": "2014-07-30 03:10:00 GMT", "slug": "a-list-of-hadoop-vendors", "blog_name": "rjurney", "summary": "A List of Hadoop Vendors", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "VpgdXXOH", "short_url": "https://tmblr.co/ZbIO5y1IndgMV", "can_send_in_message": true, "id": 88879310239, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/88879310239", "tags": [], "post_url": "http://datasyndrome.com/post/88879310239/new-robot-tattoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>New robot tattoo!</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1402859171, "note_count": 2, "trail": [{"content": "<p>New robot tattoo!</p>", "content_raw": "<p>New robot tattoo!</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "88879310239"}}], "date": "2014-06-15 19:06:11 GMT", "slug": "new-robot-tattoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/cab91dbbccbbc492076dda3465ed9326/tumblr_n7852bvyde1qe7pymo1_500.jpg", "width": 426, "height": 568}, "alt_sizes": [{"url": "https://68.media.tumblr.com/cab91dbbccbbc492076dda3465ed9326/tumblr_n7852bvyde1qe7pymo1_500.jpg", "width": 426, "height": 568}, {"url": "https://68.media.tumblr.com/cab91dbbccbbc492076dda3465ed9326/tumblr_n7852bvyde1qe7pymo1_400.jpg", "width": 400, "height": 533}, {"url": "https://68.media.tumblr.com/cab91dbbccbbc492076dda3465ed9326/tumblr_n7852bvyde1qe7pymo1_250.jpg", "width": 250, "height": 333}, {"url": "https://68.media.tumblr.com/cab91dbbccbbc492076dda3465ed9326/tumblr_n7852bvyde1qe7pymo1_100.jpg", "width": 100, "height": 133}, {"url": "https://68.media.tumblr.com/cab91dbbccbbc492076dda3465ed9326/tumblr_n7852bvyde1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "summary": "New robot tattoo!", "caption": "<p>New robot tattoo!</p>", "can_reblog": true}, {"body": "Recently I discovered how to load Avros in Spark using a Hadoop InputFormat.  \n\n<pre><code>import org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\n\nimport org.apache.avro.generic.GenericRecord\nimport org.apache.avro.mapred.AvroKey\nimport org.apache.avro.mapred.AvroInputFormat\nimport org.apache.avro.mapreduce.AvroKeyInputFormat\nimport org.apache.hadoop.io.NullWritable\nimport org.apache.commons.lang.StringEscapeUtils.escapeCsv\n\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.fs.Path\nimport org.apache.hadoop.conf.Configuration\nimport java.io.BufferedInputStream\nimport org.apache.avro.file.DataFileStream\nimport org.apache.avro.io.DatumReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.generic.{GenericDatumReader, GenericRecord}\nimport org.apache.avro.mapred.FsInput\nimport org.apache.avro.Schema\nimport org.apache.avro.Schema.Parser\nimport org.apache.hadoop.mapred.JobConf\nimport java.io.File\nimport java.net.URI\n\n// spark-shell -usejavacp -classpath \"*.jar\"\n\nval input = \"hdfs://hivecluster2/securityx/web_proxy_mef/2014/05/29/22/part-m-00016.avro\"\n\nval jobConf= new JobConf(sc.hadoopConfiguration)\nval rdd = sc.hadoopFile(\n  input,\n  classOf[org.apache.avro.mapred.AvroInputFormat[GenericRecord]],\n  classOf[org.apache.avro.mapred.AvroWrapper[GenericRecord]],\n  classOf[org.apache.hadoop.io.NullWritable],\n  10)\nval f1 = rdd.first\nval a = f1._1.datum\na.get(\"rawLog\") // Access avro fields</code></pre>", "liked": false, "followed": false, "reblog_key": "orNwYPcU", "reblog": {"comment": "<p>Recently I discovered how to load Avros in Spark using a Hadoop InputFormat.  \n\n<pre><code>import org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\n\nimport org.apache.avro.generic.GenericRecord\nimport org.apache.avro.mapred.AvroKey\nimport org.apache.avro.mapred.AvroInputFormat\nimport org.apache.avro.mapreduce.AvroKeyInputFormat\nimport org.apache.hadoop.io.NullWritable\nimport org.apache.commons.lang.StringEscapeUtils.escapeCsv\n\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.fs.Path\nimport org.apache.hadoop.conf.Configuration\nimport java.io.BufferedInputStream\nimport org.apache.avro.file.DataFileStream\nimport org.apache.avro.io.DatumReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.generic.{GenericDatumReader, GenericRecord}\nimport org.apache.avro.mapred.FsInput\nimport org.apache.avro.Schema\nimport org.apache.avro.Schema.Parser\nimport org.apache.hadoop.mapred.JobConf\nimport java.io.File\nimport java.net.URI\n\n// spark-shell -usejavacp -classpath \"*.jar\"\n\nval input = \"hdfs://hivecluster2/securityx/web_proxy_mef/2014/05/29/22/part-m-00016.avro\"\n\nval jobConf= new JobConf(sc.hadoopConfiguration)\nval rdd = sc.hadoopFile(\n  input,\n  classOf[org.apache.avro.mapred.AvroInputFormat[GenericRecord]],\n  classOf[org.apache.avro.mapred.AvroWrapper[GenericRecord]],\n  classOf[org.apache.hadoop.io.NullWritable],\n  10)\nval f1 = rdd.first\nval a = f1._1.datum\na.get(\"rawLog\") // Access avro fields</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 87434589204, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Loading Avros in Spark", "tags": [], "post_url": "http://datasyndrome.com/post/87434589204/loading-avros-in-spark", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1HRWVGK", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1401576701, "note_count": 1, "trail": [{"content": "<p><p>Recently I discovered how to load Avros in Spark using a Hadoop InputFormat.  \n\n</p><pre><code>import org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\n\nimport org.apache.avro.generic.GenericRecord\nimport org.apache.avro.mapred.AvroKey\nimport org.apache.avro.mapred.AvroInputFormat\nimport org.apache.avro.mapreduce.AvroKeyInputFormat\nimport org.apache.hadoop.io.NullWritable\nimport org.apache.commons.lang.StringEscapeUtils.escapeCsv\n\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.fs.Path\nimport org.apache.hadoop.conf.Configuration\nimport java.io.BufferedInputStream\nimport org.apache.avro.file.DataFileStream\nimport org.apache.avro.io.DatumReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.generic.{GenericDatumReader, GenericRecord}\nimport org.apache.avro.mapred.FsInput\nimport org.apache.avro.Schema\nimport org.apache.avro.Schema.Parser\nimport org.apache.hadoop.mapred.JobConf\nimport java.io.File\nimport java.net.URI\n\n// spark-shell -usejavacp -classpath \"*.jar\"\n\nval input = \"hdfs://hivecluster2/securityx/web_proxy_mef/2014/05/29/22/part-m-00016.avro\"\n\nval jobConf= new JobConf(sc.hadoopConfiguration)\nval rdd = sc.hadoopFile(\n  input,\n  classOf[org.apache.avro.mapred.AvroInputFormat[GenericRecord]],\n  classOf[org.apache.avro.mapred.AvroWrapper[GenericRecord]],\n  classOf[org.apache.hadoop.io.NullWritable],\n  10)\nval f1 = rdd.first\nval a = f1._1.datum\na.get(\"rawLog\") // Access avro fields</code></pre></p>", "content_raw": "<p>Recently I discovered how to load Avros in Spark using a Hadoop InputFormat.  \n\n<pre><code>import org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\n\nimport org.apache.avro.generic.GenericRecord\nimport org.apache.avro.mapred.AvroKey\nimport org.apache.avro.mapred.AvroInputFormat\nimport org.apache.avro.mapreduce.AvroKeyInputFormat\nimport org.apache.hadoop.io.NullWritable\nimport org.apache.commons.lang.StringEscapeUtils.escapeCsv\n\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.fs.Path\nimport org.apache.hadoop.conf.Configuration\nimport java.io.BufferedInputStream\nimport org.apache.avro.file.DataFileStream\nimport org.apache.avro.io.DatumReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.file.DataFileReader\nimport org.apache.avro.generic.{GenericDatumReader, GenericRecord}\nimport org.apache.avro.mapred.FsInput\nimport org.apache.avro.Schema\nimport org.apache.avro.Schema.Parser\nimport org.apache.hadoop.mapred.JobConf\nimport java.io.File\nimport java.net.URI\n\n// spark-shell -usejavacp -classpath \"*.jar\"\n\nval input = \"hdfs://hivecluster2/securityx/web_proxy_mef/2014/05/29/22/part-m-00016.avro\"\n\nval jobConf= new JobConf(sc.hadoopConfiguration)\nval rdd = sc.hadoopFile(\n  input,\n  classOf[org.apache.avro.mapred.AvroInputFormat[GenericRecord]],\n  classOf[org.apache.avro.mapred.AvroWrapper[GenericRecord]],\n  classOf[org.apache.hadoop.io.NullWritable],\n  10)\nval f1 = rdd.first\nval a = f1._1.datum\na.get(\"rawLog\") // Access avro fields</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "87434589204"}}], "date": "2014-05-31 22:51:41 GMT", "slug": "loading-avros-in-spark", "blog_name": "rjurney", "summary": "Loading Avros in Spark", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "3tsLDIq7", "short_url": "https://tmblr.co/ZbIO5y14DvV_6", "can_send_in_message": true, "thumbnail_width": 480, "player": [{"width": 250, "embed_code": "<iframe width=\"250\" height=\"141\"  id=\"youtube_iframe\" src=\"https://www.youtube.com/embed/woZdwluR3GM?feature=oembed&amp;enablejsapi=1&amp;origin=http://safe.txmblr.com&amp;wmode=opaque\" frameborder=\"0\" allowfullscreen></iframe>"}, {"width": 400, "embed_code": "<iframe width=\"400\" height=\"225\"  id=\"youtube_iframe\" src=\"https://www.youtube.com/embed/woZdwluR3GM?feature=oembed&amp;enablejsapi=1&amp;origin=http://safe.txmblr.com&amp;wmode=opaque\" frameborder=\"0\" allowfullscreen></iframe>"}, {"width": 500, "embed_code": "<iframe width=\"500\" height=\"281\"  id=\"youtube_iframe\" src=\"https://www.youtube.com/embed/woZdwluR3GM?feature=oembed&amp;enablejsapi=1&amp;origin=http://safe.txmblr.com&amp;wmode=opaque\" frameborder=\"0\" allowfullscreen></iframe>"}], "video": {"youtube": {"width": 540, "video_id": "woZdwluR3GM", "height": 304}}, "id": 73247620998, "display_avatar": true, "can_reply": true, "can_like": false, "tags": [], "post_url": "http://datasyndrome.com/post/73247620998/me-presenting-on-agile-data-science-to-the-sf-data", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Me presenting on Agile Data Science to the SF Data Sciene meetup. This is probably the best version of this talk I\u2019ve given.</p>", "tree_html": ""}, "html5_capable": true, "type": "video", "recommended_color": null, "format": "html", "timestamp": 1389656411, "note_count": 1, "video_type": "youtube", "trail": [{"content": "<p>Me presenting on Agile Data Science to the SF Data Sciene meetup. This is probably the best version of this talk I&rsquo;ve given.</p>", "content_raw": "<p>Me presenting on Agile Data Science to the SF Data Sciene meetup. This is probably the best version of this talk I\u2019ve given.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "73247620998"}}], "date": "2014-01-13 23:40:11 GMT", "thumbnail_height": 360, "permalink_url": "https://www.youtube.com/watch?v=woZdwluR3GM", "slug": "me-presenting-on-agile-data-science-to-the-sf-data", "blog_name": "rjurney", "summary": "Me presenting on Agile Data Science to the SF Data Sciene meetup. This is probably the best version of this talk I've given.", "caption": "<p>Me presenting on Agile Data Science to the SF Data Sciene meetup. This is probably the best version of this talk I&rsquo;ve given.</p>", "thumbnail_url": "https://i.ytimg.com/vi/woZdwluR3GM/hqdefault.jpg", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "vtVvJtub", "short_url": "https://tmblr.co/ZbIO5y12xbfWU", "can_send_in_message": true, "id": 71866685470, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/71866685470", "tags": [], "post_url": "http://datasyndrome.com/post/71866685470/my-computing-career-aspirations-age-4", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>My computing career aspirations, age =~ 4</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1388602277, "note_count": 0, "trail": [{"content": "<p>My computing career aspirations, age =~ 4</p>", "content_raw": "<p>My computing career aspirations, age =~ 4</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "71866685470"}}], "date": "2014-01-01 18:51:17 GMT", "slug": "my-computing-career-aspirations-age-4", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/d3d06692a987beaed50ab52eb05e324a/tumblr_myqkdhat6d1qe7pymo1_1280.jpg", "width": 640, "height": 640}, "alt_sizes": [{"url": "https://68.media.tumblr.com/d3d06692a987beaed50ab52eb05e324a/tumblr_myqkdhat6d1qe7pymo1_1280.jpg", "width": 640, "height": 640}, {"url": "https://68.media.tumblr.com/d3d06692a987beaed50ab52eb05e324a/tumblr_myqkdhat6d1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/d3d06692a987beaed50ab52eb05e324a/tumblr_myqkdhat6d1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/d3d06692a987beaed50ab52eb05e324a/tumblr_myqkdhat6d1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/d3d06692a987beaed50ab52eb05e324a/tumblr_myqkdhat6d1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/d3d06692a987beaed50ab52eb05e324a/tumblr_myqkdhat6d1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "summary": "My computing career aspirations, age =~ 4", "caption": "<p>My computing career aspirations, age =~ 4</p>", "can_reblog": true}, {"body": "<p>All code for this post is open source and is available on <a href=\"https://github.com/rjurney/yelp_challenge\">github</a>. I was recently introduced to <a href=\"http://leafletjs.com\">leaflet.js</a>, a javascript map library that is <a href=\"http://leafletjs.com/examples/quick-start.html\">very easy to use</a>.\n\n</p><center><img src=\"https://68.media.tumblr.com/27a3d8466399fa23ed015e27aaee34dc/tumblr_inline_myh5bfvnxu1qdyhha.png\"/></center>\n\nI\u2019m using leaflet.js as part of my entry to the <a href=\"http://www.yelp.com/dataset_challenge/\">Yelp Dataset Challenge</a> - at the \u2018reporting\u2019 level of the data-value pyramid: to link business records together with relevant nearby businesses. The data in the challenge includes business data, that includes latitude/longitude data.\n\n<center><img src=\"https://68.media.tumblr.com/e65a0cee420afd03b8f004c12725fe69/tumblr_inline_myh5jkUyaC1qdyhha.png\"/></center>\n\n<br/>\nThe business data looks like this:\n\n<pre><code>{\n    'type': 'business',\n    'business_id': (encrypted business id),\n    'name': (business name),\n    'neighborhoods': [(hood names)],\n    'full_address': (localized address),\n    'city': (city),\n    'state': (state),\n    'latitude': latitude,\n    'longitude': longitude,\n    'stars': (star rating, rounded to half-stars),\n    'review_count': review count,\n    'categories': [(localized category names)]\n    'open': True / False (corresponds to closed, not business hours),\n}</code></pre>\n\nUsing this data, I computed the distance between all businesses of the same category in the dataset in Pig, like so:\n\n<pre><code>location_comparisons = JOIN locations BY category, locations_2 BY category USING 'replicated';                                                        \ndistances = FOREACH location_comparisons GENERATE flat_locations::business_id AS business_id_1,\n                    locations_2::business_id AS business_id_2,\n                    flat_locations::category AS category,\n                    udfs.haversine(flat_locations::longitude,\n                                   flat_locations::latitude,\n                                   locations_2::longitude,\n                                   locations_2::latitude) AS distance;</code></pre>\n\nThe haversine distance UDF looks like this (it uses <a href=\"http://pig.apache.org/docs/r0.12.0/udf.html#python-udfs\">CPython UDFs</a>, available in <a href=\"http://pig.apache.org/docs/r0.12.0/\">Pig 0.12</a>):\n\n<pre><code>@outputSchema(\"distance:double\")\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    # haversine formula\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a))\n    km = 6367 * c\n    return km</code></pre>\n\nThe results were grouped into the top ten nearest businesses and published to MongoDB:\n\n<pre><code>nearest_businesses = FOREACH (GROUP with_coords BY business_1) {\n    sorted = ORDER with_coords BY distance;\n    top_10 = LIMIT sorted 10;\n    GENERATE group AS business_id, \n             (float)(2.0 * MAX(top_10.distance)) AS range:float, \n             top_10.(business_2, name, latitude, longitude) AS nearest_businesses;\n}\nSTORE nearest_businesses INTO 'mongodb://localhost/yelp.nearest_businesses' USING MongoStorage();</code></pre>\n\nThese results are then served by a Python/Flask application using Bootstrap. Upon computing the top-ten nearest, relevant businesses, I was presented with the problem of figuring out the correct level of zoom to show all ten businesses. Initially I tried a simple linear mapping from one scale to another, but I could not make the zoom fit the data consistently. In about half of cases, the top 10 businesses would either be zoomed too far out, or zoomed in too far to show all ten businesses. The initial attempt at mapping looked like this:\n\n<pre><code>def map_degree_to_zoom(degree_value):\n    # Determined by experimentation with Leaflet UI and MAX() of distances in Pig\n    range_min = 0\n    range_max = 142\n    zoom_min = 7\n    zoom_max = 12\n    \n    # Compute ranges\n    range_span = range_max - range_min\n    zoom_span = zoom_max - zoom_min\n    \n    # Convert the left range into a 0-1 range (float)\n    value_scaled = float(degree_value - range_min) / float(range_span)\n    \n    # Convert the 0-1 range into a value in the right range.\n    return int(zoom_max - (value_scaled * zoom_span))</code></pre> \n\nSo I gathered data and turned to visualization. I collected data manually, by logging the maximum distance of the ten-nearest businesses against the minimum zoom level required to visualize them all at once. The data looks like this:\n\n<br/><br/><center>\n<table style=\"text-align: center; float:center; border=\" cellspacing=\"10\"><tr><td>1.26710856</td><td style=\"padding-left: 10px;\">15</td></tr><tr><td>0.418455511</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>4.176179886</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.059176445</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>2.985990286</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.584879398</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>0.341496378</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>0.633716404</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>3.525056601</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.084414959</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>0.713507891</td><td style=\"padding-left: 10px;\">15</td></tr><tr><td>15.74468708</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>6.349864006</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>5.078705788</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>6.349864006</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>9.700486183</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>25.13388824</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>13.71557617</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>0.065407977</td><td style=\"padding-left: 10px;\">18</td></tr><tr><td>11.24457836</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>12.29977512</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>20.05439949</td><td style=\"padding-left: 10px;\">11</td></tr></table></center>\n\nThe scatterplot looks like so:\n\n<img src=\"https://68.media.tumblr.com/6d9ca1fba3d746bdb73d11594ed65d29/tumblr_inline_myh7jyzjnL1qdyhha.png\"/>\n\nThe data correlation is strongly negative:\n\n<pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom math import log\n# Build X/Y arrays from file 1\nf = open('yelp_zoom_2.csv')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\nx = np.array(x)\ny = np.array(y)\n\nplt.plot(x, y, 'ro',label=\"Original Data\")\nnp.corrcoef(x,y) #-0.78</code></pre>\n\nA straight line is not a good fit, so I tried a log regression:\n\n<pre><code>def func(x, a, b):\n    y = a*(-np.log(x)) + b\n    return y\n\npopt, pcov = curve_fit(func, x, y)\nprint \"a = %s , b = %s\" % (popt[0], popt[1])\n\n# Trying to plot without using linspace will result in a chaotic, pissy plot that will confuse you.\n# numpy.linspace simply creates a series of evenly spaced X values to plot a continiuous function.\ntest_x = np.linspace(0,30,50)\nplt.plot(test_x, func(test_x, *popt), label=\"Fitted Curve\")</code></pre>\n\nWhich looks like a reasonable fit (note: you can easily do this in Excel):\n\n<img src=\"https://68.media.tumblr.com/fad250b4ab19e727e14892e68c4f46d7/tumblr_inline_myh7tlXRkJ1qdyhha.png\"/>\n\nThe benefit of doing this regression in Python and not Excel, is that I can now include the prediction in my web application like so:\n\n<pre><code># Apply result of regression\ndef map_km_to_zoom(km, a, b):\n    y = a*(-np.log(km)) + b\n    return y\n\n# Controller: Fetch a business and display it\n@app.route(\"/business/<business_id>\")\ndef business(business_id):\n    business = businesses.find_one({'business_id': business_id})\n    nearby = nearest_businesses.find_one({'business_id': business_id})\n    zoom_level = map_km_to_zoom(nearby['range'], 1.32809669067, 14.7211913904)\n    return render_template('partials/business.html', business=business, zoom_level=zoom_level)</business_id></code></pre>\n\nThis results in a clean mapping of distance in kilometers to the correct zoom level for leaflet.js.", "liked": false, "followed": false, "reblog_key": "JfxK8ncd", "reblog": {"comment": "<p><p>All code for this post is open source and is available on <a href=\"https://github.com/rjurney/yelp_challenge\">github</a>. I was recently introduced to <a href=\"http://leafletjs.com\">leaflet.js</a>, a javascript map library that is <a href=\"http://leafletjs.com/examples/quick-start.html\">very easy to use</a>.\n\n</p><center><img src=\"https://68.media.tumblr.com/27a3d8466399fa23ed015e27aaee34dc/tumblr_inline_myh5bfvnxu1qdyhha.png\"></center>\n\nI\u2019m using leaflet.js as part of my entry to the <a href=\"http://www.yelp.com/dataset_challenge/\">Yelp Dataset Challenge</a> - at the \u2018reporting\u2019 level of the data-value pyramid: to link business records together with relevant nearby businesses. The data in the challenge includes business data, that includes latitude/longitude data.\n\n<center><img src=\"https://68.media.tumblr.com/e65a0cee420afd03b8f004c12725fe69/tumblr_inline_myh5jkUyaC1qdyhha.png\"></center>\n\n<br>\nThe business data looks like this:\n\n<pre><code>{\n    'type': 'business',\n    'business_id': (encrypted business id),\n    'name': (business name),\n    'neighborhoods': [(hood names)],\n    'full_address': (localized address),\n    'city': (city),\n    'state': (state),\n    'latitude': latitude,\n    'longitude': longitude,\n    'stars': (star rating, rounded to half-stars),\n    'review_count': review count,\n    'categories': [(localized category names)]\n    'open': True / False (corresponds to closed, not business hours),\n}</code></pre>\n\nUsing this data, I computed the distance between all businesses of the same category in the dataset in Pig, like so:\n\n<pre><code>location_comparisons = JOIN locations BY category, locations_2 BY category USING 'replicated';                                                        \ndistances = FOREACH location_comparisons GENERATE flat_locations::business_id AS business_id_1,\n                    locations_2::business_id AS business_id_2,\n                    flat_locations::category AS category,\n                    udfs.haversine(flat_locations::longitude,\n                                   flat_locations::latitude,\n                                   locations_2::longitude,\n                                   locations_2::latitude) AS distance;</code></pre>\n\nThe haversine distance UDF looks like this (it uses <a href=\"http://pig.apache.org/docs/r0.12.0/udf.html#python-udfs\">CPython UDFs</a>, available in <a href=\"http://pig.apache.org/docs/r0.12.0/\">Pig 0.12</a>):\n\n<pre><code>@outputSchema(\"distance:double\")\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    # haversine formula\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a))\n    km = 6367 * c\n    return km</code></pre>\n\nThe results were grouped into the top ten nearest businesses and published to MongoDB:\n\n<pre><code>nearest_businesses = FOREACH (GROUP with_coords BY business_1) {\n    sorted = ORDER with_coords BY distance;\n    top_10 = LIMIT sorted 10;\n    GENERATE group AS business_id, \n             (float)(2.0 * MAX(top_10.distance)) AS range:float, \n             top_10.(business_2, name, latitude, longitude) AS nearest_businesses;\n}\nSTORE nearest_businesses INTO 'mongodb://localhost/yelp.nearest_businesses' USING MongoStorage();</code></pre>\n\nThese results are then served by a Python/Flask application using Bootstrap. Upon computing the top-ten nearest, relevant businesses, I was presented with the problem of figuring out the correct level of zoom to show all ten businesses. Initially I tried a simple linear mapping from one scale to another, but I could not make the zoom fit the data consistently. In about half of cases, the top 10 businesses would either be zoomed too far out, or zoomed in too far to show all ten businesses. The initial attempt at mapping looked like this:\n\n<pre><code>def map_degree_to_zoom(degree_value):\n    # Determined by experimentation with Leaflet UI and MAX() of distances in Pig\n    range_min = 0\n    range_max = 142\n    zoom_min = 7\n    zoom_max = 12\n    \n    # Compute ranges\n    range_span = range_max - range_min\n    zoom_span = zoom_max - zoom_min\n    \n    # Convert the left range into a 0-1 range (float)\n    value_scaled = float(degree_value - range_min) / float(range_span)\n    \n    # Convert the 0-1 range into a value in the right range.\n    return int(zoom_max - (value_scaled * zoom_span))</code></pre> \n\nSo I gathered data and turned to visualization. I collected data manually, by logging the maximum distance of the ten-nearest businesses against the minimum zoom level required to visualize them all at once. The data looks like this:\n\n<br><br><center>\n<table style=\"text-align: center; float:center; border=\" cellspacing=\"10\"><tr><td>1.26710856</td><td style=\"padding-left: 10px;\">15</td></tr><tr><td>0.418455511</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>4.176179886</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.059176445</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>2.985990286</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.584879398</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>0.341496378</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>0.633716404</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>3.525056601</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.084414959</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>0.713507891</td><td style=\"padding-left: 10px;\">15</td></tr><tr><td>15.74468708</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>6.349864006</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>5.078705788</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>6.349864006</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>9.700486183</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>25.13388824</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>13.71557617</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>0.065407977</td><td style=\"padding-left: 10px;\">18</td></tr><tr><td>11.24457836</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>12.29977512</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>20.05439949</td><td style=\"padding-left: 10px;\">11</td></tr></table></center>\n\nThe scatterplot looks like so:\n\n<img src=\"https://68.media.tumblr.com/6d9ca1fba3d746bdb73d11594ed65d29/tumblr_inline_myh7jyzjnL1qdyhha.png\">\n\nThe data correlation is strongly negative:\n\n<pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom math import log\n# Build X/Y arrays from file 1\nf = open('yelp_zoom_2.csv')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\nx = np.array(x)\ny = np.array(y)\n\nplt.plot(x, y, 'ro',label=\"Original Data\")\nnp.corrcoef(x,y) #-0.78</code></pre>\n\nA straight line is not a good fit, so I tried a log regression:\n\n<pre><code>def func(x, a, b):\n    y = a*(-np.log(x)) + b\n    return y\n\npopt, pcov = curve_fit(func, x, y)\nprint \"a = %s , b = %s\" % (popt[0], popt[1])\n\n# Trying to plot without using linspace will result in a chaotic, pissy plot that will confuse you.\n# numpy.linspace simply creates a series of evenly spaced X values to plot a continiuous function.\ntest_x = np.linspace(0,30,50)\nplt.plot(test_x, func(test_x, *popt), label=\"Fitted Curve\")</code></pre>\n\nWhich looks like a reasonable fit (note: you can easily do this in Excel):\n\n<img src=\"https://68.media.tumblr.com/fad250b4ab19e727e14892e68c4f46d7/tumblr_inline_myh7tlXRkJ1qdyhha.png\">\n\nThe benefit of doing this regression in Python and not Excel, is that I can now include the prediction in my web application like so:\n\n<pre><code># Apply result of regression\ndef map_km_to_zoom(km, a, b):\n    y = a*(-np.log(km)) + b\n    return y\n\n# Controller: Fetch a business and display it\n@app.route(\"/business/<business_id>\")\ndef business(business_id):\n    business = businesses.find_one({'business_id': business_id})\n    nearby = nearest_businesses.find_one({'business_id': business_id})\n    zoom_level = map_km_to_zoom(nearby['range'], 1.32809669067, 14.7211913904)\n    return render_template('partials/business.html', business=business, zoom_level=zoom_level)</business_id></code></pre>\n\nThis results in a clean mapping of distance in kilometers to the correct zoom level for leaflet.js.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 71323365857, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Yelp Dataset Challenge Part 3: Regressing distance between businesses vs zoom level for leaflet.js map", "tags": [], "post_url": "http://datasyndrome.com/post/71323365857/yelp-dataset-challenge-part-3-regressing-distance", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y12RD37X", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1388167140, "note_count": 1, "trail": [{"content": "<p><p>All code for this post is open source and is available on <a href=\"https://github.com/rjurney/yelp_challenge\">github</a>. I was recently introduced to <a href=\"http://leafletjs.com\">leaflet.js</a>, a javascript map library that is <a href=\"http://leafletjs.com/examples/quick-start.html\">very easy to use</a>.\n\n</p><p><img src=\"https://68.media.tumblr.com/27a3d8466399fa23ed015e27aaee34dc/tumblr_inline_myh5bfvnxu1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\nI&rsquo;m using leaflet.js as part of my entry to the <a href=\"http://www.yelp.com/dataset_challenge/\">Yelp Dataset Challenge</a> - at the &lsquo;reporting&rsquo; level of the data-value pyramid: to link business records together with relevant nearby businesses. The data in the challenge includes business data, that includes latitude/longitude data.\n\n<p><img src=\"https://68.media.tumblr.com/e65a0cee420afd03b8f004c12725fe69/tumblr_inline_myh5jkUyaC1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\n<br />\nThe business data looks like this:\n\n<pre><code>{\n    'type': 'business',\n    'business_id': (encrypted business id),\n    'name': (business name),\n    'neighborhoods': [(hood names)],\n    'full_address': (localized address),\n    'city': (city),\n    'state': (state),\n    'latitude': latitude,\n    'longitude': longitude,\n    'stars': (star rating, rounded to half-stars),\n    'review_count': review count,\n    'categories': [(localized category names)]\n    'open': True / False (corresponds to closed, not business hours),\n}</code></pre>\n\nUsing this data, I computed the distance between all businesses of the same category in the dataset in Pig, like so:\n\n<pre><code>location_comparisons = JOIN locations BY category, locations_2 BY category USING 'replicated';                                                        \ndistances = FOREACH location_comparisons GENERATE flat_locations::business_id AS business_id_1,\n                    locations_2::business_id AS business_id_2,\n                    flat_locations::category AS category,\n                    udfs.haversine(flat_locations::longitude,\n                                   flat_locations::latitude,\n                                   locations_2::longitude,\n                                   locations_2::latitude) AS distance;</code></pre>\n\nThe haversine distance UDF looks like this (it uses <a href=\"http://pig.apache.org/docs/r0.12.0/udf.html#python-udfs\">CPython UDFs</a>, available in <a href=\"http://pig.apache.org/docs/r0.12.0/\">Pig 0.12</a>):\n\n<pre><code>@outputSchema(\"distance:double\")\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    # haversine formula\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a))\n    km = 6367 * c\n    return km</code></pre>\n\nThe results were grouped into the top ten nearest businesses and published to MongoDB:\n\n<pre><code>nearest_businesses = FOREACH (GROUP with_coords BY business_1) {\n    sorted = ORDER with_coords BY distance;\n    top_10 = LIMIT sorted 10;\n    GENERATE group AS business_id, \n             (float)(2.0 * MAX(top_10.distance)) AS range:float, \n             top_10.(business_2, name, latitude, longitude) AS nearest_businesses;\n}\nSTORE nearest_businesses INTO 'mongodb://localhost/yelp.nearest_businesses' USING MongoStorage();</code></pre>\n\nThese results are then served by a Python/Flask application using Bootstrap. Upon computing the top-ten nearest, relevant businesses, I was presented with the problem of figuring out the correct level of zoom to show all ten businesses. Initially I tried a simple linear mapping from one scale to another, but I could not make the zoom fit the data consistently. In about half of cases, the top 10 businesses would either be zoomed too far out, or zoomed in too far to show all ten businesses. The initial attempt at mapping looked like this:\n\n<pre><code>def map_degree_to_zoom(degree_value):\n    # Determined by experimentation with Leaflet UI and MAX() of distances in Pig\n    range_min = 0\n    range_max = 142\n    zoom_min = 7\n    zoom_max = 12\n    \n    # Compute ranges\n    range_span = range_max - range_min\n    zoom_span = zoom_max - zoom_min\n    \n    # Convert the left range into a 0-1 range (float)\n    value_scaled = float(degree_value - range_min) / float(range_span)\n    \n    # Convert the 0-1 range into a value in the right range.\n    return int(zoom_max - (value_scaled * zoom_span))</code></pre> \n\nSo I gathered data and turned to visualization. I collected data manually, by logging the maximum distance of the ten-nearest businesses against the minimum zoom level required to visualize them all at once. The data looks like this:\n\n<br /><br />\n<p><a href=\"#\"><img src=\"http://assets.tumblr.com/images/inline_placeholder.png\" width=\"18\" height=\"14\"/></a></p>\n\nThe scatterplot looks like so:\n\n<p><img src=\"https://68.media.tumblr.com/6d9ca1fba3d746bdb73d11594ed65d29/tumblr_inline_myh7jyzjnL1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\nThe data correlation is strongly negative:\n\n<pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom math import log\n# Build X/Y arrays from file 1\nf = open('yelp_zoom_2.csv')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\nx = np.array(x)\ny = np.array(y)\n\nplt.plot(x, y, 'ro',label=\"Original Data\")\nnp.corrcoef(x,y) #-0.78</code></pre>\n\nA straight line is not a good fit, so I tried a log regression:\n\n<pre><code>def func(x, a, b):\n    y = a*(-np.log(x)) + b\n    return y\n\npopt, pcov = curve_fit(func, x, y)\nprint \"a = %s , b = %s\" % (popt[0], popt[1])\n\n# Trying to plot without using linspace will result in a chaotic, pissy plot that will confuse you.\n# numpy.linspace simply creates a series of evenly spaced X values to plot a continiuous function.\ntest_x = np.linspace(0,30,50)\nplt.plot(test_x, func(test_x, *popt), label=\"Fitted Curve\")</code></pre>\n\nWhich looks like a reasonable fit (note: you can easily do this in Excel):\n\n<p><img src=\"https://68.media.tumblr.com/fad250b4ab19e727e14892e68c4f46d7/tumblr_inline_myh7tlXRkJ1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\nThe benefit of doing this regression in Python and not Excel, is that I can now include the prediction in my web application like so:\n\n<pre><code># Apply result of regression\ndef map_km_to_zoom(km, a, b):\n    y = a*(-np.log(km)) + b\n    return y\n\n# Controller: Fetch a business and display it\n@app.route(\"/business/\")\ndef business(business_id):\n    business = businesses.find_one({'business_id': business_id})\n    nearby = nearest_businesses.find_one({'business_id': business_id})\n    zoom_level = map_km_to_zoom(nearby['range'], 1.32809669067, 14.7211913904)\n    return render_template('partials/business.html', business=business, zoom_level=zoom_level)</code></pre>\n\nThis results in a clean mapping of distance in kilometers to the correct zoom level for leaflet.js.</p>", "content_raw": "<p><p>All code for this post is open source and is available on <a href=\"https://github.com/rjurney/yelp_challenge\">github</a>. I was recently introduced to <a href=\"http://leafletjs.com\">leaflet.js</a>, a javascript map library that is <a href=\"http://leafletjs.com/examples/quick-start.html\">very easy to use</a>.\n\n</p><center><img src=\"https://68.media.tumblr.com/27a3d8466399fa23ed015e27aaee34dc/tumblr_inline_myh5bfvnxu1qdyhha.png\"></center>\n\nI\u2019m using leaflet.js as part of my entry to the <a href=\"http://www.yelp.com/dataset_challenge/\">Yelp Dataset Challenge</a> - at the \u2018reporting\u2019 level of the data-value pyramid: to link business records together with relevant nearby businesses. The data in the challenge includes business data, that includes latitude/longitude data.\n\n<center><img src=\"https://68.media.tumblr.com/e65a0cee420afd03b8f004c12725fe69/tumblr_inline_myh5jkUyaC1qdyhha.png\"></center>\n\n<br>\nThe business data looks like this:\n\n<pre><code>{\n    'type': 'business',\n    'business_id': (encrypted business id),\n    'name': (business name),\n    'neighborhoods': [(hood names)],\n    'full_address': (localized address),\n    'city': (city),\n    'state': (state),\n    'latitude': latitude,\n    'longitude': longitude,\n    'stars': (star rating, rounded to half-stars),\n    'review_count': review count,\n    'categories': [(localized category names)]\n    'open': True / False (corresponds to closed, not business hours),\n}</code></pre>\n\nUsing this data, I computed the distance between all businesses of the same category in the dataset in Pig, like so:\n\n<pre><code>location_comparisons = JOIN locations BY category, locations_2 BY category USING 'replicated';                                                        \ndistances = FOREACH location_comparisons GENERATE flat_locations::business_id AS business_id_1,\n                    locations_2::business_id AS business_id_2,\n                    flat_locations::category AS category,\n                    udfs.haversine(flat_locations::longitude,\n                                   flat_locations::latitude,\n                                   locations_2::longitude,\n                                   locations_2::latitude) AS distance;</code></pre>\n\nThe haversine distance UDF looks like this (it uses <a href=\"http://pig.apache.org/docs/r0.12.0/udf.html#python-udfs\">CPython UDFs</a>, available in <a href=\"http://pig.apache.org/docs/r0.12.0/\">Pig 0.12</a>):\n\n<pre><code>@outputSchema(\"distance:double\")\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    # haversine formula\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a))\n    km = 6367 * c\n    return km</code></pre>\n\nThe results were grouped into the top ten nearest businesses and published to MongoDB:\n\n<pre><code>nearest_businesses = FOREACH (GROUP with_coords BY business_1) {\n    sorted = ORDER with_coords BY distance;\n    top_10 = LIMIT sorted 10;\n    GENERATE group AS business_id, \n             (float)(2.0 * MAX(top_10.distance)) AS range:float, \n             top_10.(business_2, name, latitude, longitude) AS nearest_businesses;\n}\nSTORE nearest_businesses INTO 'mongodb://localhost/yelp.nearest_businesses' USING MongoStorage();</code></pre>\n\nThese results are then served by a Python/Flask application using Bootstrap. Upon computing the top-ten nearest, relevant businesses, I was presented with the problem of figuring out the correct level of zoom to show all ten businesses. Initially I tried a simple linear mapping from one scale to another, but I could not make the zoom fit the data consistently. In about half of cases, the top 10 businesses would either be zoomed too far out, or zoomed in too far to show all ten businesses. The initial attempt at mapping looked like this:\n\n<pre><code>def map_degree_to_zoom(degree_value):\n    # Determined by experimentation with Leaflet UI and MAX() of distances in Pig\n    range_min = 0\n    range_max = 142\n    zoom_min = 7\n    zoom_max = 12\n    \n    # Compute ranges\n    range_span = range_max - range_min\n    zoom_span = zoom_max - zoom_min\n    \n    # Convert the left range into a 0-1 range (float)\n    value_scaled = float(degree_value - range_min) / float(range_span)\n    \n    # Convert the 0-1 range into a value in the right range.\n    return int(zoom_max - (value_scaled * zoom_span))</code></pre> \n\nSo I gathered data and turned to visualization. I collected data manually, by logging the maximum distance of the ten-nearest businesses against the minimum zoom level required to visualize them all at once. The data looks like this:\n\n<br><br><center>\n<table style=\"text-align: center; float:center; border=\" cellspacing=\"10\"><tr><td>1.26710856</td><td style=\"padding-left: 10px;\">15</td></tr><tr><td>0.418455511</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>4.176179886</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.059176445</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>2.985990286</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.584879398</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>0.341496378</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>0.633716404</td><td style=\"padding-left: 10px;\">16</td></tr><tr><td>3.525056601</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>4.084414959</td><td style=\"padding-left: 10px;\">13</td></tr><tr><td>0.713507891</td><td style=\"padding-left: 10px;\">15</td></tr><tr><td>15.74468708</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>6.349864006</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>5.078705788</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>6.349864006</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>9.700486183</td><td style=\"padding-left: 10px;\">12</td></tr><tr><td>25.13388824</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>13.71557617</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>0.065407977</td><td style=\"padding-left: 10px;\">18</td></tr><tr><td>11.24457836</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>12.29977512</td><td style=\"padding-left: 10px;\">11</td></tr><tr><td>20.05439949</td><td style=\"padding-left: 10px;\">11</td></tr></table></center>\n\nThe scatterplot looks like so:\n\n<img src=\"https://68.media.tumblr.com/6d9ca1fba3d746bdb73d11594ed65d29/tumblr_inline_myh7jyzjnL1qdyhha.png\">\n\nThe data correlation is strongly negative:\n\n<pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom math import log\n# Build X/Y arrays from file 1\nf = open('yelp_zoom_2.csv')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\nx = np.array(x)\ny = np.array(y)\n\nplt.plot(x, y, 'ro',label=\"Original Data\")\nnp.corrcoef(x,y) #-0.78</code></pre>\n\nA straight line is not a good fit, so I tried a log regression:\n\n<pre><code>def func(x, a, b):\n    y = a*(-np.log(x)) + b\n    return y\n\npopt, pcov = curve_fit(func, x, y)\nprint \"a = %s , b = %s\" % (popt[0], popt[1])\n\n# Trying to plot without using linspace will result in a chaotic, pissy plot that will confuse you.\n# numpy.linspace simply creates a series of evenly spaced X values to plot a continiuous function.\ntest_x = np.linspace(0,30,50)\nplt.plot(test_x, func(test_x, *popt), label=\"Fitted Curve\")</code></pre>\n\nWhich looks like a reasonable fit (note: you can easily do this in Excel):\n\n<img src=\"https://68.media.tumblr.com/fad250b4ab19e727e14892e68c4f46d7/tumblr_inline_myh7tlXRkJ1qdyhha.png\">\n\nThe benefit of doing this regression in Python and not Excel, is that I can now include the prediction in my web application like so:\n\n<pre><code># Apply result of regression\ndef map_km_to_zoom(km, a, b):\n    y = a*(-np.log(km)) + b\n    return y\n\n# Controller: Fetch a business and display it\n@app.route(\"/business/<business_id>\")\ndef business(business_id):\n    business = businesses.find_one({'business_id': business_id})\n    nearby = nearest_businesses.find_one({'business_id': business_id})\n    zoom_level = map_km_to_zoom(nearby['range'], 1.32809669067, 14.7211913904)\n    return render_template('partials/business.html', business=business, zoom_level=zoom_level)</business_id></code></pre>\n\nThis results in a clean mapping of distance in kilometers to the correct zoom level for leaflet.js.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "71323365857"}}], "date": "2013-12-27 17:59:00 GMT", "slug": "yelp-dataset-challenge-part-3-regressing-distance", "blog_name": "rjurney", "summary": "Yelp Dataset Challenge Part 3: Regressing distance between businesses vs zoom level for leaflet.js map", "can_reblog": true}, {"body": "As easy as with a replicated non-equijoin: \n\n<pre><code>/* Remove stop words. Note use of replicated join for mucho velocidad */\nstop_words = LOAD 'stopwords.txt' AS (word:chararray);\nwords = JOIN my_words BY word LEFT OUTER, stop_words BY word using 'replicated';\nwords = FILTER words BY stop_words::word IS NULL;</code></pre>", "liked": false, "followed": false, "reblog_key": "jA7L6AJX", "reblog": {"comment": "<p>As easy as with a replicated non-equijoin: \n\n<pre><code>/* Remove stop words. Note use of replicated join for mucho velocidad */\nstop_words = LOAD 'stopwords.txt' AS (word:chararray);\nwords = JOIN my_words BY word LEFT OUTER, stop_words BY word using 'replicated';\nwords = FILTER words BY stop_words::word IS NULL;</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 71049546361, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Filtering Stop Words in Pig", "tags": [], "post_url": "http://datasyndrome.com/post/71049546361/filtering-stop-words-in-pig", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y12AuWfv", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1387925164, "note_count": 0, "trail": [{"content": "<p><p>As easy as with a replicated non-equijoin: \n\n</p><pre><code>/* Remove stop words. Note use of replicated join for mucho velocidad */\nstop_words = LOAD 'stopwords.txt' AS (word:chararray);\nwords = JOIN my_words BY word LEFT OUTER, stop_words BY word using 'replicated';\nwords = FILTER words BY stop_words::word IS NULL;</code></pre></p>", "content_raw": "<p>As easy as with a replicated non-equijoin: \n\n<pre><code>/* Remove stop words. Note use of replicated join for mucho velocidad */\nstop_words = LOAD 'stopwords.txt' AS (word:chararray);\nwords = JOIN my_words BY word LEFT OUTER, stop_words BY word using 'replicated';\nwords = FILTER words BY stop_words::word IS NULL;</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "71049546361"}}], "date": "2013-12-24 22:46:04 GMT", "slug": "filtering-stop-words-in-pig", "blog_name": "rjurney", "summary": "Filtering Stop Words in Pig", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "qshhBll9", "short_url": "https://tmblr.co/ZbIO5y11_fpkm", "can_send_in_message": true, "id": 70844365744, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/70844365744", "tags": [], "post_url": "http://datasyndrome.com/post/70844365744/me-and-turtle-man-costar-neil-james-at-walmart", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Me and Turtle Man costar Neil James at Walmart!</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1387761666, "note_count": 0, "trail": [{"content": "<p>Me and Turtle Man costar Neil James at Walmart!</p>", "content_raw": "<p>Me and Turtle Man costar Neil James at Walmart!</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "70844365744"}}], "date": "2013-12-23 01:21:06 GMT", "slug": "me-and-turtle-man-costar-neil-james-at-walmart", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/e531bdb8de17cc5dbde8fd809fa28be5/tumblr_my8jr6dhLA1qe7pymo1_1280.jpg", "width": 640, "height": 640}, "alt_sizes": [{"url": "https://68.media.tumblr.com/e531bdb8de17cc5dbde8fd809fa28be5/tumblr_my8jr6dhLA1qe7pymo1_1280.jpg", "width": 640, "height": 640}, {"url": "https://68.media.tumblr.com/e531bdb8de17cc5dbde8fd809fa28be5/tumblr_my8jr6dhLA1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/e531bdb8de17cc5dbde8fd809fa28be5/tumblr_my8jr6dhLA1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/e531bdb8de17cc5dbde8fd809fa28be5/tumblr_my8jr6dhLA1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/e531bdb8de17cc5dbde8fd809fa28be5/tumblr_my8jr6dhLA1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/e531bdb8de17cc5dbde8fd809fa28be5/tumblr_my8jr6dhLA1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/iPrJxRRT1j/", "summary": "Me and Turtle Man costar Neil James at Walmart!", "caption": "<p>Me and Turtle Man costar Neil James at Walmart!</p>", "can_reblog": true}, {"body": "This post is heavily indebted to a four part series at streamhacker, starting with <a href=\"http://streamhacker.com/2008/11/03/part-of-speech-tagging-with-nltk-part-1/\">this post</a>. I&rsquo;m writing how to use the Brill braubt tagger up in one post because it was challenging for me to piece this together from the four posts. \n\nThe Yelp review data for Phoenix is about 200MB. This is not &lsquo;big data,&rsquo; but for the slow-performong nltk.pos_tag function, it is. pos_tag is notoriously slow. So we need an alternative. Here it is, the Brill tagger with multiple backoff taggers. A little bit is specific to the Yelp data, but not much:\n\n<pre><code>\nimport nltk, json\nfrom nltk.tag.brill import *\n\nfrom nltk.corpus import brown\nbrown_train = list(brown.tagged_sents(categories='news'))\nfrom nltk.corpus import treebank\ntreebank_train = list(treebank.tagged_sents())\ntraining_data = brown_train + treebank_train\n\nfrom nltk.tag.sequential import RegexpTagger\nregexp_tagger = RegexpTagger(\n     [(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n      (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n      (r'.*able$', 'JJ'),                # adjectives\n      (r'.*ness$', 'NN'),                # nouns formed from adjectives\n      (r'.*ly$', 'RB'),                  # adverbs\n      (r'.*s$', 'NNS'),                  # plural nouns\n      (r'.*ing$', 'VBG'),                # gerunds\n      (r'.*ed$', 'VBD'),                 # past tense verbs\n      (r'.*', 'NN')                      # nouns (default)\n])\n\nunigram_tagger_2 = nltk.UnigramTagger(brown_train, backoff=regexp_tagger)\ntemplates = [\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,3)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,3)),\n     ProximateTokensTemplate(ProximateTagsRule, (-1, -1), (1,1)),\n     ProximateTokensTemplate(ProximateWordsRule, (-1, -1), (1,1)),\n     ]\ntrainer = FastBrillTaggerTrainer(initial_tagger=unigram_tagger_2,\n                                  templates=templates, trace=3,\n                                  deterministic=True)\nbrill_tagger = trainer.train(training_data, max_rules=10)\n\nf = open('yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json')\nlines = f.readlines()\n\nsent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n\nfor line in lines:\n    review = json.loads(line)\n    sentences = sent_detector.tokenize(review['text'])\n    words = nltk.word_tokenize(sentences[0])\n    tagged = brill_tagger.tag(words)\n    adjectives = []\n    for tag in tagged:\n        if tag[1].startswith('JJ') | tag[1].startswith('RB'): # Adjectives or adverbs\n            adjectives.append(tag[0].lower())\n    if adjectives:\n        try:\n            print review['business_id'] + \"\\t\" + \" \".join(adjectives)\n        except UnicodeEncodeError:\n            pass\n\n</code></pre>", "liked": false, "followed": false, "reblog_key": "uRCLTMOg", "reblog": {"comment": "<p>This post is heavily indebted to a four part series at streamhacker, starting with <a href=\"http://streamhacker.com/2008/11/03/part-of-speech-tagging-with-nltk-part-1/\">this post</a>. I\u2019m writing how to use the Brill braubt tagger up in one post because it was challenging for me to piece this together from the four posts. \n\nThe Yelp review data for Phoenix is about 200MB. This is not \u2018big data,\u2019 but for the slow-performong nltk.pos_tag function, it is. pos_tag is notoriously slow. So we need an alternative. Here it is, the Brill tagger with multiple backoff taggers. A little bit is specific to the Yelp data, but not much:\n\n<pre><code>\nimport nltk, json\nfrom nltk.tag.brill import *\n\nfrom nltk.corpus import brown\nbrown_train = list(brown.tagged_sents(categories='news'))\nfrom nltk.corpus import treebank\ntreebank_train = list(treebank.tagged_sents())\ntraining_data = brown_train + treebank_train\n\nfrom nltk.tag.sequential import RegexpTagger\nregexp_tagger = RegexpTagger(\n     [(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n      (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n      (r'.*able$', 'JJ'),                # adjectives\n      (r'.*ness$', 'NN'),                # nouns formed from adjectives\n      (r'.*ly$', 'RB'),                  # adverbs\n      (r'.*s$', 'NNS'),                  # plural nouns\n      (r'.*ing$', 'VBG'),                # gerunds\n      (r'.*ed$', 'VBD'),                 # past tense verbs\n      (r'.*', 'NN')                      # nouns (default)\n])\n\nunigram_tagger_2 = nltk.UnigramTagger(brown_train, backoff=regexp_tagger)\ntemplates = [\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,3)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,3)),\n     ProximateTokensTemplate(ProximateTagsRule, (-1, -1), (1,1)),\n     ProximateTokensTemplate(ProximateWordsRule, (-1, -1), (1,1)),\n     ]\ntrainer = FastBrillTaggerTrainer(initial_tagger=unigram_tagger_2,\n                                  templates=templates, trace=3,\n                                  deterministic=True)\nbrill_tagger = trainer.train(training_data, max_rules=10)\n\nf = open('yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json')\nlines = f.readlines()\n\nsent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n\nfor line in lines:\n    review = json.loads(line)\n    sentences = sent_detector.tokenize(review['text'])\n    words = nltk.word_tokenize(sentences[0])\n    tagged = brill_tagger.tag(words)\n    adjectives = []\n    for tag in tagged:\n        if tag[1].startswith('JJ') | tag[1].startswith('RB'): # Adjectives or adverbs\n            adjectives.append(tag[0].lower())\n    if adjectives:\n        try:\n            print review['business_id'] + \"\\t\" + \" \".join(adjectives)\n        except UnicodeEncodeError:\n            pass\n\n</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 70331190914, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Yelp Dataset Challenge Part 2: Brill Part of Speech Tagger", "tags": [], "post_url": "http://datasyndrome.com/post/70331190914/yelp-dataset-challenge-part-2-brill-part-of", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y11W4Cw2", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1387321388, "note_count": 1, "trail": [{"content": "<p><p>This post is heavily indebted to a four part series at streamhacker, starting with <a href=\"http://streamhacker.com/2008/11/03/part-of-speech-tagging-with-nltk-part-1/\">this post</a>. I&rsquo;m writing how to use the Brill braubt tagger up in one post because it was challenging for me to piece this together from the four posts. \n\nThe Yelp review data for Phoenix is about 200MB. This is not &lsquo;big data,&rsquo; but for the slow-performong nltk.pos_tag function, it is. pos_tag is notoriously slow. So we need an alternative. Here it is, the Brill tagger with multiple backoff taggers. A little bit is specific to the Yelp data, but not much:\n\n</p><pre><code>\nimport nltk, json\nfrom nltk.tag.brill import *\n\nfrom nltk.corpus import brown\nbrown_train = list(brown.tagged_sents(categories='news'))\nfrom nltk.corpus import treebank\ntreebank_train = list(treebank.tagged_sents())\ntraining_data = brown_train + treebank_train\n\nfrom nltk.tag.sequential import RegexpTagger\nregexp_tagger = RegexpTagger(\n     [(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n      (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n      (r'.*able$', 'JJ'),                # adjectives\n      (r'.*ness$', 'NN'),                # nouns formed from adjectives\n      (r'.*ly$', 'RB'),                  # adverbs\n      (r'.*s$', 'NNS'),                  # plural nouns\n      (r'.*ing$', 'VBG'),                # gerunds\n      (r'.*ed$', 'VBD'),                 # past tense verbs\n      (r'.*', 'NN')                      # nouns (default)\n])\n\nunigram_tagger_2 = nltk.UnigramTagger(brown_train, backoff=regexp_tagger)\ntemplates = [\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,3)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,3)),\n     ProximateTokensTemplate(ProximateTagsRule, (-1, -1), (1,1)),\n     ProximateTokensTemplate(ProximateWordsRule, (-1, -1), (1,1)),\n     ]\ntrainer = FastBrillTaggerTrainer(initial_tagger=unigram_tagger_2,\n                                  templates=templates, trace=3,\n                                  deterministic=True)\nbrill_tagger = trainer.train(training_data, max_rules=10)\n\nf = open('yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json')\nlines = f.readlines()\n\nsent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n\nfor line in lines:\n    review = json.loads(line)\n    sentences = sent_detector.tokenize(review['text'])\n    words = nltk.word_tokenize(sentences[0])\n    tagged = brill_tagger.tag(words)\n    adjectives = []\n    for tag in tagged:\n        if tag[1].startswith('JJ') | tag[1].startswith('RB'): # Adjectives or adverbs\n            adjectives.append(tag[0].lower())\n    if adjectives:\n        try:\n            print review['business_id'] + \"\\t\" + \" \".join(adjectives)\n        except UnicodeEncodeError:\n            pass\n\n</code></pre></p>", "content_raw": "<p>This post is heavily indebted to a four part series at streamhacker, starting with <a href=\"http://streamhacker.com/2008/11/03/part-of-speech-tagging-with-nltk-part-1/\">this post</a>. I\u2019m writing how to use the Brill braubt tagger up in one post because it was challenging for me to piece this together from the four posts. \n\nThe Yelp review data for Phoenix is about 200MB. This is not \u2018big data,\u2019 but for the slow-performong nltk.pos_tag function, it is. pos_tag is notoriously slow. So we need an alternative. Here it is, the Brill tagger with multiple backoff taggers. A little bit is specific to the Yelp data, but not much:\n\n<pre><code>\nimport nltk, json\nfrom nltk.tag.brill import *\n\nfrom nltk.corpus import brown\nbrown_train = list(brown.tagged_sents(categories='news'))\nfrom nltk.corpus import treebank\ntreebank_train = list(treebank.tagged_sents())\ntraining_data = brown_train + treebank_train\n\nfrom nltk.tag.sequential import RegexpTagger\nregexp_tagger = RegexpTagger(\n     [(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n      (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n      (r'.*able$', 'JJ'),                # adjectives\n      (r'.*ness$', 'NN'),                # nouns formed from adjectives\n      (r'.*ly$', 'RB'),                  # adverbs\n      (r'.*s$', 'NNS'),                  # plural nouns\n      (r'.*ing$', 'VBG'),                # gerunds\n      (r'.*ed$', 'VBD'),                 # past tense verbs\n      (r'.*', 'NN')                      # nouns (default)\n])\n\nunigram_tagger_2 = nltk.UnigramTagger(brown_train, backoff=regexp_tagger)\ntemplates = [\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateTagsRule, (1,3)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,1)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (2,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,2)),\n     SymmetricProximateTokensTemplate(ProximateWordsRule, (1,3)),\n     ProximateTokensTemplate(ProximateTagsRule, (-1, -1), (1,1)),\n     ProximateTokensTemplate(ProximateWordsRule, (-1, -1), (1,1)),\n     ]\ntrainer = FastBrillTaggerTrainer(initial_tagger=unigram_tagger_2,\n                                  templates=templates, trace=3,\n                                  deterministic=True)\nbrill_tagger = trainer.train(training_data, max_rules=10)\n\nf = open('yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json')\nlines = f.readlines()\n\nsent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n\nfor line in lines:\n    review = json.loads(line)\n    sentences = sent_detector.tokenize(review['text'])\n    words = nltk.word_tokenize(sentences[0])\n    tagged = brill_tagger.tag(words)\n    adjectives = []\n    for tag in tagged:\n        if tag[1].startswith('JJ') | tag[1].startswith('RB'): # Adjectives or adverbs\n            adjectives.append(tag[0].lower())\n    if adjectives:\n        try:\n            print review['business_id'] + \"\\t\" + \" \".join(adjectives)\n        except UnicodeEncodeError:\n            pass\n\n</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "70331190914"}}], "date": "2013-12-17 23:03:08 GMT", "slug": "yelp-dataset-challenge-part-2-brill-part-of", "blog_name": "rjurney", "summary": "Yelp Dataset Challenge Part 2: Brill Part of Speech Tagger", "can_reblog": true}, {"body": "I&rsquo;m building an analytic application around the <a href=\"http://www.yelp.co.uk/dataset_challenge\">Yelp Dataset Challenge</a>, and was pleasantly surprised at how easy it is to load JSON into MongoDB.\n\n<pre><code># Import businesses, users, reviews and checkins\nmongoimport --db yelp --collection businesses yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json\nmongoimport --db yelp --collection users yelp_phoenix_academic_dataset/yelp_academic_dataset_user.json\nmongoimport --db yelp --collection reviews yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json\nmongoimport --db yelp --collection checkins yelp_phoenix_academic_dataset/yelp_academic_dataset_checkin.json\n</code></pre>", "liked": false, "followed": false, "reblog_key": "MQBP5brd", "reblog": {"comment": "<p>I\u2019m building an analytic application around the <a href=\"http://www.yelp.co.uk/dataset_challenge\">Yelp Dataset Challenge</a>, and was pleasantly surprised at how easy it is to load JSON into MongoDB.\n\n<pre><code># Import businesses, users, reviews and checkins\nmongoimport --db yelp --collection businesses yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json\nmongoimport --db yelp --collection users yelp_phoenix_academic_dataset/yelp_academic_dataset_user.json\nmongoimport --db yelp --collection reviews yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json\nmongoimport --db yelp --collection checkins yelp_phoenix_academic_dataset/yelp_academic_dataset_checkin.json\n</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 69862630791, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Yelp Dataset Challenge Part 1: Loading MongoDB", "tags": [], "post_url": "http://datasyndrome.com/post/69862630791/yelp-dataset-challenge-part-1-loading-mongodb", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1148oM7", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1386916944, "note_count": 0, "trail": [{"content": "<p><p>I&rsquo;m building an analytic application around the <a href=\"http://www.yelp.co.uk/dataset_challenge\">Yelp Dataset Challenge</a>, and was pleasantly surprised at how easy it is to load JSON into MongoDB.\n\n</p><pre><code># Import businesses, users, reviews and checkins\nmongoimport --db yelp --collection businesses yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json\nmongoimport --db yelp --collection users yelp_phoenix_academic_dataset/yelp_academic_dataset_user.json\nmongoimport --db yelp --collection reviews yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json\nmongoimport --db yelp --collection checkins yelp_phoenix_academic_dataset/yelp_academic_dataset_checkin.json\n</code></pre></p>", "content_raw": "<p>I\u2019m building an analytic application around the <a href=\"http://www.yelp.co.uk/dataset_challenge\">Yelp Dataset Challenge</a>, and was pleasantly surprised at how easy it is to load JSON into MongoDB.\n\n<pre><code># Import businesses, users, reviews and checkins\nmongoimport --db yelp --collection businesses yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json\nmongoimport --db yelp --collection users yelp_phoenix_academic_dataset/yelp_academic_dataset_user.json\nmongoimport --db yelp --collection reviews yelp_phoenix_academic_dataset/yelp_academic_dataset_review.json\nmongoimport --db yelp --collection checkins yelp_phoenix_academic_dataset/yelp_academic_dataset_checkin.json\n</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "69862630791"}}], "date": "2013-12-13 06:42:24 GMT", "slug": "yelp-dataset-challenge-part-1-loading-mongodb", "blog_name": "rjurney", "summary": "Yelp Dataset Challenge Part 1: Loading MongoDB", "can_reblog": true}, {"body": "Today I decided to experiment with unsupervised learning by clustering the <a href=\"https://www.yelp.com/academic_dataset\">Yelp Academic Dataset</a>. I decided to do a location-based clustering so that I could check my results against a map.\n\nI started by pre-processing the data in Pig into business_id/latitude/longitude records:\n\n<pre><code>REGISTER /me/Software/elephant-bird/pig/target/elephant-bird-pig-3.0.6-SNAPSHOT.jar\nREGISTER /me/Software/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nSET elephantbird.jsonloader.nestedLoad 'true'\n\nRegister 'udfs.py' using jython as udfs;\n\nSET default_parallel 10\n\nrmf yelp_phoenix_academic_dataset/locations.tsv\n\nbusinesses = LOAD 'yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\n/* {open=true, neighborhoods={}, review_count=14, stars=4.0, name=Drybar, business_id=LcAamvosJu0bcPgEVF-9sQ, state=AZ, full_address=3172 E Camelback Rd\nPhoenix, AZ85018, categories={(Hair Salons),(Hair Stylists),(Beauty &amp; Spas)}, longitude=-112.0131927, latitude=33.5107772, type=business, city=Phoenix} */\nlocations = FOREACH businesses GENERATE $0#'business_id' AS business_id:chararray, \n                                      $0#'longitude' AS longitude:double, \n                                      $0#'latitude' AS latitude:double;\n                                      \nSTORE locations INTO 'yelp_phoenix_academic_dataset/locations.tsv';</code></pre>\n\nI began with K-means, which gave me this unsatisfactory result:\n\n<center><img src=\"https://68.media.tumblr.com/0217fa7e16d9e4ac5a1fbe8124453a51/tumblr_inline_mxk4izZQgP1qdyhha.png\"/></center>\n\nThen I tried DBSCAN:\n\n<pre><code># From example at <a href=\"http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py\">http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py</a>\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nimport pylab as pl\nimport numpy as np\n\nX = []\nf = open('yelp_phoenix_academic_dataset/locations.tsv/part-m-00000')\nfor line in f:\n    business_id, latitude, longitude = line.rstrip().split('\\t')\n    X.append([float(latitude), float(longitude)])\n\nX = StandardScaler().fit_transform(X)\ndb = DBSCAN(eps=0.3, min_samples=10).fit(X)\ncore_samples = db.core_sample_indices_\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nunique_labels = set(labels)\n\ncolors = pl.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = 'k'\n        markersize = 6\n    class_members = [index[0] for index in np.argwhere(labels == k)]\n    cluster_core_samples = [index for index in core_samples\n                            if labels[index] == k]\n    for index in class_members:\n        x = X[index]\n        if index in core_samples and k != -1:\n            markersize = 14\n        else:\n            markersize = 6\n        pl.plot(x[0], x[1], 'o', markerfacecolor=col,\n                markeredgecolor='k', markersize=markersize)</code></pre>\n\nWhich results in this:\n<center><img src=\"https://68.media.tumblr.com/bf09c5d681a3e830975cde6745fe3a14/tumblr_inline_mxk4dp9fxo1qdyhha.png\"/></center>\n\nThe results look pretty good - you can see a large contiguous &lsquo;downtown&rsquo; cluster, as well as highways, townships, etc. Glancing at a map of Phoenix, Arizona, you can see that it looks right. When overlaid onto a map of Phoenix, you can see towns as separate clusters!\n\n<center><img src=\"https://68.media.tumblr.com/9c182b01124f532ba7ef45f81d4edad2/tumblr_inline_mxk4dzyaNz1qdyhha.png\"/></center>", "liked": false, "followed": false, "reblog_key": "mNbz6gFR", "reblog": {"comment": "<p>Today I decided to experiment with unsupervised learning by clustering the <a href=\"https://www.yelp.com/academic_dataset\">Yelp Academic Dataset</a>. I decided to do a location-based clustering so that I could check my results against a map.\n\nI started by pre-processing the data in Pig into business_id/latitude/longitude records:\n\n<pre><code>REGISTER /me/Software/elephant-bird/pig/target/elephant-bird-pig-3.0.6-SNAPSHOT.jar\nREGISTER /me/Software/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nSET elephantbird.jsonloader.nestedLoad 'true'\n\nRegister 'udfs.py' using jython as udfs;\n\nSET default_parallel 10\n\nrmf yelp_phoenix_academic_dataset/locations.tsv\n\nbusinesses = LOAD 'yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\n/* {open=true, neighborhoods={}, review_count=14, stars=4.0, name=Drybar, business_id=LcAamvosJu0bcPgEVF-9sQ, state=AZ, full_address=3172 E Camelback Rd\nPhoenix, AZ85018, categories={(Hair Salons),(Hair Stylists),(Beauty &amp; Spas)}, longitude=-112.0131927, latitude=33.5107772, type=business, city=Phoenix} */\nlocations = FOREACH businesses GENERATE $0#'business_id' AS business_id:chararray, \n                                      $0#'longitude' AS longitude:double, \n                                      $0#'latitude' AS latitude:double;\n                                      \nSTORE locations INTO 'yelp_phoenix_academic_dataset/locations.tsv';</code></pre>\n\nI began with K-means, which gave me this unsatisfactory result:\n\n<center><img src=\"https://68.media.tumblr.com/0217fa7e16d9e4ac5a1fbe8124453a51/tumblr_inline_mxk4izZQgP1qdyhha.png\"></center>\n\nThen I tried DBSCAN:\n\n<pre><code># From example at <a href=\"http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py\">http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py</a>\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nimport pylab as pl\nimport numpy as np\n\nX = []\nf = open('yelp_phoenix_academic_dataset/locations.tsv/part-m-00000')\nfor line in f:\n    business_id, latitude, longitude = line.rstrip().split('\\t')\n    X.append([float(latitude), float(longitude)])\n\nX = StandardScaler().fit_transform(X)\ndb = DBSCAN(eps=0.3, min_samples=10).fit(X)\ncore_samples = db.core_sample_indices_\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nunique_labels = set(labels)\n\ncolors = pl.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = 'k'\n        markersize = 6\n    class_members = [index[0] for index in np.argwhere(labels == k)]\n    cluster_core_samples = [index for index in core_samples\n                            if labels[index] == k]\n    for index in class_members:\n        x = X[index]\n        if index in core_samples and k != -1:\n            markersize = 14\n        else:\n            markersize = 6\n        pl.plot(x[0], x[1], 'o', markerfacecolor=col,\n                markeredgecolor='k', markersize=markersize)</code></pre>\n\nWhich results in this:\n<center><img src=\"https://68.media.tumblr.com/bf09c5d681a3e830975cde6745fe3a14/tumblr_inline_mxk4dp9fxo1qdyhha.png\"></center>\n\nThe results look pretty good - you can see a large contiguous \u2018downtown\u2019 cluster, as well as highways, townships, etc. Glancing at a map of Phoenix, Arizona, you can see that it looks right. When overlaid onto a map of Phoenix, you can see towns as separate clusters!\n\n<center><img src=\"https://68.media.tumblr.com/9c182b01124f532ba7ef45f81d4edad2/tumblr_inline_mxk4dzyaNz1qdyhha.png\"></center></p>", "tree_html": ""}, "can_send_in_message": true, "id": 69514893525, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Yelp Dataset Challenge Part 0: Geographic Clustering of Yelp Businesses", "tags": [], "post_url": "http://datasyndrome.com/post/69514893525/yelp-dataset-challenge-part-0-geographic", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y10lQHZL", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1386622800, "note_count": 1, "trail": [{"content": "<p>Today I decided to experiment with unsupervised learning by clustering the <a href=\"https://www.yelp.com/academic_dataset\">Yelp Academic Dataset</a>. I decided to do a location-based clustering so that I could check my results against a map.\n\nI started by pre-processing the data in Pig into business_id/latitude/longitude records:\n\n</p><pre><code>REGISTER /me/Software/elephant-bird/pig/target/elephant-bird-pig-3.0.6-SNAPSHOT.jar\nREGISTER /me/Software/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nSET elephantbird.jsonloader.nestedLoad 'true'\n\nRegister 'udfs.py' using jython as udfs;\n\nSET default_parallel 10\n\nrmf yelp_phoenix_academic_dataset/locations.tsv\n\nbusinesses = LOAD 'yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\n/* {open=true, neighborhoods={}, review_count=14, stars=4.0, name=Drybar, business_id=LcAamvosJu0bcPgEVF-9sQ, state=AZ, full_address=3172 E Camelback Rd\nPhoenix, AZ85018, categories={(Hair Salons),(Hair Stylists),(Beauty &amp; Spas)}, longitude=-112.0131927, latitude=33.5107772, type=business, city=Phoenix} */\nlocations = FOREACH businesses GENERATE $0#'business_id' AS business_id:chararray, \n                                      $0#'longitude' AS longitude:double, \n                                      $0#'latitude' AS latitude:double;\n                                      \nSTORE locations INTO 'yelp_phoenix_academic_dataset/locations.tsv';</code></pre>\n\nI began with K-means, which gave me this unsatisfactory result:\n\n<p><img src=\"https://68.media.tumblr.com/0217fa7e16d9e4ac5a1fbe8124453a51/tumblr_inline_mxk4izZQgP1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\nThen I tried DBSCAN:\n\n<pre><code># From example at <a href=\"http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py\">http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py</a>\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nimport pylab as pl\nimport numpy as np\n\nX = []\nf = open('yelp_phoenix_academic_dataset/locations.tsv/part-m-00000')\nfor line in f:\n    business_id, latitude, longitude = line.rstrip().split('\\t')\n    X.append([float(latitude), float(longitude)])\n\nX = StandardScaler().fit_transform(X)\ndb = DBSCAN(eps=0.3, min_samples=10).fit(X)\ncore_samples = db.core_sample_indices_\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nunique_labels = set(labels)\n\ncolors = pl.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = 'k'\n        markersize = 6\n    class_members = [index[0] for index in np.argwhere(labels == k)]\n    cluster_core_samples = [index for index in core_samples\n                            if labels[index] == k]\n    for index in class_members:\n        x = X[index]\n        if index in core_samples and k != -1:\n            markersize = 14\n        else:\n            markersize = 6\n        pl.plot(x[0], x[1], 'o', markerfacecolor=col,\n                markeredgecolor='k', markersize=markersize)</code></pre>\n\nWhich results in this:\n<p><img src=\"https://68.media.tumblr.com/bf09c5d681a3e830975cde6745fe3a14/tumblr_inline_mxk4dp9fxo1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\nThe results look pretty good - you can see a large contiguous &lsquo;downtown&rsquo; cluster, as well as highways, townships, etc. Glancing at a map of Phoenix, Arizona, you can see that it looks right. When overlaid onto a map of Phoenix, you can see towns as separate clusters!\n\n<p><img src=\"https://68.media.tumblr.com/9c182b01124f532ba7ef45f81d4edad2/tumblr_inline_mxk4dzyaNz1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>", "content_raw": "<p>Today I decided to experiment with unsupervised learning by clustering the <a href=\"https://www.yelp.com/academic_dataset\">Yelp Academic Dataset</a>. I decided to do a location-based clustering so that I could check my results against a map.\n\nI started by pre-processing the data in Pig into business_id/latitude/longitude records:\n\n<pre><code>REGISTER /me/Software/elephant-bird/pig/target/elephant-bird-pig-3.0.6-SNAPSHOT.jar\nREGISTER /me/Software/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nSET elephantbird.jsonloader.nestedLoad 'true'\n\nRegister 'udfs.py' using jython as udfs;\n\nSET default_parallel 10\n\nrmf yelp_phoenix_academic_dataset/locations.tsv\n\nbusinesses = LOAD 'yelp_phoenix_academic_dataset/yelp_academic_dataset_business.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\n/* {open=true, neighborhoods={}, review_count=14, stars=4.0, name=Drybar, business_id=LcAamvosJu0bcPgEVF-9sQ, state=AZ, full_address=3172 E Camelback Rd\nPhoenix, AZ85018, categories={(Hair Salons),(Hair Stylists),(Beauty &amp; Spas)}, longitude=-112.0131927, latitude=33.5107772, type=business, city=Phoenix} */\nlocations = FOREACH businesses GENERATE $0#'business_id' AS business_id:chararray, \n                                      $0#'longitude' AS longitude:double, \n                                      $0#'latitude' AS latitude:double;\n                                      \nSTORE locations INTO 'yelp_phoenix_academic_dataset/locations.tsv';</code></pre>\n\nI began with K-means, which gave me this unsatisfactory result:\n\n<center><img src=\"https://68.media.tumblr.com/0217fa7e16d9e4ac5a1fbe8124453a51/tumblr_inline_mxk4izZQgP1qdyhha.png\"></center>\n\nThen I tried DBSCAN:\n\n<pre><code># From example at <a href=\"http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py\">http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py</a>\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nimport pylab as pl\nimport numpy as np\n\nX = []\nf = open('yelp_phoenix_academic_dataset/locations.tsv/part-m-00000')\nfor line in f:\n    business_id, latitude, longitude = line.rstrip().split('\\t')\n    X.append([float(latitude), float(longitude)])\n\nX = StandardScaler().fit_transform(X)\ndb = DBSCAN(eps=0.3, min_samples=10).fit(X)\ncore_samples = db.core_sample_indices_\nlabels = db.labels_\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nunique_labels = set(labels)\n\ncolors = pl.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = 'k'\n        markersize = 6\n    class_members = [index[0] for index in np.argwhere(labels == k)]\n    cluster_core_samples = [index for index in core_samples\n                            if labels[index] == k]\n    for index in class_members:\n        x = X[index]\n        if index in core_samples and k != -1:\n            markersize = 14\n        else:\n            markersize = 6\n        pl.plot(x[0], x[1], 'o', markerfacecolor=col,\n                markeredgecolor='k', markersize=markersize)</code></pre>\n\nWhich results in this:\n<center><img src=\"https://68.media.tumblr.com/bf09c5d681a3e830975cde6745fe3a14/tumblr_inline_mxk4dp9fxo1qdyhha.png\"></center>\n\nThe results look pretty good - you can see a large contiguous \u2018downtown\u2019 cluster, as well as highways, townships, etc. Glancing at a map of Phoenix, Arizona, you can see that it looks right. When overlaid onto a map of Phoenix, you can see towns as separate clusters!\n\n<center><img src=\"https://68.media.tumblr.com/9c182b01124f532ba7ef45f81d4edad2/tumblr_inline_mxk4dzyaNz1qdyhha.png\"></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "69514893525"}}], "date": "2013-12-09 21:00:00 GMT", "slug": "yelp-dataset-challenge-part-0-geographic", "blog_name": "rjurney", "summary": "Yelp Dataset Challenge Part 0: Geographic Clustering of Yelp Businesses", "can_reblog": true}, {"body": "<p>&ldquo;How do you QA Big Data Pipelines?&rdquo; </p>\n\n<p>The harsh reality is that some extent: you can&rsquo;t, as many errors are emergent as data volumes increase. One out of a large enough group of records must be corrupt. For what its worth, this is what I have on the topic:</p>\n\n<p>I started a discussion of Big Data ETL here on Quora, and there were some great answers: <a href=\"http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss\">http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss</a></p>\n\n<p><i>In general I would think that you only care about record loss during ETL if it meaningfully impacts the answer to some question on the transformed data.</i></p>\n\n<p>Pig could pioneer a sane approach via the ON ERROR proposal, which would let you split errant records off into its own relation to deal with as needed by a custom User-Defined-Function. This would enable you to alter your pipelines to accommodate the errant records, or would at least let you understand the type of records that are going missing. In addition, you PIG-2620 would allow you to set thresholds for errors: up to some % and/or some raw number of records lost.</p>\n\n<p><a href=\"https://issues.apache.org/jira/browse/PIG-2620\">https://issues.apache.org/jira/browse/PIG-2620</a><br/>\n<a href=\"http://wiki.apache.org/pig/PigErrorHandlingInScripts\">http://wiki.apache.org/pig/PigErrorHandlingInScripts</a></p>", "liked": false, "followed": false, "reblog_key": "HHseYHoZ", "reblog": {"comment": "<p>\u201cHow do you QA Big Data Pipelines?\u201d </p>\n\n<p>The harsh reality is that some extent: you can\u2019t, as many errors are emergent as data volumes increase. One out of a large enough group of records must be corrupt. For what its worth, this is what I have on the topic:</p>\n\n<p>I started a discussion of Big Data ETL here on Quora, and there were some great answers: <a href=\"http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss\">http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss</a></p>\n\n<p><i>In general I would think that you only care about record loss during ETL if it meaningfully impacts the answer to some question on the transformed data.</i></p>\n\n<p>Pig could pioneer a sane approach via the ON ERROR proposal, which would let you split errant records off into its own relation to deal with as needed by a custom User-Defined-Function. This would enable you to alter your pipelines to accommodate the errant records, or would at least let you understand the type of records that are going missing. In addition, you PIG-2620 would allow you to set thresholds for errors: up to some % and/or some raw number of records lost.</p>\n\n<p><a href=\"https://issues.apache.org/jira/browse/PIG-2620\">https://issues.apache.org/jira/browse/PIG-2620</a><br><a href=\"http://wiki.apache.org/pig/PigErrorHandlingInScripts\">http://wiki.apache.org/pig/PigErrorHandlingInScripts</a></p>", "tree_html": ""}, "can_send_in_message": true, "id": 69510590168, "display_avatar": true, "can_reply": true, "can_like": false, "title": "ON ERROR: Error Processing in Large Data", "tags": [], "post_url": "http://datasyndrome.com/post/69510590168/on-error-error-processing-in-large-data", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y10l9sxO", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1386620100, "note_count": 1, "trail": [{"content": "<p>&ldquo;How do you QA Big Data Pipelines?&rdquo; </p>\n\n<p>The harsh reality is that some extent: you can&rsquo;t, as many errors are emergent as data volumes increase. One out of a large enough group of records must be corrupt. For what its worth, this is what I have on the topic:</p>\n\n<p>I started a discussion of Big Data ETL here on Quora, and there were some great answers: <a href=\"http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss\">http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss</a></p>\n\n<p><i>In general I would think that you only care about record loss during ETL if it meaningfully impacts the answer to some question on the transformed data.</i></p>\n\n<p>Pig could pioneer a sane approach via the ON ERROR proposal, which would let you split errant records off into its own relation to deal with as needed by a custom User-Defined-Function. This would enable you to alter your pipelines to accommodate the errant records, or would at least let you understand the type of records that are going missing. In addition, you PIG-2620 would allow you to set thresholds for errors: up to some % and/or some raw number of records lost.</p>\n\n<p><a href=\"https://issues.apache.org/jira/browse/PIG-2620\">https://issues.apache.org/jira/browse/PIG-2620</a><br /><a href=\"http://wiki.apache.org/pig/PigErrorHandlingInScripts\">http://wiki.apache.org/pig/PigErrorHandlingInScripts</a></p>", "content_raw": "<p>\u201cHow do you QA Big Data Pipelines?\u201d </p>\n\n<p>The harsh reality is that some extent: you can\u2019t, as many errors are emergent as data volumes increase. One out of a large enough group of records must be corrupt. For what its worth, this is what I have on the topic:</p>\n\n<p>I started a discussion of Big Data ETL here on Quora, and there were some great answers: <a href=\"http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss\">http://www.quora.com/Big-Data/In-Big-Data-ETL-how-many-records-are-an-acceptable-loss</a></p>\n\n<p><i>In general I would think that you only care about record loss during ETL if it meaningfully impacts the answer to some question on the transformed data.</i></p>\n\n<p>Pig could pioneer a sane approach via the ON ERROR proposal, which would let you split errant records off into its own relation to deal with as needed by a custom User-Defined-Function. This would enable you to alter your pipelines to accommodate the errant records, or would at least let you understand the type of records that are going missing. In addition, you PIG-2620 would allow you to set thresholds for errors: up to some % and/or some raw number of records lost.</p>\n\n<p><a href=\"https://issues.apache.org/jira/browse/PIG-2620\">https://issues.apache.org/jira/browse/PIG-2620</a><br><a href=\"http://wiki.apache.org/pig/PigErrorHandlingInScripts\">http://wiki.apache.org/pig/PigErrorHandlingInScripts</a></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "69510590168"}}], "date": "2013-12-09 20:15:00 GMT", "slug": "on-error-error-processing-in-large-data", "blog_name": "rjurney", "summary": "ON ERROR: Error Processing in Large Data", "can_reblog": true}, {"body": "In this example we have a dataset representing the input to a logistic regression example, for the 2nd homework in Andrew Ng&rsquo;s Coursera class. I wanted to scatter plot admissions by x1/x2, and color the dots two colors - one for admitted, one for not admitted. \n\n<br/><br/>\nBelow we do this using Numpy masks to create a negative/positive index against the y variable, which represents acceptance (0/1). Then we apply that mask to the x1/x2 variables, and issue two plot commands - one for negative, one for positive.\n\n<br/><br/>\nAnd voila!\n\n<center><img src=\"https://68.media.tumblr.com/f885d4db961526d770ffee72230399e9/tumblr_inline_mwfuaeWJHP1qdyhha.png\"/></center>\n\n<pre><code># Build X, Y from file\nf = open('ex2data1.txt')\nlines = f.readlines()\nx1 = []\nx2 = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x1.append(float(vals[0]))\n    x2.append(float(vals[1]))\n    y.append(int(vals[2]))\n\n\n# Build numpy arrays\nx1 = np.array(x1)\nx2 = np.array(x2)\ny = np.array(y)\n\n\n# Build positive/negative masks from Y\npos_mask = (y == 1)\nneg_mask = (y == 0)\n\n\n# Apply masks to X\npositive_x1 = x1[pos_mask]\nnegative_x1 = x1[neg_mask]\npositive_x2 = x2[pos_mask]\nnegative_x2 = x2[neg_mask]\n\n\n# Scatter plot results in two colors\npl.scatter(positive_x1, positive_x2, c='b')\npl.scatter(negative_x1, negative_x2, c='r')</code></pre>", "liked": false, "followed": false, "reblog_key": "iXRC6GwR", "reblog": {"comment": "<p>In this example we have a dataset representing the input to a logistic regression example, for the 2nd homework in Andrew Ng\u2019s Coursera class. I wanted to scatter plot admissions by x1/x2, and color the dots two colors - one for admitted, one for not admitted. \n\n<br><br>\nBelow we do this using Numpy masks to create a negative/positive index against the y variable, which represents acceptance (0/1). Then we apply that mask to the x1/x2 variables, and issue two plot commands - one for negative, one for positive.\n\n<br><br>\nAnd voila!\n\n<center><img src=\"https://68.media.tumblr.com/f885d4db961526d770ffee72230399e9/tumblr_inline_mwfuaeWJHP1qdyhha.png\"></center>\n\n<pre><code># Build X, Y from file\nf = open('ex2data1.txt')\nlines = f.readlines()\nx1 = []\nx2 = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x1.append(float(vals[0]))\n    x2.append(float(vals[1]))\n    y.append(int(vals[2]))\n\n\n# Build numpy arrays\nx1 = np.array(x1)\nx2 = np.array(x2)\ny = np.array(y)\n\n\n# Build positive/negative masks from Y\npos_mask = (y == 1)\nneg_mask = (y == 0)\n\n\n# Apply masks to X\npositive_x1 = x1[pos_mask]\nnegative_x1 = x1[neg_mask]\npositive_x2 = x2[pos_mask]\nnegative_x2 = x2[neg_mask]\n\n\n# Scatter plot results in two colors\npl.scatter(positive_x1, positive_x2, c='b')\npl.scatter(negative_x1, negative_x2, c='r')</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 67327023014, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Using Numpy Masks and Matplotlib to Create Multi-colored Scatterplots", "tags": [], "post_url": "http://datasyndrome.com/post/67327023014/using-numpy-masks-and-matplotlib-to-create", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y_j0DUc", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1384742760, "note_count": 0, "trail": [{"content": "<p><p>In this example we have a dataset representing the input to a logistic regression example, for the 2nd homework in Andrew Ng&rsquo;s Coursera class. I wanted to scatter plot admissions by x1/x2, and color the dots two colors - one for admitted, one for not admitted. \n\n<br /><br />\nBelow we do this using Numpy masks to create a negative/positive index against the y variable, which represents acceptance (0/1). Then we apply that mask to the x1/x2 variables, and issue two plot commands - one for negative, one for positive.\n\n<br /><br />\nAnd voila!\n\n</p><p><img src=\"https://68.media.tumblr.com/f885d4db961526d770ffee72230399e9/tumblr_inline_mwfuaeWJHP1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p>\n\n<pre><code># Build X, Y from file\nf = open('ex2data1.txt')\nlines = f.readlines()\nx1 = []\nx2 = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x1.append(float(vals[0]))\n    x2.append(float(vals[1]))\n    y.append(int(vals[2]))\n\n\n# Build numpy arrays\nx1 = np.array(x1)\nx2 = np.array(x2)\ny = np.array(y)\n\n\n# Build positive/negative masks from Y\npos_mask = (y == 1)\nneg_mask = (y == 0)\n\n\n# Apply masks to X\npositive_x1 = x1[pos_mask]\nnegative_x1 = x1[neg_mask]\npositive_x2 = x2[pos_mask]\nnegative_x2 = x2[neg_mask]\n\n\n# Scatter plot results in two colors\npl.scatter(positive_x1, positive_x2, c='b')\npl.scatter(negative_x1, negative_x2, c='r')</code></pre></p>", "content_raw": "<p>In this example we have a dataset representing the input to a logistic regression example, for the 2nd homework in Andrew Ng\u2019s Coursera class. I wanted to scatter plot admissions by x1/x2, and color the dots two colors - one for admitted, one for not admitted. \n\n<br><br>\nBelow we do this using Numpy masks to create a negative/positive index against the y variable, which represents acceptance (0/1). Then we apply that mask to the x1/x2 variables, and issue two plot commands - one for negative, one for positive.\n\n<br><br>\nAnd voila!\n\n<center><img src=\"https://68.media.tumblr.com/f885d4db961526d770ffee72230399e9/tumblr_inline_mwfuaeWJHP1qdyhha.png\"></center>\n\n<pre><code># Build X, Y from file\nf = open('ex2data1.txt')\nlines = f.readlines()\nx1 = []\nx2 = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x1.append(float(vals[0]))\n    x2.append(float(vals[1]))\n    y.append(int(vals[2]))\n\n\n# Build numpy arrays\nx1 = np.array(x1)\nx2 = np.array(x2)\ny = np.array(y)\n\n\n# Build positive/negative masks from Y\npos_mask = (y == 1)\nneg_mask = (y == 0)\n\n\n# Apply masks to X\npositive_x1 = x1[pos_mask]\nnegative_x1 = x1[neg_mask]\npositive_x2 = x2[pos_mask]\nnegative_x2 = x2[neg_mask]\n\n\n# Scatter plot results in two colors\npl.scatter(positive_x1, positive_x2, c='b')\npl.scatter(negative_x1, negative_x2, c='r')</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "67327023014"}}], "date": "2013-11-18 02:46:00 GMT", "slug": "using-numpy-masks-and-matplotlib-to-create", "blog_name": "rjurney", "summary": "Using Numpy Masks and Matplotlib to Create Multi-colored Scatterplots", "can_reblog": true}, {"body": "Pulled from this <a href=\"https://github.com/mrocklin/multipolyfit/blob/master/multipolyfit/core.py\">example on stackoverflow</a>, we can perform a higher order (x squared) polynomial regress against the same data from example one in the last post:\n\n<pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\n# Build X/Y arrays from file 1\nf = open('ex1data1.txt')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\n\nx = np.array(x)\ny = np.array(y)\n\n# Now curve fit a higher polynomial to the same data\npopt, pcov = curve_fit(func, x, y)\n\"\"\"\nThe result is:\npopt[0] = a , popt[1] = b and popt[2] = c of the function,\nso f(x) = popt[0]*x**2 + popt[1]*x**3 + popt[2].\n\"\"\"\n\nprint \"a = %s , b = %s, c = %s\" % (popt[0], popt[1], popt[2])\n\"\"\"\nPrint the coefficients and plot the funcion.\n\"\"\"\n\nplt.plot(x, func(x, *popt), label=\"Fitted Curve\")</code></pre>", "liked": false, "followed": false, "reblog_key": "RxpZLwwt", "reblog": {"comment": "<p>Pulled from this <a href=\"https://github.com/mrocklin/multipolyfit/blob/master/multipolyfit/core.py\">example on stackoverflow</a>, we can perform a higher order (x squared) polynomial regress against the same data from example one in the last post:\n\n<pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\n# Build X/Y arrays from file 1\nf = open('ex1data1.txt')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\n\nx = np.array(x)\ny = np.array(y)\n\n# Now curve fit a higher polynomial to the same data\npopt, pcov = curve_fit(func, x, y)\n\"\"\"\nThe result is:\npopt[0] = a , popt[1] = b and popt[2] = c of the function,\nso f(x) = popt[0]*x**2 + popt[1]*x**3 + popt[2].\n\"\"\"\n\nprint \"a = %s , b = %s, c = %s\" % (popt[0], popt[1], popt[2])\n\"\"\"\nPrint the coefficients and plot the funcion.\n\"\"\"\n\nplt.plot(x, func(x, *popt), label=\"Fitted Curve\")</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 67231480723, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Higher Order Curve Polynomial Regression in Python", "tags": [], "post_url": "http://datasyndrome.com/post/67231480723/higher-order-curve-polynomial-regression-in-python", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y_dJlkJ", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1384668720, "note_count": 0, "trail": [{"content": "<p><p>Pulled from this <a href=\"https://github.com/mrocklin/multipolyfit/blob/master/multipolyfit/core.py\">example on stackoverflow</a>, we can perform a higher order (x squared) polynomial regress against the same data from example one in the last post:\n\n</p><pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\n# Build X/Y arrays from file 1\nf = open('ex1data1.txt')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\n\nx = np.array(x)\ny = np.array(y)\n\n# Now curve fit a higher polynomial to the same data\npopt, pcov = curve_fit(func, x, y)\n\"\"\"\nThe result is:\npopt[0] = a , popt[1] = b and popt[2] = c of the function,\nso f(x) = popt[0]*x**2 + popt[1]*x**3 + popt[2].\n\"\"\"\n\nprint \"a = %s , b = %s, c = %s\" % (popt[0], popt[1], popt[2])\n\"\"\"\nPrint the coefficients and plot the funcion.\n\"\"\"\n\nplt.plot(x, func(x, *popt), label=\"Fitted Curve\")</code></pre></p>", "content_raw": "<p>Pulled from this <a href=\"https://github.com/mrocklin/multipolyfit/blob/master/multipolyfit/core.py\">example on stackoverflow</a>, we can perform a higher order (x squared) polynomial regress against the same data from example one in the last post:\n\n<pre><code>from scipy import stats\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\n# Build X/Y arrays from file 1\nf = open('ex1data1.txt')\nlines = f.readlines()\nx = []\ny = []\nfor line in lines:\n    line = line.replace(\"\\n\", \"\")\n    vals = line.split(\",\")\n    x.append(float(vals[0]))\n    y.append(float(vals[1]))\n\nx = np.array(x)\ny = np.array(y)\n\n# Now curve fit a higher polynomial to the same data\npopt, pcov = curve_fit(func, x, y)\n\"\"\"\nThe result is:\npopt[0] = a , popt[1] = b and popt[2] = c of the function,\nso f(x) = popt[0]*x**2 + popt[1]*x**3 + popt[2].\n\"\"\"\n\nprint \"a = %s , b = %s, c = %s\" % (popt[0], popt[1], popt[2])\n\"\"\"\nPrint the coefficients and plot the funcion.\n\"\"\"\n\nplt.plot(x, func(x, *popt), label=\"Fitted Curve\")</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "67231480723"}}], "date": "2013-11-17 06:12:00 GMT", "slug": "higher-order-curve-polynomial-regression-in-python", "blog_name": "rjurney", "summary": "Higher Order Curve Polynomial Regression in Python", "can_reblog": true}, {"body": "The data in this example comes from Andrew Ng&rsquo;s Coursera class, homework assignment 1. I&rsquo;m working the examples in Python as well as MATLAB to better remember application, and to ease the pain of using MATLAB :)\n\nThe data looks like this:\n\n<pre><code>2104,3,399900\n1600,3,329900\n2400,3,369000\n1416,2,232000\n3000,4,539900\n1985,4,299900\n1534,3,314900\n1427,3,198999\n1380,3,212000\n1494,3,242500\n1940,4,239999\n2000,3,347000\n1890,3,329999\n4478,5,699900\n1268,3,259900\n2300,4,449900\n1320,2,299900\n1236,3,199900\n2609,4,499998\n3031,4,599000\n1767,3,252900\n1888,2,255000\n1604,3,242900\n1962,4,259900\n3890,3,573900\n1100,3,249900\n1458,3,464500\n2526,3,469000\n2200,3,475000\n2637,3,299900\n1839,2,349900\n1000,1,169900\n2040,4,314900\n3137,3,579900\n1811,4,285900\n1437,3,249900\n1239,3,229900\n2132,4,345000\n4215,4,549000\n2162,4,287000\n1664,2,368500\n2238,3,329900\n2567,4,314000\n1200,3,299000\n852,2,179900\n1852,4,299900\n1203,3,239500</code></pre>\n\nIn the first example we do simple single linear regression using scipy.stats.linregress:\n\n<pre><code>    from scipy import stats\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Build X/Y arrays from file 1\n    f = open('ex1data1.txt')\n    lines = f.readlines()\n    x = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x.append(float(vals[0]))\n        y.append(float(vals[1]))\n\n    # Run regression\n    gradient, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n    print gradient, intercept, r_value, p_value, std_err\n\n    plt.scatter(x, y)\n    plt.plot(x, (gradient*x + intercept))</code></pre>\n\nIn the second example, we do multiple regression using sklearn.linear_model.LinearRegression()\n\n <pre><code>   from sklearn import  linear_model\n    \n    # Build X, Y from 2nd file\n    f = open('ex1data2.txt')\n    lines = f.readlines()\n    x1 = []\n    x2 = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x1.append(float(vals[0]))\n        x2.append(float(vals[1]))\n        y.append(float(vals[2]))\n\n    x1 = np.array(x1)\n    x2 = np.array(x2)\n    y = np.array(y)\n\n    # linregress doesn't do multi regression, so we use sklearn\n    ones = np.ones(x1.shape)\n    x = np.vstack([x1, x2]).T # don't need ones for \n\n    regr = linear_model.LinearRegression()\n    regr.fit( x, y )\n    regr.predict([3000, 3]) </code></pre>", "liked": false, "followed": false, "reblog_key": "HYFNPiGs", "reblog": {"comment": "<p>The data in this example comes from Andrew Ng\u2019s Coursera class, homework assignment 1. I\u2019m working the examples in Python as well as MATLAB to better remember application, and to ease the pain of using MATLAB :)\n\nThe data looks like this:\n\n<pre><code>2104,3,399900\n1600,3,329900\n2400,3,369000\n1416,2,232000\n3000,4,539900\n1985,4,299900\n1534,3,314900\n1427,3,198999\n1380,3,212000\n1494,3,242500\n1940,4,239999\n2000,3,347000\n1890,3,329999\n4478,5,699900\n1268,3,259900\n2300,4,449900\n1320,2,299900\n1236,3,199900\n2609,4,499998\n3031,4,599000\n1767,3,252900\n1888,2,255000\n1604,3,242900\n1962,4,259900\n3890,3,573900\n1100,3,249900\n1458,3,464500\n2526,3,469000\n2200,3,475000\n2637,3,299900\n1839,2,349900\n1000,1,169900\n2040,4,314900\n3137,3,579900\n1811,4,285900\n1437,3,249900\n1239,3,229900\n2132,4,345000\n4215,4,549000\n2162,4,287000\n1664,2,368500\n2238,3,329900\n2567,4,314000\n1200,3,299000\n852,2,179900\n1852,4,299900\n1203,3,239500</code></pre>\n\nIn the first example we do simple single linear regression using scipy.stats.linregress:\n\n<pre><code>    from scipy import stats\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Build X/Y arrays from file 1\n    f = open('ex1data1.txt')\n    lines = f.readlines()\n    x = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x.append(float(vals[0]))\n        y.append(float(vals[1]))\n\n    # Run regression\n    gradient, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n    print gradient, intercept, r_value, p_value, std_err\n\n    plt.scatter(x, y)\n    plt.plot(x, (gradient*x + intercept))</code></pre>\n\nIn the second example, we do multiple regression using sklearn.linear_model.LinearRegression()\n\n <pre><code>   from sklearn import  linear_model\n    \n    # Build X, Y from 2nd file\n    f = open('ex1data2.txt')\n    lines = f.readlines()\n    x1 = []\n    x2 = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x1.append(float(vals[0]))\n        x2.append(float(vals[1]))\n        y.append(float(vals[2]))\n\n    x1 = np.array(x1)\n    x2 = np.array(x2)\n    y = np.array(y)\n\n    # linregress doesn't do multi regression, so we use sklearn\n    ones = np.ones(x1.shape)\n    x = np.vstack([x1, x2]).T # don't need ones for \n\n    regr = linear_model.LinearRegression()\n    regr.fit( x, y )\n    regr.predict([3000, 3]) </code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 67131587619, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Linear Regression in Python", "tags": [], "post_url": "http://datasyndrome.com/post/67131587619/linear-regression-in-python", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y_XMhmZ", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1384585080, "note_count": 0, "trail": [{"content": "<p><p>The data in this example comes from Andrew Ng&rsquo;s Coursera class, homework assignment 1. I&rsquo;m working the examples in Python as well as MATLAB to better remember application, and to ease the pain of using MATLAB :)\n\nThe data looks like this:\n\n</p><pre><code>2104,3,399900\n1600,3,329900\n2400,3,369000\n1416,2,232000\n3000,4,539900\n1985,4,299900\n1534,3,314900\n1427,3,198999\n1380,3,212000\n1494,3,242500\n1940,4,239999\n2000,3,347000\n1890,3,329999\n4478,5,699900\n1268,3,259900\n2300,4,449900\n1320,2,299900\n1236,3,199900\n2609,4,499998\n3031,4,599000\n1767,3,252900\n1888,2,255000\n1604,3,242900\n1962,4,259900\n3890,3,573900\n1100,3,249900\n1458,3,464500\n2526,3,469000\n2200,3,475000\n2637,3,299900\n1839,2,349900\n1000,1,169900\n2040,4,314900\n3137,3,579900\n1811,4,285900\n1437,3,249900\n1239,3,229900\n2132,4,345000\n4215,4,549000\n2162,4,287000\n1664,2,368500\n2238,3,329900\n2567,4,314000\n1200,3,299000\n852,2,179900\n1852,4,299900\n1203,3,239500</code></pre>\n\nIn the first example we do simple single linear regression using scipy.stats.linregress:\n\n<pre><code>    from scipy import stats\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Build X/Y arrays from file 1\n    f = open('ex1data1.txt')\n    lines = f.readlines()\n    x = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x.append(float(vals[0]))\n        y.append(float(vals[1]))\n\n    # Run regression\n    gradient, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n    print gradient, intercept, r_value, p_value, std_err\n\n    plt.scatter(x, y)\n    plt.plot(x, (gradient*x + intercept))</code></pre>\n\nIn the second example, we do multiple regression using sklearn.linear_model.LinearRegression()\n\n <pre><code>   from sklearn import  linear_model\n    \n    # Build X, Y from 2nd file\n    f = open('ex1data2.txt')\n    lines = f.readlines()\n    x1 = []\n    x2 = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x1.append(float(vals[0]))\n        x2.append(float(vals[1]))\n        y.append(float(vals[2]))\n\n    x1 = np.array(x1)\n    x2 = np.array(x2)\n    y = np.array(y)\n\n    # linregress doesn't do multi regression, so we use sklearn\n    ones = np.ones(x1.shape)\n    x = np.vstack([x1, x2]).T # don't need ones for \n\n    regr = linear_model.LinearRegression()\n    regr.fit( x, y )\n    regr.predict([3000, 3]) </code></pre></p>", "content_raw": "<p>The data in this example comes from Andrew Ng\u2019s Coursera class, homework assignment 1. I\u2019m working the examples in Python as well as MATLAB to better remember application, and to ease the pain of using MATLAB :)\n\nThe data looks like this:\n\n<pre><code>2104,3,399900\n1600,3,329900\n2400,3,369000\n1416,2,232000\n3000,4,539900\n1985,4,299900\n1534,3,314900\n1427,3,198999\n1380,3,212000\n1494,3,242500\n1940,4,239999\n2000,3,347000\n1890,3,329999\n4478,5,699900\n1268,3,259900\n2300,4,449900\n1320,2,299900\n1236,3,199900\n2609,4,499998\n3031,4,599000\n1767,3,252900\n1888,2,255000\n1604,3,242900\n1962,4,259900\n3890,3,573900\n1100,3,249900\n1458,3,464500\n2526,3,469000\n2200,3,475000\n2637,3,299900\n1839,2,349900\n1000,1,169900\n2040,4,314900\n3137,3,579900\n1811,4,285900\n1437,3,249900\n1239,3,229900\n2132,4,345000\n4215,4,549000\n2162,4,287000\n1664,2,368500\n2238,3,329900\n2567,4,314000\n1200,3,299000\n852,2,179900\n1852,4,299900\n1203,3,239500</code></pre>\n\nIn the first example we do simple single linear regression using scipy.stats.linregress:\n\n<pre><code>    from scipy import stats\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Build X/Y arrays from file 1\n    f = open('ex1data1.txt')\n    lines = f.readlines()\n    x = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x.append(float(vals[0]))\n        y.append(float(vals[1]))\n\n    # Run regression\n    gradient, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n    print gradient, intercept, r_value, p_value, std_err\n\n    plt.scatter(x, y)\n    plt.plot(x, (gradient*x + intercept))</code></pre>\n\nIn the second example, we do multiple regression using sklearn.linear_model.LinearRegression()\n\n <pre><code>   from sklearn import  linear_model\n    \n    # Build X, Y from 2nd file\n    f = open('ex1data2.txt')\n    lines = f.readlines()\n    x1 = []\n    x2 = []\n    y = []\n    for line in lines:\n        line = line.replace(\"\\n\", \"\")\n        vals = line.split(\",\")\n        x1.append(float(vals[0]))\n        x2.append(float(vals[1]))\n        y.append(float(vals[2]))\n\n    x1 = np.array(x1)\n    x2 = np.array(x2)\n    y = np.array(y)\n\n    # linregress doesn't do multi regression, so we use sklearn\n    ones = np.ones(x1.shape)\n    x = np.vstack([x1, x2]).T # don't need ones for \n\n    regr = linear_model.LinearRegression()\n    regr.fit( x, y )\n    regr.predict([3000, 3]) </code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "67131587619"}}], "date": "2013-11-16 06:58:00 GMT", "slug": "linear-regression-in-python", "blog_name": "rjurney", "summary": "Linear Regression in Python", "can_reblog": true}, {"body": "<p>My first book, Agile Data Science, has been published by O'Reilly. You can buy it here: <a href=\"http://shop.oreilly.com/product/0636920025054.do\">http://shop.oreilly.com/product/0636920025054.do</a>\n</p><center>\n<img src=\"https://68.media.tumblr.com/0226f74c0ab16b00fc32ca4ff401f0bb/tumblr_inline_mv93bc3ewP1qdyhha.jpg\"/></center>", "liked": false, "followed": false, "reblog_key": "4ZIsPorX", "reblog": {"comment": "<p><p>My first book, Agile Data Science, has been published by O'Reilly. You can buy it here: <a href=\"http://shop.oreilly.com/product/0636920025054.do\">http://shop.oreilly.com/product/0636920025054.do</a>\n</p><center>\n<img src=\"https://68.media.tumblr.com/0226f74c0ab16b00fc32ca4ff401f0bb/tumblr_inline_mv93bc3ewP1qdyhha.jpg\"></center></p>", "tree_html": ""}, "can_send_in_message": true, "id": 65090671903, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Agile Data Science PUBLISHED", "tags": [], "post_url": "http://datasyndrome.com/post/65090671903/agile-data-science-published", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yydjDKV", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1382748120, "note_count": 2, "trail": [{"content": "<p>My first book, Agile Data Science, has been published by O'Reilly. You can buy it here: <a href=\"http://shop.oreilly.com/product/0636920025054.do\">http://shop.oreilly.com/product/0636920025054.do</a>\n</p>\n<p><img src=\"https://68.media.tumblr.com/0226f74c0ab16b00fc32ca4ff401f0bb/tumblr_inline_mv93bc3ewP1qdyhha.jpg\" class=\"toggle_inline_image inline_image constrained_image\"/></p>", "content_raw": "<p><p>My first book, Agile Data Science, has been published by O'Reilly. You can buy it here: <a href=\"http://shop.oreilly.com/product/0636920025054.do\">http://shop.oreilly.com/product/0636920025054.do</a>\n</p><center>\n<img src=\"https://68.media.tumblr.com/0226f74c0ab16b00fc32ca4ff401f0bb/tumblr_inline_mv93bc3ewP1qdyhha.jpg\"></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "65090671903"}}], "date": "2013-10-26 00:42:00 GMT", "slug": "agile-data-science-published", "blog_name": "rjurney", "summary": "Agile Data Science PUBLISHED", "can_reblog": true}, {"body": "<p>In our last four posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github&rsquo;s 18 event types</a>, <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a> and <a href=\"http://datasyndrome.com/post/52071797939/pearsons-correlation-between-github-projects\">calculating a Pearson&rsquo;s correlation between projects</a>.</p>\n\n<p>To create an item-based nearest neighbor recommender, <a href=\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/sphilip/cos.html\">cosine similarity</a> is a better measure of similarity between projects. Below, we implement that measure between github projects using Pig and Python.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5716929\">https://gist.github.com/rjurney/5716929</a></div>\n\n<p>Once we have a distance between projects, we can immediately display the most similar projects:</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5716952\">https://gist.github.com/rjurney/5716952</a></div>", "liked": false, "followed": false, "reblog_key": "g1mdgcel", "reblog": {"comment": "<p><p>In our last four posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github\u2019s 18 event types</a>, <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a> and <a href=\"http://datasyndrome.com/post/52071797939/pearsons-correlation-between-github-projects\">calculating a Pearson\u2019s correlation between projects</a>.</p>\n\n<p>To create an item-based nearest neighbor recommender, <a href=\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/sphilip/cos.html\">cosine similarity</a> is a better measure of similarity between projects. Below, we implement that measure between github projects using Pig and Python.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5716929\">https://gist.github.com/rjurney/5716929</a></div>\n\n<p>Once we have a distance between projects, we can immediately display the most similar projects:</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5716952\">https://gist.github.com/rjurney/5716952</a></div></p>", "tree_html": ""}, "can_send_in_message": true, "id": 52242629879, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Cosine Similarity between Github Projects", "tags": [], "post_url": "http://datasyndrome.com/post/52242629879/cosine-similarity-between-github-projects", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5ymfvqJt", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1370463780, "note_count": 0, "trail": [{"content": "<p><p>In our last four posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github&rsquo;s 18 event types</a>, <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a> and <a href=\"http://datasyndrome.com/post/52071797939/pearsons-correlation-between-github-projects\">calculating a Pearson&rsquo;s correlation between projects</a>.</p>\n\n<p>To create an item-based nearest neighbor recommender, <a href=\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/sphilip/cos.html\">cosine similarity</a> is a better measure of similarity between projects. Below, we implement that measure between github projects using Pig and Python.</p>\n\n<a href=\"https://gist.github.com/rjurney/5716929\">https://gist.github.com/rjurney/5716929</a>\n\n<p>Once we have a distance between projects, we can immediately display the most similar projects:</p>\n\n<a href=\"https://gist.github.com/rjurney/5716952\">https://gist.github.com/rjurney/5716952</a></p>", "content_raw": "<p><p>In our last four posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github\u2019s 18 event types</a>, <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a> and <a href=\"http://datasyndrome.com/post/52071797939/pearsons-correlation-between-github-projects\">calculating a Pearson\u2019s correlation between projects</a>.</p>\n\n<p>To create an item-based nearest neighbor recommender, <a href=\"http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/sphilip/cos.html\">cosine similarity</a> is a better measure of similarity between projects. Below, we implement that measure between github projects using Pig and Python.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5716929\">https://gist.github.com/rjurney/5716929</a></div>\n\n<p>Once we have a distance between projects, we can immediately display the most similar projects:</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5716952\">https://gist.github.com/rjurney/5716952</a></div></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "52242629879"}}], "date": "2013-06-05 20:23:00 GMT", "slug": "cosine-similarity-between-github-projects", "blog_name": "rjurney", "summary": "Cosine Similarity between Github Projects", "can_reblog": true}, {"body": "<h3>Introduction</h3>\n\n<p>In our last three posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github&rsquo;s 18 event types</a> and <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a>.</p>\n\n<p>In this post we will be measuring the distance between github projects (items) using the <a href=\"http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\">Pearson product-moment correlation coefficient</a> using Pig and Jython.</p>\n\n<h3>Loading the Data</h3>\n\n<p>We addressed loading the data in our last post. Briefly, this code loads select Github Archive events in the form of ratings:</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5700101\">https://gist.github.com/rjurney/5700101</a></div>\n\n<h3>Calculating Pearson&rsquo;s</h3>\n\n<p>Once the ratings are loaded, we need to make the links bidirectional, to increase their density and to make links between projects flow both-ways. Next, we need to filter out the top-most cross-linked projects, as they are not relevant and make the next step never finish. Next, we emit all co-ratings per project. This means we emit a project pair and ratings, each time a user has rated two projects. This is the meat of our recommendation data. Finally, we take a Pearson&rsquo;s distance between all projects with co-ratings.\n\n</p><div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5700143\">https://gist.github.com/rjurney/5700143</a></div>\n\nThe Pearson&rsquo;s correlation coefficient tells us how similar different projects are, based on their ratings. This data can be used to drive recommendations, which we&rsquo;ll look at tomorrow. For now, a sample of the Pearon&rsquo;s scores look like this:\n\n<pre><code>apache/pig      apache/avro     0.6914285714285715\napache/pig      apache/bval     1.0\napache/pig      apache/gora     1.0\napache/pig      apache/hive     0.6410256410256406\napache/pig      apache/isis     1.0\napache/pig      apache/jena     1.0\napache/pig      apache/lucy     1.0\napache/pig      apache/mina     1.0\napache/pig      apache/oodt     1.0\napache/pig      apache/qpid     1.0\napache/pig      apache/rave     1.0\napache/pig      apache/solr     1.0\napache/pig      apache/tika     1.0\napache/pig      apache/wink     1.0\napache/pig      enyojs/enyo     1.0\napache/pig      rails/rails     0.9486832980505138\napache/pig      scala/scala     1.0\napache/pig      zohmg/zohmg     1.0\napache/pig      andrew/split    0.8485281374238569\napache/pig      apache/camel    1.0\napache/pig      apache/derby    1.0\napache/pig      apache/flume    0.7352941176470589\napache/pig      apache/hbase    0.644736842105263\napache/pig      apache/httpd    0.7352941176470589</code></pre>", "liked": false, "followed": false, "reblog_key": "ikwTX6uE", "reblog": {"comment": "<p><h3>Introduction</h3>\n\n<p>In our last three posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github\u2019s 18 event types</a> and <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a>.</p>\n\n<p>In this post we will be measuring the distance between github projects (items) using the <a href=\"http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\">Pearson product-moment correlation coefficient</a> using Pig and Jython.</p>\n\n<h3>Loading the Data</h3>\n\n<p>We addressed loading the data in our last post. Briefly, this code loads select Github Archive events in the form of ratings:</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5700101\">https://gist.github.com/rjurney/5700101</a></div>\n\n<h3>Calculating Pearson\u2019s</h3>\n\n<p>Once the ratings are loaded, we need to make the links bidirectional, to increase their density and to make links between projects flow both-ways. Next, we need to filter out the top-most cross-linked projects, as they are not relevant and make the next step never finish. Next, we emit all co-ratings per project. This means we emit a project pair and ratings, each time a user has rated two projects. This is the meat of our recommendation data. Finally, we take a Pearson\u2019s distance between all projects with co-ratings.\n\n</p><div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5700143\">https://gist.github.com/rjurney/5700143</a></div>\n\nThe Pearson\u2019s correlation coefficient tells us how similar different projects are, based on their ratings. This data can be used to drive recommendations, which we\u2019ll look at tomorrow. For now, a sample of the Pearon\u2019s scores look like this:\n\n<pre><code>apache/pig      apache/avro     0.6914285714285715\napache/pig      apache/bval     1.0\napache/pig      apache/gora     1.0\napache/pig      apache/hive     0.6410256410256406\napache/pig      apache/isis     1.0\napache/pig      apache/jena     1.0\napache/pig      apache/lucy     1.0\napache/pig      apache/mina     1.0\napache/pig      apache/oodt     1.0\napache/pig      apache/qpid     1.0\napache/pig      apache/rave     1.0\napache/pig      apache/solr     1.0\napache/pig      apache/tika     1.0\napache/pig      apache/wink     1.0\napache/pig      enyojs/enyo     1.0\napache/pig      rails/rails     0.9486832980505138\napache/pig      scala/scala     1.0\napache/pig      zohmg/zohmg     1.0\napache/pig      andrew/split    0.8485281374238569\napache/pig      apache/camel    1.0\napache/pig      apache/derby    1.0\napache/pig      apache/flume    0.7352941176470589\napache/pig      apache/hbase    0.644736842105263\napache/pig      apache/httpd    0.7352941176470589</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 52071797939, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Pearson's Correlation between Github Projects", "tags": [], "post_url": "http://datasyndrome.com/post/52071797939/pearsons-correlation-between-github-projects", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5ymVk9Ip", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1370284500, "note_count": 0, "trail": [{"content": "<p><h3>Introduction</h3>\n\n<p>In our last three posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github&rsquo;s 18 event types</a> and <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a>.</p>\n\n<p>In this post we will be measuring the distance between github projects (items) using the <a href=\"http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\">Pearson product-moment correlation coefficient</a> using Pig and Jython.</p>\n\n<h3>Loading the Data</h3>\n\n<p>We addressed loading the data in our last post. Briefly, this code loads select Github Archive events in the form of ratings:</p>\n\n<a href=\"https://gist.github.com/rjurney/5700101\">https://gist.github.com/rjurney/5700101</a>\n\n<h3>Calculating Pearson&rsquo;s</h3>\n\n<p>Once the ratings are loaded, we need to make the links bidirectional, to increase their density and to make links between projects flow both-ways. Next, we need to filter out the top-most cross-linked projects, as they are not relevant and make the next step never finish. Next, we emit all co-ratings per project. This means we emit a project pair and ratings, each time a user has rated two projects. This is the meat of our recommendation data. Finally, we take a Pearson&rsquo;s distance between all projects with co-ratings.\n\n</p><a href=\"https://gist.github.com/rjurney/5700143\">https://gist.github.com/rjurney/5700143</a>\n\nThe Pearson&rsquo;s correlation coefficient tells us how similar different projects are, based on their ratings. This data can be used to drive recommendations, which we&rsquo;ll look at tomorrow. For now, a sample of the Pearon&rsquo;s scores look like this:\n\n<pre><code>apache/pig      apache/avro     0.6914285714285715\napache/pig      apache/bval     1.0\napache/pig      apache/gora     1.0\napache/pig      apache/hive     0.6410256410256406\napache/pig      apache/isis     1.0\napache/pig      apache/jena     1.0\napache/pig      apache/lucy     1.0\napache/pig      apache/mina     1.0\napache/pig      apache/oodt     1.0\napache/pig      apache/qpid     1.0\napache/pig      apache/rave     1.0\napache/pig      apache/solr     1.0\napache/pig      apache/tika     1.0\napache/pig      apache/wink     1.0\napache/pig      enyojs/enyo     1.0\napache/pig      rails/rails     0.9486832980505138\napache/pig      scala/scala     1.0\napache/pig      zohmg/zohmg     1.0\napache/pig      andrew/split    0.8485281374238569\napache/pig      apache/camel    1.0\napache/pig      apache/derby    1.0\napache/pig      apache/flume    0.7352941176470589\napache/pig      apache/hbase    0.644736842105263\napache/pig      apache/httpd    0.7352941176470589</code></pre></p>", "content_raw": "<p><h3>Introduction</h3>\n\n<p>In our last three posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a>, <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github\u2019s 18 event types</a> and <a href=\"http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive\">creating an implied rating system</a>.</p>\n\n<p>In this post we will be measuring the distance between github projects (items) using the <a href=\"http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\">Pearson product-moment correlation coefficient</a> using Pig and Jython.</p>\n\n<h3>Loading the Data</h3>\n\n<p>We addressed loading the data in our last post. Briefly, this code loads select Github Archive events in the form of ratings:</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5700101\">https://gist.github.com/rjurney/5700101</a></div>\n\n<h3>Calculating Pearson\u2019s</h3>\n\n<p>Once the ratings are loaded, we need to make the links bidirectional, to increase their density and to make links between projects flow both-ways. Next, we need to filter out the top-most cross-linked projects, as they are not relevant and make the next step never finish. Next, we emit all co-ratings per project. This means we emit a project pair and ratings, each time a user has rated two projects. This is the meat of our recommendation data. Finally, we take a Pearson\u2019s distance between all projects with co-ratings.\n\n</p><div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5700143\">https://gist.github.com/rjurney/5700143</a></div>\n\nThe Pearson\u2019s correlation coefficient tells us how similar different projects are, based on their ratings. This data can be used to drive recommendations, which we\u2019ll look at tomorrow. For now, a sample of the Pearon\u2019s scores look like this:\n\n<pre><code>apache/pig      apache/avro     0.6914285714285715\napache/pig      apache/bval     1.0\napache/pig      apache/gora     1.0\napache/pig      apache/hive     0.6410256410256406\napache/pig      apache/isis     1.0\napache/pig      apache/jena     1.0\napache/pig      apache/lucy     1.0\napache/pig      apache/mina     1.0\napache/pig      apache/oodt     1.0\napache/pig      apache/qpid     1.0\napache/pig      apache/rave     1.0\napache/pig      apache/solr     1.0\napache/pig      apache/tika     1.0\napache/pig      apache/wink     1.0\napache/pig      enyojs/enyo     1.0\napache/pig      rails/rails     0.9486832980505138\napache/pig      scala/scala     1.0\napache/pig      zohmg/zohmg     1.0\napache/pig      andrew/split    0.8485281374238569\napache/pig      apache/camel    1.0\napache/pig      apache/derby    1.0\napache/pig      apache/flume    0.7352941176470589\napache/pig      apache/hbase    0.644736842105263\napache/pig      apache/httpd    0.7352941176470589</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "52071797939"}}], "date": "2013-06-03 18:35:00 GMT", "slug": "pearsons-correlation-between-github-projects", "blog_name": "rjurney", "summary": "Pearson's Correlation between Github Projects", "can_reblog": true}, {"body": "<p>In our last two posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a> and <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github&rsquo;s 18 event types</a>.\n\n</p><p>In this post we&rsquo;re going to create an implied rating system from the <a href=\"http://www.githubarchive.org/\">Github Archive Data</a>. Implied rating systems - as opposed to a literal or direct rating systems - are inferred from records of user actions or gestures. You&rsquo;re familiar with implied ratings already: your FICO score is an implied rating. Just like your credit record, the <a href=\"http://www.githubarchive.org/\">github archive</a> is a rich set to infer ratings from, consisting of over 100GB of user actions from which we can infer ratings for github repositories. Inferred ratings are great for building recommender systems, which we&rsquo;ll talk more about in the next post.</p>\n\n\n<p>I reviewed the <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">18 github archive event types (covered yesterday)</a>, and came up with the following implied rating system:</p>\n\n\n<br/><p><b>ViewEvent (missing) - 0.0 Rating</b></p>\n\n\n<p>Missing from this analysis are github&rsquo;s web traffic logs, which are not public. Were we able to access those, we would rate a project 0.0 when a user views it but does not interact with it. This has the effect of dramatically increasing the scope of between-user comparisons we end up performing, increasing the performance of our recommender system.</p>\n\n<br/><p><b>WatchEvent - 1.0 Rating</b></p>\n\n<p>A WatchEvent is generated when a user clicks &lsquo;watch project&rsquo; on a github project. This indicates interest in the project and we assign it an implied rating of 1.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5686720\">https://gist.github.com/rjurney/5686720</a></div>\n\n\n<p><b>IssuesEvent - 2.0 Rating</b></p>\n\n<p>An IssuesEvent is generated when a user files an issue with a github project. This implies the user has acquired and attempted to use the project, so we give this a 2.0 implied rating.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687106\">https://gist.github.com/rjurney/5687106</a></div>\n\n<br/><p><b>ForkEvent - 3.0 Rating</b></p>\n\n<p>A ForkEvent occurs when a user forks a project, which means he is not only interested in using it but potentially in modifying it and contributing code back. Therefore we give this an implied rating of 3.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687232\">https://gist.github.com/rjurney/5687232</a></div>\n\n<br/><p><b>CreateEvent - 4.0 Rating</b></p>\n\n<p>A CreateEvent occurs when a user creates a new project. This is the highest implied vote of 4.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687269\">https://gist.github.com/rjurney/5687269</a></div>\n\n<p>As you can see, we&rsquo;ve created implied ratings from 0.0 - 4.0, which will enable us to create a recommender system tomorrow!</p>", "liked": false, "followed": false, "reblog_key": "ixVDCbzI", "reblog": {"comment": "<p>In our last two posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a> and <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github\u2019s 18 event types</a>.\n\n</p><p>In this post we\u2019re going to create an implied rating system from the <a href=\"http://www.githubarchive.org/\">Github Archive Data</a>. Implied rating systems - as opposed to a literal or direct rating systems - are inferred from records of user actions or gestures. You\u2019re familiar with implied ratings already: your FICO score is an implied rating. Just like your credit record, the <a href=\"http://www.githubarchive.org/\">github archive</a> is a rich set to infer ratings from, consisting of over 100GB of user actions from which we can infer ratings for github repositories. Inferred ratings are great for building recommender systems, which we\u2019ll talk more about in the next post.</p>\n\n\n<p>I reviewed the <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">18 github archive event types (covered yesterday)</a>, and came up with the following implied rating system:</p>\n\n\n<br><p><b>ViewEvent (missing) - 0.0 Rating</b></p>\n\n\n<p>Missing from this analysis are github\u2019s web traffic logs, which are not public. Were we able to access those, we would rate a project 0.0 when a user views it but does not interact with it. This has the effect of dramatically increasing the scope of between-user comparisons we end up performing, increasing the performance of our recommender system.</p>\n\n<br><p><b>WatchEvent - 1.0 Rating</b></p>\n\n<p>A WatchEvent is generated when a user clicks \u2018watch project\u2019 on a github project. This indicates interest in the project and we assign it an implied rating of 1.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5686720\">https://gist.github.com/rjurney/5686720</a></div>\n\n\n<p><b>IssuesEvent - 2.0 Rating</b></p>\n\n<p>An IssuesEvent is generated when a user files an issue with a github project. This implies the user has acquired and attempted to use the project, so we give this a 2.0 implied rating.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687106\">https://gist.github.com/rjurney/5687106</a></div>\n\n<br><p><b>ForkEvent - 3.0 Rating</b></p>\n\n<p>A ForkEvent occurs when a user forks a project, which means he is not only interested in using it but potentially in modifying it and contributing code back. Therefore we give this an implied rating of 3.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687232\">https://gist.github.com/rjurney/5687232</a></div>\n\n<br><p><b>CreateEvent - 4.0 Rating</b></p>\n\n<p>A CreateEvent occurs when a user creates a new project. This is the highest implied vote of 4.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687269\">https://gist.github.com/rjurney/5687269</a></div>\n\n<p>As you can see, we\u2019ve created implied ratings from 0.0 - 4.0, which will enable us to create a recommender system tomorrow!</p>", "tree_html": ""}, "can_send_in_message": true, "id": 51820658863, "display_avatar": true, "can_reply": true, "can_like": false, "title": "An Implied Rating System from the Github Archive", "tags": [], "post_url": "http://datasyndrome.com/post/51820658863/an-implied-rating-system-from-the-github-archive", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5ymGm82l", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1370027880, "note_count": 0, "trail": [{"content": "<p>In our last two posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a> and <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github&rsquo;s 18 event types</a>.\n\n</p><p>In this post we&rsquo;re going to create an implied rating system from the <a href=\"http://www.githubarchive.org/\">Github Archive Data</a>. Implied rating systems - as opposed to a literal or direct rating systems - are inferred from records of user actions or gestures. You&rsquo;re familiar with implied ratings already: your FICO score is an implied rating. Just like your credit record, the <a href=\"http://www.githubarchive.org/\">github archive</a> is a rich set to infer ratings from, consisting of over 100GB of user actions from which we can infer ratings for github repositories. Inferred ratings are great for building recommender systems, which we&rsquo;ll talk more about in the next post.</p>\n\n\n<p>I reviewed the <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">18 github archive event types (covered yesterday)</a>, and came up with the following implied rating system:</p>\n\n\n<br /><p><b>ViewEvent (missing) - 0.0 Rating</b></p>\n\n\n<p>Missing from this analysis are github&rsquo;s web traffic logs, which are not public. Were we able to access those, we would rate a project 0.0 when a user views it but does not interact with it. This has the effect of dramatically increasing the scope of between-user comparisons we end up performing, increasing the performance of our recommender system.</p>\n\n<br /><p><b>WatchEvent - 1.0 Rating</b></p>\n\n<p>A WatchEvent is generated when a user clicks &lsquo;watch project&rsquo; on a github project. This indicates interest in the project and we assign it an implied rating of 1.0.</p>\n\n<a href=\"https://gist.github.com/rjurney/5686720\">https://gist.github.com/rjurney/5686720</a>\n\n\n<p><b>IssuesEvent - 2.0 Rating</b></p>\n\n<p>An IssuesEvent is generated when a user files an issue with a github project. This implies the user has acquired and attempted to use the project, so we give this a 2.0 implied rating.</p>\n\n<a href=\"https://gist.github.com/rjurney/5687106\">https://gist.github.com/rjurney/5687106</a>\n\n<br /><p><b>ForkEvent - 3.0 Rating</b></p>\n\n<p>A ForkEvent occurs when a user forks a project, which means he is not only interested in using it but potentially in modifying it and contributing code back. Therefore we give this an implied rating of 3.0.</p>\n\n<a href=\"https://gist.github.com/rjurney/5687232\">https://gist.github.com/rjurney/5687232</a>\n\n<br /><p><b>CreateEvent - 4.0 Rating</b></p>\n\n<p>A CreateEvent occurs when a user creates a new project. This is the highest implied vote of 4.0.</p>\n\n<a href=\"https://gist.github.com/rjurney/5687269\">https://gist.github.com/rjurney/5687269</a>\n\n<p>As you can see, we&rsquo;ve created implied ratings from 0.0 - 4.0, which will enable us to create a recommender system tomorrow!</p>", "content_raw": "<p>In our last two posts, we covered <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">Downloading and Processing the Github Archive</a> and <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">Github\u2019s 18 event types</a>.\n\n</p><p>In this post we\u2019re going to create an implied rating system from the <a href=\"http://www.githubarchive.org/\">Github Archive Data</a>. Implied rating systems - as opposed to a literal or direct rating systems - are inferred from records of user actions or gestures. You\u2019re familiar with implied ratings already: your FICO score is an implied rating. Just like your credit record, the <a href=\"http://www.githubarchive.org/\">github archive</a> is a rich set to infer ratings from, consisting of over 100GB of user actions from which we can infer ratings for github repositories. Inferred ratings are great for building recommender systems, which we\u2019ll talk more about in the next post.</p>\n\n\n<p>I reviewed the <a href=\"http://datasyndrome.com/post/51755735612/github-archives-18-event-types\">18 github archive event types (covered yesterday)</a>, and came up with the following implied rating system:</p>\n\n\n<br><p><b>ViewEvent (missing) - 0.0 Rating</b></p>\n\n\n<p>Missing from this analysis are github\u2019s web traffic logs, which are not public. Were we able to access those, we would rate a project 0.0 when a user views it but does not interact with it. This has the effect of dramatically increasing the scope of between-user comparisons we end up performing, increasing the performance of our recommender system.</p>\n\n<br><p><b>WatchEvent - 1.0 Rating</b></p>\n\n<p>A WatchEvent is generated when a user clicks \u2018watch project\u2019 on a github project. This indicates interest in the project and we assign it an implied rating of 1.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5686720\">https://gist.github.com/rjurney/5686720</a></div>\n\n\n<p><b>IssuesEvent - 2.0 Rating</b></p>\n\n<p>An IssuesEvent is generated when a user files an issue with a github project. This implies the user has acquired and attempted to use the project, so we give this a 2.0 implied rating.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687106\">https://gist.github.com/rjurney/5687106</a></div>\n\n<br><p><b>ForkEvent - 3.0 Rating</b></p>\n\n<p>A ForkEvent occurs when a user forks a project, which means he is not only interested in using it but potentially in modifying it and contributing code back. Therefore we give this an implied rating of 3.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687232\">https://gist.github.com/rjurney/5687232</a></div>\n\n<br><p><b>CreateEvent - 4.0 Rating</b></p>\n\n<p>A CreateEvent occurs when a user creates a new project. This is the highest implied vote of 4.0.</p>\n\n<div class=\"gist\"><a href=\"https://gist.github.com/rjurney/5687269\">https://gist.github.com/rjurney/5687269</a></div>\n\n<p>As you can see, we\u2019ve created implied ratings from 0.0 - 4.0, which will enable us to create a recommender system tomorrow!</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51820658863"}}], "date": "2013-05-31 19:18:00 GMT", "slug": "an-implied-rating-system-from-the-github-archive", "blog_name": "rjurney", "summary": "An Implied Rating System from the Github Archive", "can_reblog": true}, {"body": "<p>Code follows&hellip;\n\n</p><div class=\"gist\"><a href=\"https://gist.github.com/1395926\">https://gist.github.com/1395926</a></div>\n\nAfter code&hellip;", "liked": false, "followed": false, "reblog_key": "5TzhkcNF", "reblog": {"comment": "<p><p>Code follows\u2026\n\n</p><div class=\"gist\"><a href=\"https://gist.github.com/1395926\">https://gist.github.com/1395926</a></div>\n\nAfter code\u2026</p>", "tree_html": ""}, "can_send_in_message": false, "id": 51815536836, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Test", "tags": [], "post_url": "http://datasyndrome.com/post/51815536836/test", "recommended_source": null, "state": "private", "short_url": "https://tmblr.co/ZbIO5ymGSbZ4", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1370022763, "note_count": 0, "trail": [{"content": "<p><p>Code follows&hellip;\n\n</p><a href=\"https://gist.github.com/1395926\">https://gist.github.com/1395926</a>\n\nAfter code&hellip;</p>", "content_raw": "<p><p>Code follows\u2026\n\n</p><div class=\"gist\"><a href=\"https://gist.github.com/1395926\">https://gist.github.com/1395926</a></div>\n\nAfter code\u2026</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51815536836"}}], "date": "2013-05-31 17:52:43 GMT", "slug": "test", "blog_name": "rjurney", "summary": "Test", "can_reblog": false}, {"body": "In <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">yesterday&rsquo;s post</a> we showed how to download and process the <a href=\"http://www.githubarchive.org/\">github archive</a>. In today&rsquo;s post we&rsquo;re going to examine that data in-depth, diving into 18 event types. This is helpful because without this as a reference, you must cross-reference the API docs, and the end-result is that you are always surprised when you sample the records and new/interesting fields show up. \n\n\n<br/><br/><p>The event types, with example data, are as follows:</p>\n<br/><br/><p>CommitCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CommitCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dabrahams\",\n        \"login\": \"dabrahams\",\n        \"id\": 44065,\n        \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/wahikihiki/boost-modularize\",\n        \"id\": 2133453,\n        \"name\": \"wahikihiki/boost-modularize\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"comment\": {\n            \"html_url\": \"https://github.com/wahikihiki/boost-modularize/commit/a339f625e4#commitcomment-830037\",\n            \"commit_id\": \"a339f625e492d21926c449c17269c4d77e94f78a\",\n            \"url\": \"https://api.github.com/repos/wahikihiki/boost-modularize/comments/830037\",\n            \"updated_at\": \"2012-01-01T00:03:11Z\",\n            \"body\": \"I think you closed the wrong issue here.\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/dabrahams\",\n                \"login\": \"dabrahams\",\n                \"id\": 44065,\n                \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n            },\n            \"position\": null,\n            \"id\": 830037,\n            \"path\": null,\n            \"created_at\": \"2012-01-01T00:03:11Z\",\n            \"line\": null\n        }\n    },\n    \"id\": \"1508512415\",\n    \"created_at\": \"2012-01-01T00:03:11Z\"\n}\n</code></pre>\n\n<p>CreateEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CreateEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/8c315bedc4ab1b9aef8f9b446030daac?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/vinced45\",\n        \"login\": \"vinced45\",\n        \"id\": 101286,\n        \"gravatar_id\": \"8c315bedc4ab1b9aef8f9b446030daac\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/vinced45/siriproxy-mashable\",\n        \"id\": 3081234,\n        \"name\": \"vinced45/siriproxy-mashable\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"repository\",\n        \"description\": \"Siri Proxy Plugin to get news from Mashable\",\n        \"master_branch\": \"master\",\n        \"ref\": null\n    },\n    \"id\": \"1508512425\",\n    \"created_at\": \"2012-01-01T00:03:28Z\"\n}\n</code></pre>\n\n<p>DeleteEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DeleteEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/71c216d75354dda636b879dfc95654fb?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/charliepark\",\n        \"login\": \"charliepark\",\n        \"id\": 22547,\n        \"gravatar_id\": \"71c216d75354dda636b879dfc95654fb\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/charliepark/hatchshow\",\n        \"id\": 3081193,\n        \"name\": \"charliepark/hatchshow\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"branch\",\n        \"ref\": \"gh-pages\"\n    },\n    \"id\": \"1508512731\",\n    \"created_at\": \"2012-01-01T00:10:11Z\"\n}\n</code></pre>\n\n<p>DownloadEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DownloadEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/610670d3633cf84993fb1508bde4dbcc?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/MihailJP\",\n        \"login\": \"MihailJP\",\n        \"id\": 990217,\n        \"gravatar_id\": \"610670d3633cf84993fb1508bde4dbcc\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/MihailJP/Sophora\",\n        \"id\": 2484028,\n        \"name\": \"MihailJP/Sophora\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"download\": {\n            \"html_url\": \"https://github.com/downloads/MihailJP/Sophora/Sophora-TTF.7z\",\n            \"url\": \"https://api.github.com/repos/MihailJP/Sophora/downloads/167647\",\n            \"description\": \"Sophora TTF release 1.2.0\",\n            \"id\": 167647,\n            \"created_at\": \"2012-01-01T00:39:26Z\",\n            \"name\": \"Sophora-TTF.7z\",\n            \"download_count\": 0,\n            \"size\": 9218048,\n            \"content_type\": \".7z\"\n        }\n    },\n    \"id\": \"1508514008\",\n    \"created_at\": \"2012-01-01T00:39:26Z\"\n}\n</code></pre>\n\n<p>FollowEvent</p>\n\n<pre><code>\n{\n    \"type\": \"FollowEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/9f3a6ded186b043354b6487efc46c7e3?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dchang00\",\n        \"login\": \"dchang00\",\n        \"id\": 1136380,\n        \"gravatar_id\": \"9f3a6ded186b043354b6487efc46c7e3\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"target\": {\n            \"html_url\": \"https://github.com/dbtsai\",\n            \"type\": \"User\",\n            \"bio\": null,\n            \"location\": \"Palo Alto, CA, USA\",\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/39e915ddd0924cc3bde7225b4690ae6d?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/dbtsai\",\n            \"login\": \"dbtsai\",\n            \"company\": null,\n            \"hireable\": false,\n            \"following\": 0,\n            \"id\": 1134574,\n            \"created_at\": \"2011-10-18T00:17:03Z\",\n            \"gravatar_id\": \"39e915ddd0924cc3bde7225b4690ae6d\",\n            \"public_gists\": 0,\n            \"blog\": \"http://www.dbtsai.com\",\n            \"name\": \"D.B. Tsai\",\n            \"email\": \"\",\n            \"followers\": 1,\n            \"public_repos\": 1\n        }\n    },\n    \"id\": \"1508514239\",\n    \"created_at\": \"2012-01-01T00:44:30Z\"\n}\n</code></pre>\n\n<p>ForkEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/goreckm\",\n        \"login\": \"goreckm\",\n        \"id\": 308672,\n        \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/thedersen/backbone.validation\",\n        \"id\": 2456444,\n        \"name\": \"thedersen/backbone.validation\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"forkee\": {\n            \"owner\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/goreckm\",\n                \"login\": \"goreckm\",\n                \"id\": 308672,\n                \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n            },\n            \"clone_url\": \"https://github.com/goreckm/backbone.validation.git\",\n            \"html_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"url\": \"https://api.github.com/repos/goreckm/backbone.validation\",\n            \"git_url\": \"git://github.com/goreckm/backbone.validation.git\",\n            \"updated_at\": \"2012-01-01T00:50:43Z\",\n            \"private\": false,\n            \"svn_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"public\": true,\n            \"language\": \"JavaScript\",\n            \"watchers\": 1,\n            \"description\": \"A validation plugin for Backbone.js\",\n            \"id\": 3081331,\n            \"fork\": true,\n            \"created_at\": \"2012-01-01T00:50:43Z\",\n            \"master_branch\": null,\n            \"name\": \"backbone.validation\",\n            \"open_issues\": 0,\n            \"size\": 124,\n            \"pushed_at\": \"2011-12-27T19:42:56Z\",\n            \"homepage\": \"\",\n            \"forks\": 0,\n            \"ssh_url\": \"git@github.com:goreckm/backbone.validation.git\"\n        }\n    },\n    \"id\": \"1508514511\",\n    \"created_at\": \"2012-01-01T00:50:43Z\"\n}\n</code></pre>\n\n<p>ForkApplyEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkApplyEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/76621dab58e151dee5adab9c71b1033a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jakeday\",\n        \"login\": \"jakeday\",\n        \"id\": 554899,\n        \"gravatar_id\": \"76621dab58e151dee5adab9c71b1033a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jakeday/KangBang-OMAP\",\n        \"id\": 3060269,\n        \"name\": \"jakeday/KangBang-OMAP\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"before\": \"a0d608d086a1cb68aa15254e3cf4a101625dc1f3\",\n        \"after\": \"c4d8bb808af0d446724a63212c6a8d485242f958\",\n        \"head\": \"master\"\n    },\n    \"id\": \"1508515330\",\n    \"created_at\": \"2012-01-01T01:10:07Z\"\n}\n</code></pre>\n\n<p>GistEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GistEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/berkerpeksag\",\n        \"login\": \"berkerpeksag\",\n        \"id\": 26338,\n        \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"update\",\n        \"gist\": {\n            \"html_url\": \"https://gist.github.com/1545854\",\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/gists/1545854\",\n            \"updated_at\": \"2012-01-01T01:12:51Z\",\n            \"public\": true,\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/berkerpeksag\",\n                \"login\": \"berkerpeksag\",\n                \"id\": 26338,\n                \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n            },\n            \"git_push_url\": \"git@gist.github.com:1545854.git\",\n            \"description\": \"GitHub Badge JSONP Example\",\n            \"id\": \"1545854\",\n            \"created_at\": \"2012-01-01T01:08:36Z\",\n            \"files\": {},\n            \"git_pull_url\": \"git://gist.github.com/1545854.git\"\n        }\n    },\n    \"id\": \"1508515439\",\n    \"created_at\": \"2012-01-01T01:12:53Z\"\n}\n</code></pre>\n\n<p>GollumEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GollumEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/09fd78807043975bacd0db17347a99da?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/Technius\",\n        \"login\": \"Technius\",\n        \"id\": 1066652,\n        \"gravatar_id\": \"09fd78807043975bacd0db17347a99da\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/Technius/SkyrimRPG\",\n        \"id\": 3004403,\n        \"name\": \"Technius/SkyrimRPG\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"pages\": [\n            {\n                \"summary\": null,\n                \"html_url\": \"https://github.com/Technius/SkyrimRPG/wiki/Plugin-plans\",\n                \"action\": \"edited\",\n                \"title\": \"Plugin plans\",\n                \"page_name\": \"Plugin plans\",\n                \"sha\": \"0ff0f1441b86782ea60f62d031d7e9a2240fae61\"\n            }\n        ]\n    },\n    \"id\": \"1508515608\",\n    \"created_at\": \"2012-01-01T01:17:14Z\"\n}\n</code></pre>\n\n<p>IssueCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssueCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/zml2008\",\n        \"login\": \"zml2008\",\n        \"id\": 629092,\n        \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/sk89q/commandbook\",\n        \"id\": 1423268,\n        \"name\": \"sk89q/commandbook\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"created\",\n        \"comment\": {\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/comments/3323504\",\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"body\": \"Merged in f4930b7\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/zml2008\",\n                \"login\": \"zml2008\",\n                \"id\": 629092,\n                \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n            },\n            \"id\": 3323504,\n            \"created_at\": \"2012-01-01T01:18:31Z\"\n        },\n        \"issue\": {\n            \"html_url\": \"https://github.com/sk89q/commandbook/issues/66\",\n            \"comments\": 7,\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/66\",\n            \"closed_at\": \"2012-01-01T01:18:31Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": null,\n            \"body\": \"I made the take command :)\",\n            \"pull_request\": {\n                \"html_url\": \"https://github.com/sk89q/commandbook/pull/66\",\n                \"patch_url\": \"https://github.com/sk89q/commandbook/pull/66.patch\",\n                \"diff_url\": \"https://github.com/sk89q/commandbook/pull/66.diff\"\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/22c0e20e348d2fd80e74e1c1473d05dd?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/DarkArc\",\n                \"login\": \"DarkArc\",\n                \"id\": 778012,\n                \"gravatar_id\": \"22c0e20e348d2fd80e74e1c1473d05dd\"\n            },\n            \"id\": 2696201,\n            \"created_at\": \"2012-01-01T00:47:36Z\",\n            \"title\": \"Implemented take comammand\",\n            \"number\": 66\n        }\n    },\n    \"id\": \"1508515658\",\n    \"created_at\": \"2012-01-01T01:18:31Z\"\n}\n</code></pre>\n\n<p>IssuesEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssuesEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/addyosmani\",\n        \"login\": \"addyosmani\",\n        \"id\": 110953,\n        \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/addyosmani/todomvc\",\n        \"id\": 1844251,\n        \"name\": \"addyosmani/todomvc\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"closed\",\n        \"issue\": {\n            \"html_url\": \"https://github.com/addyosmani/todomvc/issues/22\",\n            \"comments\": 1,\n            \"url\": \"https://api.github.com/repos/addyosmani/todomvc/issues/22\",\n            \"closed_at\": \"2012-01-01T01:21:46Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:21:46Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/addyosmani\",\n                \"login\": \"addyosmani\",\n                \"id\": 110953,\n                \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n            },\n            \"body\": \"In the index.html file there is this code:\\r\\n\\r\\n\\r\\n\\r\\nThis fails while loading from the file:// scheme for obvious reasons.\\r\\nNot sure if it should be considered a bug but in chrome 14 it's quite annoying having the page trying to load for some time before failing.\",\n            \"pull_request\": {\n                \"html_url\": null,\n                \"patch_url\": null,\n                \"diff_url\": null\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/37fc491db95105ff67aa9b45a2834dca?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/graphnode\",\n                \"login\": \"graphnode\",\n                \"id\": 216518,\n                \"gravatar_id\": \"37fc491db95105ff67aa9b45a2834dca\"\n            },\n            \"id\": 2016566,\n            \"created_at\": \"2011-10-21T15:27:47Z\",\n            \"title\": \"Twitter \\\"widgets.js\\\" fails when in file://\",\n            \"number\": 22\n        }\n    },\n    \"id\": \"1508515785\",\n    \"created_at\": \"2012-01-01T01:21:48Z\"\n}\n</code></pre>\n\n\nMemberEvent\n\n<pre><code>\n{\n    \"type\": \"MemberEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/36d8ad4e46e0c5e3c260e3761f8c7e68?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/balr0g\",\n        \"login\": \"balr0g\",\n        \"id\": 1091609,\n        \"gravatar_id\": \"36d8ad4e46e0c5e3c260e3761f8c7e68\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/balr0g/MineFactoryReloaded\",\n        \"id\": 3081425,\n        \"name\": \"balr0g/MineFactoryReloaded\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"member\": {\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/5d109d40b17aafa502ad85a361071db4?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/TehKrush\",\n            \"login\": \"TehKrush\",\n            \"id\": 509984,\n            \"gravatar_id\": \"5d109d40b17aafa502ad85a361071db4\"\n        },\n        \"action\": \"added\"\n    },\n    \"id\": \"1508516755\",\n    \"created_at\": \"2012-01-01T01:46:47Z\"\n}\n</code></pre>\n\n<p>PublicEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PublicEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/d0f85fcd119bc36e61d4d37a3cfffe60?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jialongl\",\n        \"login\": \"jialongl\",\n        \"id\": 667031,\n        \"gravatar_id\": \"d0f85fcd119bc36e61d4d37a3cfffe60\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jialongl/pad\",\n        \"id\": 2859592,\n        \"name\": \"jialongl/pad\"\n    },\n    \"public\": true,\n    \"payload\": {},\n    \"id\": \"1508537305\",\n    \"created_at\": \"2012-01-01T10:51:50Z\"\n}\n</code></pre>\n\n<p>PullRequestEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PullRequestEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/freeakk\",\n        \"login\": \"freeakk\",\n        \"id\": 639796,\n        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/qooxdoo/qooxdoo\",\n        \"id\": 548213,\n        \"name\": \"qooxdoo/qooxdoo\"\n    },\n    \"org\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-org-420.png\",\n        \"url\": \"https://api.github.dev/orgs/qooxdoo\",\n        \"login\": \"qooxdoo\",\n        \"id\": 105118,\n        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"opened\",\n        \"pull_request\": {\n            \"html_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7\",\n            \"mergeable\": null,\n            \"deletions\": 0,\n            \"merged\": false,\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\",\n            \"closed_at\": null,\n            \"merged_by\": null,\n            \"review_comments\": 0,\n            \"updated_at\": \"2012-01-01T11:26:35Z\",\n            \"patch_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.patch\",\n            \"state\": \"open\",\n            \"changed_files\": 1,\n            \"body\": \"http://bugzilla.qooxdoo.org/show_bug.cgi?id=5798\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/freeakk\",\n                \"login\": \"freeakk\",\n                \"id\": 639796,\n                \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n            },\n            \"issue_url\": \"https://github.com/qooxdoo/qooxdoo/issues/7\",\n            \"id\": 642757,\n            \"created_at\": \"2012-01-01T11:26:35Z\",\n            \"diff_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.diff\",\n            \"title\": \"Fix bug 5798\",\n            \"merged_at\": null,\n            \"_links\": {\n                \"comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/issues/7/comments\"\n                },\n                \"self\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\"\n                },\n                \"review_comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7/comments\"\n                },\n                \"html\": {\n                    \"href\": \"https://github.com/qooxdoo/qooxdoo/pull/7\"\n                }\n            },\n            \"head\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                        \"url\": \"https://api.github.com/users/freeakk\",\n                        \"login\": \"freeakk\",\n                        \"id\": 639796,\n                        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                    },\n                    \"clone_url\": \"https://github.com/freeakk/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/freeakk/qooxdoo\",\n                    \"git_url\": \"git://github.com/freeakk/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T11:24:35Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 1,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 3082044,\n                    \"fork\": true,\n                    \"created_at\": \"2012-01-01T07:28:44Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 0,\n                    \"size\": 484,\n                    \"pushed_at\": \"2012-01-01T11:24:09Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 0,\n                    \"ssh_url\": \"git@github.com:freeakk/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                    \"url\": \"https://api.github.com/users/freeakk\",\n                    \"login\": \"freeakk\",\n                    \"id\": 639796,\n                    \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                },\n                \"label\": \"freeakk:master\",\n                \"sha\": \"c6ebd5b54914e2244fe1401d6843dc77dd23fe07\",\n                \"ref\": \"master\"\n            },\n            \"number\": 7,\n            \"commits\": 1,\n            \"additions\": 5,\n            \"base\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                        \"url\": \"https://api.github.com/users/qooxdoo\",\n                        \"login\": \"qooxdoo\",\n                        \"id\": 105118,\n                        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                    },\n                    \"clone_url\": \"https://github.com/qooxdoo/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo\",\n                    \"git_url\": \"git://github.com/qooxdoo/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T07:28:44Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 140,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 548213,\n                    \"fork\": false,\n                    \"created_at\": \"2010-03-05T10:01:27Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 3,\n                    \"size\": 5620,\n                    \"pushed_at\": \"2011-12-23T13:20:26Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 28,\n                    \"ssh_url\": \"git@github.com:qooxdoo/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                    \"url\": \"https://api.github.com/users/qooxdoo\",\n                    \"login\": \"qooxdoo\",\n                    \"id\": 105118,\n                    \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                },\n                \"label\": \"qooxdoo:master\",\n                \"sha\": \"5c8f02ee1b3886edb213c91351bfbcbe6b8655ff\",\n                \"ref\": \"master\"\n            }\n        },\n        \"number\": 7\n    },\n    \"id\": \"1508538441\",\n    \"created_at\": \"2012-01-01T11:26:37Z\"\n}\n</code></pre>\n\n<p>PullRequestReviewCommentEvent</p>\n\nNone found.\n<br/><br/><p>PushEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PushEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/a8584f48cb2c4028c1aeca24a4645cd4?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/eatnumber1\",\n        \"login\": \"eatnumber1\",\n        \"id\": 17551,\n        \"gravatar_id\": \"a8584f48cb2c4028c1aeca24a4645cd4\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/eatnumber1/eatnumber1.github.com\",\n        \"id\": 3007212,\n        \"name\": \"eatnumber1/eatnumber1.github.com\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"size\": 1,\n        \"head\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n        \"push_id\": 55756270,\n        \"commits\": [\n            {\n                \"author\": {\n                    \"name\": \"Russell Harmon\",\n                    \"email\": \"russ@eatnumber1.com\"\n                },\n                \"url\": \"https://api.github.com/repos/eatnumber1/eatnumber1.github.com/commits/5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n                \"message\": \"Automatically generated site on Sat Dec 31 18:59:49 EST 2011\",\n                \"sha\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\"\n            }\n        ],\n        \"ref\": \"refs/heads/master\"\n    },\n    \"id\": \"1508512238\",\n    \"created_at\": \"2012-01-01T00:00:12Z\"\n}\n</code></pre>\n\n<p>TeamAddEvent</p>\n\nNone found.\n<br/><br/><p>WatchEvent</p>\n\n<pre><code>\n{\n    \"type\": \"WatchEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2a8d090768d237544a7c69a0f9c217c7?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/timgluz\",\n        \"login\": \"timgluz\",\n        \"id\": 1223889,\n        \"gravatar_id\": \"2a8d090768d237544a7c69a0f9c217c7\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/bartaz/impress.js\",\n        \"id\": 3065454,\n        \"name\": \"bartaz/impress.js\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"started\"\n    },\n    \"id\": \"1508512289\",\n    \"created_at\": \"2012-01-01T00:01:12Z\"\n}\n</code></pre>", "liked": false, "followed": false, "reblog_key": "ZsCzLjiJ", "reblog": {"comment": "<p>In <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">yesterday\u2019s post</a> we showed how to download and process the <a href=\"http://www.githubarchive.org/\">github archive</a>. In today\u2019s post we\u2019re going to examine that data in-depth, diving into 18 event types. This is helpful because without this as a reference, you must cross-reference the API docs, and the end-result is that you are always surprised when you sample the records and new/interesting fields show up. \n\n\n<br><br><p>The event types, with example data, are as follows:</p>\n<br><br><p>CommitCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CommitCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dabrahams\",\n        \"login\": \"dabrahams\",\n        \"id\": 44065,\n        \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/wahikihiki/boost-modularize\",\n        \"id\": 2133453,\n        \"name\": \"wahikihiki/boost-modularize\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"comment\": {\n            \"html_url\": \"https://github.com/wahikihiki/boost-modularize/commit/a339f625e4#commitcomment-830037\",\n            \"commit_id\": \"a339f625e492d21926c449c17269c4d77e94f78a\",\n            \"url\": \"https://api.github.com/repos/wahikihiki/boost-modularize/comments/830037\",\n            \"updated_at\": \"2012-01-01T00:03:11Z\",\n            \"body\": \"I think you closed the wrong issue here.\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/dabrahams\",\n                \"login\": \"dabrahams\",\n                \"id\": 44065,\n                \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n            },\n            \"position\": null,\n            \"id\": 830037,\n            \"path\": null,\n            \"created_at\": \"2012-01-01T00:03:11Z\",\n            \"line\": null\n        }\n    },\n    \"id\": \"1508512415\",\n    \"created_at\": \"2012-01-01T00:03:11Z\"\n}\n</code></pre>\n\n<p>CreateEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CreateEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/8c315bedc4ab1b9aef8f9b446030daac?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/vinced45\",\n        \"login\": \"vinced45\",\n        \"id\": 101286,\n        \"gravatar_id\": \"8c315bedc4ab1b9aef8f9b446030daac\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/vinced45/siriproxy-mashable\",\n        \"id\": 3081234,\n        \"name\": \"vinced45/siriproxy-mashable\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"repository\",\n        \"description\": \"Siri Proxy Plugin to get news from Mashable\",\n        \"master_branch\": \"master\",\n        \"ref\": null\n    },\n    \"id\": \"1508512425\",\n    \"created_at\": \"2012-01-01T00:03:28Z\"\n}\n</code></pre>\n\n<p>DeleteEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DeleteEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/71c216d75354dda636b879dfc95654fb?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/charliepark\",\n        \"login\": \"charliepark\",\n        \"id\": 22547,\n        \"gravatar_id\": \"71c216d75354dda636b879dfc95654fb\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/charliepark/hatchshow\",\n        \"id\": 3081193,\n        \"name\": \"charliepark/hatchshow\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"branch\",\n        \"ref\": \"gh-pages\"\n    },\n    \"id\": \"1508512731\",\n    \"created_at\": \"2012-01-01T00:10:11Z\"\n}\n</code></pre>\n\n<p>DownloadEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DownloadEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/610670d3633cf84993fb1508bde4dbcc?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/MihailJP\",\n        \"login\": \"MihailJP\",\n        \"id\": 990217,\n        \"gravatar_id\": \"610670d3633cf84993fb1508bde4dbcc\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/MihailJP/Sophora\",\n        \"id\": 2484028,\n        \"name\": \"MihailJP/Sophora\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"download\": {\n            \"html_url\": \"https://github.com/downloads/MihailJP/Sophora/Sophora-TTF.7z\",\n            \"url\": \"https://api.github.com/repos/MihailJP/Sophora/downloads/167647\",\n            \"description\": \"Sophora TTF release 1.2.0\",\n            \"id\": 167647,\n            \"created_at\": \"2012-01-01T00:39:26Z\",\n            \"name\": \"Sophora-TTF.7z\",\n            \"download_count\": 0,\n            \"size\": 9218048,\n            \"content_type\": \".7z\"\n        }\n    },\n    \"id\": \"1508514008\",\n    \"created_at\": \"2012-01-01T00:39:26Z\"\n}\n</code></pre>\n\n<p>FollowEvent</p>\n\n<pre><code>\n{\n    \"type\": \"FollowEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/9f3a6ded186b043354b6487efc46c7e3?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dchang00\",\n        \"login\": \"dchang00\",\n        \"id\": 1136380,\n        \"gravatar_id\": \"9f3a6ded186b043354b6487efc46c7e3\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"target\": {\n            \"html_url\": \"https://github.com/dbtsai\",\n            \"type\": \"User\",\n            \"bio\": null,\n            \"location\": \"Palo Alto, CA, USA\",\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/39e915ddd0924cc3bde7225b4690ae6d?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/dbtsai\",\n            \"login\": \"dbtsai\",\n            \"company\": null,\n            \"hireable\": false,\n            \"following\": 0,\n            \"id\": 1134574,\n            \"created_at\": \"2011-10-18T00:17:03Z\",\n            \"gravatar_id\": \"39e915ddd0924cc3bde7225b4690ae6d\",\n            \"public_gists\": 0,\n            \"blog\": \"http://www.dbtsai.com\",\n            \"name\": \"D.B. Tsai\",\n            \"email\": \"\",\n            \"followers\": 1,\n            \"public_repos\": 1\n        }\n    },\n    \"id\": \"1508514239\",\n    \"created_at\": \"2012-01-01T00:44:30Z\"\n}\n</code></pre>\n\n<p>ForkEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/goreckm\",\n        \"login\": \"goreckm\",\n        \"id\": 308672,\n        \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/thedersen/backbone.validation\",\n        \"id\": 2456444,\n        \"name\": \"thedersen/backbone.validation\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"forkee\": {\n            \"owner\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/goreckm\",\n                \"login\": \"goreckm\",\n                \"id\": 308672,\n                \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n            },\n            \"clone_url\": \"https://github.com/goreckm/backbone.validation.git\",\n            \"html_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"url\": \"https://api.github.com/repos/goreckm/backbone.validation\",\n            \"git_url\": \"git://github.com/goreckm/backbone.validation.git\",\n            \"updated_at\": \"2012-01-01T00:50:43Z\",\n            \"private\": false,\n            \"svn_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"public\": true,\n            \"language\": \"JavaScript\",\n            \"watchers\": 1,\n            \"description\": \"A validation plugin for Backbone.js\",\n            \"id\": 3081331,\n            \"fork\": true,\n            \"created_at\": \"2012-01-01T00:50:43Z\",\n            \"master_branch\": null,\n            \"name\": \"backbone.validation\",\n            \"open_issues\": 0,\n            \"size\": 124,\n            \"pushed_at\": \"2011-12-27T19:42:56Z\",\n            \"homepage\": \"\",\n            \"forks\": 0,\n            \"ssh_url\": \"git@github.com:goreckm/backbone.validation.git\"\n        }\n    },\n    \"id\": \"1508514511\",\n    \"created_at\": \"2012-01-01T00:50:43Z\"\n}\n</code></pre>\n\n<p>ForkApplyEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkApplyEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/76621dab58e151dee5adab9c71b1033a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jakeday\",\n        \"login\": \"jakeday\",\n        \"id\": 554899,\n        \"gravatar_id\": \"76621dab58e151dee5adab9c71b1033a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jakeday/KangBang-OMAP\",\n        \"id\": 3060269,\n        \"name\": \"jakeday/KangBang-OMAP\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"before\": \"a0d608d086a1cb68aa15254e3cf4a101625dc1f3\",\n        \"after\": \"c4d8bb808af0d446724a63212c6a8d485242f958\",\n        \"head\": \"master\"\n    },\n    \"id\": \"1508515330\",\n    \"created_at\": \"2012-01-01T01:10:07Z\"\n}\n</code></pre>\n\n<p>GistEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GistEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/berkerpeksag\",\n        \"login\": \"berkerpeksag\",\n        \"id\": 26338,\n        \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"update\",\n        \"gist\": {\n            \"html_url\": \"https://gist.github.com/1545854\",\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/gists/1545854\",\n            \"updated_at\": \"2012-01-01T01:12:51Z\",\n            \"public\": true,\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/berkerpeksag\",\n                \"login\": \"berkerpeksag\",\n                \"id\": 26338,\n                \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n            },\n            \"git_push_url\": \"git@gist.github.com:1545854.git\",\n            \"description\": \"GitHub Badge JSONP Example\",\n            \"id\": \"1545854\",\n            \"created_at\": \"2012-01-01T01:08:36Z\",\n            \"files\": {},\n            \"git_pull_url\": \"git://gist.github.com/1545854.git\"\n        }\n    },\n    \"id\": \"1508515439\",\n    \"created_at\": \"2012-01-01T01:12:53Z\"\n}\n</code></pre>\n\n<p>GollumEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GollumEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/09fd78807043975bacd0db17347a99da?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/Technius\",\n        \"login\": \"Technius\",\n        \"id\": 1066652,\n        \"gravatar_id\": \"09fd78807043975bacd0db17347a99da\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/Technius/SkyrimRPG\",\n        \"id\": 3004403,\n        \"name\": \"Technius/SkyrimRPG\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"pages\": [\n            {\n                \"summary\": null,\n                \"html_url\": \"https://github.com/Technius/SkyrimRPG/wiki/Plugin-plans\",\n                \"action\": \"edited\",\n                \"title\": \"Plugin plans\",\n                \"page_name\": \"Plugin plans\",\n                \"sha\": \"0ff0f1441b86782ea60f62d031d7e9a2240fae61\"\n            }\n        ]\n    },\n    \"id\": \"1508515608\",\n    \"created_at\": \"2012-01-01T01:17:14Z\"\n}\n</code></pre>\n\n<p>IssueCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssueCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/zml2008\",\n        \"login\": \"zml2008\",\n        \"id\": 629092,\n        \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/sk89q/commandbook\",\n        \"id\": 1423268,\n        \"name\": \"sk89q/commandbook\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"created\",\n        \"comment\": {\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/comments/3323504\",\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"body\": \"Merged in f4930b7\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/zml2008\",\n                \"login\": \"zml2008\",\n                \"id\": 629092,\n                \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n            },\n            \"id\": 3323504,\n            \"created_at\": \"2012-01-01T01:18:31Z\"\n        },\n        \"issue\": {\n            \"html_url\": \"https://github.com/sk89q/commandbook/issues/66\",\n            \"comments\": 7,\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/66\",\n            \"closed_at\": \"2012-01-01T01:18:31Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": null,\n            \"body\": \"I made the take command :)\",\n            \"pull_request\": {\n                \"html_url\": \"https://github.com/sk89q/commandbook/pull/66\",\n                \"patch_url\": \"https://github.com/sk89q/commandbook/pull/66.patch\",\n                \"diff_url\": \"https://github.com/sk89q/commandbook/pull/66.diff\"\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/22c0e20e348d2fd80e74e1c1473d05dd?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/DarkArc\",\n                \"login\": \"DarkArc\",\n                \"id\": 778012,\n                \"gravatar_id\": \"22c0e20e348d2fd80e74e1c1473d05dd\"\n            },\n            \"id\": 2696201,\n            \"created_at\": \"2012-01-01T00:47:36Z\",\n            \"title\": \"Implemented take comammand\",\n            \"number\": 66\n        }\n    },\n    \"id\": \"1508515658\",\n    \"created_at\": \"2012-01-01T01:18:31Z\"\n}\n</code></pre>\n\n<p>IssuesEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssuesEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/addyosmani\",\n        \"login\": \"addyosmani\",\n        \"id\": 110953,\n        \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/addyosmani/todomvc\",\n        \"id\": 1844251,\n        \"name\": \"addyosmani/todomvc\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"closed\",\n        \"issue\": {\n            \"html_url\": \"https://github.com/addyosmani/todomvc/issues/22\",\n            \"comments\": 1,\n            \"url\": \"https://api.github.com/repos/addyosmani/todomvc/issues/22\",\n            \"closed_at\": \"2012-01-01T01:21:46Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:21:46Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/addyosmani\",\n                \"login\": \"addyosmani\",\n                \"id\": 110953,\n                \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n            },\n            \"body\": \"In the index.html file there is this code:\\r\\n\\r\\n\\r\\n\\r\\nThis fails while loading from the file:// scheme for obvious reasons.\\r\\nNot sure if it should be considered a bug but in chrome 14 it's quite annoying having the page trying to load for some time before failing.\",\n            \"pull_request\": {\n                \"html_url\": null,\n                \"patch_url\": null,\n                \"diff_url\": null\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/37fc491db95105ff67aa9b45a2834dca?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/graphnode\",\n                \"login\": \"graphnode\",\n                \"id\": 216518,\n                \"gravatar_id\": \"37fc491db95105ff67aa9b45a2834dca\"\n            },\n            \"id\": 2016566,\n            \"created_at\": \"2011-10-21T15:27:47Z\",\n            \"title\": \"Twitter \\\"widgets.js\\\" fails when in file://\",\n            \"number\": 22\n        }\n    },\n    \"id\": \"1508515785\",\n    \"created_at\": \"2012-01-01T01:21:48Z\"\n}\n</code></pre>\n\n\nMemberEvent\n\n<pre><code>\n{\n    \"type\": \"MemberEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/36d8ad4e46e0c5e3c260e3761f8c7e68?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/balr0g\",\n        \"login\": \"balr0g\",\n        \"id\": 1091609,\n        \"gravatar_id\": \"36d8ad4e46e0c5e3c260e3761f8c7e68\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/balr0g/MineFactoryReloaded\",\n        \"id\": 3081425,\n        \"name\": \"balr0g/MineFactoryReloaded\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"member\": {\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/5d109d40b17aafa502ad85a361071db4?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/TehKrush\",\n            \"login\": \"TehKrush\",\n            \"id\": 509984,\n            \"gravatar_id\": \"5d109d40b17aafa502ad85a361071db4\"\n        },\n        \"action\": \"added\"\n    },\n    \"id\": \"1508516755\",\n    \"created_at\": \"2012-01-01T01:46:47Z\"\n}\n</code></pre>\n\n<p>PublicEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PublicEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/d0f85fcd119bc36e61d4d37a3cfffe60?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jialongl\",\n        \"login\": \"jialongl\",\n        \"id\": 667031,\n        \"gravatar_id\": \"d0f85fcd119bc36e61d4d37a3cfffe60\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jialongl/pad\",\n        \"id\": 2859592,\n        \"name\": \"jialongl/pad\"\n    },\n    \"public\": true,\n    \"payload\": {},\n    \"id\": \"1508537305\",\n    \"created_at\": \"2012-01-01T10:51:50Z\"\n}\n</code></pre>\n\n<p>PullRequestEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PullRequestEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/freeakk\",\n        \"login\": \"freeakk\",\n        \"id\": 639796,\n        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/qooxdoo/qooxdoo\",\n        \"id\": 548213,\n        \"name\": \"qooxdoo/qooxdoo\"\n    },\n    \"org\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-org-420.png\",\n        \"url\": \"https://api.github.dev/orgs/qooxdoo\",\n        \"login\": \"qooxdoo\",\n        \"id\": 105118,\n        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"opened\",\n        \"pull_request\": {\n            \"html_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7\",\n            \"mergeable\": null,\n            \"deletions\": 0,\n            \"merged\": false,\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\",\n            \"closed_at\": null,\n            \"merged_by\": null,\n            \"review_comments\": 0,\n            \"updated_at\": \"2012-01-01T11:26:35Z\",\n            \"patch_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.patch\",\n            \"state\": \"open\",\n            \"changed_files\": 1,\n            \"body\": \"http://bugzilla.qooxdoo.org/show_bug.cgi?id=5798\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/freeakk\",\n                \"login\": \"freeakk\",\n                \"id\": 639796,\n                \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n            },\n            \"issue_url\": \"https://github.com/qooxdoo/qooxdoo/issues/7\",\n            \"id\": 642757,\n            \"created_at\": \"2012-01-01T11:26:35Z\",\n            \"diff_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.diff\",\n            \"title\": \"Fix bug 5798\",\n            \"merged_at\": null,\n            \"_links\": {\n                \"comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/issues/7/comments\"\n                },\n                \"self\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\"\n                },\n                \"review_comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7/comments\"\n                },\n                \"html\": {\n                    \"href\": \"https://github.com/qooxdoo/qooxdoo/pull/7\"\n                }\n            },\n            \"head\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                        \"url\": \"https://api.github.com/users/freeakk\",\n                        \"login\": \"freeakk\",\n                        \"id\": 639796,\n                        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                    },\n                    \"clone_url\": \"https://github.com/freeakk/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/freeakk/qooxdoo\",\n                    \"git_url\": \"git://github.com/freeakk/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T11:24:35Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 1,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 3082044,\n                    \"fork\": true,\n                    \"created_at\": \"2012-01-01T07:28:44Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 0,\n                    \"size\": 484,\n                    \"pushed_at\": \"2012-01-01T11:24:09Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 0,\n                    \"ssh_url\": \"git@github.com:freeakk/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                    \"url\": \"https://api.github.com/users/freeakk\",\n                    \"login\": \"freeakk\",\n                    \"id\": 639796,\n                    \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                },\n                \"label\": \"freeakk:master\",\n                \"sha\": \"c6ebd5b54914e2244fe1401d6843dc77dd23fe07\",\n                \"ref\": \"master\"\n            },\n            \"number\": 7,\n            \"commits\": 1,\n            \"additions\": 5,\n            \"base\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                        \"url\": \"https://api.github.com/users/qooxdoo\",\n                        \"login\": \"qooxdoo\",\n                        \"id\": 105118,\n                        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                    },\n                    \"clone_url\": \"https://github.com/qooxdoo/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo\",\n                    \"git_url\": \"git://github.com/qooxdoo/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T07:28:44Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 140,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 548213,\n                    \"fork\": false,\n                    \"created_at\": \"2010-03-05T10:01:27Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 3,\n                    \"size\": 5620,\n                    \"pushed_at\": \"2011-12-23T13:20:26Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 28,\n                    \"ssh_url\": \"git@github.com:qooxdoo/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                    \"url\": \"https://api.github.com/users/qooxdoo\",\n                    \"login\": \"qooxdoo\",\n                    \"id\": 105118,\n                    \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                },\n                \"label\": \"qooxdoo:master\",\n                \"sha\": \"5c8f02ee1b3886edb213c91351bfbcbe6b8655ff\",\n                \"ref\": \"master\"\n            }\n        },\n        \"number\": 7\n    },\n    \"id\": \"1508538441\",\n    \"created_at\": \"2012-01-01T11:26:37Z\"\n}\n</code></pre>\n\n<p>PullRequestReviewCommentEvent</p>\n\nNone found.\n<br><br><p>PushEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PushEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/a8584f48cb2c4028c1aeca24a4645cd4?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/eatnumber1\",\n        \"login\": \"eatnumber1\",\n        \"id\": 17551,\n        \"gravatar_id\": \"a8584f48cb2c4028c1aeca24a4645cd4\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/eatnumber1/eatnumber1.github.com\",\n        \"id\": 3007212,\n        \"name\": \"eatnumber1/eatnumber1.github.com\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"size\": 1,\n        \"head\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n        \"push_id\": 55756270,\n        \"commits\": [\n            {\n                \"author\": {\n                    \"name\": \"Russell Harmon\",\n                    \"email\": \"russ@eatnumber1.com\"\n                },\n                \"url\": \"https://api.github.com/repos/eatnumber1/eatnumber1.github.com/commits/5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n                \"message\": \"Automatically generated site on Sat Dec 31 18:59:49 EST 2011\",\n                \"sha\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\"\n            }\n        ],\n        \"ref\": \"refs/heads/master\"\n    },\n    \"id\": \"1508512238\",\n    \"created_at\": \"2012-01-01T00:00:12Z\"\n}\n</code></pre>\n\n<p>TeamAddEvent</p>\n\nNone found.\n<br><br><p>WatchEvent</p>\n\n<pre><code>\n{\n    \"type\": \"WatchEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2a8d090768d237544a7c69a0f9c217c7?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/timgluz\",\n        \"login\": \"timgluz\",\n        \"id\": 1223889,\n        \"gravatar_id\": \"2a8d090768d237544a7c69a0f9c217c7\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/bartaz/impress.js\",\n        \"id\": 3065454,\n        \"name\": \"bartaz/impress.js\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"started\"\n    },\n    \"id\": \"1508512289\",\n    \"created_at\": \"2012-01-01T00:01:12Z\"\n}\n</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 51755735612, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Github Archive's 18 Event Types", "tags": [], "post_url": "http://datasyndrome.com/post/51755735612/github-archives-18-event-types", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5ymCuTey", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1369953480, "note_count": 0, "trail": [{"content": "<p><p>In <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">yesterday&rsquo;s post</a> we showed how to download and process the <a href=\"http://www.githubarchive.org/\">github archive</a>. In today&rsquo;s post we&rsquo;re going to examine that data in-depth, diving into 18 event types. This is helpful because without this as a reference, you must cross-reference the API docs, and the end-result is that you are always surprised when you sample the records and new/interesting fields show up. \n\n\n<br /><br /></p><p>The event types, with example data, are as follows:</p>\n<br /><br /><p>CommitCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CommitCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dabrahams\",\n        \"login\": \"dabrahams\",\n        \"id\": 44065,\n        \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/wahikihiki/boost-modularize\",\n        \"id\": 2133453,\n        \"name\": \"wahikihiki/boost-modularize\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"comment\": {\n            \"html_url\": \"https://github.com/wahikihiki/boost-modularize/commit/a339f625e4#commitcomment-830037\",\n            \"commit_id\": \"a339f625e492d21926c449c17269c4d77e94f78a\",\n            \"url\": \"https://api.github.com/repos/wahikihiki/boost-modularize/comments/830037\",\n            \"updated_at\": \"2012-01-01T00:03:11Z\",\n            \"body\": \"I think you closed the wrong issue here.\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/dabrahams\",\n                \"login\": \"dabrahams\",\n                \"id\": 44065,\n                \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n            },\n            \"position\": null,\n            \"id\": 830037,\n            \"path\": null,\n            \"created_at\": \"2012-01-01T00:03:11Z\",\n            \"line\": null\n        }\n    },\n    \"id\": \"1508512415\",\n    \"created_at\": \"2012-01-01T00:03:11Z\"\n}\n</code></pre>\n\n<p>CreateEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CreateEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/8c315bedc4ab1b9aef8f9b446030daac?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/vinced45\",\n        \"login\": \"vinced45\",\n        \"id\": 101286,\n        \"gravatar_id\": \"8c315bedc4ab1b9aef8f9b446030daac\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/vinced45/siriproxy-mashable\",\n        \"id\": 3081234,\n        \"name\": \"vinced45/siriproxy-mashable\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"repository\",\n        \"description\": \"Siri Proxy Plugin to get news from Mashable\",\n        \"master_branch\": \"master\",\n        \"ref\": null\n    },\n    \"id\": \"1508512425\",\n    \"created_at\": \"2012-01-01T00:03:28Z\"\n}\n</code></pre>\n\n<p>DeleteEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DeleteEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/71c216d75354dda636b879dfc95654fb?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/charliepark\",\n        \"login\": \"charliepark\",\n        \"id\": 22547,\n        \"gravatar_id\": \"71c216d75354dda636b879dfc95654fb\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/charliepark/hatchshow\",\n        \"id\": 3081193,\n        \"name\": \"charliepark/hatchshow\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"branch\",\n        \"ref\": \"gh-pages\"\n    },\n    \"id\": \"1508512731\",\n    \"created_at\": \"2012-01-01T00:10:11Z\"\n}\n</code></pre>\n\n<p>DownloadEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DownloadEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/610670d3633cf84993fb1508bde4dbcc?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/MihailJP\",\n        \"login\": \"MihailJP\",\n        \"id\": 990217,\n        \"gravatar_id\": \"610670d3633cf84993fb1508bde4dbcc\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/MihailJP/Sophora\",\n        \"id\": 2484028,\n        \"name\": \"MihailJP/Sophora\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"download\": {\n            \"html_url\": \"https://github.com/downloads/MihailJP/Sophora/Sophora-TTF.7z\",\n            \"url\": \"https://api.github.com/repos/MihailJP/Sophora/downloads/167647\",\n            \"description\": \"Sophora TTF release 1.2.0\",\n            \"id\": 167647,\n            \"created_at\": \"2012-01-01T00:39:26Z\",\n            \"name\": \"Sophora-TTF.7z\",\n            \"download_count\": 0,\n            \"size\": 9218048,\n            \"content_type\": \".7z\"\n        }\n    },\n    \"id\": \"1508514008\",\n    \"created_at\": \"2012-01-01T00:39:26Z\"\n}\n</code></pre>\n\n<p>FollowEvent</p>\n\n<pre><code>\n{\n    \"type\": \"FollowEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/9f3a6ded186b043354b6487efc46c7e3?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dchang00\",\n        \"login\": \"dchang00\",\n        \"id\": 1136380,\n        \"gravatar_id\": \"9f3a6ded186b043354b6487efc46c7e3\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"target\": {\n            \"html_url\": \"https://github.com/dbtsai\",\n            \"type\": \"User\",\n            \"bio\": null,\n            \"location\": \"Palo Alto, CA, USA\",\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/39e915ddd0924cc3bde7225b4690ae6d?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/dbtsai\",\n            \"login\": \"dbtsai\",\n            \"company\": null,\n            \"hireable\": false,\n            \"following\": 0,\n            \"id\": 1134574,\n            \"created_at\": \"2011-10-18T00:17:03Z\",\n            \"gravatar_id\": \"39e915ddd0924cc3bde7225b4690ae6d\",\n            \"public_gists\": 0,\n            \"blog\": \"http://www.dbtsai.com\",\n            \"name\": \"D.B. Tsai\",\n            \"email\": \"\",\n            \"followers\": 1,\n            \"public_repos\": 1\n        }\n    },\n    \"id\": \"1508514239\",\n    \"created_at\": \"2012-01-01T00:44:30Z\"\n}\n</code></pre>\n\n<p>ForkEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/goreckm\",\n        \"login\": \"goreckm\",\n        \"id\": 308672,\n        \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/thedersen/backbone.validation\",\n        \"id\": 2456444,\n        \"name\": \"thedersen/backbone.validation\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"forkee\": {\n            \"owner\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/goreckm\",\n                \"login\": \"goreckm\",\n                \"id\": 308672,\n                \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n            },\n            \"clone_url\": \"https://github.com/goreckm/backbone.validation.git\",\n            \"html_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"url\": \"https://api.github.com/repos/goreckm/backbone.validation\",\n            \"git_url\": \"git://github.com/goreckm/backbone.validation.git\",\n            \"updated_at\": \"2012-01-01T00:50:43Z\",\n            \"private\": false,\n            \"svn_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"public\": true,\n            \"language\": \"JavaScript\",\n            \"watchers\": 1,\n            \"description\": \"A validation plugin for Backbone.js\",\n            \"id\": 3081331,\n            \"fork\": true,\n            \"created_at\": \"2012-01-01T00:50:43Z\",\n            \"master_branch\": null,\n            \"name\": \"backbone.validation\",\n            \"open_issues\": 0,\n            \"size\": 124,\n            \"pushed_at\": \"2011-12-27T19:42:56Z\",\n            \"homepage\": \"\",\n            \"forks\": 0,\n            \"ssh_url\": \"git@github.com:goreckm/backbone.validation.git\"\n        }\n    },\n    \"id\": \"1508514511\",\n    \"created_at\": \"2012-01-01T00:50:43Z\"\n}\n</code></pre>\n\n<p>ForkApplyEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkApplyEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/76621dab58e151dee5adab9c71b1033a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jakeday\",\n        \"login\": \"jakeday\",\n        \"id\": 554899,\n        \"gravatar_id\": \"76621dab58e151dee5adab9c71b1033a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jakeday/KangBang-OMAP\",\n        \"id\": 3060269,\n        \"name\": \"jakeday/KangBang-OMAP\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"before\": \"a0d608d086a1cb68aa15254e3cf4a101625dc1f3\",\n        \"after\": \"c4d8bb808af0d446724a63212c6a8d485242f958\",\n        \"head\": \"master\"\n    },\n    \"id\": \"1508515330\",\n    \"created_at\": \"2012-01-01T01:10:07Z\"\n}\n</code></pre>\n\n<p>GistEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GistEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/berkerpeksag\",\n        \"login\": \"berkerpeksag\",\n        \"id\": 26338,\n        \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"update\",\n        \"gist\": {\n            \"html_url\": \"https://gist.github.com/1545854\",\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/gists/1545854\",\n            \"updated_at\": \"2012-01-01T01:12:51Z\",\n            \"public\": true,\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/berkerpeksag\",\n                \"login\": \"berkerpeksag\",\n                \"id\": 26338,\n                \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n            },\n            \"git_push_url\": \"git@gist.github.com:1545854.git\",\n            \"description\": \"GitHub Badge JSONP Example\",\n            \"id\": \"1545854\",\n            \"created_at\": \"2012-01-01T01:08:36Z\",\n            \"files\": {},\n            \"git_pull_url\": \"git://gist.github.com/1545854.git\"\n        }\n    },\n    \"id\": \"1508515439\",\n    \"created_at\": \"2012-01-01T01:12:53Z\"\n}\n</code></pre>\n\n<p>GollumEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GollumEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/09fd78807043975bacd0db17347a99da?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/Technius\",\n        \"login\": \"Technius\",\n        \"id\": 1066652,\n        \"gravatar_id\": \"09fd78807043975bacd0db17347a99da\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/Technius/SkyrimRPG\",\n        \"id\": 3004403,\n        \"name\": \"Technius/SkyrimRPG\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"pages\": [\n            {\n                \"summary\": null,\n                \"html_url\": \"https://github.com/Technius/SkyrimRPG/wiki/Plugin-plans\",\n                \"action\": \"edited\",\n                \"title\": \"Plugin plans\",\n                \"page_name\": \"Plugin plans\",\n                \"sha\": \"0ff0f1441b86782ea60f62d031d7e9a2240fae61\"\n            }\n        ]\n    },\n    \"id\": \"1508515608\",\n    \"created_at\": \"2012-01-01T01:17:14Z\"\n}\n</code></pre>\n\n<p>IssueCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssueCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/zml2008\",\n        \"login\": \"zml2008\",\n        \"id\": 629092,\n        \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/sk89q/commandbook\",\n        \"id\": 1423268,\n        \"name\": \"sk89q/commandbook\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"created\",\n        \"comment\": {\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/comments/3323504\",\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"body\": \"Merged in f4930b7\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/zml2008\",\n                \"login\": \"zml2008\",\n                \"id\": 629092,\n                \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n            },\n            \"id\": 3323504,\n            \"created_at\": \"2012-01-01T01:18:31Z\"\n        },\n        \"issue\": {\n            \"html_url\": \"https://github.com/sk89q/commandbook/issues/66\",\n            \"comments\": 7,\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/66\",\n            \"closed_at\": \"2012-01-01T01:18:31Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": null,\n            \"body\": \"I made the take command :)\",\n            \"pull_request\": {\n                \"html_url\": \"https://github.com/sk89q/commandbook/pull/66\",\n                \"patch_url\": \"https://github.com/sk89q/commandbook/pull/66.patch\",\n                \"diff_url\": \"https://github.com/sk89q/commandbook/pull/66.diff\"\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/22c0e20e348d2fd80e74e1c1473d05dd?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/DarkArc\",\n                \"login\": \"DarkArc\",\n                \"id\": 778012,\n                \"gravatar_id\": \"22c0e20e348d2fd80e74e1c1473d05dd\"\n            },\n            \"id\": 2696201,\n            \"created_at\": \"2012-01-01T00:47:36Z\",\n            \"title\": \"Implemented take comammand\",\n            \"number\": 66\n        }\n    },\n    \"id\": \"1508515658\",\n    \"created_at\": \"2012-01-01T01:18:31Z\"\n}\n</code></pre>\n\n<p>IssuesEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssuesEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/addyosmani\",\n        \"login\": \"addyosmani\",\n        \"id\": 110953,\n        \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/addyosmani/todomvc\",\n        \"id\": 1844251,\n        \"name\": \"addyosmani/todomvc\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"closed\",\n        \"issue\": {\n            \"html_url\": \"https://github.com/addyosmani/todomvc/issues/22\",\n            \"comments\": 1,\n            \"url\": \"https://api.github.com/repos/addyosmani/todomvc/issues/22\",\n            \"closed_at\": \"2012-01-01T01:21:46Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:21:46Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/addyosmani\",\n                \"login\": \"addyosmani\",\n                \"id\": 110953,\n                \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n            },\n            \"body\": \"In the index.html file there is this code:\\r\\n\\r\\n\\r\\n\\r\\nThis fails while loading from the file:// scheme for obvious reasons.\\r\\nNot sure if it should be considered a bug but in chrome 14 it's quite annoying having the page trying to load for some time before failing.\",\n            \"pull_request\": {\n                \"html_url\": null,\n                \"patch_url\": null,\n                \"diff_url\": null\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/37fc491db95105ff67aa9b45a2834dca?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/graphnode\",\n                \"login\": \"graphnode\",\n                \"id\": 216518,\n                \"gravatar_id\": \"37fc491db95105ff67aa9b45a2834dca\"\n            },\n            \"id\": 2016566,\n            \"created_at\": \"2011-10-21T15:27:47Z\",\n            \"title\": \"Twitter \\\"widgets.js\\\" fails when in file://\",\n            \"number\": 22\n        }\n    },\n    \"id\": \"1508515785\",\n    \"created_at\": \"2012-01-01T01:21:48Z\"\n}\n</code></pre>\n\n\nMemberEvent\n\n<pre><code>\n{\n    \"type\": \"MemberEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/36d8ad4e46e0c5e3c260e3761f8c7e68?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/balr0g\",\n        \"login\": \"balr0g\",\n        \"id\": 1091609,\n        \"gravatar_id\": \"36d8ad4e46e0c5e3c260e3761f8c7e68\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/balr0g/MineFactoryReloaded\",\n        \"id\": 3081425,\n        \"name\": \"balr0g/MineFactoryReloaded\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"member\": {\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/5d109d40b17aafa502ad85a361071db4?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/TehKrush\",\n            \"login\": \"TehKrush\",\n            \"id\": 509984,\n            \"gravatar_id\": \"5d109d40b17aafa502ad85a361071db4\"\n        },\n        \"action\": \"added\"\n    },\n    \"id\": \"1508516755\",\n    \"created_at\": \"2012-01-01T01:46:47Z\"\n}\n</code></pre>\n\n<p>PublicEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PublicEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/d0f85fcd119bc36e61d4d37a3cfffe60?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jialongl\",\n        \"login\": \"jialongl\",\n        \"id\": 667031,\n        \"gravatar_id\": \"d0f85fcd119bc36e61d4d37a3cfffe60\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jialongl/pad\",\n        \"id\": 2859592,\n        \"name\": \"jialongl/pad\"\n    },\n    \"public\": true,\n    \"payload\": {},\n    \"id\": \"1508537305\",\n    \"created_at\": \"2012-01-01T10:51:50Z\"\n}\n</code></pre>\n\n<p>PullRequestEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PullRequestEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/freeakk\",\n        \"login\": \"freeakk\",\n        \"id\": 639796,\n        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/qooxdoo/qooxdoo\",\n        \"id\": 548213,\n        \"name\": \"qooxdoo/qooxdoo\"\n    },\n    \"org\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-org-420.png\",\n        \"url\": \"https://api.github.dev/orgs/qooxdoo\",\n        \"login\": \"qooxdoo\",\n        \"id\": 105118,\n        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"opened\",\n        \"pull_request\": {\n            \"html_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7\",\n            \"mergeable\": null,\n            \"deletions\": 0,\n            \"merged\": false,\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\",\n            \"closed_at\": null,\n            \"merged_by\": null,\n            \"review_comments\": 0,\n            \"updated_at\": \"2012-01-01T11:26:35Z\",\n            \"patch_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.patch\",\n            \"state\": \"open\",\n            \"changed_files\": 1,\n            \"body\": \"http://bugzilla.qooxdoo.org/show_bug.cgi?id=5798\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/freeakk\",\n                \"login\": \"freeakk\",\n                \"id\": 639796,\n                \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n            },\n            \"issue_url\": \"https://github.com/qooxdoo/qooxdoo/issues/7\",\n            \"id\": 642757,\n            \"created_at\": \"2012-01-01T11:26:35Z\",\n            \"diff_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.diff\",\n            \"title\": \"Fix bug 5798\",\n            \"merged_at\": null,\n            \"_links\": {\n                \"comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/issues/7/comments\"\n                },\n                \"self\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\"\n                },\n                \"review_comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7/comments\"\n                },\n                \"html\": {\n                    \"href\": \"https://github.com/qooxdoo/qooxdoo/pull/7\"\n                }\n            },\n            \"head\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                        \"url\": \"https://api.github.com/users/freeakk\",\n                        \"login\": \"freeakk\",\n                        \"id\": 639796,\n                        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                    },\n                    \"clone_url\": \"https://github.com/freeakk/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/freeakk/qooxdoo\",\n                    \"git_url\": \"git://github.com/freeakk/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T11:24:35Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 1,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 3082044,\n                    \"fork\": true,\n                    \"created_at\": \"2012-01-01T07:28:44Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 0,\n                    \"size\": 484,\n                    \"pushed_at\": \"2012-01-01T11:24:09Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 0,\n                    \"ssh_url\": \"git@github.com:freeakk/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                    \"url\": \"https://api.github.com/users/freeakk\",\n                    \"login\": \"freeakk\",\n                    \"id\": 639796,\n                    \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                },\n                \"label\": \"freeakk:master\",\n                \"sha\": \"c6ebd5b54914e2244fe1401d6843dc77dd23fe07\",\n                \"ref\": \"master\"\n            },\n            \"number\": 7,\n            \"commits\": 1,\n            \"additions\": 5,\n            \"base\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                        \"url\": \"https://api.github.com/users/qooxdoo\",\n                        \"login\": \"qooxdoo\",\n                        \"id\": 105118,\n                        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                    },\n                    \"clone_url\": \"https://github.com/qooxdoo/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo\",\n                    \"git_url\": \"git://github.com/qooxdoo/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T07:28:44Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 140,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 548213,\n                    \"fork\": false,\n                    \"created_at\": \"2010-03-05T10:01:27Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 3,\n                    \"size\": 5620,\n                    \"pushed_at\": \"2011-12-23T13:20:26Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 28,\n                    \"ssh_url\": \"git@github.com:qooxdoo/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                    \"url\": \"https://api.github.com/users/qooxdoo\",\n                    \"login\": \"qooxdoo\",\n                    \"id\": 105118,\n                    \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                },\n                \"label\": \"qooxdoo:master\",\n                \"sha\": \"5c8f02ee1b3886edb213c91351bfbcbe6b8655ff\",\n                \"ref\": \"master\"\n            }\n        },\n        \"number\": 7\n    },\n    \"id\": \"1508538441\",\n    \"created_at\": \"2012-01-01T11:26:37Z\"\n}\n</code></pre>\n\n<p>PullRequestReviewCommentEvent</p>\n\nNone found.\n<br /><br /><p>PushEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PushEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/a8584f48cb2c4028c1aeca24a4645cd4?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/eatnumber1\",\n        \"login\": \"eatnumber1\",\n        \"id\": 17551,\n        \"gravatar_id\": \"a8584f48cb2c4028c1aeca24a4645cd4\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/eatnumber1/eatnumber1.github.com\",\n        \"id\": 3007212,\n        \"name\": \"eatnumber1/eatnumber1.github.com\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"size\": 1,\n        \"head\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n        \"push_id\": 55756270,\n        \"commits\": [\n            {\n                \"author\": {\n                    \"name\": \"Russell Harmon\",\n                    \"email\": \"russ@eatnumber1.com\"\n                },\n                \"url\": \"https://api.github.com/repos/eatnumber1/eatnumber1.github.com/commits/5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n                \"message\": \"Automatically generated site on Sat Dec 31 18:59:49 EST 2011\",\n                \"sha\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\"\n            }\n        ],\n        \"ref\": \"refs/heads/master\"\n    },\n    \"id\": \"1508512238\",\n    \"created_at\": \"2012-01-01T00:00:12Z\"\n}\n</code></pre>\n\n<p>TeamAddEvent</p>\n\nNone found.\n<br /><br /><p>WatchEvent</p>\n\n<pre><code>\n{\n    \"type\": \"WatchEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2a8d090768d237544a7c69a0f9c217c7?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/timgluz\",\n        \"login\": \"timgluz\",\n        \"id\": 1223889,\n        \"gravatar_id\": \"2a8d090768d237544a7c69a0f9c217c7\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/bartaz/impress.js\",\n        \"id\": 3065454,\n        \"name\": \"bartaz/impress.js\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"started\"\n    },\n    \"id\": \"1508512289\",\n    \"created_at\": \"2012-01-01T00:01:12Z\"\n}\n</code></pre></p>", "content_raw": "<p>In <a href=\"http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data\">yesterday\u2019s post</a> we showed how to download and process the <a href=\"http://www.githubarchive.org/\">github archive</a>. In today\u2019s post we\u2019re going to examine that data in-depth, diving into 18 event types. This is helpful because without this as a reference, you must cross-reference the API docs, and the end-result is that you are always surprised when you sample the records and new/interesting fields show up. \n\n\n<br><br><p>The event types, with example data, are as follows:</p>\n<br><br><p>CommitCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CommitCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dabrahams\",\n        \"login\": \"dabrahams\",\n        \"id\": 44065,\n        \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/wahikihiki/boost-modularize\",\n        \"id\": 2133453,\n        \"name\": \"wahikihiki/boost-modularize\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"comment\": {\n            \"html_url\": \"https://github.com/wahikihiki/boost-modularize/commit/a339f625e4#commitcomment-830037\",\n            \"commit_id\": \"a339f625e492d21926c449c17269c4d77e94f78a\",\n            \"url\": \"https://api.github.com/repos/wahikihiki/boost-modularize/comments/830037\",\n            \"updated_at\": \"2012-01-01T00:03:11Z\",\n            \"body\": \"I think you closed the wrong issue here.\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/5b45540ae377ec54a071f313b7193a27?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/dabrahams\",\n                \"login\": \"dabrahams\",\n                \"id\": 44065,\n                \"gravatar_id\": \"5b45540ae377ec54a071f313b7193a27\"\n            },\n            \"position\": null,\n            \"id\": 830037,\n            \"path\": null,\n            \"created_at\": \"2012-01-01T00:03:11Z\",\n            \"line\": null\n        }\n    },\n    \"id\": \"1508512415\",\n    \"created_at\": \"2012-01-01T00:03:11Z\"\n}\n</code></pre>\n\n<p>CreateEvent</p>\n\n<pre><code>\n{\n    \"type\": \"CreateEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/8c315bedc4ab1b9aef8f9b446030daac?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/vinced45\",\n        \"login\": \"vinced45\",\n        \"id\": 101286,\n        \"gravatar_id\": \"8c315bedc4ab1b9aef8f9b446030daac\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/vinced45/siriproxy-mashable\",\n        \"id\": 3081234,\n        \"name\": \"vinced45/siriproxy-mashable\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"repository\",\n        \"description\": \"Siri Proxy Plugin to get news from Mashable\",\n        \"master_branch\": \"master\",\n        \"ref\": null\n    },\n    \"id\": \"1508512425\",\n    \"created_at\": \"2012-01-01T00:03:28Z\"\n}\n</code></pre>\n\n<p>DeleteEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DeleteEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/71c216d75354dda636b879dfc95654fb?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/charliepark\",\n        \"login\": \"charliepark\",\n        \"id\": 22547,\n        \"gravatar_id\": \"71c216d75354dda636b879dfc95654fb\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/charliepark/hatchshow\",\n        \"id\": 3081193,\n        \"name\": \"charliepark/hatchshow\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"ref_type\": \"branch\",\n        \"ref\": \"gh-pages\"\n    },\n    \"id\": \"1508512731\",\n    \"created_at\": \"2012-01-01T00:10:11Z\"\n}\n</code></pre>\n\n<p>DownloadEvent</p>\n\n<pre><code>\n{\n    \"type\": \"DownloadEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/610670d3633cf84993fb1508bde4dbcc?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/MihailJP\",\n        \"login\": \"MihailJP\",\n        \"id\": 990217,\n        \"gravatar_id\": \"610670d3633cf84993fb1508bde4dbcc\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/MihailJP/Sophora\",\n        \"id\": 2484028,\n        \"name\": \"MihailJP/Sophora\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"download\": {\n            \"html_url\": \"https://github.com/downloads/MihailJP/Sophora/Sophora-TTF.7z\",\n            \"url\": \"https://api.github.com/repos/MihailJP/Sophora/downloads/167647\",\n            \"description\": \"Sophora TTF release 1.2.0\",\n            \"id\": 167647,\n            \"created_at\": \"2012-01-01T00:39:26Z\",\n            \"name\": \"Sophora-TTF.7z\",\n            \"download_count\": 0,\n            \"size\": 9218048,\n            \"content_type\": \".7z\"\n        }\n    },\n    \"id\": \"1508514008\",\n    \"created_at\": \"2012-01-01T00:39:26Z\"\n}\n</code></pre>\n\n<p>FollowEvent</p>\n\n<pre><code>\n{\n    \"type\": \"FollowEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/9f3a6ded186b043354b6487efc46c7e3?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/dchang00\",\n        \"login\": \"dchang00\",\n        \"id\": 1136380,\n        \"gravatar_id\": \"9f3a6ded186b043354b6487efc46c7e3\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"target\": {\n            \"html_url\": \"https://github.com/dbtsai\",\n            \"type\": \"User\",\n            \"bio\": null,\n            \"location\": \"Palo Alto, CA, USA\",\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/39e915ddd0924cc3bde7225b4690ae6d?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/dbtsai\",\n            \"login\": \"dbtsai\",\n            \"company\": null,\n            \"hireable\": false,\n            \"following\": 0,\n            \"id\": 1134574,\n            \"created_at\": \"2011-10-18T00:17:03Z\",\n            \"gravatar_id\": \"39e915ddd0924cc3bde7225b4690ae6d\",\n            \"public_gists\": 0,\n            \"blog\": \"http://www.dbtsai.com\",\n            \"name\": \"D.B. Tsai\",\n            \"email\": \"\",\n            \"followers\": 1,\n            \"public_repos\": 1\n        }\n    },\n    \"id\": \"1508514239\",\n    \"created_at\": \"2012-01-01T00:44:30Z\"\n}\n</code></pre>\n\n<p>ForkEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/goreckm\",\n        \"login\": \"goreckm\",\n        \"id\": 308672,\n        \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/thedersen/backbone.validation\",\n        \"id\": 2456444,\n        \"name\": \"thedersen/backbone.validation\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"forkee\": {\n            \"owner\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/b39787c57ab1c8330a60278e76a47fb8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/goreckm\",\n                \"login\": \"goreckm\",\n                \"id\": 308672,\n                \"gravatar_id\": \"b39787c57ab1c8330a60278e76a47fb8\"\n            },\n            \"clone_url\": \"https://github.com/goreckm/backbone.validation.git\",\n            \"html_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"url\": \"https://api.github.com/repos/goreckm/backbone.validation\",\n            \"git_url\": \"git://github.com/goreckm/backbone.validation.git\",\n            \"updated_at\": \"2012-01-01T00:50:43Z\",\n            \"private\": false,\n            \"svn_url\": \"https://github.com/goreckm/backbone.validation\",\n            \"public\": true,\n            \"language\": \"JavaScript\",\n            \"watchers\": 1,\n            \"description\": \"A validation plugin for Backbone.js\",\n            \"id\": 3081331,\n            \"fork\": true,\n            \"created_at\": \"2012-01-01T00:50:43Z\",\n            \"master_branch\": null,\n            \"name\": \"backbone.validation\",\n            \"open_issues\": 0,\n            \"size\": 124,\n            \"pushed_at\": \"2011-12-27T19:42:56Z\",\n            \"homepage\": \"\",\n            \"forks\": 0,\n            \"ssh_url\": \"git@github.com:goreckm/backbone.validation.git\"\n        }\n    },\n    \"id\": \"1508514511\",\n    \"created_at\": \"2012-01-01T00:50:43Z\"\n}\n</code></pre>\n\n<p>ForkApplyEvent</p>\n\n<pre><code>\n{\n    \"type\": \"ForkApplyEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/76621dab58e151dee5adab9c71b1033a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jakeday\",\n        \"login\": \"jakeday\",\n        \"id\": 554899,\n        \"gravatar_id\": \"76621dab58e151dee5adab9c71b1033a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jakeday/KangBang-OMAP\",\n        \"id\": 3060269,\n        \"name\": \"jakeday/KangBang-OMAP\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"before\": \"a0d608d086a1cb68aa15254e3cf4a101625dc1f3\",\n        \"after\": \"c4d8bb808af0d446724a63212c6a8d485242f958\",\n        \"head\": \"master\"\n    },\n    \"id\": \"1508515330\",\n    \"created_at\": \"2012-01-01T01:10:07Z\"\n}\n</code></pre>\n\n<p>GistEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GistEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/berkerpeksag\",\n        \"login\": \"berkerpeksag\",\n        \"id\": 26338,\n        \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos//\",\n        \"name\": \"/\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"update\",\n        \"gist\": {\n            \"html_url\": \"https://gist.github.com/1545854\",\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/gists/1545854\",\n            \"updated_at\": \"2012-01-01T01:12:51Z\",\n            \"public\": true,\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/df8e51d7618d5ed7ccbbc8dea9a9afee?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/berkerpeksag\",\n                \"login\": \"berkerpeksag\",\n                \"id\": 26338,\n                \"gravatar_id\": \"df8e51d7618d5ed7ccbbc8dea9a9afee\"\n            },\n            \"git_push_url\": \"git@gist.github.com:1545854.git\",\n            \"description\": \"GitHub Badge JSONP Example\",\n            \"id\": \"1545854\",\n            \"created_at\": \"2012-01-01T01:08:36Z\",\n            \"files\": {},\n            \"git_pull_url\": \"git://gist.github.com/1545854.git\"\n        }\n    },\n    \"id\": \"1508515439\",\n    \"created_at\": \"2012-01-01T01:12:53Z\"\n}\n</code></pre>\n\n<p>GollumEvent</p>\n\n<pre><code>\n{\n    \"type\": \"GollumEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/09fd78807043975bacd0db17347a99da?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/Technius\",\n        \"login\": \"Technius\",\n        \"id\": 1066652,\n        \"gravatar_id\": \"09fd78807043975bacd0db17347a99da\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/Technius/SkyrimRPG\",\n        \"id\": 3004403,\n        \"name\": \"Technius/SkyrimRPG\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"pages\": [\n            {\n                \"summary\": null,\n                \"html_url\": \"https://github.com/Technius/SkyrimRPG/wiki/Plugin-plans\",\n                \"action\": \"edited\",\n                \"title\": \"Plugin plans\",\n                \"page_name\": \"Plugin plans\",\n                \"sha\": \"0ff0f1441b86782ea60f62d031d7e9a2240fae61\"\n            }\n        ]\n    },\n    \"id\": \"1508515608\",\n    \"created_at\": \"2012-01-01T01:17:14Z\"\n}\n</code></pre>\n\n<p>IssueCommentEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssueCommentEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/zml2008\",\n        \"login\": \"zml2008\",\n        \"id\": 629092,\n        \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/sk89q/commandbook\",\n        \"id\": 1423268,\n        \"name\": \"sk89q/commandbook\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"created\",\n        \"comment\": {\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/comments/3323504\",\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"body\": \"Merged in f4930b7\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/2320ab48d0715a4e9c73b7ec13fd6f3a?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/zml2008\",\n                \"login\": \"zml2008\",\n                \"id\": 629092,\n                \"gravatar_id\": \"2320ab48d0715a4e9c73b7ec13fd6f3a\"\n            },\n            \"id\": 3323504,\n            \"created_at\": \"2012-01-01T01:18:31Z\"\n        },\n        \"issue\": {\n            \"html_url\": \"https://github.com/sk89q/commandbook/issues/66\",\n            \"comments\": 7,\n            \"url\": \"https://api.github.com/repos/sk89q/commandbook/issues/66\",\n            \"closed_at\": \"2012-01-01T01:18:31Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:18:31Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": null,\n            \"body\": \"I made the take command :)\",\n            \"pull_request\": {\n                \"html_url\": \"https://github.com/sk89q/commandbook/pull/66\",\n                \"patch_url\": \"https://github.com/sk89q/commandbook/pull/66.patch\",\n                \"diff_url\": \"https://github.com/sk89q/commandbook/pull/66.diff\"\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/22c0e20e348d2fd80e74e1c1473d05dd?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/DarkArc\",\n                \"login\": \"DarkArc\",\n                \"id\": 778012,\n                \"gravatar_id\": \"22c0e20e348d2fd80e74e1c1473d05dd\"\n            },\n            \"id\": 2696201,\n            \"created_at\": \"2012-01-01T00:47:36Z\",\n            \"title\": \"Implemented take comammand\",\n            \"number\": 66\n        }\n    },\n    \"id\": \"1508515658\",\n    \"created_at\": \"2012-01-01T01:18:31Z\"\n}\n</code></pre>\n\n<p>IssuesEvent</p>\n\n<pre><code>\n{\n    \"type\": \"IssuesEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/addyosmani\",\n        \"login\": \"addyosmani\",\n        \"id\": 110953,\n        \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/addyosmani/todomvc\",\n        \"id\": 1844251,\n        \"name\": \"addyosmani/todomvc\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"closed\",\n        \"issue\": {\n            \"html_url\": \"https://github.com/addyosmani/todomvc/issues/22\",\n            \"comments\": 1,\n            \"url\": \"https://api.github.com/repos/addyosmani/todomvc/issues/22\",\n            \"closed_at\": \"2012-01-01T01:21:46Z\",\n            \"labels\": [],\n            \"updated_at\": \"2012-01-01T01:21:46Z\",\n            \"state\": \"closed\",\n            \"milestone\": null,\n            \"assignee\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/96270e4c3e5e9806cf7245475c00b275?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/addyosmani\",\n                \"login\": \"addyosmani\",\n                \"id\": 110953,\n                \"gravatar_id\": \"96270e4c3e5e9806cf7245475c00b275\"\n            },\n            \"body\": \"In the index.html file there is this code:\\r\\n\\r\\n\\r\\n\\r\\nThis fails while loading from the file:// scheme for obvious reasons.\\r\\nNot sure if it should be considered a bug but in chrome 14 it's quite annoying having the page trying to load for some time before failing.\",\n            \"pull_request\": {\n                \"html_url\": null,\n                \"patch_url\": null,\n                \"diff_url\": null\n            },\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/37fc491db95105ff67aa9b45a2834dca?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/graphnode\",\n                \"login\": \"graphnode\",\n                \"id\": 216518,\n                \"gravatar_id\": \"37fc491db95105ff67aa9b45a2834dca\"\n            },\n            \"id\": 2016566,\n            \"created_at\": \"2011-10-21T15:27:47Z\",\n            \"title\": \"Twitter \\\"widgets.js\\\" fails when in file://\",\n            \"number\": 22\n        }\n    },\n    \"id\": \"1508515785\",\n    \"created_at\": \"2012-01-01T01:21:48Z\"\n}\n</code></pre>\n\n\nMemberEvent\n\n<pre><code>\n{\n    \"type\": \"MemberEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/36d8ad4e46e0c5e3c260e3761f8c7e68?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/balr0g\",\n        \"login\": \"balr0g\",\n        \"id\": 1091609,\n        \"gravatar_id\": \"36d8ad4e46e0c5e3c260e3761f8c7e68\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/balr0g/MineFactoryReloaded\",\n        \"id\": 3081425,\n        \"name\": \"balr0g/MineFactoryReloaded\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"member\": {\n            \"avatar_url\": \"https://secure.gravatar.com/avatar/5d109d40b17aafa502ad85a361071db4?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n            \"url\": \"https://api.github.com/users/TehKrush\",\n            \"login\": \"TehKrush\",\n            \"id\": 509984,\n            \"gravatar_id\": \"5d109d40b17aafa502ad85a361071db4\"\n        },\n        \"action\": \"added\"\n    },\n    \"id\": \"1508516755\",\n    \"created_at\": \"2012-01-01T01:46:47Z\"\n}\n</code></pre>\n\n<p>PublicEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PublicEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/d0f85fcd119bc36e61d4d37a3cfffe60?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/jialongl\",\n        \"login\": \"jialongl\",\n        \"id\": 667031,\n        \"gravatar_id\": \"d0f85fcd119bc36e61d4d37a3cfffe60\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/jialongl/pad\",\n        \"id\": 2859592,\n        \"name\": \"jialongl/pad\"\n    },\n    \"public\": true,\n    \"payload\": {},\n    \"id\": \"1508537305\",\n    \"created_at\": \"2012-01-01T10:51:50Z\"\n}\n</code></pre>\n\n<p>PullRequestEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PullRequestEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/freeakk\",\n        \"login\": \"freeakk\",\n        \"id\": 639796,\n        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/qooxdoo/qooxdoo\",\n        \"id\": 548213,\n        \"name\": \"qooxdoo/qooxdoo\"\n    },\n    \"org\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-org-420.png\",\n        \"url\": \"https://api.github.dev/orgs/qooxdoo\",\n        \"login\": \"qooxdoo\",\n        \"id\": 105118,\n        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"opened\",\n        \"pull_request\": {\n            \"html_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7\",\n            \"mergeable\": null,\n            \"deletions\": 0,\n            \"merged\": false,\n            \"comments\": 0,\n            \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\",\n            \"closed_at\": null,\n            \"merged_by\": null,\n            \"review_comments\": 0,\n            \"updated_at\": \"2012-01-01T11:26:35Z\",\n            \"patch_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.patch\",\n            \"state\": \"open\",\n            \"changed_files\": 1,\n            \"body\": \"http://bugzilla.qooxdoo.org/show_bug.cgi?id=5798\",\n            \"user\": {\n                \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                \"url\": \"https://api.github.com/users/freeakk\",\n                \"login\": \"freeakk\",\n                \"id\": 639796,\n                \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n            },\n            \"issue_url\": \"https://github.com/qooxdoo/qooxdoo/issues/7\",\n            \"id\": 642757,\n            \"created_at\": \"2012-01-01T11:26:35Z\",\n            \"diff_url\": \"https://github.com/qooxdoo/qooxdoo/pull/7.diff\",\n            \"title\": \"Fix bug 5798\",\n            \"merged_at\": null,\n            \"_links\": {\n                \"comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/issues/7/comments\"\n                },\n                \"self\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7\"\n                },\n                \"review_comments\": {\n                    \"href\": \"https://api.github.com/repos/qooxdoo/qooxdoo/pulls/7/comments\"\n                },\n                \"html\": {\n                    \"href\": \"https://github.com/qooxdoo/qooxdoo/pull/7\"\n                }\n            },\n            \"head\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                        \"url\": \"https://api.github.com/users/freeakk\",\n                        \"login\": \"freeakk\",\n                        \"id\": 639796,\n                        \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                    },\n                    \"clone_url\": \"https://github.com/freeakk/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/freeakk/qooxdoo\",\n                    \"git_url\": \"git://github.com/freeakk/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T11:24:35Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/freeakk/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 1,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 3082044,\n                    \"fork\": true,\n                    \"created_at\": \"2012-01-01T07:28:44Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 0,\n                    \"size\": 484,\n                    \"pushed_at\": \"2012-01-01T11:24:09Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 0,\n                    \"ssh_url\": \"git@github.com:freeakk/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/6871c553d49147b8e04baffa46a9bed8?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-140.png\",\n                    \"url\": \"https://api.github.com/users/freeakk\",\n                    \"login\": \"freeakk\",\n                    \"id\": 639796,\n                    \"gravatar_id\": \"6871c553d49147b8e04baffa46a9bed8\"\n                },\n                \"label\": \"freeakk:master\",\n                \"sha\": \"c6ebd5b54914e2244fe1401d6843dc77dd23fe07\",\n                \"ref\": \"master\"\n            },\n            \"number\": 7,\n            \"commits\": 1,\n            \"additions\": 5,\n            \"base\": {\n                \"repo\": {\n                    \"owner\": {\n                        \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                        \"url\": \"https://api.github.com/users/qooxdoo\",\n                        \"login\": \"qooxdoo\",\n                        \"id\": 105118,\n                        \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                    },\n                    \"clone_url\": \"https://github.com/qooxdoo/qooxdoo.git\",\n                    \"html_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"url\": \"https://api.github.com/repos/qooxdoo/qooxdoo\",\n                    \"git_url\": \"git://github.com/qooxdoo/qooxdoo.git\",\n                    \"updated_at\": \"2012-01-01T07:28:44Z\",\n                    \"private\": false,\n                    \"svn_url\": \"https://github.com/qooxdoo/qooxdoo\",\n                    \"language\": \"JavaScript\",\n                    \"watchers\": 140,\n                    \"description\": \"qooxdoo - Universal JavaScript Framework\",\n                    \"id\": 548213,\n                    \"fork\": false,\n                    \"created_at\": \"2010-03-05T10:01:27Z\",\n                    \"master_branch\": null,\n                    \"name\": \"qooxdoo\",\n                    \"open_issues\": 3,\n                    \"size\": 5620,\n                    \"pushed_at\": \"2011-12-23T13:20:26Z\",\n                    \"homepage\": \"http://qooxdoo.org\",\n                    \"forks\": 28,\n                    \"ssh_url\": \"git@github.com:qooxdoo/qooxdoo.git\"\n                },\n                \"user\": {\n                    \"avatar_url\": \"https://secure.gravatar.com/avatar/4d12dc3e9cb5835e51cfd5648ee16a59?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-orgs.png\",\n                    \"url\": \"https://api.github.com/users/qooxdoo\",\n                    \"login\": \"qooxdoo\",\n                    \"id\": 105118,\n                    \"gravatar_id\": \"4d12dc3e9cb5835e51cfd5648ee16a59\"\n                },\n                \"label\": \"qooxdoo:master\",\n                \"sha\": \"5c8f02ee1b3886edb213c91351bfbcbe6b8655ff\",\n                \"ref\": \"master\"\n            }\n        },\n        \"number\": 7\n    },\n    \"id\": \"1508538441\",\n    \"created_at\": \"2012-01-01T11:26:37Z\"\n}\n</code></pre>\n\n<p>PullRequestReviewCommentEvent</p>\n\nNone found.\n<br><br><p>PushEvent</p>\n\n<pre><code>\n{\n    \"type\": \"PushEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/a8584f48cb2c4028c1aeca24a4645cd4?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/eatnumber1\",\n        \"login\": \"eatnumber1\",\n        \"id\": 17551,\n        \"gravatar_id\": \"a8584f48cb2c4028c1aeca24a4645cd4\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/eatnumber1/eatnumber1.github.com\",\n        \"id\": 3007212,\n        \"name\": \"eatnumber1/eatnumber1.github.com\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"size\": 1,\n        \"head\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n        \"push_id\": 55756270,\n        \"commits\": [\n            {\n                \"author\": {\n                    \"name\": \"Russell Harmon\",\n                    \"email\": \"russ@eatnumber1.com\"\n                },\n                \"url\": \"https://api.github.com/repos/eatnumber1/eatnumber1.github.com/commits/5df581c1c68bad3860409fddeb5cc21e8c38f18c\",\n                \"message\": \"Automatically generated site on Sat Dec 31 18:59:49 EST 2011\",\n                \"sha\": \"5df581c1c68bad3860409fddeb5cc21e8c38f18c\"\n            }\n        ],\n        \"ref\": \"refs/heads/master\"\n    },\n    \"id\": \"1508512238\",\n    \"created_at\": \"2012-01-01T00:00:12Z\"\n}\n</code></pre>\n\n<p>TeamAddEvent</p>\n\nNone found.\n<br><br><p>WatchEvent</p>\n\n<pre><code>\n{\n    \"type\": \"WatchEvent\",\n    \"actor\": {\n        \"avatar_url\": \"https://secure.gravatar.com/avatar/2a8d090768d237544a7c69a0f9c217c7?d=http://github.dev%2Fimages%2Fgravatars%2Fgravatar-user-420.png\",\n        \"url\": \"https://api.github.dev/users/timgluz\",\n        \"login\": \"timgluz\",\n        \"id\": 1223889,\n        \"gravatar_id\": \"2a8d090768d237544a7c69a0f9c217c7\"\n    },\n    \"repo\": {\n        \"url\": \"https://api.github.dev/repos/bartaz/impress.js\",\n        \"id\": 3065454,\n        \"name\": \"bartaz/impress.js\"\n    },\n    \"public\": true,\n    \"payload\": {\n        \"action\": \"started\"\n    },\n    \"id\": \"1508512289\",\n    \"created_at\": \"2012-01-01T00:01:12Z\"\n}\n</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51755735612"}}], "date": "2013-05-30 22:38:00 GMT", "slug": "github-archives-18-event-types", "blog_name": "rjurney", "summary": "Github Archive's 18 Event Types", "can_reblog": true}, {"body": "<p>The Github Archive is a rich dataset available to all via <a href=\"http://www.githubarchive.org/\">githubarchive.org</a>. In this post we will download and create relations from the github archive.</p> \n\n<p>Instructions for downloading it are available on that site, but don&rsquo;t work well with the version of Bash included with some versions of Mac OS X. To download the github data, I created a ruby script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/get_all_data.rb\">get_all_data.rb</a> which will do the job.</p>\n\n<pre><code>def prepend(number)\n  return number &lt;= 9 ? (\"0\" + number.to_s) : number.to_s\nend\n\nfor year in ['11', '12', '13'] do\n  for month in (1..12) do\n    month = prepend(month)\n    for day in (1..31) do\n      day = prepend(day)\n      unless File.exist?(\"data/20#{year}-#{month}-#{day}-23.json.gz\")\n        system \"wget -P data/ <a href=\"http://data.githubarchive.org/20#%7Byear%7D-#%7Bmonth%7D-#%7Bday%7D-%7B0..24%7D.json.gz\">http://data.githubarchive.org/20#{year}-#{month}-#{day}-{0..24}.json.gz</a>\"\n      else\n        puts \"Skipped file...\\n\\n\\n\"\n      end\n    end\n  end\nend\n</code></pre>\n\n<p>That script will produce 8,760 gzip files per year - 24 for each hour per day * 365 days. In my own experiments, I work with the data between 2012 and present day, which is about 90GB uncompressed json. Unzipped, the files contain a list of JSON objects that describe 18 event types, delineated by the common field, &lsquo;type.&rsquo; This type field can be used to split the data into 18 relations of like-formatted records. Splitting records this way is a common step for processing this data, and is therefore best split out in a pre-processing step for efficiency&rsquo;s sake. We&rsquo;ll use Apache Pig to split our data into relations.</p>\n\n<p>From the <a href=\"http://pig.apache.org/\">Apache Pig site</a>:\n\n<i>Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. The salient property of Pig programs is that their structure is amenable to substantial parallelization, which in turns enables them to handle very large data sets.</i></p>\n\n<p>Pig lets us define dataflows to query any data, large or small. We can load JSON records into Pig maps using the <a href=\"https://github.com/kevinweil/elephant-bird\">elephant-bird project&rsquo;s</a> <a href=\"https://github.com/kevinweil/elephant-bird/blob/master/pig/src/main/java/com/twitter/elephantbird/pig/load/JsonLoader.java\">JsonLoader</a>. To get Pig to parse these records though, we need a carriage return after each one instead of a Javascript array of objects. To achieve this, I created a simple script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/newline_format.rb\">newline_format.rb</a> based on the githubarchive example. It is simple:\n\n</p><pre><code>require 'rubygems'\nrequire 'zlib'\nrequire 'yajl'\n \nDir.glob('data/*.json.gz').each do |f|\n  begin\n    gz = open(f)\n    js = Zlib::GzipReader.new(gz).read\n \n    Yajl::Parser.parse(js) do |event|\n      puts Yajl::Encoder.encode(event)\n    end\n  rescue\n  end\nend\ngz.close\n</code></pre>\n\nThis can be run locally in hours or as a Hadoop streaming job in minutes. It will produce one large JSON file. Next, we split that file using <a href=\"https://github.com/rjurney/github-explorer/blob/master/split_events.pig\">split_events.pig</a>.\n\n<pre><code>github_events = load '/tmp/newline.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\nSPLIT github_events INTO CommitCommentEvent IF $0#'type' == 'CommitCommentEvent',\n                         CreateEvent IF $0#'type'        == 'CreateEvent',\n                         DeleteEvent IF $0#'type'        == 'DeleteEvent',\n                         DownloadEvent IF $0#'type'      == 'DownloadEvent',\n                         FollowEvent IF $0#'type'        == 'FollowEvent',\n                         ForkEvent IF $0#'type'          == 'ForkEvent',\n                         ForkApplyEvent IF $0#'type'     == 'ForkApplyEvent',\n                         GistEvent IF $0#'type'          == 'GistEvent',\n                         GollumEvent IF $0#'type'        == 'GollumEvent',\n                         IssueCommentEvent IF $0#'type'  == 'IssueCommentEvent',\n                         IssuesEvent IF $0#'type'        == 'IssuesEvent',\n                         MemberEvent IF $0#'type'        == 'MemberEvent',\n                         PublicEvent IF $0#'type'        == 'Public Event',\n                         PullRequestEvent IF $0#'type'   == 'PullRequestEvent',\n                         PullRequestReviewCommentEvent IF $0#'type' == 'PullRequestReviewCommentEvent',\n                         PushEvent IF $0#'type'          == 'PushEvent',\n                         TeamAddEvent IF $0#'type'       == 'TeamAddEvent',\n                         WatchEvent IF $0#'type'         == 'WatchEvent';</code></pre>\n\n<p>This data is now split into 18 different files, ranging from megabytes to gigabytes, which can be joined together as needed. At this point the data is still within the capabilities of Pig&rsquo;s local mode, <code>pig -l /tmp -x local</code> to process the data, so you can begin experimenting locally. In my own case, the data quickly balooned to nearly 1TB, necessitating uploading the split data to S3 and continuing my analysis using Hadoop via Elastic MapReduce.</p>\n\n<p>In the next post, we&rsquo;ll look at what these 18 different event types have to offer.</p>", "liked": false, "followed": false, "reblog_key": "Bo9R5vME", "reblog": {"comment": "<p>The Github Archive is a rich dataset available to all via <a href=\"http://www.githubarchive.org/\">githubarchive.org</a>. In this post we will download and create relations from the github archive.</p> \n\n<p>Instructions for downloading it are available on that site, but don\u2019t work well with the version of Bash included with some versions of Mac OS X. To download the github data, I created a ruby script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/get_all_data.rb\">get_all_data.rb</a> which will do the job.</p>\n\n<pre><code>def prepend(number)\n  return number &lt;= 9 ? (\"0\" + number.to_s) : number.to_s\nend\n\nfor year in ['11', '12', '13'] do\n  for month in (1..12) do\n    month = prepend(month)\n    for day in (1..31) do\n      day = prepend(day)\n      unless File.exist?(\"data/20#{year}-#{month}-#{day}-23.json.gz\")\n        system \"wget -P data/ <a href=\"http://data.githubarchive.org/20#%7Byear%7D-#%7Bmonth%7D-#%7Bday%7D-%7B0..24%7D.json.gz\">http://data.githubarchive.org/20#{year}-#{month}-#{day}-{0..24}.json.gz</a>\"\n      else\n        puts \"Skipped file...\\n\\n\\n\"\n      end\n    end\n  end\nend\n</code></pre>\n\n<p>That script will produce 8,760 gzip files per year - 24 for each hour per day * 365 days. In my own experiments, I work with the data between 2012 and present day, which is about 90GB uncompressed json. Unzipped, the files contain a list of JSON objects that describe 18 event types, delineated by the common field, \u2018type.\u2019 This type field can be used to split the data into 18 relations of like-formatted records. Splitting records this way is a common step for processing this data, and is therefore best split out in a pre-processing step for efficiency\u2019s sake. We\u2019ll use Apache Pig to split our data into relations.</p>\n\n<p>From the <a href=\"http://pig.apache.org/\">Apache Pig site</a>:\n\n<i>Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. The salient property of Pig programs is that their structure is amenable to substantial parallelization, which in turns enables them to handle very large data sets.</i></p>\n\n<p>Pig lets us define dataflows to query any data, large or small. We can load JSON records into Pig maps using the <a href=\"https://github.com/kevinweil/elephant-bird\">elephant-bird project\u2019s</a> <a href=\"https://github.com/kevinweil/elephant-bird/blob/master/pig/src/main/java/com/twitter/elephantbird/pig/load/JsonLoader.java\">JsonLoader</a>. To get Pig to parse these records though, we need a carriage return after each one instead of a Javascript array of objects. To achieve this, I created a simple script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/newline_format.rb\">newline_format.rb</a> based on the githubarchive example. It is simple:\n\n</p><pre><code>require 'rubygems'\nrequire 'zlib'\nrequire 'yajl'\n \nDir.glob('data/*.json.gz').each do |f|\n  begin\n    gz = open(f)\n    js = Zlib::GzipReader.new(gz).read\n \n    Yajl::Parser.parse(js) do |event|\n      puts Yajl::Encoder.encode(event)\n    end\n  rescue\n  end\nend\ngz.close\n</code></pre>\n\nThis can be run locally in hours or as a Hadoop streaming job in minutes. It will produce one large JSON file. Next, we split that file using <a href=\"https://github.com/rjurney/github-explorer/blob/master/split_events.pig\">split_events.pig</a>.\n\n<pre><code>github_events = load '/tmp/newline.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\nSPLIT github_events INTO CommitCommentEvent IF $0#'type' == 'CommitCommentEvent',\n                         CreateEvent IF $0#'type'        == 'CreateEvent',\n                         DeleteEvent IF $0#'type'        == 'DeleteEvent',\n                         DownloadEvent IF $0#'type'      == 'DownloadEvent',\n                         FollowEvent IF $0#'type'        == 'FollowEvent',\n                         ForkEvent IF $0#'type'          == 'ForkEvent',\n                         ForkApplyEvent IF $0#'type'     == 'ForkApplyEvent',\n                         GistEvent IF $0#'type'          == 'GistEvent',\n                         GollumEvent IF $0#'type'        == 'GollumEvent',\n                         IssueCommentEvent IF $0#'type'  == 'IssueCommentEvent',\n                         IssuesEvent IF $0#'type'        == 'IssuesEvent',\n                         MemberEvent IF $0#'type'        == 'MemberEvent',\n                         PublicEvent IF $0#'type'        == 'Public Event',\n                         PullRequestEvent IF $0#'type'   == 'PullRequestEvent',\n                         PullRequestReviewCommentEvent IF $0#'type' == 'PullRequestReviewCommentEvent',\n                         PushEvent IF $0#'type'          == 'PushEvent',\n                         TeamAddEvent IF $0#'type'       == 'TeamAddEvent',\n                         WatchEvent IF $0#'type'         == 'WatchEvent';</code></pre>\n\n<p>This data is now split into 18 different files, ranging from megabytes to gigabytes, which can be joined together as needed. At this point the data is still within the capabilities of Pig\u2019s local mode, <code>pig -l /tmp -x local</code> to process the data, so you can begin experimenting locally. In my own case, the data quickly balooned to nearly 1TB, necessitating uploading the split data to S3 and continuing my analysis using Hadoop via Elastic MapReduce.</p>\n\n<p>In the next post, we\u2019ll look at what these 18 different event types have to offer.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 51657080886, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Downloading and Processing the Github Data", "tags": [], "post_url": "http://datasyndrome.com/post/51657080886/downloading-and-processing-the-github-data", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5ym7080s", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1369852500, "note_count": 3, "trail": [{"content": "<p>The Github Archive is a rich dataset available to all via <a href=\"http://www.githubarchive.org/\">githubarchive.org</a>. In this post we will download and create relations from the github archive.</p> \n\n<p>Instructions for downloading it are available on that site, but don&rsquo;t work well with the version of Bash included with some versions of Mac OS X. To download the github data, I created a ruby script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/get_all_data.rb\">get_all_data.rb</a> which will do the job.</p>\n\n<pre><code>def prepend(number)\n  return number &lt;= 9 ? (\"0\" + number.to_s) : number.to_s\nend\n\nfor year in ['11', '12', '13'] do\n  for month in (1..12) do\n    month = prepend(month)\n    for day in (1..31) do\n      day = prepend(day)\n      unless File.exist?(\"data/20#{year}-#{month}-#{day}-23.json.gz\")\n        system \"wget -P data/ <a href=\"http://data.githubarchive.org/20#%7Byear%7D-#%7Bmonth%7D-#%7Bday%7D-%7B0..24%7D.json.gz\">http://data.githubarchive.org/20#{year}-#{month}-#{day}-{0..24}.json.gz</a>\"\n      else\n        puts \"Skipped file...\\n\\n\\n\"\n      end\n    end\n  end\nend\n</code></pre>\n\n<p>That script will produce 8,760 gzip files per year - 24 for each hour per day * 365 days. In my own experiments, I work with the data between 2012 and present day, which is about 90GB uncompressed json. Unzipped, the files contain a list of JSON objects that describe 18 event types, delineated by the common field, &lsquo;type.&rsquo; This type field can be used to split the data into 18 relations of like-formatted records. Splitting records this way is a common step for processing this data, and is therefore best split out in a pre-processing step for efficiency&rsquo;s sake. We&rsquo;ll use Apache Pig to split our data into relations.</p>\n\n<p>From the <a href=\"http://pig.apache.org/\">Apache Pig site</a>:\n\n<i>Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. The salient property of Pig programs is that their structure is amenable to substantial parallelization, which in turns enables them to handle very large data sets.</i></p>\n\n<p>Pig lets us define dataflows to query any data, large or small. We can load JSON records into Pig maps using the <a href=\"https://github.com/kevinweil/elephant-bird\">elephant-bird project&rsquo;s</a> <a href=\"https://github.com/kevinweil/elephant-bird/blob/master/pig/src/main/java/com/twitter/elephantbird/pig/load/JsonLoader.java\">JsonLoader</a>. To get Pig to parse these records though, we need a carriage return after each one instead of a Javascript array of objects. To achieve this, I created a simple script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/newline_format.rb\">newline_format.rb</a> based on the githubarchive example. It is simple:\n\n</p><pre><code>require 'rubygems'\nrequire 'zlib'\nrequire 'yajl'\n \nDir.glob('data/*.json.gz').each do |f|\n  begin\n    gz = open(f)\n    js = Zlib::GzipReader.new(gz).read\n \n    Yajl::Parser.parse(js) do |event|\n      puts Yajl::Encoder.encode(event)\n    end\n  rescue\n  end\nend\ngz.close\n</code></pre>\n\nThis can be run locally in hours or as a Hadoop streaming job in minutes. It will produce one large JSON file. Next, we split that file using <a href=\"https://github.com/rjurney/github-explorer/blob/master/split_events.pig\">split_events.pig</a>.\n\n<pre><code>github_events = load '/tmp/newline.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\nSPLIT github_events INTO CommitCommentEvent IF $0#'type' == 'CommitCommentEvent',\n                         CreateEvent IF $0#'type'        == 'CreateEvent',\n                         DeleteEvent IF $0#'type'        == 'DeleteEvent',\n                         DownloadEvent IF $0#'type'      == 'DownloadEvent',\n                         FollowEvent IF $0#'type'        == 'FollowEvent',\n                         ForkEvent IF $0#'type'          == 'ForkEvent',\n                         ForkApplyEvent IF $0#'type'     == 'ForkApplyEvent',\n                         GistEvent IF $0#'type'          == 'GistEvent',\n                         GollumEvent IF $0#'type'        == 'GollumEvent',\n                         IssueCommentEvent IF $0#'type'  == 'IssueCommentEvent',\n                         IssuesEvent IF $0#'type'        == 'IssuesEvent',\n                         MemberEvent IF $0#'type'        == 'MemberEvent',\n                         PublicEvent IF $0#'type'        == 'Public Event',\n                         PullRequestEvent IF $0#'type'   == 'PullRequestEvent',\n                         PullRequestReviewCommentEvent IF $0#'type' == 'PullRequestReviewCommentEvent',\n                         PushEvent IF $0#'type'          == 'PushEvent',\n                         TeamAddEvent IF $0#'type'       == 'TeamAddEvent',\n                         WatchEvent IF $0#'type'         == 'WatchEvent';</code></pre>\n\n<p>This data is now split into 18 different files, ranging from megabytes to gigabytes, which can be joined together as needed. At this point the data is still within the capabilities of Pig&rsquo;s local mode, <code>pig -l /tmp -x local</code> to process the data, so you can begin experimenting locally. In my own case, the data quickly balooned to nearly 1TB, necessitating uploading the split data to S3 and continuing my analysis using Hadoop via Elastic MapReduce.</p>\n\n<p>In the next post, we&rsquo;ll look at what these 18 different event types have to offer.</p>", "content_raw": "<p>The Github Archive is a rich dataset available to all via <a href=\"http://www.githubarchive.org/\">githubarchive.org</a>. In this post we will download and create relations from the github archive.</p> \n\n<p>Instructions for downloading it are available on that site, but don\u2019t work well with the version of Bash included with some versions of Mac OS X. To download the github data, I created a ruby script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/get_all_data.rb\">get_all_data.rb</a> which will do the job.</p>\n\n<pre><code>def prepend(number)\n  return number &lt;= 9 ? (\"0\" + number.to_s) : number.to_s\nend\n\nfor year in ['11', '12', '13'] do\n  for month in (1..12) do\n    month = prepend(month)\n    for day in (1..31) do\n      day = prepend(day)\n      unless File.exist?(\"data/20#{year}-#{month}-#{day}-23.json.gz\")\n        system \"wget -P data/ <a href=\"http://data.githubarchive.org/20#%7Byear%7D-#%7Bmonth%7D-#%7Bday%7D-%7B0..24%7D.json.gz\">http://data.githubarchive.org/20#{year}-#{month}-#{day}-{0..24}.json.gz</a>\"\n      else\n        puts \"Skipped file...\\n\\n\\n\"\n      end\n    end\n  end\nend\n</code></pre>\n\n<p>That script will produce 8,760 gzip files per year - 24 for each hour per day * 365 days. In my own experiments, I work with the data between 2012 and present day, which is about 90GB uncompressed json. Unzipped, the files contain a list of JSON objects that describe 18 event types, delineated by the common field, \u2018type.\u2019 This type field can be used to split the data into 18 relations of like-formatted records. Splitting records this way is a common step for processing this data, and is therefore best split out in a pre-processing step for efficiency\u2019s sake. We\u2019ll use Apache Pig to split our data into relations.</p>\n\n<p>From the <a href=\"http://pig.apache.org/\">Apache Pig site</a>:\n\n<i>Apache Pig is a platform for analyzing large data sets that consists of a high-level language for expressing data analysis programs, coupled with infrastructure for evaluating these programs. The salient property of Pig programs is that their structure is amenable to substantial parallelization, which in turns enables them to handle very large data sets.</i></p>\n\n<p>Pig lets us define dataflows to query any data, large or small. We can load JSON records into Pig maps using the <a href=\"https://github.com/kevinweil/elephant-bird\">elephant-bird project\u2019s</a> <a href=\"https://github.com/kevinweil/elephant-bird/blob/master/pig/src/main/java/com/twitter/elephantbird/pig/load/JsonLoader.java\">JsonLoader</a>. To get Pig to parse these records though, we need a carriage return after each one instead of a Javascript array of objects. To achieve this, I created a simple script called <a href=\"https://github.com/rjurney/github-explorer/blob/master/newline_format.rb\">newline_format.rb</a> based on the githubarchive example. It is simple:\n\n</p><pre><code>require 'rubygems'\nrequire 'zlib'\nrequire 'yajl'\n \nDir.glob('data/*.json.gz').each do |f|\n  begin\n    gz = open(f)\n    js = Zlib::GzipReader.new(gz).read\n \n    Yajl::Parser.parse(js) do |event|\n      puts Yajl::Encoder.encode(event)\n    end\n  rescue\n  end\nend\ngz.close\n</code></pre>\n\nThis can be run locally in hours or as a Hadoop streaming job in minutes. It will produce one large JSON file. Next, we split that file using <a href=\"https://github.com/rjurney/github-explorer/blob/master/split_events.pig\">split_events.pig</a>.\n\n<pre><code>github_events = load '/tmp/newline.json' using com.twitter.elephantbird.pig.load.JsonLoader() as json:map[];\n\nSPLIT github_events INTO CommitCommentEvent IF $0#'type' == 'CommitCommentEvent',\n                         CreateEvent IF $0#'type'        == 'CreateEvent',\n                         DeleteEvent IF $0#'type'        == 'DeleteEvent',\n                         DownloadEvent IF $0#'type'      == 'DownloadEvent',\n                         FollowEvent IF $0#'type'        == 'FollowEvent',\n                         ForkEvent IF $0#'type'          == 'ForkEvent',\n                         ForkApplyEvent IF $0#'type'     == 'ForkApplyEvent',\n                         GistEvent IF $0#'type'          == 'GistEvent',\n                         GollumEvent IF $0#'type'        == 'GollumEvent',\n                         IssueCommentEvent IF $0#'type'  == 'IssueCommentEvent',\n                         IssuesEvent IF $0#'type'        == 'IssuesEvent',\n                         MemberEvent IF $0#'type'        == 'MemberEvent',\n                         PublicEvent IF $0#'type'        == 'Public Event',\n                         PullRequestEvent IF $0#'type'   == 'PullRequestEvent',\n                         PullRequestReviewCommentEvent IF $0#'type' == 'PullRequestReviewCommentEvent',\n                         PushEvent IF $0#'type'          == 'PushEvent',\n                         TeamAddEvent IF $0#'type'       == 'TeamAddEvent',\n                         WatchEvent IF $0#'type'         == 'WatchEvent';</code></pre>\n\n<p>This data is now split into 18 different files, ranging from megabytes to gigabytes, which can be joined together as needed. At this point the data is still within the capabilities of Pig\u2019s local mode, <code>pig -l /tmp -x local</code> to process the data, so you can begin experimenting locally. In my own case, the data quickly balooned to nearly 1TB, necessitating uploading the split data to S3 and continuing my analysis using Hadoop via Elastic MapReduce.</p>\n\n<p>In the next post, we\u2019ll look at what these 18 different event types have to offer.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51657080886"}}], "date": "2013-05-29 18:35:00 GMT", "slug": "downloading-and-processing-the-github-data", "blog_name": "rjurney", "summary": "Downloading and Processing the Github Data", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "Ve7E9w6q", "short_url": "https://tmblr.co/ZbIO5ym2OpMM", "can_send_in_message": true, "id": 51579663766, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51579663766", "tags": [], "post_url": "http://datasyndrome.com/post/51579663766/super-nice-outside-at-samovar-tea-lounge", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Super nice outside (at Samovar Tea Lounge)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369770805, "note_count": 0, "trail": [{"content": "<p>Super nice outside (at Samovar Tea Lounge)</p>", "content_raw": "<p>Super nice outside (at Samovar Tea Lounge)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51579663766"}}], "date": "2013-05-28 19:53:25 GMT", "slug": "super-nice-outside-at-samovar-tea-lounge", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/c682c24f70a882535f01b885dee23215/tumblr_mnixx2CFn11qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/c682c24f70a882535f01b885dee23215/tumblr_mnixx2CFn11qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/c682c24f70a882535f01b885dee23215/tumblr_mnixx2CFn11qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/c682c24f70a882535f01b885dee23215/tumblr_mnixx2CFn11qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/c682c24f70a882535f01b885dee23215/tumblr_mnixx2CFn11qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/c682c24f70a882535f01b885dee23215/tumblr_mnixx2CFn11qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/c682c24f70a882535f01b885dee23215/tumblr_mnixx2CFn11qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z3iqICRT0t/", "summary": "Super nice outside (at Samovar Tea Lounge)", "caption": "<p>Super nice outside (at Samovar Tea Lounge)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "HbDPHToQ", "short_url": "https://tmblr.co/ZbIO5yl_So8e", "can_send_in_message": true, "id": 51513598504, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51513598504", "tags": [], "post_url": "http://datasyndrome.com/post/51513598504/dinner-with-brother-and-dad-at-the-stinking-rose", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Dinner with brother and dad (at The Stinking Rose)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369697602, "note_count": 0, "trail": [{"content": "<p>Dinner with brother and dad (at The Stinking Rose)</p>", "content_raw": "<p>Dinner with brother and dad (at The Stinking Rose)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51513598504"}}], "date": "2013-05-27 23:33:22 GMT", "slug": "dinner-with-brother-and-dad-at-the-stinking-rose", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/b1a91da58b8788d70df20ff814ae73d8/tumblr_mnhdfm9hwX1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/b1a91da58b8788d70df20ff814ae73d8/tumblr_mnhdfm9hwX1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/b1a91da58b8788d70df20ff814ae73d8/tumblr_mnhdfm9hwX1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/b1a91da58b8788d70df20ff814ae73d8/tumblr_mnhdfm9hwX1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/b1a91da58b8788d70df20ff814ae73d8/tumblr_mnhdfm9hwX1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/b1a91da58b8788d70df20ff814ae73d8/tumblr_mnhdfm9hwX1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/b1a91da58b8788d70df20ff814ae73d8/tumblr_mnhdfm9hwX1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1W9pUxTxP/", "summary": "Dinner with brother and dad (at The Stinking Rose)", "caption": "<p>Dinner with brother and dad (at The Stinking Rose)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "bOCC8bMj", "short_url": "https://tmblr.co/ZbIO5yl_C7gM", "can_send_in_message": true, "id": 51509230230, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51509230230", "tags": [], "post_url": "http://datasyndrome.com/post/51509230230/almost-too-fat-for-the-cray-at-computer-history", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Almost too fat for the cray (at Computer History Museum)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369694094, "note_count": 0, "trail": [{"content": "<p>Almost too fat for the cray (at Computer History Museum)</p>", "content_raw": "<p>Almost too fat for the cray (at Computer History Museum)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51509230230"}}], "date": "2013-05-27 22:34:54 GMT", "slug": "almost-too-fat-for-the-cray-at-computer-history", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/8e3ef19e0fa619ad8b2f1c0f429c5fc6/tumblr_mnhaq6xyTC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/8e3ef19e0fa619ad8b2f1c0f429c5fc6/tumblr_mnhaq6xyTC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/8e3ef19e0fa619ad8b2f1c0f429c5fc6/tumblr_mnhaq6xyTC1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/8e3ef19e0fa619ad8b2f1c0f429c5fc6/tumblr_mnhaq6xyTC1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/8e3ef19e0fa619ad8b2f1c0f429c5fc6/tumblr_mnhaq6xyTC1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/8e3ef19e0fa619ad8b2f1c0f429c5fc6/tumblr_mnhaq6xyTC1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/8e3ef19e0fa619ad8b2f1c0f429c5fc6/tumblr_mnhaq6xyTC1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1QT6zxT3f/", "summary": "Almost too fat for the cray (at Computer History Museum)", "caption": "<p>Almost too fat for the cray (at Computer History Museum)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "cSq4xMLy", "short_url": "https://tmblr.co/ZbIO5yl_Bahc", "can_send_in_message": true, "id": 51509086950, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51509086950", "tags": [], "post_url": "http://datasyndrome.com/post/51509086950/google-earth-explorer-at-computer-history-museum", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Google Earth explorer (at Computer History Museum)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369693979, "note_count": 0, "trail": [{"content": "<p>Google Earth explorer (at Computer History Museum)</p>", "content_raw": "<p>Google Earth explorer (at Computer History Museum)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51509086950"}}], "date": "2013-05-27 22:32:59 GMT", "slug": "google-earth-explorer-at-computer-history-museum", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/130c3cf47a753e9b27797425a5663cf4/tumblr_mnhamzKKve1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/130c3cf47a753e9b27797425a5663cf4/tumblr_mnhamzKKve1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/130c3cf47a753e9b27797425a5663cf4/tumblr_mnhamzKKve1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/130c3cf47a753e9b27797425a5663cf4/tumblr_mnhamzKKve1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/130c3cf47a753e9b27797425a5663cf4/tumblr_mnhamzKKve1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/130c3cf47a753e9b27797425a5663cf4/tumblr_mnhamzKKve1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/130c3cf47a753e9b27797425a5663cf4/tumblr_mnhamzKKve1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1QIecxT3F/", "summary": "Google Earth explorer (at Computer History Museum)", "caption": "<p>Google Earth explorer (at Computer History Museum)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "ahgM1mYq", "short_url": "https://tmblr.co/ZbIO5yl_4dJD", "can_send_in_message": true, "id": 51507262669, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51507262669", "tags": [], "post_url": "http://datasyndrome.com/post/51507262669/cyberpunk-book-at-computer-history-museum", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Cyberpunk book (at Computer History Museum)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369692536, "note_count": 0, "trail": [{"content": "<p>Cyberpunk book (at Computer History Museum)</p>", "content_raw": "<p>Cyberpunk book (at Computer History Museum)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51507262669"}}], "date": "2013-05-27 22:08:56 GMT", "slug": "cyberpunk-book-at-computer-history-museum", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/44748c549b8e6b70ccb689bacc287852/tumblr_mnh9iwjY331qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/44748c549b8e6b70ccb689bacc287852/tumblr_mnh9iwjY331qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/44748c549b8e6b70ccb689bacc287852/tumblr_mnh9iwjY331qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/44748c549b8e6b70ccb689bacc287852/tumblr_mnh9iwjY331qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/44748c549b8e6b70ccb689bacc287852/tumblr_mnh9iwjY331qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/44748c549b8e6b70ccb689bacc287852/tumblr_mnh9iwjY331qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/44748c549b8e6b70ccb689bacc287852/tumblr_mnh9iwjY331qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1NYVIxTzK/", "summary": "Cyberpunk book (at Computer History Museum)", "caption": "<p>Cyberpunk book (at Computer History Museum)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "TM4n9TXz", "short_url": "https://tmblr.co/ZbIO5ylz_dio", "can_send_in_message": true, "id": 51505691442, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51505691442", "tags": [], "post_url": "http://datasyndrome.com/post/51505691442/cray-1-at-computer-history-museum", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Cray-1 (at Computer History Museum)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369691305, "note_count": 1, "trail": [{"content": "<p>Cray-1 (at Computer History Museum)</p>", "content_raw": "<p>Cray-1 (at Computer History Museum)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51505691442"}}], "date": "2013-05-27 21:48:25 GMT", "slug": "cray-1-at-computer-history-museum", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/3791a072c1cf779250c10a28a911379f/tumblr_mnh8kqdbJ21qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/3791a072c1cf779250c10a28a911379f/tumblr_mnh8kqdbJ21qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/3791a072c1cf779250c10a28a911379f/tumblr_mnh8kqdbJ21qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/3791a072c1cf779250c10a28a911379f/tumblr_mnh8kqdbJ21qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/3791a072c1cf779250c10a28a911379f/tumblr_mnh8kqdbJ21qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/3791a072c1cf779250c10a28a911379f/tumblr_mnh8kqdbJ21qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/3791a072c1cf779250c10a28a911379f/tumblr_mnh8kqdbJ21qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1LCNUxT_Y/", "summary": "Cray-1 (at Computer History Museum)", "caption": "<p>Cray-1 (at Computer History Museum)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "N1raaltS", "short_url": "https://tmblr.co/ZbIO5ylzwwu8", "can_send_in_message": true, "id": 51504721416, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51504721416", "tags": [], "post_url": "http://datasyndrome.com/post/51504721416/near-and-dear-to-my-heart-at-computer-history", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Near and dear to my heart (at Computer History Museum)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369690540, "note_count": 0, "trail": [{"content": "<p>Near and dear to my heart (at Computer History Museum)</p>", "content_raw": "<p>Near and dear to my heart (at Computer History Museum)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51504721416"}}], "date": "2013-05-27 21:35:40 GMT", "slug": "near-and-dear-to-my-heart-at-computer-history", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/8709da82502949cfeda94f251a2deef3/tumblr_mnh7zgD7qC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/8709da82502949cfeda94f251a2deef3/tumblr_mnh7zgD7qC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/8709da82502949cfeda94f251a2deef3/tumblr_mnh7zgD7qC1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/8709da82502949cfeda94f251a2deef3/tumblr_mnh7zgD7qC1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/8709da82502949cfeda94f251a2deef3/tumblr_mnh7zgD7qC1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/8709da82502949cfeda94f251a2deef3/tumblr_mnh7zgD7qC1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/8709da82502949cfeda94f251a2deef3/tumblr_mnh7zgD7qC1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1JlTsRT9M/", "summary": "Near and dear to my heart (at Computer History Museum)", "caption": "<p>Near and dear to my heart (at Computer History Museum)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "ZohH5UUw", "short_url": "https://tmblr.co/ZbIO5ylzv_pN", "can_send_in_message": true, "id": 51504475351, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51504475351", "tags": [], "post_url": "http://datasyndrome.com/post/51504475351/sage-duck-hunter-nuclear-war-at-computer-history", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>SAGE duck hunter nuclear war (at Computer History Museum)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369690348, "note_count": 0, "trail": [{"content": "<p>SAGE duck hunter nuclear war (at Computer History Museum)</p>", "content_raw": "<p>SAGE duck hunter nuclear war (at Computer History Museum)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51504475351"}}], "date": "2013-05-27 21:32:28 GMT", "slug": "sage-duck-hunter-nuclear-war-at-computer-history", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/c1d2f55d149a4b26a0e117dfe7791f47/tumblr_mnh7u5BtKn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/c1d2f55d149a4b26a0e117dfe7791f47/tumblr_mnh7u5BtKn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/c1d2f55d149a4b26a0e117dfe7791f47/tumblr_mnh7u5BtKn1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/c1d2f55d149a4b26a0e117dfe7791f47/tumblr_mnh7u5BtKn1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/c1d2f55d149a4b26a0e117dfe7791f47/tumblr_mnh7u5BtKn1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/c1d2f55d149a4b26a0e117dfe7791f47/tumblr_mnh7u5BtKn1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/c1d2f55d149a4b26a0e117dfe7791f47/tumblr_mnh7u5BtKn1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1JMRYxT8d/", "summary": "SAGE duck hunter nuclear war (at Computer History Museum)", "caption": "<p>SAGE duck hunter nuclear war (at Computer History Museum)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "oLwWw17J", "short_url": "https://tmblr.co/ZbIO5ylzsoCD", "can_send_in_message": true, "id": 51503637261, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/51503637261", "tags": [], "post_url": "http://datasyndrome.com/post/51503637261/eniac-floorplan-at-computer-history-museum", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>ENIAC floorplan (at Computer History Museum)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1369689702, "note_count": 0, "trail": [{"content": "<p>ENIAC floorplan (at Computer History Museum)</p>", "content_raw": "<p>ENIAC floorplan (at Computer History Museum)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "51503637261"}}], "date": "2013-05-27 21:21:42 GMT", "slug": "eniac-floorplan-at-computer-history-museum", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/a364f9f3d365890d4868c81d3f7c706f/tumblr_mnh7c6eMtJ1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/a364f9f3d365890d4868c81d3f7c706f/tumblr_mnh7c6eMtJ1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/a364f9f3d365890d4868c81d3f7c706f/tumblr_mnh7c6eMtJ1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/a364f9f3d365890d4868c81d3f7c706f/tumblr_mnh7c6eMtJ1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/a364f9f3d365890d4868c81d3f7c706f/tumblr_mnh7c6eMtJ1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/a364f9f3d365890d4868c81d3f7c706f/tumblr_mnh7c6eMtJ1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/a364f9f3d365890d4868c81d3f7c706f/tumblr_mnh7c6eMtJ1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Z1H7evRT6c/", "summary": "ENIAC floorplan (at Computer History Museum)", "caption": "<p>ENIAC floorplan (at Computer History Museum)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "sL1GCb2T", "short_url": "https://tmblr.co/ZbIO5ylE0pZB", "can_send_in_message": true, "id": 50700957899, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/50700957899", "tags": [], "post_url": "http://datasyndrome.com/post/50700957899/new-book-recommender-systems-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>New book: Recommender systems (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1368847049, "note_count": 2, "trail": [{"content": "<p>New book: Recommender systems (at Manor Beach)</p>", "content_raw": "<p>New book: Recommender systems (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "50700957899"}}], "date": "2013-05-18 03:17:29 GMT", "slug": "new-book-recommender-systems-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/f0d62c7724d49e6c28996f46d8846c16/tumblr_mmz555PWOD1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/f0d62c7724d49e6c28996f46d8846c16/tumblr_mmz555PWOD1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/f0d62c7724d49e6c28996f46d8846c16/tumblr_mmz555PWOD1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/f0d62c7724d49e6c28996f46d8846c16/tumblr_mmz555PWOD1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/f0d62c7724d49e6c28996f46d8846c16/tumblr_mmz555PWOD1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/f0d62c7724d49e6c28996f46d8846c16/tumblr_mmz555PWOD1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/f0d62c7724d49e6c28996f46d8846c16/tumblr_mmz555PWOD1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/ZcAuPGRT5w/", "summary": "New book: Recommender systems (at Manor Beach)", "caption": "<p>New book: Recommender systems (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "RYy3rtNg", "short_url": "https://tmblr.co/ZbIO5ykZbop4", "can_send_in_message": true, "id": 49989233860, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/49989233860", "tags": [], "post_url": "http://datasyndrome.com/post/49989233860/presenting-agile-big-data-at-bluekai", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Presenting Agile Big Data at BlueKai</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1368071236, "note_count": 0, "trail": [{"content": "<p>Presenting Agile Big Data at BlueKai</p>", "content_raw": "<p>Presenting Agile Big Data at BlueKai</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "49989233860"}}], "date": "2013-05-09 03:47:16 GMT", "slug": "presenting-agile-big-data-at-bluekai", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/2b3b62c0b21414622963d2e8bfed894a/tumblr_mmiiisGrkM1qe7pymo1_1280.jpg", "width": 1024, "height": 1365}, "alt_sizes": [{"url": "https://68.media.tumblr.com/2b3b62c0b21414622963d2e8bfed894a/tumblr_mmiiisGrkM1qe7pymo1_1280.jpg", "width": 1024, "height": 1365}, {"url": "https://68.media.tumblr.com/2b3b62c0b21414622963d2e8bfed894a/tumblr_mmiiisGrkM1qe7pymo1_500.jpg", "width": 500, "height": 667}, {"url": "https://68.media.tumblr.com/2b3b62c0b21414622963d2e8bfed894a/tumblr_mmiiisGrkM1qe7pymo1_400.jpg", "width": 400, "height": 533}, {"url": "https://68.media.tumblr.com/2b3b62c0b21414622963d2e8bfed894a/tumblr_mmiiisGrkM1qe7pymo1_250.jpg", "width": 250, "height": 333}, {"url": "https://68.media.tumblr.com/2b3b62c0b21414622963d2e8bfed894a/tumblr_mmiiisGrkM1qe7pymo1_100.jpg", "width": 100, "height": 133}, {"url": "https://68.media.tumblr.com/2b3b62c0b21414622963d2e8bfed894a/tumblr_mmiiisGrkM1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "summary": "Presenting Agile Big Data at BlueKai", "caption": "<p>Presenting Agile Big Data at BlueKai</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "vWRQv4LK", "short_url": "https://tmblr.co/ZbIO5ykKpzWk", "can_send_in_message": true, "id": 49741289518, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/49741289518", "tags": [], "post_url": "http://datasyndrome.com/post/49741289518/aerogarden-first-harvest-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Aerogarden first harvest (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1367806037, "note_count": 0, "trail": [{"content": "<p>Aerogarden first harvest (at Manor Beach)</p>", "content_raw": "<p>Aerogarden first harvest (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "49741289518"}}], "date": "2013-05-06 02:07:17 GMT", "slug": "aerogarden-first-harvest-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/e19c555512867fd72aad5e8ce07a1655/tumblr_mmctw62OAQ1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/e19c555512867fd72aad5e8ce07a1655/tumblr_mmctw62OAQ1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/e19c555512867fd72aad5e8ce07a1655/tumblr_mmctw62OAQ1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/e19c555512867fd72aad5e8ce07a1655/tumblr_mmctw62OAQ1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/e19c555512867fd72aad5e8ce07a1655/tumblr_mmctw62OAQ1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/e19c555512867fd72aad5e8ce07a1655/tumblr_mmctw62OAQ1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/e19c555512867fd72aad5e8ce07a1655/tumblr_mmctw62OAQ1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Y8_FLqxT2C/", "summary": "Aerogarden first harvest (at Manor Beach)", "caption": "<p>Aerogarden first harvest (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "bgi9K9jO", "short_url": "https://tmblr.co/ZbIO5yio4qju", "can_send_in_message": true, "id": 48084765560, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/48084765560", "tags": [], "post_url": "http://datasyndrome.com/post/48084765560/windy-at-moss-beach-distillery", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Windy (at Moss Beach Distillery)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1366074603, "note_count": 1, "trail": [{"content": "<p>Windy (at Moss Beach Distillery)</p>", "content_raw": "<p>Windy (at Moss Beach Distillery)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "48084765560"}}], "date": "2013-04-16 01:10:03 GMT", "slug": "windy-at-moss-beach-distillery", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/9a4bd05cb126401a8d2cb1caa5879d13/tumblr_mlbpwrTQE11qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/9a4bd05cb126401a8d2cb1caa5879d13/tumblr_mlbpwrTQE11qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/9a4bd05cb126401a8d2cb1caa5879d13/tumblr_mlbpwrTQE11qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/9a4bd05cb126401a8d2cb1caa5879d13/tumblr_mlbpwrTQE11qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/9a4bd05cb126401a8d2cb1caa5879d13/tumblr_mlbpwrTQE11qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/9a4bd05cb126401a8d2cb1caa5879d13/tumblr_mlbpwrTQE11qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/9a4bd05cb126401a8d2cb1caa5879d13/tumblr_mlbpwrTQE11qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/YJYwBNRT4y/", "summary": "Windy (at Moss Beach Distillery)", "caption": "<p>Windy (at Moss Beach Distillery)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "WM86MqvK", "short_url": "https://tmblr.co/ZbIO5yieCrh9", "can_send_in_message": true, "id": 47919094473, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/47919094473", "tags": [], "post_url": "http://datasyndrome.com/post/47919094473/jim-jones-house-at-haightashbury", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Jim Jones house (at Haight/Ashbury)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1365907825, "note_count": 0, "trail": [{"content": "<p>Jim Jones house (at Haight/Ashbury)</p>", "content_raw": "<p>Jim Jones house (at Haight/Ashbury)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "47919094473"}}], "date": "2013-04-14 02:50:25 GMT", "slug": "jim-jones-house-at-haightashbury", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/30a49d8f2c8cde9f3b23f000a5ababd9/tumblr_ml85827aTF1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/30a49d8f2c8cde9f3b23f000a5ababd9/tumblr_ml85827aTF1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/30a49d8f2c8cde9f3b23f000a5ababd9/tumblr_ml85827aTF1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/30a49d8f2c8cde9f3b23f000a5ababd9/tumblr_ml85827aTF1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/30a49d8f2c8cde9f3b23f000a5ababd9/tumblr_ml85827aTF1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/30a49d8f2c8cde9f3b23f000a5ababd9/tumblr_ml85827aTF1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/30a49d8f2c8cde9f3b23f000a5ababd9/tumblr_ml85827aTF1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/YEaovPRT_1/", "summary": "Jim Jones house (at Haight/Ashbury)", "caption": "<p>Jim Jones house (at Haight/Ashbury)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "mdhO2N2i", "short_url": "https://tmblr.co/ZbIO5yiS_0tl", "can_send_in_message": true, "id": 47730658799, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/47730658799", "tags": [], "post_url": "http://datasyndrome.com/post/47730658799/here-goes-at-packard-place", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Here goes! (at Packard Place)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1365718477, "note_count": 1, "trail": [{"content": "<p>Here goes! (at Packard Place)</p>", "content_raw": "<p>Here goes! (at Packard Place)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "47730658799"}}], "date": "2013-04-11 22:14:37 GMT", "slug": "here-goes-at-packard-place", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/4b6b967e7a7c9be9e3516a8b3b03fa02/tumblr_ml434fqP6W1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/4b6b967e7a7c9be9e3516a8b3b03fa02/tumblr_ml434fqP6W1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/4b6b967e7a7c9be9e3516a8b3b03fa02/tumblr_ml434fqP6W1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/4b6b967e7a7c9be9e3516a8b3b03fa02/tumblr_ml434fqP6W1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/4b6b967e7a7c9be9e3516a8b3b03fa02/tumblr_ml434fqP6W1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/4b6b967e7a7c9be9e3516a8b3b03fa02/tumblr_ml434fqP6W1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/4b6b967e7a7c9be9e3516a8b3b03fa02/tumblr_ml434fqP6W1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/X-xettxTyl/", "summary": "Here goes! (at Packard Place)", "caption": "<p>Here goes! (at Packard Place)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "oc7k2OqQ", "short_url": "https://tmblr.co/ZbIO5yiSxLLU", "can_send_in_message": true, "id": 47729956190, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/47729956190", "tags": [], "post_url": "http://datasyndrome.com/post/47729956190/charlotte-hadoopers-at-packard-place", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Charlotte Hadoopers (at Packard Place)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1365717933, "note_count": 0, "trail": [{"content": "<p>Charlotte Hadoopers (at Packard Place)</p>", "content_raw": "<p>Charlotte Hadoopers (at Packard Place)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "47729956190"}}], "date": "2013-04-11 22:05:33 GMT", "slug": "charlotte-hadoopers-at-packard-place", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/c0265a62db1d2e4be184831477dd461c/tumblr_ml42paowlC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/c0265a62db1d2e4be184831477dd461c/tumblr_ml42paowlC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/c0265a62db1d2e4be184831477dd461c/tumblr_ml42paowlC1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/c0265a62db1d2e4be184831477dd461c/tumblr_ml42paowlC1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/c0265a62db1d2e4be184831477dd461c/tumblr_ml42paowlC1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/c0265a62db1d2e4be184831477dd461c/tumblr_ml42paowlC1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/c0265a62db1d2e4be184831477dd461c/tumblr_ml42paowlC1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/X-wcGdRTxH/", "summary": "Charlotte Hadoopers (at Packard Place)", "caption": "<p>Charlotte Hadoopers (at Packard Place)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "Hb2AMtMU", "short_url": "https://tmblr.co/ZbIO5yiSp95P", "can_send_in_message": true, "id": 47727808857, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/47727808857", "tags": [], "post_url": "http://datasyndrome.com/post/47727808857/speaking-at-charlottes-entrepreneur-hub-garage", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Speaking at Charlotte\u2019s entrepreneur hub, Garage at Packard Place (at Packard Place)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1365716295, "note_count": 0, "trail": [{"content": "<p>Speaking at Charlotte&rsquo;s entrepreneur hub, Garage at Packard Place (at Packard Place)</p>", "content_raw": "<p>Speaking at Charlotte\u2019s entrepreneur hub, Garage at Packard Place (at Packard Place)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "47727808857"}}], "date": "2013-04-11 21:38:15 GMT", "slug": "speaking-at-charlottes-entrepreneur-hub-garage", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/fb222490d32016bb37578a2aaa91b22f/tumblr_ml41frS7gO1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/fb222490d32016bb37578a2aaa91b22f/tumblr_ml41frS7gO1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/fb222490d32016bb37578a2aaa91b22f/tumblr_ml41frS7gO1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/fb222490d32016bb37578a2aaa91b22f/tumblr_ml41frS7gO1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/fb222490d32016bb37578a2aaa91b22f/tumblr_ml41frS7gO1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/fb222490d32016bb37578a2aaa91b22f/tumblr_ml41frS7gO1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/fb222490d32016bb37578a2aaa91b22f/tumblr_ml41frS7gO1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/X-tNI2xT8K/", "summary": "Speaking at Charlotte's entrepreneur hub, Garage at Packard Place (at Packard Place)", "caption": "<p>Speaking at Charlotte&rsquo;s entrepreneur hub, Garage at Packard Place (at Packard Place)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "8qn3K5zj", "short_url": "https://tmblr.co/ZbIO5yiFzS3J", "can_send_in_message": true, "id": 47512404179, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/47512404179", "tags": [], "post_url": "http://datasyndrome.com/post/47512404179/the-pimp-room-at-github-with-lorennorman-at", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>The pimp room at github with @lorennorman (at GitHub HQ 2.0)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1365477076, "note_count": 1, "trail": [{"content": "<p>The pimp room at github with @lorennorman (at GitHub HQ 2.0)</p>", "content_raw": "<p>The pimp room at github with @lorennorman (at GitHub HQ 2.0)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "47512404179"}}], "date": "2013-04-09 03:11:16 GMT", "slug": "the-pimp-room-at-github-with-lorennorman-at", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/54d0d77c7e54117a7ff1e8456dbe753c/tumblr_mkywuwgoLG1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/54d0d77c7e54117a7ff1e8456dbe753c/tumblr_mkywuwgoLG1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/54d0d77c7e54117a7ff1e8456dbe753c/tumblr_mkywuwgoLG1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/54d0d77c7e54117a7ff1e8456dbe753c/tumblr_mkywuwgoLG1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/54d0d77c7e54117a7ff1e8456dbe753c/tumblr_mkywuwgoLG1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/54d0d77c7e54117a7ff1e8456dbe753c/tumblr_mkywuwgoLG1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/54d0d77c7e54117a7ff1e8456dbe753c/tumblr_mkywuwgoLG1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/X3k4P2RT_V/", "summary": "The pimp room at github with @lorennorman (at GitHub HQ 2.0)", "caption": "<p>The pimp room at github with @lorennorman (at GitHub HQ 2.0)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "zA5mEYTq", "short_url": "https://tmblr.co/ZbIO5yiF66-L", "can_send_in_message": true, "id": 47497899989, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/47497899989", "tags": [], "post_url": "http://datasyndrome.com/post/47497899989/miss-piggie-princess-at-pacific-manor-plaza", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Miss Piggie = Princess (at Pacific Manor Plaza)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1365467219, "note_count": 0, "trail": [{"content": "<p>Miss Piggie = Princess (at Pacific Manor Plaza)</p>", "content_raw": "<p>Miss Piggie = Princess (at Pacific Manor Plaza)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "47497899989"}}], "date": "2013-04-09 00:26:59 GMT", "slug": "miss-piggie-princess-at-pacific-manor-plaza", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/c27e9d0ce7a8113ec6c424dcd6259f1d/tumblr_mkyp8zufCB1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/c27e9d0ce7a8113ec6c424dcd6259f1d/tumblr_mkyp8zufCB1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/c27e9d0ce7a8113ec6c424dcd6259f1d/tumblr_mkyp8zufCB1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/c27e9d0ce7a8113ec6c424dcd6259f1d/tumblr_mkyp8zufCB1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/c27e9d0ce7a8113ec6c424dcd6259f1d/tumblr_mkyp8zufCB1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/c27e9d0ce7a8113ec6c424dcd6259f1d/tumblr_mkyp8zufCB1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/c27e9d0ce7a8113ec6c424dcd6259f1d/tumblr_mkyp8zufCB1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/X3SLfBxT2J/", "summary": "Miss Piggie = Princess (at Pacific Manor Plaza)", "caption": "<p>Miss Piggie = Princess (at Pacific Manor Plaza)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "fDvU2ppb", "short_url": "https://tmblr.co/ZbIO5yhN91JE", "can_send_in_message": true, "id": 46559139022, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/46559139022", "tags": [], "post_url": "http://datasyndrome.com/post/46559139022/x-marks-the-spot-at-the-grassy-knoll", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>X marks the spot (at The Grassy Knoll)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1364524306, "note_count": 0, "trail": [{"content": "<p>X marks the spot (at The Grassy Knoll)</p>", "content_raw": "<p>X marks the spot (at The Grassy Knoll)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "46559139022"}}], "date": "2013-03-29 02:31:46 GMT", "slug": "x-marks-the-spot-at-the-grassy-knoll", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/777c3dd3b92e2a083237817f30ced760/tumblr_mkehoy8MTm1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/777c3dd3b92e2a083237817f30ced760/tumblr_mkehoy8MTm1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/777c3dd3b92e2a083237817f30ced760/tumblr_mkehoy8MTm1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/777c3dd3b92e2a083237817f30ced760/tumblr_mkehoy8MTm1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/777c3dd3b92e2a083237817f30ced760/tumblr_mkehoy8MTm1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/777c3dd3b92e2a083237817f30ced760/tumblr_mkehoy8MTm1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/777c3dd3b92e2a083237817f30ced760/tumblr_mkehoy8MTm1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/XbLw6gxT_q/", "summary": "X marks the spot (at The Grassy Knoll)", "caption": "<p>X marks the spot (at The Grassy Knoll)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "Z6q7zdCA", "short_url": "https://tmblr.co/ZbIO5yhN8Ckk", "can_send_in_message": true, "id": 46558923694, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/46558923694", "tags": [], "post_url": "http://datasyndrome.com/post/46558923694/the-book-depository-at-the-grassy-knoll", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>The book depository (at The Grassy Knoll)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1364524158, "note_count": 0, "trail": [{"content": "<p>The book depository (at The Grassy Knoll)</p>", "content_raw": "<p>The book depository (at The Grassy Knoll)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "46558923694"}}], "date": "2013-03-29 02:29:18 GMT", "slug": "the-book-depository-at-the-grassy-knoll", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/7af05b85a013086fc05264256e73db26/tumblr_mkehkvQ5Ff1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/7af05b85a013086fc05264256e73db26/tumblr_mkehkvQ5Ff1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/7af05b85a013086fc05264256e73db26/tumblr_mkehkvQ5Ff1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/7af05b85a013086fc05264256e73db26/tumblr_mkehkvQ5Ff1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/7af05b85a013086fc05264256e73db26/tumblr_mkehkvQ5Ff1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/7af05b85a013086fc05264256e73db26/tumblr_mkehkvQ5Ff1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/7af05b85a013086fc05264256e73db26/tumblr_mkehkvQ5Ff1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/XbLcmzRT_L/", "summary": "The book depository (at The Grassy Knoll)", "caption": "<p>The book depository (at The Grassy Knoll)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "GLNW8X6k", "short_url": "https://tmblr.co/ZbIO5yhMOXeb", "can_send_in_message": true, "id": 46546426405, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/46546426405", "tags": [], "post_url": "http://datasyndrome.com/post/46546426405/full-house-at-the-dallas-hadoop-meetup-talking", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Full house at the Dallas Hadoop meetup talking Stinger (at Pariveda Solutions HQ)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1364515079, "note_count": 0, "trail": [{"content": "<p>Full house at the Dallas Hadoop meetup talking Stinger (at Pariveda Solutions HQ)</p>", "content_raw": "<p>Full house at the Dallas Hadoop meetup talking Stinger (at Pariveda Solutions HQ)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "46546426405"}}], "date": "2013-03-28 23:57:59 GMT", "slug": "full-house-at-the-dallas-hadoop-meetup-talking", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/55faab78b95dafafe6d12fd43c04d61b/tumblr_mkeaknHpWE1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/55faab78b95dafafe6d12fd43c04d61b/tumblr_mkeaknHpWE1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/55faab78b95dafafe6d12fd43c04d61b/tumblr_mkeaknHpWE1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/55faab78b95dafafe6d12fd43c04d61b/tumblr_mkeaknHpWE1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/55faab78b95dafafe6d12fd43c04d61b/tumblr_mkeaknHpWE1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/55faab78b95dafafe6d12fd43c04d61b/tumblr_mkeaknHpWE1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/55faab78b95dafafe6d12fd43c04d61b/tumblr_mkeaknHpWE1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagram.com/p/Xa6FvpxT0V/", "summary": "Full house at the Dallas Hadoop meetup talking Stinger (at Pariveda Solutions HQ)", "caption": "<p>Full house at the Dallas Hadoop meetup talking Stinger (at Pariveda Solutions HQ)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "C9VaDX8Y", "short_url": "https://tmblr.co/ZbIO5ygUwrNI", "can_send_in_message": true, "id": 45615896018, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/45615896018", "tags": [], "post_url": "http://datasyndrome.com/post/45615896018/hippiedom-at-the-love-of-ganesha", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Hippiedom (at The Love of Ganesha)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1363554119, "note_count": 0, "trail": [{"content": "<p>Hippiedom (at The Love of Ganesha)</p>", "content_raw": "<p>Hippiedom (at The Love of Ganesha)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "45615896018"}}], "date": "2013-03-17 21:01:59 GMT", "slug": "hippiedom-at-the-love-of-ganesha", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/fd84b7819fadf7a7bb8bc0fe07c828d8/tumblr_mjtp3bdqQg1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/fd84b7819fadf7a7bb8bc0fe07c828d8/tumblr_mjtp3bdqQg1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/fd84b7819fadf7a7bb8bc0fe07c828d8/tumblr_mjtp3bdqQg1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/fd84b7819fadf7a7bb8bc0fe07c828d8/tumblr_mjtp3bdqQg1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/fd84b7819fadf7a7bb8bc0fe07c828d8/tumblr_mjtp3bdqQg1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/fd84b7819fadf7a7bb8bc0fe07c828d8/tumblr_mjtp3bdqQg1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/fd84b7819fadf7a7bb8bc0fe07c828d8/tumblr_mjtp3bdqQg1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/W-RReQxT0M/", "summary": "Hippiedom (at The Love of Ganesha)", "caption": "<p>Hippiedom (at The Love of Ganesha)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "OB1pVqQ4", "short_url": "https://tmblr.co/ZbIO5yfz7lkh", "can_send_in_message": true, "id": 45048855467, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/45048855467", "tags": [], "post_url": "http://datasyndrome.com/post/45048855467/moma", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Moma</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1362945911, "note_count": 1, "trail": [{"content": "<p>Moma</p>", "content_raw": "<p>Moma</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "45048855467"}}], "date": "2013-03-10 20:05:11 GMT", "slug": "moma", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/7b16a2e7d3447c98cf83c515d441d672/tumblr_mjgnsncaRl1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/7b16a2e7d3447c98cf83c515d441d672/tumblr_mjgnsncaRl1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/7b16a2e7d3447c98cf83c515d441d672/tumblr_mjgnsncaRl1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/7b16a2e7d3447c98cf83c515d441d672/tumblr_mjgnsncaRl1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/7b16a2e7d3447c98cf83c515d441d672/tumblr_mjgnsncaRl1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/7b16a2e7d3447c98cf83c515d441d672/tumblr_mjgnsncaRl1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/7b16a2e7d3447c98cf83c515d441d672/tumblr_mjgnsncaRl1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WsJHZ1RTxO/", "summary": "Moma", "caption": "<p>Moma</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "DnBPDAgu", "short_url": "https://tmblr.co/ZbIO5yf9-8qI", "can_send_in_message": true, "id": 44190960914, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/44190960914", "tags": [], "post_url": "http://datasyndrome.com/post/44190960914/mushroom-stew", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Mushroom stew</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1362020903, "note_count": 0, "trail": [{"content": "<p>Mushroom stew</p>", "content_raw": "<p>Mushroom stew</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "44190960914"}}], "date": "2013-02-28 03:08:23 GMT", "slug": "mushroom-stew", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/f7ef0057c1f265e8fae9c939cdbce0e4/tumblr_miwu1zdgiC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/f7ef0057c1f265e8fae9c939cdbce0e4/tumblr_miwu1zdgiC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/f7ef0057c1f265e8fae9c939cdbce0e4/tumblr_miwu1zdgiC1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/f7ef0057c1f265e8fae9c939cdbce0e4/tumblr_miwu1zdgiC1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/f7ef0057c1f265e8fae9c939cdbce0e4/tumblr_miwu1zdgiC1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/f7ef0057c1f265e8fae9c939cdbce0e4/tumblr_miwu1zdgiC1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/f7ef0057c1f265e8fae9c939cdbce0e4/tumblr_miwu1zdgiC1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WQk6uUxT3v/", "summary": "Mushroom stew", "caption": "<p>Mushroom stew</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "IIr3XIcL", "short_url": "https://tmblr.co/ZbIO5yf9xma4", "can_send_in_message": true, "id": 44190075140, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/44190075140", "tags": [], "post_url": "http://datasyndrome.com/post/44190075140/just-chopped-and-ate-some-hydroponic-dill", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Just chopped and ate some hydroponic dill</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1362020271, "note_count": 0, "trail": [{"content": "<p>Just chopped and ate some hydroponic dill</p>", "content_raw": "<p>Just chopped and ate some hydroponic dill</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "44190075140"}}], "date": "2013-02-28 02:57:51 GMT", "slug": "just-chopped-and-ate-some-hydroponic-dill", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/5d26b3b83663a019be1f683fc6d215b9/tumblr_miwtkf5ykW1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/5d26b3b83663a019be1f683fc6d215b9/tumblr_miwtkf5ykW1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/5d26b3b83663a019be1f683fc6d215b9/tumblr_miwtkf5ykW1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/5d26b3b83663a019be1f683fc6d215b9/tumblr_miwtkf5ykW1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/5d26b3b83663a019be1f683fc6d215b9/tumblr_miwtkf5ykW1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/5d26b3b83663a019be1f683fc6d215b9/tumblr_miwtkf5ykW1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/5d26b3b83663a019be1f683fc6d215b9/tumblr_miwtkf5ykW1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WQjrjqxT2O/", "summary": "Just chopped and ate some hydroponic dill", "caption": "<p>Just chopped and ate some hydroponic dill</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "UfF00eOs", "short_url": "https://tmblr.co/ZbIO5ye_UVQw", "can_send_in_message": true, "id": 43997853370, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43997853370", "tags": [], "post_url": "http://datasyndrome.com/post/43997853370/pyramid-foam-at-hortonworks", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Pyramid foam (at Hortonworks)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361820286, "note_count": 0, "trail": [{"content": "<p>Pyramid foam (at Hortonworks)</p>", "content_raw": "<p>Pyramid foam (at Hortonworks)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43997853370"}}], "date": "2013-02-25 19:24:46 GMT", "slug": "pyramid-foam-at-hortonworks", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/768897449fd27c210f87d8aa771e0072/tumblr_misj9b8x4P1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/768897449fd27c210f87d8aa771e0072/tumblr_misj9b8x4P1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/768897449fd27c210f87d8aa771e0072/tumblr_misj9b8x4P1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/768897449fd27c210f87d8aa771e0072/tumblr_misj9b8x4P1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/768897449fd27c210f87d8aa771e0072/tumblr_misj9b8x4P1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/768897449fd27c210f87d8aa771e0072/tumblr_misj9b8x4P1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/768897449fd27c210f87d8aa771e0072/tumblr_misj9b8x4P1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WKmRLWxT13/", "summary": "Pyramid foam (at Hortonworks)", "caption": "<p>Pyramid foam (at Hortonworks)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "ZCwHbAgs", "short_url": "https://tmblr.co/ZbIO5yeiWLg9", "can_send_in_message": true, "id": 43696347785, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43696347785", "tags": [], "post_url": "http://datasyndrome.com/post/43696347785/crowd-of-hadoopers-at-shopzillacom", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Crowd of hadoopers (at Shopzilla.com)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361503444, "note_count": 0, "trail": [{"content": "<p>Crowd of hadoopers (at Shopzilla.com)</p>", "content_raw": "<p>Crowd of hadoopers (at Shopzilla.com)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43696347785"}}], "date": "2013-02-22 03:24:04 GMT", "slug": "crowd-of-hadoopers-at-shopzillacom", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/bb2e7fb94a709b9b639566b388a4cf9f/tumblr_milqs5nPMS1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/bb2e7fb94a709b9b639566b388a4cf9f/tumblr_milqs5nPMS1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/bb2e7fb94a709b9b639566b388a4cf9f/tumblr_milqs5nPMS1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/bb2e7fb94a709b9b639566b388a4cf9f/tumblr_milqs5nPMS1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/bb2e7fb94a709b9b639566b388a4cf9f/tumblr_milqs5nPMS1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/bb2e7fb94a709b9b639566b388a4cf9f/tumblr_milqs5nPMS1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/bb2e7fb94a709b9b639566b388a4cf9f/tumblr_milqs5nPMS1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WBJ8M0xT9Q/", "summary": "Crowd of hadoopers (at Shopzilla.com)", "caption": "<p>Crowd of hadoopers (at Shopzilla.com)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "2Y8hK5E4", "short_url": "https://tmblr.co/ZbIO5yeiVloR", "can_send_in_message": true, "id": 43696192667, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43696192667", "tags": [], "post_url": "http://datasyndrome.com/post/43696192667/teenagers-do-not-trust-intuition-they-trust", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>\u201cTeenagers do not trust intuition, they trust google\u2019s big data.\u201d (at Shopzilla.com)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361503328, "note_count": 0, "trail": [{"content": "<p>&ldquo;Teenagers do not trust intuition, they trust google&rsquo;s big data.&rdquo; (at Shopzilla.com)</p>", "content_raw": "<p>\u201cTeenagers do not trust intuition, they trust google\u2019s big data.\u201d (at Shopzilla.com)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43696192667"}}], "date": "2013-02-22 03:22:08 GMT", "slug": "teenagers-do-not-trust-intuition-they-trust", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/b44a098b92a485d2764b4bdec5f014f9/tumblr_milqowWTVT1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/b44a098b92a485d2764b4bdec5f014f9/tumblr_milqowWTVT1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/b44a098b92a485d2764b4bdec5f014f9/tumblr_milqowWTVT1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/b44a098b92a485d2764b4bdec5f014f9/tumblr_milqowWTVT1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/b44a098b92a485d2764b4bdec5f014f9/tumblr_milqowWTVT1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/b44a098b92a485d2764b4bdec5f014f9/tumblr_milqowWTVT1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/b44a098b92a485d2764b4bdec5f014f9/tumblr_milqowWTVT1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WBJk-exT8t/", "summary": "\"Teenagers do not trust intuition, they trust google's big data.\" (at Shopzilla.com)", "caption": "<p>&ldquo;Teenagers do not trust intuition, they trust google&rsquo;s big data.&rdquo; (at Shopzilla.com)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "XnFuAPpA", "short_url": "https://tmblr.co/ZbIO5yeiV2L5", "can_send_in_message": true, "id": 43696006469, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43696006469", "tags": [], "post_url": "http://datasyndrome.com/post/43696006469/up-first-edmunds-using-hadoop-to-source", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Up first: Edmunds, Using Hadoop to Source Applications (at Shopzilla.com)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361503189, "note_count": 0, "trail": [{"content": "<p>Up first: Edmunds, Using Hadoop to Source Applications (at Shopzilla.com)</p>", "content_raw": "<p>Up first: Edmunds, Using Hadoop to Source Applications (at Shopzilla.com)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43696006469"}}], "date": "2013-02-22 03:19:49 GMT", "slug": "up-first-edmunds-using-hadoop-to-source", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/44094c2f5b32bb16aa9f3e2261072ff7/tumblr_milql16IRM1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/44094c2f5b32bb16aa9f3e2261072ff7/tumblr_milql16IRM1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/44094c2f5b32bb16aa9f3e2261072ff7/tumblr_milql16IRM1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/44094c2f5b32bb16aa9f3e2261072ff7/tumblr_milql16IRM1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/44094c2f5b32bb16aa9f3e2261072ff7/tumblr_milql16IRM1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/44094c2f5b32bb16aa9f3e2261072ff7/tumblr_milql16IRM1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/44094c2f5b32bb16aa9f3e2261072ff7/tumblr_milql16IRM1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WBJTzSRT8U/", "summary": "Up first: Edmunds, Using Hadoop to Source Applications (at Shopzilla.com)", "caption": "<p>Up first: Edmunds, Using Hadoop to Source Applications (at Shopzilla.com)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "9j45I4ej", "short_url": "https://tmblr.co/ZbIO5yeiTokB", "can_send_in_message": true, "id": 43695680395, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43695680395", "tags": [], "post_url": "http://datasyndrome.com/post/43695680395/la-hug-is-crunk-at-shopzillacom", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>LA HUG is crunk (at Shopzilla.com)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361502946, "note_count": 0, "trail": [{"content": "<p>LA HUG is crunk (at Shopzilla.com)</p>", "content_raw": "<p>LA HUG is crunk (at Shopzilla.com)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43695680395"}}], "date": "2013-02-22 03:15:46 GMT", "slug": "la-hug-is-crunk-at-shopzillacom", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/b5c14317f257214061bde86a9a52980a/tumblr_milqeaDzOW1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/b5c14317f257214061bde86a9a52980a/tumblr_milqeaDzOW1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/b5c14317f257214061bde86a9a52980a/tumblr_milqeaDzOW1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/b5c14317f257214061bde86a9a52980a/tumblr_milqeaDzOW1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/b5c14317f257214061bde86a9a52980a/tumblr_milqeaDzOW1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/b5c14317f257214061bde86a9a52980a/tumblr_milqeaDzOW1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/b5c14317f257214061bde86a9a52980a/tumblr_milqeaDzOW1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/WBIzgERT7a/", "summary": "LA HUG is crunk (at Shopzilla.com)", "caption": "<p>LA HUG is crunk (at Shopzilla.com)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "R6mMhV43", "short_url": "https://tmblr.co/ZbIO5yeTxmr0", "can_send_in_message": true, "id": 43451878720, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43451878720", "tags": [], "post_url": "http://datasyndrome.com/post/43451878720/weekend-project-secure-tvs-against-seismic-events", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Weekend project: secure TVs against seismic events (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361239777, "note_count": 0, "trail": [{"content": "<p>Weekend project: secure TVs against seismic events (at Manor Beach)</p>", "content_raw": "<p>Weekend project: secure TVs against seismic events (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43451878720"}}], "date": "2013-02-19 02:09:37 GMT", "slug": "weekend-project-secure-tvs-against-seismic-events", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/6dc0c468b869e3b764374b349172baf2/tumblr_mig3c1gBHG1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/6dc0c468b869e3b764374b349172baf2/tumblr_mig3c1gBHG1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/6dc0c468b869e3b764374b349172baf2/tumblr_mig3c1gBHG1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/6dc0c468b869e3b764374b349172baf2/tumblr_mig3c1gBHG1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/6dc0c468b869e3b764374b349172baf2/tumblr_mig3c1gBHG1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/6dc0c468b869e3b764374b349172baf2/tumblr_mig3c1gBHG1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/6dc0c468b869e3b764374b349172baf2/tumblr_mig3c1gBHG1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/V5S3qixT9H/", "summary": "Weekend project: secure TVs against seismic events (at Manor Beach)", "caption": "<p>Weekend project: secure TVs against seismic events (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "YYGVKx2N", "short_url": "https://tmblr.co/ZbIO5yeORp0k", "can_send_in_message": true, "id": 43359612974, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43359612974", "tags": [], "post_url": "http://datasyndrome.com/post/43359612974/herbs-and-grape-tomatoes-indoors-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Herbs and grape tomatoes indoors! (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361150138, "note_count": 0, "trail": [{"content": "<p>Herbs and grape tomatoes indoors! (at Manor Beach)</p>", "content_raw": "<p>Herbs and grape tomatoes indoors! (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43359612974"}}], "date": "2013-02-18 01:15:38 GMT", "slug": "herbs-and-grape-tomatoes-indoors-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/f9f3182a60ac634b93ffddcc907efaf8/tumblr_mie662WKrC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/f9f3182a60ac634b93ffddcc907efaf8/tumblr_mie662WKrC1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/f9f3182a60ac634b93ffddcc907efaf8/tumblr_mie662WKrC1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/f9f3182a60ac634b93ffddcc907efaf8/tumblr_mie662WKrC1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/f9f3182a60ac634b93ffddcc907efaf8/tumblr_mie662WKrC1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/f9f3182a60ac634b93ffddcc907efaf8/tumblr_mie662WKrC1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/f9f3182a60ac634b93ffddcc907efaf8/tumblr_mie662WKrC1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/V2oBNcRT8O/", "summary": "Herbs and grape tomatoes indoors! (at Manor Beach)", "caption": "<p>Herbs and grape tomatoes indoors! (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "6rTGjNA9", "short_url": "https://tmblr.co/ZbIO5yeIxA-V", "can_send_in_message": true, "id": 43267174367, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43267174367", "tags": [], "post_url": "http://datasyndrome.com/post/43267174367/this-is-a-hydroponic-heirloom-tomater-at-manor", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>This is a hydroponic heirloom tomater (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361060297, "note_count": 0, "trail": [{"content": "<p>This is a hydroponic heirloom tomater (at Manor Beach)</p>", "content_raw": "<p>This is a hydroponic heirloom tomater (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43267174367"}}], "date": "2013-02-17 00:18:17 GMT", "slug": "this-is-a-hydroponic-heirloom-tomater-at-manor", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/ef5893e838b035d86c743144c70cbe69/tumblr_mic8ui3G931qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/ef5893e838b035d86c743144c70cbe69/tumblr_mic8ui3G931qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/ef5893e838b035d86c743144c70cbe69/tumblr_mic8ui3G931qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/ef5893e838b035d86c743144c70cbe69/tumblr_mic8ui3G931qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/ef5893e838b035d86c743144c70cbe69/tumblr_mic8ui3G931qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/ef5893e838b035d86c743144c70cbe69/tumblr_mic8ui3G931qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/ef5893e838b035d86c743144c70cbe69/tumblr_mic8ui3G931qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/Vz8rmTRT_Q/", "summary": "This is a hydroponic heirloom tomater (at Manor Beach)", "caption": "<p>This is a hydroponic heirloom tomater (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "YN4h78gB", "short_url": "https://tmblr.co/ZbIO5yeIwyGQ", "can_send_in_message": true, "id": 43267114010, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43267114010", "tags": [], "post_url": "http://datasyndrome.com/post/43267114010/i-hope-u-like-meatloaf-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>I hope u like meatloaf (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1361060249, "note_count": 0, "trail": [{"content": "<p>I hope u like meatloaf (at Manor Beach)</p>", "content_raw": "<p>I hope u like meatloaf (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43267114010"}}], "date": "2013-02-17 00:17:29 GMT", "slug": "i-hope-u-like-meatloaf-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/21cb769c6f59c4069e5dcfa5b1a510ee/tumblr_mic8t5wMbs1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/21cb769c6f59c4069e5dcfa5b1a510ee/tumblr_mic8t5wMbs1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/21cb769c6f59c4069e5dcfa5b1a510ee/tumblr_mic8t5wMbs1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/21cb769c6f59c4069e5dcfa5b1a510ee/tumblr_mic8t5wMbs1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/21cb769c6f59c4069e5dcfa5b1a510ee/tumblr_mic8t5wMbs1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/21cb769c6f59c4069e5dcfa5b1a510ee/tumblr_mic8t5wMbs1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/21cb769c6f59c4069e5dcfa5b1a510ee/tumblr_mic8t5wMbs1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/Vz8mEwRT_G/", "summary": "I hope u like meatloaf (at Manor Beach)", "caption": "<p>I hope u like meatloaf (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "55aHWyHE", "short_url": "https://tmblr.co/ZbIO5yeES08Q", "can_send_in_message": true, "id": 43191894554, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/43191894554", "tags": [], "post_url": "http://datasyndrome.com/post/43191894554/the-new-hortonworks-office-is-classy-at", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>The new @hortonworks office is classy (at Hortonworks)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1360980062, "note_count": 0, "trail": [{"content": "<p>The new @hortonworks office is classy (at Hortonworks)</p>", "content_raw": "<p>The new @hortonworks office is classy (at Hortonworks)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "43191894554"}}], "date": "2013-02-16 02:01:02 GMT", "slug": "the-new-hortonworks-office-is-classy-at", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/d32937d6c8bbf73e6879a12e7427cd09/tumblr_miaixrT4qq1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/d32937d6c8bbf73e6879a12e7427cd09/tumblr_miaixrT4qq1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/d32937d6c8bbf73e6879a12e7427cd09/tumblr_miaixrT4qq1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/d32937d6c8bbf73e6879a12e7427cd09/tumblr_miaixrT4qq1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/d32937d6c8bbf73e6879a12e7427cd09/tumblr_miaixrT4qq1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/d32937d6c8bbf73e6879a12e7427cd09/tumblr_miaixrT4qq1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/d32937d6c8bbf73e6879a12e7427cd09/tumblr_miaixrT4qq1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/Vxjsp0xT8O/", "summary": "The new @hortonworks office is classy (at Hortonworks)", "caption": "<p>The new @hortonworks office is classy (at Hortonworks)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "ajDhFiMC", "short_url": "https://tmblr.co/ZbIO5ydvOYzN", "can_send_in_message": true, "id": 42838667095, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/42838667095", "tags": [], "post_url": "http://datasyndrome.com/post/42838667095/using-the-hortonworks-sandbox-to-load-common-crawl", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Using the Hortonworks Sandbox to load Common Crawl text data using Twitter\u2019s elephant-bird. SHA BANG!</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1360587631, "note_count": 0, "trail": [{"content": "<p>Using the Hortonworks Sandbox to load Common Crawl text data using Twitter&rsquo;s elephant-bird. SHA BANG!</p>", "content_raw": "<p>Using the Hortonworks Sandbox to load Common Crawl text data using Twitter\u2019s elephant-bird. SHA BANG!</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "42838667095"}}], "date": "2013-02-11 13:00:31 GMT", "slug": "using-the-hortonworks-sandbox-to-load-common-crawl", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/ab73ee58734b9a2f829db7a7992cec06/tumblr_mi244vndQI1qe7pymo1_1280.gif", "width": 1280, "height": 753}, "alt_sizes": [{"url": "https://68.media.tumblr.com/ab73ee58734b9a2f829db7a7992cec06/tumblr_mi244vndQI1qe7pymo1_1280.gif", "width": 1280, "height": 753}, {"url": "https://68.media.tumblr.com/ab73ee58734b9a2f829db7a7992cec06/tumblr_mi244vndQI1qe7pymo1_500.gif", "width": 500, "height": 294}, {"url": "https://68.media.tumblr.com/ab73ee58734b9a2f829db7a7992cec06/tumblr_mi244vndQI1qe7pymo1_400.gif", "width": 400, "height": 235}, {"url": "https://68.media.tumblr.com/ab73ee58734b9a2f829db7a7992cec06/tumblr_mi244vndQI1qe7pymo1_250.gif", "width": 250, "height": 147}, {"url": "https://68.media.tumblr.com/ab73ee58734b9a2f829db7a7992cec06/tumblr_mi244vndQI1qe7pymo1_100.gif", "width": 100, "height": 59}, {"url": "https://68.media.tumblr.com/ab73ee58734b9a2f829db7a7992cec06/tumblr_mi244vndQI1qe7pymo1_75sq.gif", "width": 75, "height": 75}]}], "summary": "Using the Hortonworks Sandbox to load Common Crawl text data using Twitter's elephant-bird. SHA BANG!", "caption": "<p>Using the Hortonworks Sandbox to load Common Crawl text data using Twitter&rsquo;s elephant-bird. SHA BANG!</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "4jhJlvwk", "short_url": "https://tmblr.co/ZbIO5ydv1d9_", "can_send_in_message": true, "id": 42832654974, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/42832654974", "tags": [], "post_url": "http://datasyndrome.com/post/42832654974/my-two-favorite-movies-at-once-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>My two favorite movies at once. (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1360575206, "note_count": 0, "trail": [{"content": "<p>My two favorite movies at once. (at Manor Beach)</p>", "content_raw": "<p>My two favorite movies at once. (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "42832654974"}}], "date": "2013-02-11 09:33:26 GMT", "slug": "my-two-favorite-movies-at-once-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/ef1953075460a3ea7fa1a7e2a8009484/tumblr_mi1ujr1JXI1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/ef1953075460a3ea7fa1a7e2a8009484/tumblr_mi1ujr1JXI1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/ef1953075460a3ea7fa1a7e2a8009484/tumblr_mi1ujr1JXI1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/ef1953075460a3ea7fa1a7e2a8009484/tumblr_mi1ujr1JXI1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/ef1953075460a3ea7fa1a7e2a8009484/tumblr_mi1ujr1JXI1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/ef1953075460a3ea7fa1a7e2a8009484/tumblr_mi1ujr1JXI1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/ef1953075460a3ea7fa1a7e2a8009484/tumblr_mi1ujr1JXI1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/VlfUujxTwi/", "summary": "My two favorite movies at once. (at Manor Beach)", "caption": "<p>My two favorite movies at once. (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "WLo74Ckk", "short_url": "https://tmblr.co/ZbIO5ydnKZIK", "excerpt": null, "link_author": null, "id": 42703402132, "display_avatar": true, "can_reply": true, "can_like": false, "title": "I <3 ILLUSTRATE in Pig", "tags": [], "post_url": "http://datasyndrome.com/post/42703402132/i-3-illustrate-in-pig", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Illustrate feels like magic each time I use it.</p>", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "<p>Illustrate feels like magic each time I use it.</p>", "format": "html", "timestamp": 1360452250, "note_count": 1, "trail": [{"content": "<p>Illustrate feels like magic each time I use it.</p>", "content_raw": "<p>Illustrate feels like magic each time I use it.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "42703402132"}}], "date": "2013-02-09 23:24:10 GMT", "slug": "i-3-illustrate-in-pig", "blog_name": "rjurney", "publisher": "gist.github.com", "url": "https://gist.github.com/rjurney/4747553", "can_send_in_message": true, "summary": "I <3 ILLUSTRATE in Pig", "can_reblog": true}, {"body": "<p>Whats new in Pig 0.11? <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\">http://www.slideshare.net/hortonworks/new-features-in-pig-011</a>\n\n</p><center>\n<iframe src=\"http://www.slideshare.net/slideshow/embed_code/14872896\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\"> </iframe> <div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\" title=\"New features in Pig 0.11\" target=\"_blank\">New features in Pig 0.11</a> </strong> from <strong><a href=\"http://www.slideshare.net/hortonworks\" target=\"_blank\">Hortonworks</a></strong> </div></center>", "liked": false, "followed": false, "reblog_key": "VzfCNbQw", "short_url": "https://tmblr.co/ZbIO5ydmSwvl", "can_send_in_message": true, "id": 42688818799, "display_avatar": true, "can_reply": true, "source_title": "slideshare.net", "title": null, "tags": [], "post_url": "http://datasyndrome.com/post/42688818799/whats-new-in-pig-011", "recommended_source": null, "state": "published", "reblog": {"comment": "<p><p>Whats new in Pig 0.11? <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\">http://www.slideshare.net/hortonworks/new-features-in-pig-011</a>\n\n</p><center>\n<iframe src=\"http://www.slideshare.net/slideshow/embed_code/14872896\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\"> </iframe> <div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\" title=\"New features in Pig 0.11\" target=\"_blank\">New features in Pig 0.11</a> </strong> from <strong><a href=\"http://www.slideshare.net/hortonworks\" target=\"_blank\">Hortonworks</a></strong> </div></center></p>", "tree_html": ""}, "type": "text", "recommended_color": null, "format": "html", "timestamp": 1360440900, "note_count": 0, "source_url": "http://t.umblr.com/redirect?z=http%3A%2F%2Fwww.slideshare.net%2Fhortonworks%2Fnew-features-in-pig-011&t=ODU3YTc3YWQ0OGVlYTBkZTBkMzBmYzc3MjFmZmJlYTVkZGY2YjRjOCw0MjY4ODgxODc5OQ%3D%3D&b=t%3AXeWQ4yj1xjxNZ5gW6kub1g&p=http%3A%2F%2Fdatasyndrome.com%2Fpost%2F42688818799%2Fwhats-new-in-pig-011&m=1", "trail": [{"content": "<p><p>Whats new in Pig 0.11? <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\">http://www.slideshare.net/hortonworks/new-features-in-pig-011</a>\n\n</p>\n<p><a href=\"#\"><img src=\"http://assets.tumblr.com/images/inline_placeholder.png\" width=\"18\" height=\"14\"/></a></p>  <strong> <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\" title=\"New features in Pig 0.11\" target=\"_blank\">New features in Pig 0.11</a> </strong> from <strong><a href=\"http://www.slideshare.net/hortonworks\" target=\"_blank\">Hortonworks</a></strong> </p>", "content_raw": "<p><p>Whats new in Pig 0.11? <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\">http://www.slideshare.net/hortonworks/new-features-in-pig-011</a>\n\n</p><center>\n<iframe src=\"http://www.slideshare.net/slideshow/embed_code/14872896\" width=\"427\" height=\"356\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\"> </iframe> <div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/hortonworks/new-features-in-pig-011\" title=\"New features in Pig 0.11\" target=\"_blank\">New features in Pig 0.11</a> </strong> from <strong><a href=\"http://www.slideshare.net/hortonworks\" target=\"_blank\">Hortonworks</a></strong> </div></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "42688818799"}}], "date": "2013-02-09 20:15:00 GMT", "can_like": false, "slug": "whats-new-in-pig-011", "blog_name": "rjurney", "summary": "Whats new in Pig 0.11? http://www.slideshare.net/hortonworks/new-features-in-pig-011\r\n\r\n\r\n    New features in Pig 0.11  from...", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "togWfirz", "short_url": "https://tmblr.co/ZbIO5ydixUzH", "can_send_in_message": true, "id": 42629721937, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/42629721937", "tags": [], "post_url": "http://datasyndrome.com/post/42629721937/everyone-in-norcal-should-have-hydroponic-herbs-in", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Everyone in Norcal should have hydroponic herbs in their kitchen. Grape tomatoes at right.</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1360376039, "note_count": 0, "trail": [{"content": "<p>Everyone in Norcal should have hydroponic herbs in their kitchen. Grape tomatoes at right.</p>", "content_raw": "<p>Everyone in Norcal should have hydroponic herbs in their kitchen. Grape tomatoes at right.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "42629721937"}}], "date": "2013-02-09 02:13:59 GMT", "slug": "everyone-in-norcal-should-have-hydroponic-herbs-in", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/9d29eb513ece0881aa9b13079964904e/tumblr_mhxkvcpVhN1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/9d29eb513ece0881aa9b13079964904e/tumblr_mhxkvcpVhN1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/9d29eb513ece0881aa9b13079964904e/tumblr_mhxkvcpVhN1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/9d29eb513ece0881aa9b13079964904e/tumblr_mhxkvcpVhN1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/9d29eb513ece0881aa9b13079964904e/tumblr_mhxkvcpVhN1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/9d29eb513ece0881aa9b13079964904e/tumblr_mhxkvcpVhN1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/9d29eb513ece0881aa9b13079964904e/tumblr_mhxkvcpVhN1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/VfjZWKRT9L/", "summary": "Everyone in Norcal should have hydroponic herbs in their kitchen. Grape tomatoes at right.", "caption": "<p>Everyone in Norcal should have hydroponic herbs in their kitchen. Grape tomatoes at right.</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "Gys58Lrl", "short_url": "https://tmblr.co/ZbIO5ydTwL6b", "can_send_in_message": true, "id": 42377761189, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/42377761189", "tags": [], "post_url": "http://datasyndrome.com/post/42377761189/99mpg", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>99mpg</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1360100983, "note_count": 0, "trail": [{"content": "<p>99mpg</p>", "content_raw": "<p>99mpg</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "42377761189"}}], "date": "2013-02-05 21:49:43 GMT", "slug": "99mpg", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/1b4b05e060f0d7f878498d4334095315/tumblr_mhromv5uGG1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/1b4b05e060f0d7f878498d4334095315/tumblr_mhromv5uGG1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/1b4b05e060f0d7f878498d4334095315/tumblr_mhromv5uGG1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/1b4b05e060f0d7f878498d4334095315/tumblr_mhromv5uGG1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/1b4b05e060f0d7f878498d4334095315/tumblr_mhromv5uGG1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/1b4b05e060f0d7f878498d4334095315/tumblr_mhromv5uGG1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/1b4b05e060f0d7f878498d4334095315/tumblr_mhromv5uGG1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/VXW5PDRTyy/", "summary": "99mpg", "caption": "<p>99mpg</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "uSlkiKxE", "short_url": "https://tmblr.co/ZbIO5ydL4whf", "can_send_in_message": true, "id": 42229541609, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/42229541609", "tags": [], "post_url": "http://datasyndrome.com/post/42229541609/miss-piggie-and-kjurney-at-pacific-manor-plaza", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Miss Piggie and @kjurney (at Pacific Manor Plaza)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1359934925, "note_count": 0, "trail": [{"content": "<p>Miss Piggie and @kjurney (at Pacific Manor Plaza)</p>", "content_raw": "<p>Miss Piggie and @kjurney (at Pacific Manor Plaza)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "42229541609"}}], "date": "2013-02-03 23:42:05 GMT", "slug": "miss-piggie-and-kjurney-at-pacific-manor-plaza", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/eefd8ae10c120a0f573045ea07cc7158/tumblr_mho4i5rXl71qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/eefd8ae10c120a0f573045ea07cc7158/tumblr_mho4i5rXl71qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/eefd8ae10c120a0f573045ea07cc7158/tumblr_mho4i5rXl71qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/eefd8ae10c120a0f573045ea07cc7158/tumblr_mho4i5rXl71qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/eefd8ae10c120a0f573045ea07cc7158/tumblr_mho4i5rXl71qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/eefd8ae10c120a0f573045ea07cc7158/tumblr_mho4i5rXl71qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/eefd8ae10c120a0f573045ea07cc7158/tumblr_mho4i5rXl71qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/VSaMj7xT_9/", "summary": "Miss Piggie and @kjurney (at Pacific Manor Plaza)", "caption": "<p>Miss Piggie and @kjurney (at Pacific Manor Plaza)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "ip6ZZAU1", "short_url": "https://tmblr.co/ZbIO5yd61SKa", "can_send_in_message": true, "id": 41976972580, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/41976972580", "tags": [], "post_url": "http://datasyndrome.com/post/41976972580/nom-at-tommys-joynt", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Nom (at Tommy\u2019s Joynt)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1359674696, "note_count": 0, "trail": [{"content": "<p>Nom (at Tommy&rsquo;s Joynt)</p>", "content_raw": "<p>Nom (at Tommy\u2019s Joynt)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "41976972580"}}], "date": "2013-01-31 23:24:56 GMT", "slug": "nom-at-tommys-joynt", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/f5e75522def644ae9c3a324487b34e44/tumblr_mhijpk3DSL1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/f5e75522def644ae9c3a324487b34e44/tumblr_mhijpk3DSL1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/f5e75522def644ae9c3a324487b34e44/tumblr_mhijpk3DSL1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/f5e75522def644ae9c3a324487b34e44/tumblr_mhijpk3DSL1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/f5e75522def644ae9c3a324487b34e44/tumblr_mhijpk3DSL1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/f5e75522def644ae9c3a324487b34e44/tumblr_mhijpk3DSL1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/f5e75522def644ae9c3a324487b34e44/tumblr_mhijpk3DSL1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/VKp0IvRT6Q/", "summary": "Nom (at Tommy's Joynt)", "caption": "<p>Nom (at Tommy&rsquo;s Joynt)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "V91sTY1c", "short_url": "https://tmblr.co/ZbIO5ycryuA1", "can_send_in_message": true, "id": 41707340417, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/41707340417", "tags": [], "post_url": "http://datasyndrome.com/post/41707340417/katie-is-a-tardis-at-pacific-manor-plaza", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Katie is a TARDIS. (at Pacific Manor Plaza)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1359392051, "note_count": 0, "trail": [{"content": "<p>Katie is a TARDIS. (at Pacific Manor Plaza)</p>", "content_raw": "<p>Katie is a TARDIS. (at Pacific Manor Plaza)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "41707340417"}}], "date": "2013-01-28 16:54:11 GMT", "slug": "katie-is-a-tardis-at-pacific-manor-plaza", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/d360fcaed47744ef4367d2e3cdf4dc1c/tumblr_mhchmc5rlX1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/d360fcaed47744ef4367d2e3cdf4dc1c/tumblr_mhchmc5rlX1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/d360fcaed47744ef4367d2e3cdf4dc1c/tumblr_mhchmc5rlX1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/d360fcaed47744ef4367d2e3cdf4dc1c/tumblr_mhchmc5rlX1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/d360fcaed47744ef4367d2e3cdf4dc1c/tumblr_mhchmc5rlX1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/d360fcaed47744ef4367d2e3cdf4dc1c/tumblr_mhchmc5rlX1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/d360fcaed47744ef4367d2e3cdf4dc1c/tumblr_mhchmc5rlX1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/VCOuX0xT1a/", "summary": "Katie is a TARDIS. (at Pacific Manor Plaza)", "caption": "<p>Katie is a TARDIS. (at Pacific Manor Plaza)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "scYnLwzU", "short_url": "https://tmblr.co/ZbIO5ycjhS4K", "can_send_in_message": true, "id": 41568551188, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/41568551188", "tags": [], "post_url": "http://datasyndrome.com/post/41568551188", "recommended_source": null, "state": "published", "reblog": {"comment": "", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1359250313, "note_count": 1, "trail": [], "date": "2013-01-27 01:31:53 GMT", "slug": "", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/4637b9d22c1353b0dd30bf05738f8d37/tumblr_mh9g95wvJ71qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/4637b9d22c1353b0dd30bf05738f8d37/tumblr_mh9g95wvJ71qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/4637b9d22c1353b0dd30bf05738f8d37/tumblr_mh9g95wvJ71qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/4637b9d22c1353b0dd30bf05738f8d37/tumblr_mh9g95wvJ71qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/4637b9d22c1353b0dd30bf05738f8d37/tumblr_mh9g95wvJ71qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/4637b9d22c1353b0dd30bf05738f8d37/tumblr_mh9g95wvJ71qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/4637b9d22c1353b0dd30bf05738f8d37/tumblr_mh9g95wvJ71qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/U-AcfZRT4N/", "summary": "", "caption": "", "can_reblog": true}, {"body": "<p>Pacifica is a small town just over the hump from the rest of the peninsula, making it a great place to live, surf, play. What follows is a guide to the best of Pacifica for new friends that have moved to the area.\n\n</p><ol><li><a href=\"http://www.mazzettisbakery.com/\">Mazetti&rsquo;s Bakery (Flash only)</a> - <a href=\"http://www.yelp.com/biz/mazzettis-bakery-pacifica\">Yelp</a> -  Amazing cupcakes, pies, cookies, coffee and pastries and up at 6AM daily.</li>\n<li><a href=\"http://www.oceanfishsushi.com/\">Ocean Fish</a> - Great sushi at great prices. Delivers.</li>\n<li><a href=\"http://www.yelp.com/biz/bay-coffee-company-pacifica\">\nBay Coffee Company</a> - Best cup of coffee, good wifi.</li>\n<li><a href=\"http://www.cityofpacifica.org/depts/rec_department/aquatics/adult_swim/default.asp\">Pacifica Pool at Oceana Highschool</a> - Great pool. Limited adult swim hours, but an all access pass is $67/month. Open till 8-9PM weekdays.</li>\n<li><a href=\"http://norcalsurfshop.com/\">Nor Cal Surf Shop</a> - Great surf/bodyboarding shop. Wetsuits, boards, fins, plus great NorCal attire. Yes, this is the shop name you see everyone wearing :)</li>\n<li><a href=\"http://www.yelp.com/biz/high-tide-restaurant-cafe-and-creperie-pacifica#query:crepes\">High Tide Restaurant-Cafe and Creperie</a> - great brunch. Amazing crepes.</li>\n<li><a href=\"http://www.coastsidefarmersmarket.org/\">Coastside Farmers Market</a> - The best produce, by Safeway.</li>\n<li><a href=\"https://plus.google.com/103987053706080475477/about?gl=us&amp;hl=en\">Oil Changers</a> - $7 deluxe carwash with super-fun tricolor foam!</li>\n<li><a href=\"http://www.yelp.com/biz/pacifica-dog-park-at-sanchez-art-center-pacifica\">Sanchez Dog Park</a> - Great park. Bitchy neighbors.</li>\n<li><a href=\"https://plus.google.com/108112625069629536663/about?gl=us&amp;hl=en\">Pacifica State Beach</a> - THE PLACE to learn to surf, bodyboard, swim. Get a lesson a NorCal Surf Shop.</li>\n</ol>", "liked": false, "followed": false, "reblog_key": "W1ZMwpM4", "reblog": {"comment": "<p><p>Pacifica is a small town just over the hump from the rest of the peninsula, making it a great place to live, surf, play. What follows is a guide to the best of Pacifica for new friends that have moved to the area.\n\n</p><ol><li><a href=\"http://www.mazzettisbakery.com/\">Mazetti\u2019s Bakery (Flash only)</a> - <a href=\"http://www.yelp.com/biz/mazzettis-bakery-pacifica\">Yelp</a> -  Amazing cupcakes, pies, cookies, coffee and pastries and up at 6AM daily.</li>\n<li><a href=\"http://www.oceanfishsushi.com/\">Ocean Fish</a> - Great sushi at great prices. Delivers.</li>\n<li><a href=\"http://www.yelp.com/biz/bay-coffee-company-pacifica\">\nBay Coffee Company</a> - Best cup of coffee, good wifi.</li>\n<li><a href=\"http://www.cityofpacifica.org/depts/rec_department/aquatics/adult_swim/default.asp\">Pacifica Pool at Oceana Highschool</a> - Great pool. Limited adult swim hours, but an all access pass is $67/month. Open till 8-9PM weekdays.</li>\n<li><a href=\"http://norcalsurfshop.com/\">Nor Cal Surf Shop</a> - Great surf/bodyboarding shop. Wetsuits, boards, fins, plus great NorCal attire. Yes, this is the shop name you see everyone wearing :)</li>\n<li><a href=\"http://www.yelp.com/biz/high-tide-restaurant-cafe-and-creperie-pacifica#query:crepes\">High Tide Restaurant-Cafe and Creperie</a> - great brunch. Amazing crepes.</li>\n<li><a href=\"http://www.coastsidefarmersmarket.org/\">Coastside Farmers Market</a> - The best produce, by Safeway.</li>\n<li><a href=\"https://plus.google.com/103987053706080475477/about?gl=us&amp;hl=en\">Oil Changers</a> - $7 deluxe carwash with super-fun tricolor foam!</li>\n<li><a href=\"http://www.yelp.com/biz/pacifica-dog-park-at-sanchez-art-center-pacifica\">Sanchez Dog Park</a> - Great park. Bitchy neighbors.</li>\n<li><a href=\"https://plus.google.com/108112625069629536663/about?gl=us&amp;hl=en\">Pacifica State Beach</a> - THE PLACE to learn to surf, bodyboard, swim. Get a lesson a NorCal Surf Shop.</li>\n</ol></p>", "tree_html": ""}, "can_send_in_message": true, "id": 41546210399, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Best of Pacifica", "tags": [], "post_url": "http://datasyndrome.com/post/41546210399/best-of-pacifica", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yciMDnV", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1359232380, "note_count": 1, "trail": [{"content": "<p><p>Pacifica is a small town just over the hump from the rest of the peninsula, making it a great place to live, surf, play. What follows is a guide to the best of Pacifica for new friends that have moved to the area.\n\n</p><ol><li><a href=\"http://www.mazzettisbakery.com/\">Mazetti&rsquo;s Bakery (Flash only)</a> - <a href=\"http://www.yelp.com/biz/mazzettis-bakery-pacifica\">Yelp</a> -  Amazing cupcakes, pies, cookies, coffee and pastries and up at 6AM daily.</li>\n<li><a href=\"http://www.oceanfishsushi.com/\">Ocean Fish</a> - Great sushi at great prices. Delivers.</li>\n<li><a href=\"http://www.yelp.com/biz/bay-coffee-company-pacifica\">\nBay Coffee Company</a> - Best cup of coffee, good wifi.</li>\n<li><a href=\"http://www.cityofpacifica.org/depts/rec_department/aquatics/adult_swim/default.asp\">Pacifica Pool at Oceana Highschool</a> - Great pool. Limited adult swim hours, but an all access pass is $67/month. Open till 8-9PM weekdays.</li>\n<li><a href=\"http://norcalsurfshop.com/\">Nor Cal Surf Shop</a> - Great surf/bodyboarding shop. Wetsuits, boards, fins, plus great NorCal attire. Yes, this is the shop name you see everyone wearing :)</li>\n<li><a href=\"http://www.yelp.com/biz/high-tide-restaurant-cafe-and-creperie-pacifica#query:crepes\">High Tide Restaurant-Cafe and Creperie</a> - great brunch. Amazing crepes.</li>\n<li><a href=\"http://www.coastsidefarmersmarket.org/\">Coastside Farmers Market</a> - The best produce, by Safeway.</li>\n<li><a href=\"https://plus.google.com/103987053706080475477/about?gl=us&amp;hl=en\">Oil Changers</a> - $7 deluxe carwash with super-fun tricolor foam!</li>\n<li><a href=\"http://www.yelp.com/biz/pacifica-dog-park-at-sanchez-art-center-pacifica\">Sanchez Dog Park</a> - Great park. Bitchy neighbors.</li>\n<li><a href=\"https://plus.google.com/108112625069629536663/about?gl=us&amp;hl=en\">Pacifica State Beach</a> - THE PLACE to learn to surf, bodyboard, swim. Get a lesson a NorCal Surf Shop.</li>\n</ol></p>", "content_raw": "<p><p>Pacifica is a small town just over the hump from the rest of the peninsula, making it a great place to live, surf, play. What follows is a guide to the best of Pacifica for new friends that have moved to the area.\n\n</p><ol><li><a href=\"http://www.mazzettisbakery.com/\">Mazetti\u2019s Bakery (Flash only)</a> - <a href=\"http://www.yelp.com/biz/mazzettis-bakery-pacifica\">Yelp</a> -  Amazing cupcakes, pies, cookies, coffee and pastries and up at 6AM daily.</li>\n<li><a href=\"http://www.oceanfishsushi.com/\">Ocean Fish</a> - Great sushi at great prices. Delivers.</li>\n<li><a href=\"http://www.yelp.com/biz/bay-coffee-company-pacifica\">\nBay Coffee Company</a> - Best cup of coffee, good wifi.</li>\n<li><a href=\"http://www.cityofpacifica.org/depts/rec_department/aquatics/adult_swim/default.asp\">Pacifica Pool at Oceana Highschool</a> - Great pool. Limited adult swim hours, but an all access pass is $67/month. Open till 8-9PM weekdays.</li>\n<li><a href=\"http://norcalsurfshop.com/\">Nor Cal Surf Shop</a> - Great surf/bodyboarding shop. Wetsuits, boards, fins, plus great NorCal attire. Yes, this is the shop name you see everyone wearing :)</li>\n<li><a href=\"http://www.yelp.com/biz/high-tide-restaurant-cafe-and-creperie-pacifica#query:crepes\">High Tide Restaurant-Cafe and Creperie</a> - great brunch. Amazing crepes.</li>\n<li><a href=\"http://www.coastsidefarmersmarket.org/\">Coastside Farmers Market</a> - The best produce, by Safeway.</li>\n<li><a href=\"https://plus.google.com/103987053706080475477/about?gl=us&amp;hl=en\">Oil Changers</a> - $7 deluxe carwash with super-fun tricolor foam!</li>\n<li><a href=\"http://www.yelp.com/biz/pacifica-dog-park-at-sanchez-art-center-pacifica\">Sanchez Dog Park</a> - Great park. Bitchy neighbors.</li>\n<li><a href=\"https://plus.google.com/108112625069629536663/about?gl=us&amp;hl=en\">Pacifica State Beach</a> - THE PLACE to learn to surf, bodyboard, swim. Get a lesson a NorCal Surf Shop.</li>\n</ol></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "41546210399"}}], "date": "2013-01-26 20:33:00 GMT", "slug": "best-of-pacifica", "blog_name": "rjurney", "summary": "Best of Pacifica", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "vDihwDQl", "short_url": "https://tmblr.co/ZbIO5ycBAjsm", "can_send_in_message": true, "id": 40989547952, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/40989547952", "tags": [], "post_url": "http://datasyndrome.com/post/40989547952/microwave-idli-at-pacific-manor-plaza", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Microwave Idli!  (at Pacific Manor Plaza)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1358661041, "note_count": 0, "trail": [{"content": "<p>Microwave Idli!  (at Pacific Manor Plaza)</p>", "content_raw": "<p>Microwave Idli!  (at Pacific Manor Plaza)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "40989547952"}}], "date": "2013-01-20 05:50:41 GMT", "slug": "microwave-idli-at-pacific-manor-plaza", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/aa5406c593c97899e0b693ee248db628/tumblr_mgwtkhmL4R1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/aa5406c593c97899e0b693ee248db628/tumblr_mgwtkhmL4R1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/aa5406c593c97899e0b693ee248db628/tumblr_mgwtkhmL4R1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/aa5406c593c97899e0b693ee248db628/tumblr_mgwtkhmL4R1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/aa5406c593c97899e0b693ee248db628/tumblr_mgwtkhmL4R1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/aa5406c593c97899e0b693ee248db628/tumblr_mgwtkhmL4R1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/aa5406c593c97899e0b693ee248db628/tumblr_mgwtkhmL4R1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/UscahgRTxe/", "summary": "Microwave Idli!  (at Pacific Manor Plaza)", "caption": "<p>Microwave Idli!  (at Pacific Manor Plaza)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "8RUw1bBF", "short_url": "https://tmblr.co/ZbIO5ybc9iKh", "can_send_in_message": true, "id": 40368522539, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/40368522539", "tags": [], "post_url": "http://datasyndrome.com/post/40368522539/lots-of-fun-at-linda-mar-at-pacifica-state-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Lots of fun at Linda Mar (at Pacifica State Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1358027904, "note_count": 0, "trail": [{"content": "<p>Lots of fun at Linda Mar (at Pacifica State Beach)</p>", "content_raw": "<p>Lots of fun at Linda Mar (at Pacifica State Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "40368522539"}}], "date": "2013-01-12 21:58:24 GMT", "slug": "lots-of-fun-at-linda-mar-at-pacifica-state-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/729c2181273510f8bdd864360072ccd5/tumblr_mgj91c6Ag61qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/729c2181273510f8bdd864360072ccd5/tumblr_mgj91c6Ag61qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/729c2181273510f8bdd864360072ccd5/tumblr_mgj91c6Ag61qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/729c2181273510f8bdd864360072ccd5/tumblr_mgj91c6Ag61qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/729c2181273510f8bdd864360072ccd5/tumblr_mgj91c6Ag61qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/729c2181273510f8bdd864360072ccd5/tumblr_mgj91c6Ag61qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/729c2181273510f8bdd864360072ccd5/tumblr_mgj91c6Ag61qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/UZk20mxT4B/", "summary": "Lots of fun at Linda Mar (at Pacifica State Beach)", "caption": "<p>Lots of fun at Linda Mar (at Pacifica State Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "fdllY2XX", "short_url": "https://tmblr.co/ZbIO5ybWd-3e", "can_send_in_message": true, "id": 40275800296, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/40275800296", "tags": [], "post_url": "http://datasyndrome.com/post/40275800296/at-java-beach-cafe-great-coffee-at-ocean-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>At Java Beach Cafe, great coffee at Ocean Beach (at Java Beach Cafe)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1357937804, "note_count": 0, "trail": [{"content": "<p>At Java Beach Cafe, great coffee at Ocean Beach (at Java Beach Cafe)</p>", "content_raw": "<p>At Java Beach Cafe, great coffee at Ocean Beach (at Java Beach Cafe)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "40275800296"}}], "date": "2013-01-11 20:56:44 GMT", "slug": "at-java-beach-cafe-great-coffee-at-ocean-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/faa27b4cbc5d9cd72db2ef0e113354f3/tumblr_mghbilZR7W1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/faa27b4cbc5d9cd72db2ef0e113354f3/tumblr_mghbilZR7W1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/faa27b4cbc5d9cd72db2ef0e113354f3/tumblr_mghbilZR7W1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/faa27b4cbc5d9cd72db2ef0e113354f3/tumblr_mghbilZR7W1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/faa27b4cbc5d9cd72db2ef0e113354f3/tumblr_mghbilZR7W1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/faa27b4cbc5d9cd72db2ef0e113354f3/tumblr_mghbilZR7W1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/faa27b4cbc5d9cd72db2ef0e113354f3/tumblr_mghbilZR7W1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/UW493sxT6o/", "summary": "At Java Beach Cafe, great coffee at Ocean Beach (at Java Beach Cafe)", "caption": "<p>At Java Beach Cafe, great coffee at Ocean Beach (at Java Beach Cafe)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "HUZSWWYI", "short_url": "https://tmblr.co/ZbIO5ybEOBoi", "can_send_in_message": true, "id": 39969668268, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39969668268", "tags": [], "post_url": "http://datasyndrome.com/post/39969668268/sutro-at-sutro-baths-at-sutro-baths-ruins", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Sutro at Sutro baths (at Sutro Baths Ruins)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1357605622, "note_count": 0, "trail": [{"content": "<p>Sutro at Sutro baths (at Sutro Baths Ruins)</p>", "content_raw": "<p>Sutro at Sutro baths (at Sutro Baths Ruins)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39969668268"}}], "date": "2013-01-08 00:40:22 GMT", "slug": "sutro-at-sutro-baths-at-sutro-baths-ruins", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/4f234ceaea87aa04c66f4d1c2fc24d35/tumblr_mga77aB6031qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/4f234ceaea87aa04c66f4d1c2fc24d35/tumblr_mga77aB6031qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/4f234ceaea87aa04c66f4d1c2fc24d35/tumblr_mga77aB6031qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/4f234ceaea87aa04c66f4d1c2fc24d35/tumblr_mga77aB6031qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/4f234ceaea87aa04c66f4d1c2fc24d35/tumblr_mga77aB6031qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/4f234ceaea87aa04c66f4d1c2fc24d35/tumblr_mga77aB6031qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/4f234ceaea87aa04c66f4d1c2fc24d35/tumblr_mga77aB6031qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/UM_bCWRT14/", "summary": "Sutro at Sutro baths (at Sutro Baths Ruins)", "caption": "<p>Sutro at Sutro baths (at Sutro Baths Ruins)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "x2dJF3XW", "short_url": "https://tmblr.co/ZbIO5yb9IWGq", "can_send_in_message": true, "id": 39884293172, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39884293172", "tags": [], "post_url": "http://datasyndrome.com/post/39884293172/coffee-and-cupcakes-with-kjurney-at-mazzettis", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Coffee and cupcakes with @kjurney (at Mazzetti\u2019s Bakery)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1357519501, "note_count": 0, "trail": [{"content": "<p>Coffee and cupcakes with @kjurney (at Mazzetti&rsquo;s Bakery)</p>", "content_raw": "<p>Coffee and cupcakes with @kjurney (at Mazzetti\u2019s Bakery)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39884293172"}}], "date": "2013-01-07 00:45:01 GMT", "slug": "coffee-and-cupcakes-with-kjurney-at-mazzettis", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/bedc5b737642c3052c485f6f835ef28c/tumblr_mg8cr29KNa1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/bedc5b737642c3052c485f6f835ef28c/tumblr_mg8cr29KNa1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/bedc5b737642c3052c485f6f835ef28c/tumblr_mg8cr29KNa1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/bedc5b737642c3052c485f6f835ef28c/tumblr_mg8cr29KNa1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/bedc5b737642c3052c485f6f835ef28c/tumblr_mg8cr29KNa1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/bedc5b737642c3052c485f6f835ef28c/tumblr_mg8cr29KNa1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/bedc5b737642c3052c485f6f835ef28c/tumblr_mg8cr29KNa1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/UKbFRHRT_p/", "summary": "Coffee and cupcakes with @kjurney (at Mazzetti's Bakery)", "caption": "<p>Coffee and cupcakes with @kjurney (at Mazzetti&rsquo;s Bakery)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "fZ2rYkHt", "short_url": "https://tmblr.co/ZbIO5yanBsHI", "can_send_in_message": true, "id": 39479895122, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39479895122", "tags": [], "post_url": "http://datasyndrome.com/post/39479895122/apple-turnover-at-mazettis-6-for-coffee-and", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Apple turnover at Mazetti\u2019s, $6 for coffee and danish for two. Standout. (at Mazzetti\u2019s Bakery)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1357143962, "note_count": 0, "trail": [{"content": "<p>Apple turnover at Mazetti&rsquo;s, $6 for coffee and danish for two. Standout. (at Mazzetti&rsquo;s Bakery)</p>", "content_raw": "<p>Apple turnover at Mazetti\u2019s, $6 for coffee and danish for two. Standout. (at Mazzetti\u2019s Bakery)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39479895122"}}], "date": "2013-01-02 16:26:02 GMT", "slug": "apple-turnover-at-mazettis-6-for-coffee-and", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/56086a3c7583ceaf5e9dd12e758025c1/tumblr_mg0azeLsnN1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/56086a3c7583ceaf5e9dd12e758025c1/tumblr_mg0azeLsnN1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/56086a3c7583ceaf5e9dd12e758025c1/tumblr_mg0azeLsnN1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/56086a3c7583ceaf5e9dd12e758025c1/tumblr_mg0azeLsnN1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/56086a3c7583ceaf5e9dd12e758025c1/tumblr_mg0azeLsnN1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/56086a3c7583ceaf5e9dd12e758025c1/tumblr_mg0azeLsnN1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/56086a3c7583ceaf5e9dd12e758025c1/tumblr_mg0azeLsnN1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T_OyqrxT7q/", "summary": "Apple turnover at Mazetti's, $6 for coffee and danish for two. Standout. (at Mazzetti's Bakery)", "caption": "<p>Apple turnover at Mazetti&rsquo;s, $6 for coffee and danish for two. Standout. (at Mazzetti&rsquo;s Bakery)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "alm5hFBk", "short_url": "https://tmblr.co/ZbIO5yajZr5k", "can_send_in_message": true, "id": 39419072878, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39419072878", "tags": [], "post_url": "http://datasyndrome.com/post/39419072878/2-3x-overhead-i-lack-those-cojones-at-rockaway", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>2-3x overhead. I lack those cojones. (at Rockaway Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1357082680, "note_count": 0, "trail": [{"content": "<p>2-3x overhead. I lack those cojones. (at Rockaway Beach)</p>", "content_raw": "<p>2-3x overhead. I lack those cojones. (at Rockaway Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39419072878"}}], "date": "2013-01-01 23:24:40 GMT", "slug": "2-3x-overhead-i-lack-those-cojones-at-rockaway", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/6dbd6b3890b5f626bfaa1a1329456946/tumblr_mfyzp4bMxn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/6dbd6b3890b5f626bfaa1a1329456946/tumblr_mfyzp4bMxn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/6dbd6b3890b5f626bfaa1a1329456946/tumblr_mfyzp4bMxn1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/6dbd6b3890b5f626bfaa1a1329456946/tumblr_mfyzp4bMxn1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/6dbd6b3890b5f626bfaa1a1329456946/tumblr_mfyzp4bMxn1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/6dbd6b3890b5f626bfaa1a1329456946/tumblr_mfyzp4bMxn1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/6dbd6b3890b5f626bfaa1a1329456946/tumblr_mfyzp4bMxn1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T9Z6eCRTxI/", "summary": "2-3x overhead. I lack those cojones. (at Rockaway Beach)", "caption": "<p>2-3x overhead. I lack those cojones. (at Rockaway Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "77TLcbQs", "short_url": "https://tmblr.co/ZbIO5yafZYZc", "can_send_in_message": true, "id": 39351888102, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39351888102", "tags": [], "post_url": "http://datasyndrome.com/post/39351888102/miss-piggie-edits-like-a-boss-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Miss Piggie edits like a boss. (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1357007794, "note_count": 0, "trail": [{"content": "<p>Miss Piggie edits like a boss. (at Manor Beach)</p>", "content_raw": "<p>Miss Piggie edits like a boss. (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39351888102"}}], "date": "2013-01-01 02:36:34 GMT", "slug": "miss-piggie-edits-like-a-boss-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/9008463ec288346eb71f1cfa900f8d2f/tumblr_mfxdwyarcW1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/9008463ec288346eb71f1cfa900f8d2f/tumblr_mfxdwyarcW1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/9008463ec288346eb71f1cfa900f8d2f/tumblr_mfxdwyarcW1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/9008463ec288346eb71f1cfa900f8d2f/tumblr_mfxdwyarcW1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/9008463ec288346eb71f1cfa900f8d2f/tumblr_mfxdwyarcW1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/9008463ec288346eb71f1cfa900f8d2f/tumblr_mfxdwyarcW1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/9008463ec288346eb71f1cfa900f8d2f/tumblr_mfxdwyarcW1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T7LCxyRT1i/", "summary": "Miss Piggie edits like a boss. (at Manor Beach)", "caption": "<p>Miss Piggie edits like a boss. (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "U2zNnaL4", "short_url": "https://tmblr.co/ZbIO5yaZvNRq", "can_send_in_message": true, "id": 39256946420, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39256946420", "tags": [], "post_url": "http://datasyndrome.com/post/39256946420/blue-and-gold-macaw-at-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Blue and Gold Macaw (at Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356912553, "note_count": 1, "trail": [{"content": "<p>Blue and Gold Macaw (at Oakland Zoo)</p>", "content_raw": "<p>Blue and Gold Macaw (at Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39256946420"}}], "date": "2012-12-31 00:09:13 GMT", "slug": "blue-and-gold-macaw-at-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/9456e2acad520a144cb749dd79e58ad4/tumblr_mfvcfdv09B1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/9456e2acad520a144cb749dd79e58ad4/tumblr_mfvcfdv09B1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/9456e2acad520a144cb749dd79e58ad4/tumblr_mfvcfdv09B1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/9456e2acad520a144cb749dd79e58ad4/tumblr_mfvcfdv09B1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/9456e2acad520a144cb749dd79e58ad4/tumblr_mfvcfdv09B1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/9456e2acad520a144cb749dd79e58ad4/tumblr_mfvcfdv09B1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/9456e2acad520a144cb749dd79e58ad4/tumblr_mfvcfdv09B1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4Vg-axT12/", "summary": "Blue and Gold Macaw (at Oakland Zoo)", "caption": "<p>Blue and Gold Macaw (at Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "eDOzzcbf", "short_url": "https://tmblr.co/ZbIO5yaZRsvg", "can_send_in_message": true, "id": 39249210986, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39249210986", "tags": [], "post_url": "http://datasyndrome.com/post/39249210986/big-turtle-at-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Big turtle (at Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356906890, "note_count": 1, "trail": [{"content": "<p>Big turtle (at Oakland Zoo)</p>", "content_raw": "<p>Big turtle (at Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39249210986"}}], "date": "2012-12-30 22:34:50 GMT", "slug": "big-turtle-at-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/faedcf37b22c0ea0b065699c1004f932/tumblr_mfv823rmmB1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/faedcf37b22c0ea0b065699c1004f932/tumblr_mfv823rmmB1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/faedcf37b22c0ea0b065699c1004f932/tumblr_mfv823rmmB1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/faedcf37b22c0ea0b065699c1004f932/tumblr_mfv823rmmB1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/faedcf37b22c0ea0b065699c1004f932/tumblr_mfv823rmmB1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/faedcf37b22c0ea0b065699c1004f932/tumblr_mfv823rmmB1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/faedcf37b22c0ea0b065699c1004f932/tumblr_mfv823rmmB1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4KtBaxT5O/", "summary": "Big turtle (at Oakland Zoo)", "caption": "<p>Big turtle (at Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "SA1l5TKr", "short_url": "https://tmblr.co/ZbIO5yaZQfq2", "can_send_in_message": true, "id": 39248895234, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39248895234", "tags": [], "post_url": "http://datasyndrome.com/post/39248895234/otters-are-great-at-play-area-in-the-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Otters are great (at Play Area in the Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356906656, "note_count": 0, "trail": [{"content": "<p>Otters are great (at Play Area in the Oakland Zoo)</p>", "content_raw": "<p>Otters are great (at Play Area in the Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39248895234"}}], "date": "2012-12-30 22:30:56 GMT", "slug": "otters-are-great-at-play-area-in-the-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/f3d09ed5bf262de59e36db5999fbfe9d/tumblr_mfv7vkjxGm1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/f3d09ed5bf262de59e36db5999fbfe9d/tumblr_mfv7vkjxGm1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/f3d09ed5bf262de59e36db5999fbfe9d/tumblr_mfv7vkjxGm1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/f3d09ed5bf262de59e36db5999fbfe9d/tumblr_mfv7vkjxGm1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/f3d09ed5bf262de59e36db5999fbfe9d/tumblr_mfv7vkjxGm1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/f3d09ed5bf262de59e36db5999fbfe9d/tumblr_mfv7vkjxGm1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/f3d09ed5bf262de59e36db5999fbfe9d/tumblr_mfv7vkjxGm1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4KQ5pRT4x/", "summary": "Otters are great (at Play Area in the Oakland Zoo)", "caption": "<p>Otters are great (at Play Area in the Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "zkZrR8Yl", "short_url": "https://tmblr.co/ZbIO5yaZPslm", "can_send_in_message": true, "id": 39248686064, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39248686064", "tags": [], "post_url": "http://datasyndrome.com/post/39248686064/mating-frogs-at-play-area-in-the-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Mating frogs (at Play Area in the Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356906506, "note_count": 0, "trail": [{"content": "<p>Mating frogs (at Play Area in the Oakland Zoo)</p>", "content_raw": "<p>Mating frogs (at Play Area in the Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39248686064"}}], "date": "2012-12-30 22:28:26 GMT", "slug": "mating-frogs-at-play-area-in-the-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/ac5445807fe728aea03e852d5ffffc51/tumblr_mfv7rfFRN21qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/ac5445807fe728aea03e852d5ffffc51/tumblr_mfv7rfFRN21qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/ac5445807fe728aea03e852d5ffffc51/tumblr_mfv7rfFRN21qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/ac5445807fe728aea03e852d5ffffc51/tumblr_mfv7rfFRN21qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/ac5445807fe728aea03e852d5ffffc51/tumblr_mfv7rfFRN21qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/ac5445807fe728aea03e852d5ffffc51/tumblr_mfv7rfFRN21qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/ac5445807fe728aea03e852d5ffffc51/tumblr_mfv7rfFRN21qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4J_Y4RT4h/", "summary": "Mating frogs (at Play Area in the Oakland Zoo)", "caption": "<p>Mating frogs (at Play Area in the Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "u05wIY9S", "short_url": "https://tmblr.co/ZbIO5yaZOcIa", "can_send_in_message": true, "id": 39248356516, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39248356516", "tags": [], "post_url": "http://datasyndrome.com/post/39248356516/bats-sleeping-at-play-area-in-the-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Bats sleeping (at Play Area in the Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356906265, "note_count": 0, "trail": [{"content": "<p>Bats sleeping (at Play Area in the Oakland Zoo)</p>", "content_raw": "<p>Bats sleeping (at Play Area in the Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39248356516"}}], "date": "2012-12-30 22:24:25 GMT", "slug": "bats-sleeping-at-play-area-in-the-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/cd2b0801d700a67c9990cfe79791af1e/tumblr_mfv7kqMKgy1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/cd2b0801d700a67c9990cfe79791af1e/tumblr_mfv7kqMKgy1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/cd2b0801d700a67c9990cfe79791af1e/tumblr_mfv7kqMKgy1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/cd2b0801d700a67c9990cfe79791af1e/tumblr_mfv7kqMKgy1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/cd2b0801d700a67c9990cfe79791af1e/tumblr_mfv7kqMKgy1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/cd2b0801d700a67c9990cfe79791af1e/tumblr_mfv7kqMKgy1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/cd2b0801d700a67c9990cfe79791af1e/tumblr_mfv7kqMKgy1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4JgqWRT3w/", "summary": "Bats sleeping (at Play Area in the Oakland Zoo)", "caption": "<p>Bats sleeping (at Play Area in the Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "fDcKaf6D", "short_url": "https://tmblr.co/ZbIO5yaZ6HE0", "can_send_in_message": true, "id": 39243551616, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39243551616", "tags": [], "post_url": "http://datasyndrome.com/post/39243551616/a-frame-split-to-drink-at-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>A frame split to drink (at Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356902707, "note_count": 0, "trail": [{"content": "<p>A frame split to drink (at Oakland Zoo)</p>", "content_raw": "<p>A frame split to drink (at Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39243551616"}}], "date": "2012-12-30 21:25:07 GMT", "slug": "a-frame-split-to-drink-at-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/c70ad7bd7fe47272d050fb3a882da3d6/tumblr_mfv4tvyUfL1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/c70ad7bd7fe47272d050fb3a882da3d6/tumblr_mfv4tvyUfL1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/c70ad7bd7fe47272d050fb3a882da3d6/tumblr_mfv4tvyUfL1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/c70ad7bd7fe47272d050fb3a882da3d6/tumblr_mfv4tvyUfL1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/c70ad7bd7fe47272d050fb3a882da3d6/tumblr_mfv4tvyUfL1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/c70ad7bd7fe47272d050fb3a882da3d6/tumblr_mfv4tvyUfL1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/c70ad7bd7fe47272d050fb3a882da3d6/tumblr_mfv4tvyUfL1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4Ct9pxTwA/", "summary": "A frame split to drink (at Oakland Zoo)", "caption": "<p>A frame split to drink (at Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "wWdBUhWL", "short_url": "https://tmblr.co/ZbIO5yaZ5THi", "can_send_in_message": true, "id": 39243338860, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39243338860", "tags": [], "post_url": "http://datasyndrome.com/post/39243338860/sexy-giraffe-at-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Sexy giraffe (at Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356902546, "note_count": 0, "trail": [{"content": "<p>Sexy giraffe (at Oakland Zoo)</p>", "content_raw": "<p>Sexy giraffe (at Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39243338860"}}], "date": "2012-12-30 21:22:26 GMT", "slug": "sexy-giraffe-at-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/60dbb9d95b10a769a93fa26c9b1db3bc/tumblr_mfv4pee3r81qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/60dbb9d95b10a769a93fa26c9b1db3bc/tumblr_mfv4pee3r81qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/60dbb9d95b10a769a93fa26c9b1db3bc/tumblr_mfv4pee3r81qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/60dbb9d95b10a769a93fa26c9b1db3bc/tumblr_mfv4pee3r81qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/60dbb9d95b10a769a93fa26c9b1db3bc/tumblr_mfv4pee3r81qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/60dbb9d95b10a769a93fa26c9b1db3bc/tumblr_mfv4pee3r81qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/60dbb9d95b10a769a93fa26c9b1db3bc/tumblr_mfv4pee3r81qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4CZRaxT_g/", "summary": "Sexy giraffe (at Oakland Zoo)", "caption": "<p>Sexy giraffe (at Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "nhhuTmJp", "short_url": "https://tmblr.co/ZbIO5yaZ4wUN", "can_send_in_message": true, "id": 39243196311, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/39243196311", "tags": [], "post_url": "http://datasyndrome.com/post/39243196311/tiger-seems-fat-and-lazy-at-oakland-zoo", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Tiger seems fat and lazy (at Oakland Zoo)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356902438, "note_count": 0, "trail": [{"content": "<p>Tiger seems fat and lazy (at Oakland Zoo)</p>", "content_raw": "<p>Tiger seems fat and lazy (at Oakland Zoo)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "39243196311"}}], "date": "2012-12-30 21:20:38 GMT", "slug": "tiger-seems-fat-and-lazy-at-oakland-zoo", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/190aeddd8f490696d4ac2fd576b74a15/tumblr_mfv4mexhnn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/190aeddd8f490696d4ac2fd576b74a15/tumblr_mfv4mexhnn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/190aeddd8f490696d4ac2fd576b74a15/tumblr_mfv4mexhnn1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/190aeddd8f490696d4ac2fd576b74a15/tumblr_mfv4mexhnn1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/190aeddd8f490696d4ac2fd576b74a15/tumblr_mfv4mexhnn1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/190aeddd8f490696d4ac2fd576b74a15/tumblr_mfv4mexhnn1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/190aeddd8f490696d4ac2fd576b74a15/tumblr_mfv4mexhnn1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/T4CISexT_D/", "summary": "Tiger seems fat and lazy (at Oakland Zoo)", "caption": "<p>Tiger seems fat and lazy (at Oakland Zoo)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "cytEoNLo", "short_url": "https://tmblr.co/ZbIO5yaAGCqD", "can_send_in_message": true, "id": 38826724621, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38826724621", "tags": [], "post_url": "http://datasyndrome.com/post/38826724621/fun-times-earlier-at-rockaway-at-rockaway-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Fun times earlier at Rockaway\u2026 (at Rockaway Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356482385, "note_count": 1, "trail": [{"content": "<p>Fun times earlier at Rockaway&hellip; (at Rockaway Beach)</p>", "content_raw": "<p>Fun times earlier at Rockaway\u2026 (at Rockaway Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38826724621"}}], "date": "2012-12-26 00:39:45 GMT", "slug": "fun-times-earlier-at-rockaway-at-rockaway-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/96e09d73eaddabc4436e92e9c2a70e53/tumblr_mfm4iazIOe1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/96e09d73eaddabc4436e92e9c2a70e53/tumblr_mfm4iazIOe1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/96e09d73eaddabc4436e92e9c2a70e53/tumblr_mfm4iazIOe1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/96e09d73eaddabc4436e92e9c2a70e53/tumblr_mfm4iazIOe1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/96e09d73eaddabc4436e92e9c2a70e53/tumblr_mfm4iazIOe1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/96e09d73eaddabc4436e92e9c2a70e53/tumblr_mfm4iazIOe1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/96e09d73eaddabc4436e92e9c2a70e53/tumblr_mfm4iazIOe1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/Trg6SGxTwY/", "summary": "Fun times earlier at Rockaway... (at Rockaway Beach)", "caption": "<p>Fun times earlier at Rockaway&hellip; (at Rockaway Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "SiwGTBk6", "short_url": "https://tmblr.co/ZbIO5yaACZlv", "can_send_in_message": true, "id": 38825769977, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38825769977", "tags": [], "post_url": "http://datasyndrome.com/post/38825769977/i-did-more-good-helping-ppl-than-any-obama-ever", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>\u201cI did more good helping ppl than any Obama ever did!\u201d \u2013Bill Jurney on Housing Crisis, 2012 (at Whole Foods Market)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356481552, "note_count": 0, "trail": [{"content": "<p>&ldquo;I did more good helping ppl than any Obama ever did!&rdquo; &ndash;Bill Jurney on Housing Crisis, 2012 (at Whole Foods Market)</p>", "content_raw": "<p>\u201cI did more good helping ppl than any Obama ever did!\u201d \u2013Bill Jurney on Housing Crisis, 2012 (at Whole Foods Market)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38825769977"}}], "date": "2012-12-26 00:25:52 GMT", "slug": "i-did-more-good-helping-ppl-than-any-obama-ever", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/4699dfc61b6b6149f23e5334d137e7a7/tumblr_mfm3v4yb3k1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/4699dfc61b6b6149f23e5334d137e7a7/tumblr_mfm3v4yb3k1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/4699dfc61b6b6149f23e5334d137e7a7/tumblr_mfm3v4yb3k1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/4699dfc61b6b6149f23e5334d137e7a7/tumblr_mfm3v4yb3k1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/4699dfc61b6b6149f23e5334d137e7a7/tumblr_mfm3v4yb3k1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/4699dfc61b6b6149f23e5334d137e7a7/tumblr_mfm3v4yb3k1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/4699dfc61b6b6149f23e5334d137e7a7/tumblr_mfm3v4yb3k1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TrfO6iRT9x/", "summary": "\"I did more good helping ppl than any Obama ever did!\" --Bill Jurney on Housing Crisis, 2012 (at Whole Foods Market)", "caption": "<p>&ldquo;I did more good helping ppl than any Obama ever did!&rdquo; &ndash;Bill Jurney on Housing Crisis, 2012 (at Whole Foods Market)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "zrqQKYsS", "short_url": "https://tmblr.co/ZbIO5ya0mTjz", "can_send_in_message": true, "id": 38667410301, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38667410301", "tags": [], "post_url": "http://datasyndrome.com/post/38667410301/cant-see-past-the-breaking-waves-for-the-rain", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Can\u2019t see past the breaking waves for the rain. (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356307960, "note_count": 0, "trail": [{"content": "<p>Can&rsquo;t see past the breaking waves for the rain. (at Manor Beach)</p>", "content_raw": "<p>Can\u2019t see past the breaking waves for the rain. (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38667410301"}}], "date": "2012-12-24 00:12:40 GMT", "slug": "cant-see-past-the-breaking-waves-for-the-rain", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/0111c92f9f5954bd982bb112ba821ae9/tumblr_mfidx4PUJV1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/0111c92f9f5954bd982bb112ba821ae9/tumblr_mfidx4PUJV1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/0111c92f9f5954bd982bb112ba821ae9/tumblr_mfidx4PUJV1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/0111c92f9f5954bd982bb112ba821ae9/tumblr_mfidx4PUJV1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/0111c92f9f5954bd982bb112ba821ae9/tumblr_mfidx4PUJV1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/0111c92f9f5954bd982bb112ba821ae9/tumblr_mfidx4PUJV1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/0111c92f9f5954bd982bb112ba821ae9/tumblr_mfidx4PUJV1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TmUJXcRTyk/", "summary": "Can't see past the breaking waves for the rain. (at Manor Beach)", "caption": "<p>Can&rsquo;t see past the breaking waves for the rain. (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "g8aNDhRE", "short_url": "https://tmblr.co/ZbIO5yZ_mxGd", "can_send_in_message": true, "id": 38633976871, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38633976871", "tags": [], "post_url": "http://datasyndrome.com/post/38633976871/tights-snuggle-socks-and-cargos-i-u-at-bay", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Tights, snuggle socks and cargos. I < U. (at Bay Coffee Company)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356281324, "note_count": 0, "trail": [{"content": "<p>Tights, snuggle socks and cargos. I </p>", "content_raw": "<p>Tights, snuggle socks and cargos. I < U. (at Bay Coffee Company)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38633976871"}}], "date": "2012-12-23 16:48:44 GMT", "slug": "tights-snuggle-socks-and-cargos-i-u-at-bay", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/273690f78704cace814f067ba27e63bd/tumblr_mfhtd9PMRr1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/273690f78704cace814f067ba27e63bd/tumblr_mfhtd9PMRr1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/273690f78704cace814f067ba27e63bd/tumblr_mfhtd9PMRr1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/273690f78704cace814f067ba27e63bd/tumblr_mfhtd9PMRr1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/273690f78704cace814f067ba27e63bd/tumblr_mfhtd9PMRr1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/273690f78704cace814f067ba27e63bd/tumblr_mfhtd9PMRr1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/273690f78704cace814f067ba27e63bd/tumblr_mfhtd9PMRr1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TlhY0vxTzM/", "summary": "Tights, snuggle socks and cargos. I < U. (at Bay Coffee Company)", "caption": "<p>Tights, snuggle socks and cargos. I &lt; U. (at Bay Coffee Company)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "xXagL27i", "short_url": "https://tmblr.co/ZbIO5yZ_kmJw", "can_send_in_message": true, "id": 38633407738, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38633407738", "tags": [], "post_url": "http://datasyndrome.com/post/38633407738/30-pages-into-editing-agile-data-at-bay-coffee", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>30 pages into editing Agile Data! (at Bay Coffee Company)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356280810, "note_count": 1, "trail": [{"content": "<p>30 pages into editing Agile Data! (at Bay Coffee Company)</p>", "content_raw": "<p>30 pages into editing Agile Data! (at Bay Coffee Company)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38633407738"}}], "date": "2012-12-23 16:40:10 GMT", "slug": "30-pages-into-editing-agile-data-at-bay-coffee", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/069388de9c93728bef631e84cebf6ed7/tumblr_mfhsyyLXQ61qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/069388de9c93728bef631e84cebf6ed7/tumblr_mfhsyyLXQ61qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/069388de9c93728bef631e84cebf6ed7/tumblr_mfhsyyLXQ61qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/069388de9c93728bef631e84cebf6ed7/tumblr_mfhsyyLXQ61qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/069388de9c93728bef631e84cebf6ed7/tumblr_mfhsyyLXQ61qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/069388de9c93728bef631e84cebf6ed7/tumblr_mfhsyyLXQ61qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/069388de9c93728bef631e84cebf6ed7/tumblr_mfhsyyLXQ61qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TlghXxxTyN/", "summary": "30 pages into editing Agile Data! (at Bay Coffee Company)", "caption": "<p>30 pages into editing Agile Data! (at Bay Coffee Company)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "OXD2p3u7", "short_url": "https://tmblr.co/ZbIO5yZ_MKe2", "can_send_in_message": true, "id": 38627002882, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38627002882", "tags": [], "post_url": "http://datasyndrome.com/post/38627002882/editing-crap-into-gold-at-mazzettis-bakery", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Editing crap into gold\u2026 (at Mazzetti\u2019s Bakery)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356274282, "note_count": 0, "trail": [{"content": "<p>Editing crap into gold&hellip; (at Mazzetti&rsquo;s Bakery)</p>", "content_raw": "<p>Editing crap into gold\u2026 (at Mazzetti\u2019s Bakery)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38627002882"}}], "date": "2012-12-23 14:51:22 GMT", "slug": "editing-crap-into-gold-at-mazzettis-bakery", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/65396a4ffcdb66eff2579bb460ce2a7c/tumblr_mfhnxnTQRQ1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/65396a4ffcdb66eff2579bb460ce2a7c/tumblr_mfhnxnTQRQ1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/65396a4ffcdb66eff2579bb460ce2a7c/tumblr_mfhnxnTQRQ1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/65396a4ffcdb66eff2579bb460ce2a7c/tumblr_mfhnxnTQRQ1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/65396a4ffcdb66eff2579bb460ce2a7c/tumblr_mfhnxnTQRQ1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/65396a4ffcdb66eff2579bb460ce2a7c/tumblr_mfhnxnTQRQ1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/65396a4ffcdb66eff2579bb460ce2a7c/tumblr_mfhnxnTQRQ1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TlUBnQxT2N/", "summary": "Editing crap into gold... (at Mazzetti's Bakery)", "caption": "<p>Editing crap into gold&hellip; (at Mazzetti&rsquo;s Bakery)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "I5yjIdAG", "short_url": "https://tmblr.co/ZbIO5yZ_L69P", "can_send_in_message": true, "id": 38626681433, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38626681433", "tags": [], "post_url": "http://datasyndrome.com/post/38626681433/editing-a-bound-manuscript-of-agile-data-thanks", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Editing a bound manuscript of Agile Data. Thanks @kjurney!</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356273891, "note_count": 0, "trail": [{"content": "<p>Editing a bound manuscript of Agile Data. Thanks @kjurney!</p>", "content_raw": "<p>Editing a bound manuscript of Agile Data. Thanks @kjurney!</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38626681433"}}], "date": "2012-12-23 14:44:51 GMT", "slug": "editing-a-bound-manuscript-of-agile-data-thanks", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/e4e6dccc86763011e722913dee21babf/tumblr_mfhnms4brI1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/e4e6dccc86763011e722913dee21babf/tumblr_mfhnms4brI1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/e4e6dccc86763011e722913dee21babf/tumblr_mfhnms4brI1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/e4e6dccc86763011e722913dee21babf/tumblr_mfhnms4brI1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/e4e6dccc86763011e722913dee21babf/tumblr_mfhnms4brI1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/e4e6dccc86763011e722913dee21babf/tumblr_mfhnms4brI1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/e4e6dccc86763011e722913dee21babf/tumblr_mfhnms4brI1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TlTIIJRT1L/", "summary": "Editing a bound manuscript of Agile Data. Thanks @kjurney!", "caption": "<p>Editing a bound manuscript of Agile Data. Thanks @kjurney!</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "SIA3A39Y", "short_url": "https://tmblr.co/ZbIO5yZwxKVA", "can_send_in_message": true, "id": 38569592778, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38569592778", "tags": [], "post_url": "http://datasyndrome.com/post/38569592778/me-and-miss-piggie-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Me and Miss Piggie (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356210655, "note_count": 0, "trail": [{"content": "<p>Me and Miss Piggie (at Manor Beach)</p>", "content_raw": "<p>Me and Miss Piggie (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38569592778"}}], "date": "2012-12-22 21:10:55 GMT", "slug": "me-and-miss-piggie-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/85ad0cf6cb78b8fca52ef42aff259cac/tumblr_mfgau7jJwn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/85ad0cf6cb78b8fca52ef42aff259cac/tumblr_mfgau7jJwn1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/85ad0cf6cb78b8fca52ef42aff259cac/tumblr_mfgau7jJwn1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/85ad0cf6cb78b8fca52ef42aff259cac/tumblr_mfgau7jJwn1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/85ad0cf6cb78b8fca52ef42aff259cac/tumblr_mfgau7jJwn1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/85ad0cf6cb78b8fca52ef42aff259cac/tumblr_mfgau7jJwn1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/85ad0cf6cb78b8fca52ef42aff259cac/tumblr_mfgau7jJwn1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/Tjash9xT-I/", "summary": "Me and Miss Piggie (at Manor Beach)", "caption": "<p>Me and Miss Piggie (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "LsfQgyUq", "short_url": "https://tmblr.co/ZbIO5yZwvoJR", "can_send_in_message": true, "id": 38569190619, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38569190619", "tags": [], "post_url": "http://datasyndrome.com/post/38569190619/editing-my-book-at-manor-beach", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>Editing my book\u2026 (at Manor Beach)</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356210321, "note_count": 0, "trail": [{"content": "<p>Editing my book&hellip; (at Manor Beach)</p>", "content_raw": "<p>Editing my book\u2026 (at Manor Beach)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38569190619"}}], "date": "2012-12-22 21:05:21 GMT", "slug": "editing-my-book-at-manor-beach", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/73eb5ec955ea41ffd73464f3fb4f654b/tumblr_mfgakx4gPP1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/73eb5ec955ea41ffd73464f3fb4f654b/tumblr_mfgakx4gPP1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/73eb5ec955ea41ffd73464f3fb4f654b/tumblr_mfgakx4gPP1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/73eb5ec955ea41ffd73464f3fb4f654b/tumblr_mfgakx4gPP1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/73eb5ec955ea41ffd73464f3fb4f654b/tumblr_mfgakx4gPP1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/73eb5ec955ea41ffd73464f3fb4f654b/tumblr_mfgakx4gPP1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/73eb5ec955ea41ffd73464f3fb4f654b/tumblr_mfgakx4gPP1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TjaFrUxT9c/", "summary": "Editing my book... (at Manor Beach)", "caption": "<p>Editing my book&hellip; (at Manor Beach)</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "HcuaimET", "short_url": "https://tmblr.co/ZbIO5yZrMAME", "can_send_in_message": true, "id": 38475965838, "display_avatar": true, "can_reply": true, "can_like": false, "image_permalink": "http://datasyndrome.com/image/38475965838", "tags": [], "post_url": "http://datasyndrome.com/post/38475965838/i-got-a-thermos-made-green-tea-last-night-still", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>I got a thermos! Made green tea last night, still warm.</p>", "tree_html": ""}, "type": "photo", "recommended_color": null, "format": "html", "timestamp": 1356112960, "note_count": 0, "trail": [{"content": "<p>I got a thermos! Made green tea last night, still warm.</p>", "content_raw": "<p>I got a thermos! Made green tea last night, still warm.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "38475965838"}}], "date": "2012-12-21 18:02:40 GMT", "slug": "i-got-a-thermos-made-green-tea-last-night-still", "blog_name": "rjurney", "photos": [{"caption": "", "original_size": {"url": "https://68.media.tumblr.com/dffe317176d087239f8b6943c87ea560/tumblr_mfe7ggy8jN1qe7pymo1_1280.jpg", "width": 612, "height": 612}, "alt_sizes": [{"url": "https://68.media.tumblr.com/dffe317176d087239f8b6943c87ea560/tumblr_mfe7ggy8jN1qe7pymo1_1280.jpg", "width": 612, "height": 612}, {"url": "https://68.media.tumblr.com/dffe317176d087239f8b6943c87ea560/tumblr_mfe7ggy8jN1qe7pymo1_500.jpg", "width": 500, "height": 500}, {"url": "https://68.media.tumblr.com/dffe317176d087239f8b6943c87ea560/tumblr_mfe7ggy8jN1qe7pymo1_400.jpg", "width": 400, "height": 400}, {"url": "https://68.media.tumblr.com/dffe317176d087239f8b6943c87ea560/tumblr_mfe7ggy8jN1qe7pymo1_250.jpg", "width": 250, "height": 250}, {"url": "https://68.media.tumblr.com/dffe317176d087239f8b6943c87ea560/tumblr_mfe7ggy8jN1qe7pymo1_100.jpg", "width": 100, "height": 100}, {"url": "https://68.media.tumblr.com/dffe317176d087239f8b6943c87ea560/tumblr_mfe7ggy8jN1qe7pymo1_75sq.jpg", "width": 75, "height": 75}]}], "link_url": "http://instagr.am/p/TggPGuxT3U/", "summary": "I got a thermos! Made green tea last night, still warm.", "caption": "<p>I got a thermos! Made green tea last night, still warm.</p>", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "m6DQQA0c", "short_url": "https://tmblr.co/ZbIO5yVXMMx-", "excerpt": null, "link_author": null, "id": 33845505791, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Pig Meetup during Strata NYC!", "tags": [], "post_url": "http://datasyndrome.com/post/33845505791/pig-meetup-during-strata-nyc", "recommended_source": null, "state": "published", "reblog": {"comment": "", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "", "format": "html", "timestamp": 1350585686, "note_count": 1, "trail": [], "date": "2012-10-18 18:41:26 GMT", "slug": "pig-meetup-during-strata-nyc", "blog_name": "rjurney", "publisher": "meetup.com", "url": "http://www.meetup.com/NYC-Pig-User-Group/events/85107232/", "can_send_in_message": true, "summary": "Pig Meetup during Strata NYC!", "can_reblog": true}, {"body": "<p>Check out my latest post on the Hortonworks Blog: <a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\">http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/</a></p>\n\n<p><a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\"><i>In this post, we are going to mine topics from the Enron email message bodies via TF-IDF using Pig Streaming with Python\u2019s NLTK library and store them in Cassandra to be served in a REST API via Python and Flask.</i></a></p>", "liked": false, "followed": false, "reblog_key": "F5t14GVg", "reblog": {"comment": "<p>Check out my latest post on the Hortonworks Blog: <a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\">http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/</a></p>\n\n<p><a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\"><i>In this post, we are going to mine topics from the Enron email message bodies via TF-IDF using Pig Streaming with Python\u2019s NLTK library and store them in Cassandra to be served in a REST API via Python and Flask.</i></a></p>", "tree_html": ""}, "can_send_in_message": true, "id": 31884124467, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Pig as Duct Tape, Part Three: TF-IDF Topics with Cassandra, Python Streaming and Flask", "tags": [], "post_url": "http://datasyndrome.com/post/31884124467/pig-as-duct-tape-part-three-tf-idf-topics-with", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yTiSI4p", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1348094605, "note_count": 1, "trail": [{"content": "<p>Check out my latest post on the Hortonworks Blog: <a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\">http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/</a></p>\n\n<p><a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\"><i>In this post, we are going to mine topics from the Enron email message bodies via TF-IDF using Pig Streaming with Python&rsquo;s NLTK library and store them in Cassandra to be served in a REST API via Python and Flask.</i></a></p>", "content_raw": "<p>Check out my latest post on the Hortonworks Blog: <a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\">http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/</a></p>\n\n<p><a href=\"http://hortonworks.com/blog/pig-as-duct-tape-part-three-tf-idf-topics-with-cassandra-python-streaming-and-flask/\"><i>In this post, we are going to mine topics from the Enron email message bodies via TF-IDF using Pig Streaming with Python\u2019s NLTK library and store them in Cassandra to be served in a REST API via Python and Flask.</i></a></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "31884124467"}}], "date": "2012-09-19 22:43:25 GMT", "slug": "pig-as-duct-tape-part-three-tf-idf-topics-with", "blog_name": "rjurney", "summary": "Pig as Duct Tape, Part Three: TF-IDF Topics with Cassandra, Python Streaming and Flask", "can_reblog": true}, {"body": "<p><a href=\"http://hortonworks.com/blog/pig-as-hadoop-connector-part-two-hbase-jruby-and-sinatra/\"><i>Hadoop is about freedom as much as scale: providing you disk spindles and processor cores together to process your data with whatever tool you choose. Unleash your creativity. Pig as duct tape facilitates this freedom, enabling you to connect distributed systems at scale in minutes, not hours. In this post we\u2019ll demonstrate how you can turn raw data into a web service using Hadoop, Pig, HBase, JRuby and Sinatra. In doing so we will demonstrate yet another way to use Pig as connector to publish data you\u2019ve processed on Hadoop.</i></a>\n\n&hellip;\n\n</p><center><a href=\"http://hortonworks.com/blog/pig-as-hadoop-connector-part-two-hbase-jruby-and-sinatra/\"><img src=\"http://hortonworks.com/wp-content/uploads/2012/08/hbase_jruby.png\"/></a></center>", "liked": false, "followed": false, "reblog_key": "CbLBVR9r", "reblog": {"comment": "<p><p><a href=\"http://hortonworks.com/blog/pig-as-hadoop-connector-part-two-hbase-jruby-and-sinatra/\"><i>Hadoop is about freedom as much as scale: providing you disk spindles and processor cores together to process your data with whatever tool you choose. Unleash your creativity. Pig as duct tape facilitates this freedom, enabling you to connect distributed systems at scale in minutes, not hours. In this post we\u2019ll demonstrate how you can turn raw data into a web service using Hadoop, Pig, HBase, JRuby and Sinatra. In doing so we will demonstrate yet another way to use Pig as connector to publish data you\u2019ve processed on Hadoop.</i></a>\n\n\u2026\n\n</p><center><a href=\"http://hortonworks.com/blog/pig-as-hadoop-connector-part-two-hbase-jruby-and-sinatra/\"><img src=\"http://hortonworks.com/wp-content/uploads/2012/08/hbase_jruby.png\"></a></center></p>", "tree_html": ""}, "can_send_in_message": true, "id": 30313367855, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Hortonworks Blog, Pig as Hadoop Connector Part Two: HBase, JRuby and Sinatra", "tags": [], "post_url": "http://datasyndrome.com/post/30313367855/hortonworks-blog-pig-as-hadoop-connector-part", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5ySEqKal", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1346073000, "note_count": 0, "trail": [{"content": "<p><p><a href=\"http://hortonworks.com/blog/pig-as-hadoop-connector-part-two-hbase-jruby-and-sinatra/\"><i>Hadoop is about freedom as much as scale: providing you disk spindles and processor cores together to process your data with whatever tool you choose. Unleash your creativity. Pig as duct tape facilitates this freedom, enabling you to connect distributed systems at scale in minutes, not hours. In this post we&rsquo;ll demonstrate how you can turn raw data into a web service using Hadoop, Pig, HBase, JRuby and Sinatra. In doing so we will demonstrate yet another way to use Pig as connector to publish data you&rsquo;ve processed on Hadoop.</i></a>\n\n&hellip;\n\n</p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://hortonworks.com/wp-content/uploads/2012/08/hbase_jruby.png\">External image</div></p>", "content_raw": "<p><p><a href=\"http://hortonworks.com/blog/pig-as-hadoop-connector-part-two-hbase-jruby-and-sinatra/\"><i>Hadoop is about freedom as much as scale: providing you disk spindles and processor cores together to process your data with whatever tool you choose. Unleash your creativity. Pig as duct tape facilitates this freedom, enabling you to connect distributed systems at scale in minutes, not hours. In this post we\u2019ll demonstrate how you can turn raw data into a web service using Hadoop, Pig, HBase, JRuby and Sinatra. In doing so we will demonstrate yet another way to use Pig as connector to publish data you\u2019ve processed on Hadoop.</i></a>\n\n\u2026\n\n</p><center><a href=\"http://hortonworks.com/blog/pig-as-hadoop-connector-part-two-hbase-jruby-and-sinatra/\"><img src=\"http://hortonworks.com/wp-content/uploads/2012/08/hbase_jruby.png\"></a></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "30313367855"}}], "date": "2012-08-27 13:10:00 GMT", "slug": "hortonworks-blog-pig-as-hadoop-connector-part", "blog_name": "rjurney", "summary": "Hortonworks Blog, Pig as Hadoop Connector Part Two: HBase, JRuby and Sinatra", "can_reblog": true}, {"body": "<p><a href=\"http://hortonworks.com/blog/pig-as-connector-part-one-pig-mongodb-and-node-js/\"><i>In this post we\u2019ll be using Hadoop, Pig, mongo-hadoop, MongoDB and Node.js to turn Avro records into a web service. We do so to illustrate Pig\u2019s ability to act as glue between distributed systems, and to show how easy it is to publish data from Hadoop to the web.</i></a>\n\n</p><center><a href=\"http://hortonworks.com/blog/pig-as-connector-part-one-pig-mongodb-and-node-js/\"><img src=\"http://hortonworks.com/wp-content/uploads/2012/08/hadoop_mongo_small.png\"/></a></center>", "liked": false, "followed": false, "reblog_key": "YEItkTuM", "reblog": {"comment": "<p><p><a href=\"http://hortonworks.com/blog/pig-as-connector-part-one-pig-mongodb-and-node-js/\"><i>In this post we\u2019ll be using Hadoop, Pig, mongo-hadoop, MongoDB and Node.js to turn Avro records into a web service. We do so to illustrate Pig\u2019s ability to act as glue between distributed systems, and to show how easy it is to publish data from Hadoop to the web.</i></a>\n\n</p><center><a href=\"http://hortonworks.com/blog/pig-as-connector-part-one-pig-mongodb-and-node-js/\"><img src=\"http://hortonworks.com/wp-content/uploads/2012/08/hadoop_mongo_small.png\"></a></center></p>", "tree_html": ""}, "can_send_in_message": true, "id": 29643744053, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Hortonworks: Pig as Hadoop Connector, Part One: Pig, MongoDB and Node.js", "tags": [], "post_url": "http://datasyndrome.com/post/29643744053/hortonworks-pig-as-hadoop-connector-part-one", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yRcvwCr", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1345238940, "note_count": 0, "trail": [{"content": "<p><p><a href=\"http://hortonworks.com/blog/pig-as-connector-part-one-pig-mongodb-and-node-js/\"><i>In this post we&rsquo;ll be using Hadoop, Pig, mongo-hadoop, MongoDB and Node.js to turn Avro records into a web service. We do so to illustrate Pig&rsquo;s ability to act as glue between distributed systems, and to show how easy it is to publish data from Hadoop to the web.</i></a>\n\n</p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://hortonworks.com/wp-content/uploads/2012/08/hadoop_mongo_small.png\">External image</div></p>", "content_raw": "<p><p><a href=\"http://hortonworks.com/blog/pig-as-connector-part-one-pig-mongodb-and-node-js/\"><i>In this post we\u2019ll be using Hadoop, Pig, mongo-hadoop, MongoDB and Node.js to turn Avro records into a web service. We do so to illustrate Pig\u2019s ability to act as glue between distributed systems, and to show how easy it is to publish data from Hadoop to the web.</i></a>\n\n</p><center><a href=\"http://hortonworks.com/blog/pig-as-connector-part-one-pig-mongodb-and-node-js/\"><img src=\"http://hortonworks.com/wp-content/uploads/2012/08/hadoop_mongo_small.png\"></a></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "29643744053"}}], "date": "2012-08-17 21:29:00 GMT", "slug": "hortonworks-pig-as-hadoop-connector-part-one", "blog_name": "rjurney", "summary": "Hortonworks: Pig as Hadoop Connector, Part One: Pig, MongoDB and Node.js", "can_reblog": true}, {"body": "<p><img src=\"https://lh3.googleusercontent.com/-_a7Ho8kaMSg/UAEEDS-LGyI/AAAAAAAAAEg/khhiopFc18o/s737/pig_user_chart.jpg\"/></p>\n\n<p>A fun peek into <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_9.html\">chapter 9</a> of Agile Data, from O'Reilly, which you can <a href=\"http://shop.oreilly.com/product/0636920025054.do\">preorder</a>, read and comment on at <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_2.html\">O'Reilly OFPS</a>.</p>\n\n<p>The chart shows a smoothed distribution of the time emails are sent to user@pig.apache.org, as well as the most related emails for that list.</p>", "liked": false, "followed": false, "reblog_key": "yyZame5n", "reblog": {"comment": "<p><img src=\"https://lh3.googleusercontent.com/-_a7Ho8kaMSg/UAEEDS-LGyI/AAAAAAAAAEg/khhiopFc18o/s737/pig_user_chart.jpg\"></p>\n\n<p>A fun peek into <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_9.html\">chapter 9</a> of Agile Data, from O'Reilly, which you can <a href=\"http://shop.oreilly.com/product/0636920025054.do\">preorder</a>, read and comment on at <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_2.html\">O'Reilly OFPS</a>.</p>\n\n<p>The chart shows a smoothed distribution of the time emails are sent to user@pig.apache.org, as well as the most related emails for that list.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 27177684498, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Emails sent by hour to user@pig.apache.org and related email addresses", "tags": [], "post_url": "http://datasyndrome.com/post/27177684498/emails-sent-by-hour-to-userpigapacheorg-and", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yPJweuI", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1342244011, "note_count": 0, "trail": [{"content": "<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://lh3.googleusercontent.com/-_a7Ho8kaMSg/UAEEDS-LGyI/AAAAAAAAAEg/khhiopFc18o/s737/pig_user_chart.jpg\">External image</div></p>\n\n<p>A fun peek into <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_9.html\">chapter 9</a> of Agile Data, from O'Reilly, which you can <a href=\"http://shop.oreilly.com/product/0636920025054.do\">preorder</a>, read and comment on at <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_2.html\">O'Reilly OFPS</a>.</p>\n\n<p>The chart shows a smoothed distribution of the time emails are sent to user@pig.apache.org, as well as the most related emails for that list.</p>", "content_raw": "<p><img src=\"https://lh3.googleusercontent.com/-_a7Ho8kaMSg/UAEEDS-LGyI/AAAAAAAAAEg/khhiopFc18o/s737/pig_user_chart.jpg\"></p>\n\n<p>A fun peek into <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_9.html\">chapter 9</a> of Agile Data, from O'Reilly, which you can <a href=\"http://shop.oreilly.com/product/0636920025054.do\">preorder</a>, read and comment on at <a href=\"http://ofps.oreilly.com/titles/9781449326265/chapter_2.html\">O'Reilly OFPS</a>.</p>\n\n<p>The chart shows a smoothed distribution of the time emails are sent to user@pig.apache.org, as well as the most related emails for that list.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "27177684498"}}], "date": "2012-07-14 05:33:31 GMT", "slug": "emails-sent-by-hour-to-userpigapacheorg-and", "blog_name": "rjurney", "summary": "Emails sent by hour to user@pig.apache.org and related email addresses", "can_reblog": true}, {"body": "Send avros to MongoDB in one line with Pig parameter substitution:\n\n<pre>[bash]$ pig -param avros='/tmp/my_avros/' \\\n-param mongourl='mongodb://localhost/me.my_collection' avro_to_mongo.pig\n\n...\n\n2012-07-12 14:19:49,014 [main] INFO  com.mongodb.hadoop.pig.MongoStorage - Store Location Config: Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml For URI: mongodb://localhost/me.my_collection\n2012-07-12 14:19:49,014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - <b>Success!</b>\n</pre>\n\nSource code to avro_to_mongo.pig:\n\n<pre>/* Load Avro jars and define shortcut */\nregister /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nregister /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nregister /me/pig/build/ivy/lib/Pig/joda-time-1.6.jar\ndefine AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n/* MongoDB */\nregister /me/mongo-hadoop/mongo-2.7.3.jar\nregister /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0.0.jar\nregister /me/mongo-hadoop/pig/target/mongo-hadoop-pig-1.0.0.jar\nset mapred.map.tasks.speculative.execution false\nset mapred.reduce.tasks.speculative.execution false\ndefine MongoStorage com.mongodb.hadoop.pig.MongoStorage();\n\n/* Piggybank */\nregister /me/pig/contrib/piggybank/java/piggybank.jar\n\nset default_parallel 5\n\navros = load '$avros' using AvroStorage();\nstore avros into '$mongourl' using MongoStorage();</pre>\n\nTest out our new collection in MongoDB:\n\n<pre>[bash]$ mongo me --eval 'printjson(db.my_collection.findOne())'</pre>\n\n<pre>{\n\t\"_id\" : ObjectId(\"4fff3f70036418714387de3e\"),\n\t\"field1\" : \"foobar\",\n\t\"bozos\" : [\n\t\t{\n\t\t\t\"bozo\" : \"russell.jurney@gmail.com\"\n\t\t}\n\t]\n}</pre>", "liked": false, "followed": false, "reblog_key": "pHSFgrBA", "reblog": {"comment": "<p>Send avros to MongoDB in one line with Pig parameter substitution:\n\n<pre>[bash]$ pig -param avros='/tmp/my_avros/' \\\n-param mongourl='mongodb://localhost/me.my_collection' avro_to_mongo.pig\n\n...\n\n2012-07-12 14:19:49,014 [main] INFO  com.mongodb.hadoop.pig.MongoStorage - Store Location Config: Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml For URI: mongodb://localhost/me.my_collection\n2012-07-12 14:19:49,014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - <b>Success!</b>\n</pre>\n\nSource code to avro_to_mongo.pig:\n\n<pre>/* Load Avro jars and define shortcut */\nregister /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nregister /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nregister /me/pig/build/ivy/lib/Pig/joda-time-1.6.jar\ndefine AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n/* MongoDB */\nregister /me/mongo-hadoop/mongo-2.7.3.jar\nregister /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0.0.jar\nregister /me/mongo-hadoop/pig/target/mongo-hadoop-pig-1.0.0.jar\nset mapred.map.tasks.speculative.execution false\nset mapred.reduce.tasks.speculative.execution false\ndefine MongoStorage com.mongodb.hadoop.pig.MongoStorage();\n\n/* Piggybank */\nregister /me/pig/contrib/piggybank/java/piggybank.jar\n\nset default_parallel 5\n\navros = load '$avros' using AvroStorage();\nstore avros into '$mongourl' using MongoStorage();</pre>\n\nTest out our new collection in MongoDB:\n\n<pre>[bash]$ mongo me --eval 'printjson(db.my_collection.findOne())'</pre>\n\n<pre>{\n\t\"_id\" : ObjectId(\"4fff3f70036418714387de3e\"),\n\t\"field1\" : \"foobar\",\n\t\"bozos\" : [\n\t\t{\n\t\t\t\"bozo\" : \"russell.jurney@gmail.com\"\n\t\t}\n\t]\n}</pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 27075009640, "display_avatar": true, "can_reply": true, "can_like": false, "title": "From Avro to Mongo in One Line with avro_to_mongo.pig", "tags": [], "post_url": "http://datasyndrome.com/post/27075009640/from-avro-to-mongo-in-one-line-with", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yPDozne", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1342128300, "note_count": 0, "trail": [{"content": "<p><p>Send avros to MongoDB in one line with Pig parameter substitution:\n\n</p><pre>[bash]$ pig -param avros='/tmp/my_avros/' \\\n-param mongourl='mongodb://localhost/me.my_collection' avro_to_mongo.pig\n\n...\n\n2012-07-12 14:19:49,014 [main] INFO  com.mongodb.hadoop.pig.MongoStorage - Store Location Config: Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml For URI: mongodb://localhost/me.my_collection\n2012-07-12 14:19:49,014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - <b>Success!</b>\n</pre>\n\nSource code to avro_to_mongo.pig:\n\n<pre>/* Load Avro jars and define shortcut */\nregister /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nregister /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nregister /me/pig/build/ivy/lib/Pig/joda-time-1.6.jar\ndefine AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n/* MongoDB */\nregister /me/mongo-hadoop/mongo-2.7.3.jar\nregister /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0.0.jar\nregister /me/mongo-hadoop/pig/target/mongo-hadoop-pig-1.0.0.jar\nset mapred.map.tasks.speculative.execution false\nset mapred.reduce.tasks.speculative.execution false\ndefine MongoStorage com.mongodb.hadoop.pig.MongoStorage();\n\n/* Piggybank */\nregister /me/pig/contrib/piggybank/java/piggybank.jar\n\nset default_parallel 5\n\navros = load '$avros' using AvroStorage();\nstore avros into '$mongourl' using MongoStorage();</pre>\n\nTest out our new collection in MongoDB:\n\n<pre>[bash]$ mongo me --eval 'printjson(db.my_collection.findOne())'</pre>\n\n<pre>{\n\t\"_id\" : ObjectId(\"4fff3f70036418714387de3e\"),\n\t\"field1\" : \"foobar\",\n\t\"bozos\" : [\n\t\t{\n\t\t\t\"bozo\" : \"russell.jurney@gmail.com\"\n\t\t}\n\t]\n}</pre></p>", "content_raw": "<p>Send avros to MongoDB in one line with Pig parameter substitution:\n\n<pre>[bash]$ pig -param avros='/tmp/my_avros/' \\\n-param mongourl='mongodb://localhost/me.my_collection' avro_to_mongo.pig\n\n...\n\n2012-07-12 14:19:49,014 [main] INFO  com.mongodb.hadoop.pig.MongoStorage - Store Location Config: Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml For URI: mongodb://localhost/me.my_collection\n2012-07-12 14:19:49,014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - <b>Success!</b>\n</pre>\n\nSource code to avro_to_mongo.pig:\n\n<pre>/* Load Avro jars and define shortcut */\nregister /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nregister /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nregister /me/pig/build/ivy/lib/Pig/joda-time-1.6.jar\ndefine AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n/* MongoDB */\nregister /me/mongo-hadoop/mongo-2.7.3.jar\nregister /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0.0.jar\nregister /me/mongo-hadoop/pig/target/mongo-hadoop-pig-1.0.0.jar\nset mapred.map.tasks.speculative.execution false\nset mapred.reduce.tasks.speculative.execution false\ndefine MongoStorage com.mongodb.hadoop.pig.MongoStorage();\n\n/* Piggybank */\nregister /me/pig/contrib/piggybank/java/piggybank.jar\n\nset default_parallel 5\n\navros = load '$avros' using AvroStorage();\nstore avros into '$mongourl' using MongoStorage();</pre>\n\nTest out our new collection in MongoDB:\n\n<pre>[bash]$ mongo me --eval 'printjson(db.my_collection.findOne())'</pre>\n\n<pre>{\n\t\"_id\" : ObjectId(\"4fff3f70036418714387de3e\"),\n\t\"field1\" : \"foobar\",\n\t\"bozos\" : [\n\t\t{\n\t\t\t\"bozo\" : \"russell.jurney@gmail.com\"\n\t\t}\n\t]\n}</pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "27075009640"}}], "date": "2012-07-12 21:25:00 GMT", "slug": "from-avro-to-mongo-in-one-line-with", "blog_name": "rjurney", "summary": "From Avro to Mongo in One Line with avro_to_mongo.pig", "can_reblog": true}, {"body": "<p>This is part three of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we\u2019re exploring the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in Hive, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\n</p><ul><li>Series Part One: Avroizing the Enron Emails.  In that post, we used Pig to extract, transform and load a MySQL database of the Enron emails to document format and serialize them in Avro.  The <a href=\"http://s3.amazonaws.com/rjurney.public/hive-site.xml\">Enron emails are available in Avro format here.</a></li>\n\n<li>Series Part Two: Mining Avros with Pig, Consuming Data with Hive.  In part two of the series, we extracted new and interesting properties from our data for consumption by analysts and users, using Pig, EC2 and Hive.  Code examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hcatalog.\">https://github.com/rjurney/enron-hcatalog.</a></li>\n\n<li><a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-three-booting-hcatalog-on-elastic-mapreduce/\">Series Part Three: Booting HCatalog on Elastic MapReduce.</a>  Here we will use HCatalog to streamline the sharing of data between Pig and Hive, and to aid data discovery for consumers of processed data.</li>\n</ul>", "liked": false, "followed": false, "reblog_key": "Q2pJFipH", "reblog": {"comment": "<p><p>This is part three of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we\u2019re exploring the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in Hive, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\n</p><ul><li>Series Part One: Avroizing the Enron Emails.  In that post, we used Pig to extract, transform and load a MySQL database of the Enron emails to document format and serialize them in Avro.  The <a href=\"http://s3.amazonaws.com/rjurney.public/hive-site.xml\">Enron emails are available in Avro format here.</a></li>\n\n<li>Series Part Two: Mining Avros with Pig, Consuming Data with Hive.  In part two of the series, we extracted new and interesting properties from our data for consumption by analysts and users, using Pig, EC2 and Hive.  Code examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hcatalog.\">https://github.com/rjurney/enron-hcatalog.</a></li>\n\n<li><a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-three-booting-hcatalog-on-elastic-mapreduce/\">Series Part Three: Booting HCatalog on Elastic MapReduce.</a>  Here we will use HCatalog to streamline the sharing of data between Pig and Hive, and to aid data discovery for consumers of processed data.</li>\n</ul></p>", "tree_html": ""}, "can_send_in_message": true, "id": 25965529332, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Booting HCatalog on Elastic MapReduce - Hortonworks Blog Post", "tags": [], "post_url": "http://datasyndrome.com/post/25965529332/booting-hcatalog-on-elastic-mapreduce", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yOBgeZq", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1340758123, "note_count": 0, "trail": [{"content": "<p><p>This is part three of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we&rsquo;re exploring the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in Hive, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\n</p><ul><li>Series Part One: Avroizing the Enron Emails.  In that post, we used Pig to extract, transform and load a MySQL database of the Enron emails to document format and serialize them in Avro.  The <a href=\"http://s3.amazonaws.com/rjurney.public/hive-site.xml\">Enron emails are available in Avro format here.</a></li>\n\n<li>Series Part Two: Mining Avros with Pig, Consuming Data with Hive.  In part two of the series, we extracted new and interesting properties from our data for consumption by analysts and users, using Pig, EC2 and Hive.  Code examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hcatalog.\">https://github.com/rjurney/enron-hcatalog.</a></li>\n\n<li><a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-three-booting-hcatalog-on-elastic-mapreduce/\">Series Part Three: Booting HCatalog on Elastic MapReduce.</a>  Here we will use HCatalog to streamline the sharing of data between Pig and Hive, and to aid data discovery for consumers of processed data.</li>\n</ul></p>", "content_raw": "<p><p>This is part three of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we\u2019re exploring the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in Hive, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\n</p><ul><li>Series Part One: Avroizing the Enron Emails.  In that post, we used Pig to extract, transform and load a MySQL database of the Enron emails to document format and serialize them in Avro.  The <a href=\"http://s3.amazonaws.com/rjurney.public/hive-site.xml\">Enron emails are available in Avro format here.</a></li>\n\n<li>Series Part Two: Mining Avros with Pig, Consuming Data with Hive.  In part two of the series, we extracted new and interesting properties from our data for consumption by analysts and users, using Pig, EC2 and Hive.  Code examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hcatalog.\">https://github.com/rjurney/enron-hcatalog.</a></li>\n\n<li><a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-three-booting-hcatalog-on-elastic-mapreduce/\">Series Part Three: Booting HCatalog on Elastic MapReduce.</a>  Here we will use HCatalog to streamline the sharing of data between Pig and Hive, and to aid data discovery for consumers of processed data.</li>\n</ul></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "25965529332"}}], "date": "2012-06-27 00:48:43 GMT", "slug": "booting-hcatalog-on-elastic-mapreduce", "blog_name": "rjurney", "summary": "Booting HCatalog on Elastic MapReduce - Hortonworks Blog Post", "can_reblog": true}, {"body": "<p>AngelHack is today and I&rsquo;m taking the opportunity to try out new tools.\n\n</p><ol><li><a href=\"http://c9.io\">Cloud 9 IDE</a> - Amazing web-based development for Node.js, includes a server to deploy your app to and a *nixish command line with excellent HTML5 autocomplete for common commands.</li>\n<li><a href=\"http://dotcloud.com\">dotCloud</a> - Awesome cloud provider with support for celery workers in python and python apps. <b>Auto-scaling.</b></li>\n<li><a href=\"http://celeryproject.org/\">Celery workers</a> are an excellent way to process data in queues with python.</li>\n</ol>", "liked": false, "followed": false, "reblog_key": "4UYFBLxm", "reblog": {"comment": "<p><p>AngelHack is today and I\u2019m taking the opportunity to try out new tools.\n\n</p><ol><li><a href=\"http://c9.io\">Cloud 9 IDE</a> - Amazing web-based development for Node.js, includes a server to deploy your app to and a *nixish command line with excellent HTML5 autocomplete for common commands.</li>\n<li><a href=\"http://dotcloud.com\">dotCloud</a> - Awesome cloud provider with support for celery workers in python and python apps. <b>Auto-scaling.</b></li>\n<li><a href=\"http://celeryproject.org/\">Celery workers</a> are an excellent way to process data in queues with python.</li>\n</ol></p>", "tree_html": ""}, "can_send_in_message": true, "id": 25821312882, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Three Cool New Tools at Angel Hack ", "tags": [], "post_url": "http://datasyndrome.com/post/25821312882/three-cool-new-tools-at-angel-hack", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yO34VTo", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1340587860, "note_count": 0, "trail": [{"content": "<p><p>AngelHack is today and I&rsquo;m taking the opportunity to try out new tools.\n\n</p><ol><li><a href=\"http://c9.io\">Cloud 9 IDE</a> - Amazing web-based development for Node.js, includes a server to deploy your app to and a *nixish command line with excellent HTML5 autocomplete for common commands.</li>\n<li><a href=\"http://dotcloud.com\">dotCloud</a> - Awesome cloud provider with support for celery workers in python and python apps. <b>Auto-scaling.</b></li>\n<li><a href=\"http://celeryproject.org/\">Celery workers</a> are an excellent way to process data in queues with python.</li>\n</ol></p>", "content_raw": "<p><p>AngelHack is today and I\u2019m taking the opportunity to try out new tools.\n\n</p><ol><li><a href=\"http://c9.io\">Cloud 9 IDE</a> - Amazing web-based development for Node.js, includes a server to deploy your app to and a *nixish command line with excellent HTML5 autocomplete for common commands.</li>\n<li><a href=\"http://dotcloud.com\">dotCloud</a> - Awesome cloud provider with support for celery workers in python and python apps. <b>Auto-scaling.</b></li>\n<li><a href=\"http://celeryproject.org/\">Celery workers</a> are an excellent way to process data in queues with python.</li>\n</ol></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "25821312882"}}], "date": "2012-06-25 01:31:00 GMT", "slug": "three-cool-new-tools-at-angel-hack", "blog_name": "rjurney", "summary": "Three Cool New Tools at Angel Hack", "can_reblog": true}, {"body": "<p><a href=\"http://hortonworks.com/blog/my-review-of-hadoop-summit-2012/\">My review of Hadoop Summit 2012 is up on the Hortonworks Blog.</a></p>\n\n<p><i>Daniel Dai and Thejas Nair\u2019s talk, Pig programming is more fun: New features in Pig (slides available), covered new features of Pig in v0.10, which you can read more about here. Improvements to Piggybank to include Pig Macros were discussed. ILLUSTRATE has been fixed in Pig 0.10 and now works with AvroStorage. Pig\u2019s ability to cast single-record relations as scalars is a great addition to the language. UDFs in JRuby greatly simplify extending Pig, bringing many JRuby compatible gems into Pig. Pig embedding enables iterative pig scripts, such as training statistical models. Pig\u2019s HCatalog integration enables sharing resources with Hive and MapReduce users. MongoStorage integration enables simple data publishing to MongoDB, a popular NoSQL database. Finally, Talend integration allows graphical programming of Pig.</i></p>\n\n<p><i>The Hadoop market continues to mature and grow, but \u201cyou ain\u2019t seen nothing, yet!\u201d Every shred of data on earth is going on HDFS, and we\u2019ve only just begun the big data journey. I can\u2019t wait till next year\u2019s Hadoop Summit to find out more!</i></p>", "liked": false, "followed": false, "reblog_key": "OCQkcEx1", "reblog": {"comment": "<p><a href=\"http://hortonworks.com/blog/my-review-of-hadoop-summit-2012/\">My review of Hadoop Summit 2012 is up on the Hortonworks Blog.</a></p>\n\n<p><i>Daniel Dai and Thejas Nair\u2019s talk, Pig programming is more fun: New features in Pig (slides available), covered new features of Pig in v0.10, which you can read more about here. Improvements to Piggybank to include Pig Macros were discussed. ILLUSTRATE has been fixed in Pig 0.10 and now works with AvroStorage. Pig\u2019s ability to cast single-record relations as scalars is a great addition to the language. UDFs in JRuby greatly simplify extending Pig, bringing many JRuby compatible gems into Pig. Pig embedding enables iterative pig scripts, such as training statistical models. Pig\u2019s HCatalog integration enables sharing resources with Hive and MapReduce users. MongoStorage integration enables simple data publishing to MongoDB, a popular NoSQL database. Finally, Talend integration allows graphical programming of Pig.</i></p>\n\n<p><i>The Hadoop market continues to mature and grow, but \u201cyou ain\u2019t seen nothing, yet!\u201d Every shred of data on earth is going on HDFS, and we\u2019ve only just begun the big data journey. I can\u2019t wait till next year\u2019s Hadoop Summit to find out more!</i></p>", "tree_html": ""}, "can_send_in_message": true, "id": 25459367222, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Hadoop Summit 2012 Review", "tags": [], "post_url": "http://datasyndrome.com/post/25459367222/hadoop-summit-2012-review", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yNjVnqs", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1340142557, "note_count": 0, "trail": [{"content": "<p><a href=\"http://hortonworks.com/blog/my-review-of-hadoop-summit-2012/\">My review of Hadoop Summit 2012 is up on the Hortonworks Blog.</a></p>\n\n<p><i>Daniel Dai and Thejas Nair&rsquo;s talk, Pig programming is more fun: New features in Pig (slides available), covered new features of Pig in v0.10, which you can read more about here. Improvements to Piggybank to include Pig Macros were discussed. ILLUSTRATE has been fixed in Pig 0.10 and now works with AvroStorage. Pig&rsquo;s ability to cast single-record relations as scalars is a great addition to the language. UDFs in JRuby greatly simplify extending Pig, bringing many JRuby compatible gems into Pig. Pig embedding enables iterative pig scripts, such as training statistical models. Pig&rsquo;s HCatalog integration enables sharing resources with Hive and MapReduce users. MongoStorage integration enables simple data publishing to MongoDB, a popular NoSQL database. Finally, Talend integration allows graphical programming of Pig.</i></p>\n\n<p><i>The Hadoop market continues to mature and grow, but &ldquo;you ain&rsquo;t seen nothing, yet!&rdquo; Every shred of data on earth is going on HDFS, and we&rsquo;ve only just begun the big data journey. I can&rsquo;t wait till next year&rsquo;s Hadoop Summit to find out more!</i></p>", "content_raw": "<p><a href=\"http://hortonworks.com/blog/my-review-of-hadoop-summit-2012/\">My review of Hadoop Summit 2012 is up on the Hortonworks Blog.</a></p>\n\n<p><i>Daniel Dai and Thejas Nair\u2019s talk, Pig programming is more fun: New features in Pig (slides available), covered new features of Pig in v0.10, which you can read more about here. Improvements to Piggybank to include Pig Macros were discussed. ILLUSTRATE has been fixed in Pig 0.10 and now works with AvroStorage. Pig\u2019s ability to cast single-record relations as scalars is a great addition to the language. UDFs in JRuby greatly simplify extending Pig, bringing many JRuby compatible gems into Pig. Pig embedding enables iterative pig scripts, such as training statistical models. Pig\u2019s HCatalog integration enables sharing resources with Hive and MapReduce users. MongoStorage integration enables simple data publishing to MongoDB, a popular NoSQL database. Finally, Talend integration allows graphical programming of Pig.</i></p>\n\n<p><i>The Hadoop market continues to mature and grow, but \u201cyou ain\u2019t seen nothing, yet!\u201d Every shred of data on earth is going on HDFS, and we\u2019ve only just begun the big data journey. I can\u2019t wait till next year\u2019s Hadoop Summit to find out more!</i></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "25459367222"}}], "date": "2012-06-19 21:49:17 GMT", "slug": "hadoop-summit-2012-review", "blog_name": "rjurney", "summary": "Hadoop Summit 2012 Review", "can_reblog": true}, {"body": "<p>Part two of my series on the enterprise data lifecycle is available at <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-two-mining-avros-with-pig-consuming-data-with-hive/\">Hortonworks.com</a>.\n\n</p><blockquote>This is part two of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we\u2019re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\nPart one of this series is <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-one-avroizing-the-enron-emails/\">available here</a>.\n\nCode examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hive.\">https://github.com/rjurney/enron-hive.</a></blockquote>", "liked": false, "followed": false, "reblog_key": "XI3EcDFM", "reblog": {"comment": "<p><p>Part two of my series on the enterprise data lifecycle is available at <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-two-mining-avros-with-pig-consuming-data-with-hive/\">Hortonworks.com</a>.\n\n</p><blockquote>This is part two of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we\u2019re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\nPart one of this series is <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-one-avroizing-the-enron-emails/\">available here</a>.\n\nCode examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hive.\">https://github.com/rjurney/enron-hive.</a></blockquote></p>", "tree_html": ""}, "can_send_in_message": true, "id": 24478930412, "display_avatar": true, "can_reply": true, "can_like": false, "title": "The Data Lifecycle, Part Two: Mining Avros with Pig, Consuming Data with HIVE", "tags": [], "post_url": "http://datasyndrome.com/post/24478930412/the-data-lifecycle-part-two-mining-avros-with", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yMp3jNi", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1338917388, "note_count": 0, "trail": [{"content": "<p><p>Part two of my series on the enterprise data lifecycle is available at <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-two-mining-avros-with-pig-consuming-data-with-hive/\">Hortonworks.com</a>.\n\n</p><blockquote><p>This is part two of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we&rsquo;re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\nPart one of this series is <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-one-avroizing-the-enron-emails/\">available here</a>.\n\nCode examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hive.\">https://github.com/rjurney/enron-hive.</a></p></blockquote></p>", "content_raw": "<p><p>Part two of my series on the enterprise data lifecycle is available at <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-two-mining-avros-with-pig-consuming-data-with-hive/\">Hortonworks.com</a>.\n\n</p><blockquote>This is part two of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data.  In a series of posts, we\u2019re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.\n\nPart one of this series is <a href=\"http://hortonworks.com/blog/the-data-lifecycle-part-one-avroizing-the-enron-emails/\">available here</a>.\n\nCode examples for this post are available here: <a href=\"https://github.com/rjurney/enron-hive.\">https://github.com/rjurney/enron-hive.</a></blockquote></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "24478930412"}}], "date": "2012-06-05 17:29:48 GMT", "slug": "the-data-lifecycle-part-two-mining-avros-with", "blog_name": "rjurney", "summary": "The Data Lifecycle, Part Two: Mining Avros with Pig, Consuming Data with HIVE", "can_reblog": true}, {"body": "<p>A fun but morbid math problem. :)<br/><br/><span class=\"qlink_container\"><a href=\"http://www.quora.com/San-Francisco-Bay-Area/Will-my-apartment-on-the-ocean-cliff-next-to-the-San-Andreas-fault-where-it-enters-the-ocean-fall-into-the-water-and-kill-me-when-the-Big-One-hits\" routing=\"q://question/(663788)\">Will my apartment on the ocean cliff next to the San Andreas fault (where it enters the ocean) fall into the water and kill me when the Big One hits?</a></span></p>", "liked": false, "followed": false, "reblog_key": "db8FrC9P", "reblog": {"comment": "<p>A fun but morbid math problem. :)<br><br><span class=\"qlink_container\"><a href=\"http://www.quora.com/San-Francisco-Bay-Area/Will-my-apartment-on-the-ocean-cliff-next-to-the-San-Andreas-fault-where-it-enters-the-ocean-fall-into-the-water-and-kill-me-when-the-Big-One-hits\" routing=\"q://question/(663788)\">Will my apartment on the ocean cliff next to the San Andreas fault (where it enters the ocean) fall into the water and kill me when the Big One hits?</a></span></p>", "tree_html": ""}, "can_send_in_message": true, "id": 23832338031, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Will my apartment on the ocean cliff next to the San Andreas fault (where it enters the ocean) fall into the water and kill me when the Big ", "tags": [], "post_url": "http://datasyndrome.com/post/23832338031/will-my-apartment-on-the-ocean-cliff-next-to-the", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yMCX9vl", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1338081611, "note_count": 0, "trail": [{"content": "<p>A fun but morbid math problem. :)<br /><br /><a href=\"http://www.quora.com/San-Francisco-Bay-Area/Will-my-apartment-on-the-ocean-cliff-next-to-the-San-Andreas-fault-where-it-enters-the-ocean-fall-into-the-water-and-kill-me-when-the-Big-One-hits\">Will my apartment on the ocean cliff next to the San Andreas fault (where it enters the ocean) fall into the water and kill me when the Big One hits?</a></p>", "content_raw": "<p>A fun but morbid math problem. :)<br><br><span class=\"qlink_container\"><a href=\"http://www.quora.com/San-Francisco-Bay-Area/Will-my-apartment-on-the-ocean-cliff-next-to-the-San-Andreas-fault-where-it-enters-the-ocean-fall-into-the-water-and-kill-me-when-the-Big-One-hits\" routing=\"q://question/(663788)\">Will my apartment on the ocean cliff next to the San Andreas fault (where it enters the ocean) fall into the water and kill me when the Big One hits?</a></span></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "23832338031"}}], "date": "2012-05-27 01:20:11 GMT", "slug": "will-my-apartment-on-the-ocean-cliff-next-to-the", "blog_name": "rjurney", "summary": "Will my apartment on the ocean cliff next to the San Andreas fault (where it enters the ocean) fall into the water and kill me...", "can_reblog": true}, {"body": "<p>Many of you have read my code, and you are aware that it can best be described as, &lsquo;eventually good.&rsquo; It is with great honor then that I announce my bid to be one of the greatest software engineers in the world. </p>\n\n<p><a href=\"http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers\">http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers</a></p>\n\n<p>Scroll down, vote up. </p>\n\n<p>I had a shit year, but things are looking up. I got a brand new pacemaker and bionic powers, and so I encourage you to help promote this truthiness. In return your support, you will all receive boons in the coming successes I am sure to enjoy. Perhaps a case study in my book. In addition, by upvoting me, you will be earning a Jurney number of 1, that Erdos shit having gotten stale.</p>\n\n<p>Thanks for your support, </p>\n\n<p>The Greatest Software Engineer in the World and Medtronic Bionic Man, <br/>\nRussell Jurney</p>", "liked": false, "followed": false, "reblog_key": "dcswt2us", "reblog": {"comment": "<p>Many of you have read my code, and you are aware that it can best be described as, \u2018eventually good.\u2019 It is with great honor then that I announce my bid to be one of the greatest software engineers in the world. </p>\n\n<p><a href=\"http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers\">http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers</a></p>\n\n<p>Scroll down, vote up. </p>\n\n<p>I had a shit year, but things are looking up. I got a brand new pacemaker and bionic powers, and so I encourage you to help promote this truthiness. In return your support, you will all receive boons in the coming successes I am sure to enjoy. Perhaps a case study in my book. In addition, by upvoting me, you will be earning a Jurney number of 1, that Erdos shit having gotten stale.</p>\n\n<p>Thanks for your support, </p>\n\n<p>The Greatest Software Engineer in the World and Medtronic Bionic Man, <br>\nRussell Jurney</p>", "tree_html": ""}, "can_send_in_message": true, "id": 23601038345, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Help me become the Greatest Software Engineer in the World", "tags": [], "post_url": "http://datasyndrome.com/post/23601038345/help-me-become-the-greatest-software-engineer-in", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yL_kqG9", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1337763660, "note_count": 0, "trail": [{"content": "<p>Many of you have read my code, and you are aware that it can best be described as, &lsquo;eventually good.&rsquo; It is with great honor then that I announce my bid to be one of the greatest software engineers in the world. </p>\n\n<p><a href=\"http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers\">http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers</a></p>\n\n<p>Scroll down, vote up. </p>\n\n<p>I had a shit year, but things are looking up. I got a brand new pacemaker and bionic powers, and so I encourage you to help promote this truthiness. In return your support, you will all receive boons in the coming successes I am sure to enjoy. Perhaps a case study in my book. In addition, by upvoting me, you will be earning a Jurney number of 1, that Erdos shit having gotten stale.</p>\n\n<p>Thanks for your support, </p>\n\n<p>The Greatest Software Engineer in the World and Medtronic Bionic Man, <br />\nRussell Jurney</p>", "content_raw": "<p>Many of you have read my code, and you are aware that it can best be described as, \u2018eventually good.\u2019 It is with great honor then that I announce my bid to be one of the greatest software engineers in the world. </p>\n\n<p><a href=\"http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers\">http://www.quora.com/Who-are-some-of-the-best-software-engineers-alive#answers</a></p>\n\n<p>Scroll down, vote up. </p>\n\n<p>I had a shit year, but things are looking up. I got a brand new pacemaker and bionic powers, and so I encourage you to help promote this truthiness. In return your support, you will all receive boons in the coming successes I am sure to enjoy. Perhaps a case study in my book. In addition, by upvoting me, you will be earning a Jurney number of 1, that Erdos shit having gotten stale.</p>\n\n<p>Thanks for your support, </p>\n\n<p>The Greatest Software Engineer in the World and Medtronic Bionic Man, <br>\nRussell Jurney</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "23601038345"}}], "date": "2012-05-23 09:01:00 GMT", "slug": "help-me-become-the-greatest-software-engineer-in", "blog_name": "rjurney", "summary": "Help me become the Greatest Software Engineer in the World", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "Zd07O8dp", "short_url": "https://tmblr.co/ZbIO5yLy6xS5", "excerpt": null, "link_author": null, "id": 23557027589, "display_avatar": true, "can_reply": true, "can_like": false, "title": "The Data Lifecycle Part One: Avroizing the Enron Emails", "tags": [], "post_url": "http://datasyndrome.com/post/23557027589/the-data-lifecycle-part-one-avroizing-the-enron", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>This is part one of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data. \u00a0In a series of posts, we\u2019re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.</p>", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "<p>This is part one of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data. \u00a0In a series of posts, we\u2019re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.</p>", "format": "html", "timestamp": 1337715199, "note_count": 1, "trail": [{"content": "<p>This is part one of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data. &nbsp;In a series of posts, we&rsquo;re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.</p>", "content_raw": "<p>This is part one of a series of blog posts covering new developments in the Hadoop pantheon that enable productivity throughout the lifecycle of big data. \u00a0In a series of posts, we\u2019re going to explore the full lifecycle of data in the enterprise: Introducing new data sources to the Hadoop filesystem via ETL, processing this data in data-flows with Pig and Python to expose new and interesting properties, consuming this data as an analyst in HIVE, and discovering and accessing these resources as analysts and application developers using HCatalog and Templeton.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "23557027589"}}], "date": "2012-05-22 19:33:19 GMT", "slug": "the-data-lifecycle-part-one-avroizing-the-enron", "blog_name": "rjurney", "publisher": "hortonworks.com", "url": "http://hortonworks.com/blog/the-data-lifecycle-part-one-avroizing-the-enron-emails/", "can_send_in_message": true, "summary": "The Data Lifecycle Part One: Avroizing the Enron Emails", "can_reblog": true}, {"body": "<p>Reposted from Quora: <a href=\"http://www.quora.com/What-does-it-feel-like-to-be-stupid/answer/Russell-Jurney\"></a></p>\n\n<p><b>What does it feel like to be stupid?</b></p>\n\n<p>I recently found out I had Bradycardia for a year. Oximetry indicated frequent hypoxia. My heart paused for 5, 6 then 7 seconds during one short window.\u00a0 My brain was starved for oxygen for a year and every day I was exhausted by these &lsquo;near death&rsquo; experiences while I slept.</p>\n\n<p>Once doctors put a pacemaker in, I noticed a profound improvement. So did my family. I am myself again. :)</p>\n\n<p>Becoming dumb was like forgetting your lines as an actor. Lines you&rsquo;ve worked like hell to remember and then stumble over on stage, in front of a live audience. The words don&rsquo;t come.</p>\n\n<p>Being dumb came with a shocking loss of privilege. This was humbling. Smart people, like the very attractive, get special treatment they do not know they are getting. A slower mind and the normal treatment that comes with it makes the world look cruel, unfair and cold.</p>\n\n<p>It was a shocking blow, a loss of identity. I was the guy that came up with the answers. Not anymore.</p>\n\n<p>It was most frustrating to be tricked, manipulated and used. I could sense what was happening but could not sidestep the tricks. I could see myself being manipulated but was helpless to defend myself as my intellect became overwhelmed.</p>\n\n<p>Worst of all was feeling like people thought I was some kind of fraud, in that I could no longer reproduce or even accurately describe feats from the past. To be challenged in your accomplishments adds insults to injury as you struggle with your limitations.</p>\n\n<p>There was some upside. I learned to cry freely. I can now openly weep at an emotional part of a film and feel it more than I would have before. I learned to control my temper. I learned patience. And I learned what remains if you take away all that makes me unique and special - and I learned to be okay with that person. I&rsquo;d rather be smart, but I can always find something to do, enjoy my family and spend my spare time painting.</p>\n\n<p>I decided to focus more on writing and teaching than doing, which I found to be easier than the applied work I was doing before. Now that I can finish it, I got a book out of it.</p>", "liked": false, "followed": false, "reblog_key": "bwbyOAGK", "reblog": {"comment": "<p>Reposted from Quora: <a href=\"http://www.quora.com/What-does-it-feel-like-to-be-stupid/answer/Russell-Jurney\"></a></p>\n\n<p><b>What does it feel like to be stupid?</b></p>\n\n<p>I recently found out I had Bradycardia for a year. Oximetry indicated frequent hypoxia. My heart paused for 5, 6 then 7 seconds during one short window.\u00a0 My brain was starved for oxygen for a year and every day I was exhausted by these \u2018near death\u2019 experiences while I slept.</p>\n\n<p>Once doctors put a pacemaker in, I noticed a profound improvement. So did my family. I am myself again. :)</p>\n\n<p>Becoming dumb was like forgetting your lines as an actor. Lines you\u2019ve worked like hell to remember and then stumble over on stage, in front of a live audience. The words don\u2019t come.</p>\n\n<p>Being dumb came with a shocking loss of privilege. This was humbling. Smart people, like the very attractive, get special treatment they do not know they are getting. A slower mind and the normal treatment that comes with it makes the world look cruel, unfair and cold.</p>\n\n<p>It was a shocking blow, a loss of identity. I was the guy that came up with the answers. Not anymore.</p>\n\n<p>It was most frustrating to be tricked, manipulated and used. I could sense what was happening but could not sidestep the tricks. I could see myself being manipulated but was helpless to defend myself as my intellect became overwhelmed.</p>\n\n<p>Worst of all was feeling like people thought I was some kind of fraud, in that I could no longer reproduce or even accurately describe feats from the past. To be challenged in your accomplishments adds insults to injury as you struggle with your limitations.</p>\n\n<p>There was some upside. I learned to cry freely. I can now openly weep at an emotional part of a film and feel it more than I would have before. I learned to control my temper. I learned patience. And I learned what remains if you take away all that makes me unique and special - and I learned to be okay with that person. I\u2019d rather be smart, but I can always find something to do, enjoy my family and spend my spare time painting.</p>\n\n<p>I decided to focus more on writing and teaching than doing, which I found to be easier than the applied work I was doing before. Now that I can finish it, I got a book out of it.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 23339122301, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Dumb Like Me", "tags": [], "post_url": "http://datasyndrome.com/post/23339122301/dumb-like-me", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yLl7hvz", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1337412936, "note_count": 10, "trail": [{"content": "<p>Reposted from Quora: <a href=\"http://www.quora.com/What-does-it-feel-like-to-be-stupid/answer/Russell-Jurney\"></a></p>\n\n<p><b>What does it feel like to be stupid?</b></p>\n\n<p>I recently found out I had Bradycardia for a year. Oximetry indicated frequent hypoxia. My heart paused for 5, 6 then 7 seconds during one short window.&nbsp; My brain was starved for oxygen for a year and every day I was exhausted by these &lsquo;near death&rsquo; experiences while I slept.</p>\n\n<p>Once doctors put a pacemaker in, I noticed a profound improvement. So did my family. I am myself again. :)</p>\n\n<p>Becoming dumb was like forgetting your lines as an actor. Lines you&rsquo;ve worked like hell to remember and then stumble over on stage, in front of a live audience. The words don&rsquo;t come.</p>\n\n<p>Being dumb came with a shocking loss of privilege. This was humbling. Smart people, like the very attractive, get special treatment they do not know they are getting. A slower mind and the normal treatment that comes with it makes the world look cruel, unfair and cold.</p>\n\n<p>It was a shocking blow, a loss of identity. I was the guy that came up with the answers. Not anymore.</p>\n\n<p>It was most frustrating to be tricked, manipulated and used. I could sense what was happening but could not sidestep the tricks. I could see myself being manipulated but was helpless to defend myself as my intellect became overwhelmed.</p>\n\n<p>Worst of all was feeling like people thought I was some kind of fraud, in that I could no longer reproduce or even accurately describe feats from the past. To be challenged in your accomplishments adds insults to injury as you struggle with your limitations.</p>\n\n<p>There was some upside. I learned to cry freely. I can now openly weep at an emotional part of a film and feel it more than I would have before. I learned to control my temper. I learned patience. And I learned what remains if you take away all that makes me unique and special - and I learned to be okay with that person. I&rsquo;d rather be smart, but I can always find something to do, enjoy my family and spend my spare time painting.</p>\n\n<p>I decided to focus more on writing and teaching than doing, which I found to be easier than the applied work I was doing before. Now that I can finish it, I got a book out of it.</p>", "content_raw": "<p>Reposted from Quora: <a href=\"http://www.quora.com/What-does-it-feel-like-to-be-stupid/answer/Russell-Jurney\"></a></p>\n\n<p><b>What does it feel like to be stupid?</b></p>\n\n<p>I recently found out I had Bradycardia for a year. Oximetry indicated frequent hypoxia. My heart paused for 5, 6 then 7 seconds during one short window.\u00a0 My brain was starved for oxygen for a year and every day I was exhausted by these \u2018near death\u2019 experiences while I slept.</p>\n\n<p>Once doctors put a pacemaker in, I noticed a profound improvement. So did my family. I am myself again. :)</p>\n\n<p>Becoming dumb was like forgetting your lines as an actor. Lines you\u2019ve worked like hell to remember and then stumble over on stage, in front of a live audience. The words don\u2019t come.</p>\n\n<p>Being dumb came with a shocking loss of privilege. This was humbling. Smart people, like the very attractive, get special treatment they do not know they are getting. A slower mind and the normal treatment that comes with it makes the world look cruel, unfair and cold.</p>\n\n<p>It was a shocking blow, a loss of identity. I was the guy that came up with the answers. Not anymore.</p>\n\n<p>It was most frustrating to be tricked, manipulated and used. I could sense what was happening but could not sidestep the tricks. I could see myself being manipulated but was helpless to defend myself as my intellect became overwhelmed.</p>\n\n<p>Worst of all was feeling like people thought I was some kind of fraud, in that I could no longer reproduce or even accurately describe feats from the past. To be challenged in your accomplishments adds insults to injury as you struggle with your limitations.</p>\n\n<p>There was some upside. I learned to cry freely. I can now openly weep at an emotional part of a film and feel it more than I would have before. I learned to control my temper. I learned patience. And I learned what remains if you take away all that makes me unique and special - and I learned to be okay with that person. I\u2019d rather be smart, but I can always find something to do, enjoy my family and spend my spare time painting.</p>\n\n<p>I decided to focus more on writing and teaching than doing, which I found to be easier than the applied work I was doing before. Now that I can finish it, I got a book out of it.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "23339122301"}}], "date": "2012-05-19 07:35:36 GMT", "slug": "dumb-like-me", "blog_name": "rjurney", "summary": "Dumb Like Me", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "bPFnP6q0", "short_url": "https://tmblr.co/ZbIO5yLOBwE9", "excerpt": null, "link_author": null, "id": 22954353545, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Isomorphismes: I feel vindicated in several ways by the Netflix Engineering team\u2019s...", "tags": [], "post_url": "http://datasyndrome.com/post/22954353545/isomorphismes-i-feel-vindicated-in-several-ways", "recommended_source": null, "state": "published", "reblog": {"comment": "", "tree_html": "<p><a href=\"http://isomorphismes.tumblr.com/post/22940787200/netflix\" class=\"tumblr_blog\">isomorphismes</a>:</p><blockquote>\n<p>I feel vindicated in several ways by the Netflix Engineering team\u2019s recent blog post explaining what they did with the results of the Netflix Prize. What they wrote confirms what I\u2019ve been saying about recommendations as well as my experience designing recommendation engines for clients, in\u2026</p>\n</blockquote>"}, "type": "link", "recommended_color": null, "description": "<p><a href=\"http://isomorphismes.tumblr.com/post/22940787200/netflix\" class=\"tumblr_blog\">isomorphismes</a>:</p>\n\n<blockquote>\n<p>I feel vindicated in several ways by the Netflix Engineering team\u2019s recent blog post explaining what they did with the results of the Netflix Prize. What they wrote confirms what I\u2019ve been saying about recommendations as well as my experience designing recommendation engines for clients, in&hellip;</p></blockquote>", "format": "html", "timestamp": 1336887244, "note_count": 26, "trail": [{"blog": {"can_be_followed": true, "name": "isomorphismes", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "header_full_height": 872, "title_color": "#444444", "header_bounds": "148,1024,724,0", "title_font": "Helvetica Neue", "link_color": "#529ECC", "header_image_focused": "https://secure.static.tumblr.com/d0e53fd21650b5b8e300519bb870afb8/7axmvqp/srcn5f6ys/tumblr_static_tumblr_static_d5zxpyulu5w8kss84w4k4oos8_focused_v3.jpg", "show_description": true, "header_full_width": 1024, "header_focus_width": 1024, "header_stretch": true, "show_header_image": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://secure.static.tumblr.com/d0e53fd21650b5b8e300519bb870afb8/7axmvqp/fADn5f6yq/tumblr_static_d5zxpyulu5w8kss84w4k4oos8_2048_v2.jpg", "avatar_shape": "circle", "show_avatar": true, "header_focus_height": 576, "background_color": "#F6F6F6", "header_image": "https://secure.static.tumblr.com/d0e53fd21650b5b8e300519bb870afb8/7axmvqp/fADn5f6yq/tumblr_static_d5zxpyulu5w8kss84w4k4oos8.jpg"}, "active": true}, "content": "<p>I feel vindicated in several ways by the Netflix Engineering team&rsquo;s recent blog post explaining what they did with the results of the Netflix Prize. What they wrote confirms what I&rsquo;ve been saying about recommendations as well as my experience designing recommendation engines for clients, in&hellip;</p>", "post": {"id": "22940787200"}, "content_raw": "<p>I feel vindicated in several ways by the Netflix Engineering team\u2019s recent blog post explaining what they did with the results of the Netflix Prize. What they wrote confirms what I\u2019ve been saying about recommendations as well as my experience designing recommendation engines for clients, in\u2026</p>", "is_root_item": true}], "date": "2012-05-13 05:34:04 GMT", "slug": "isomorphismes-i-feel-vindicated-in-several-ways", "blog_name": "rjurney", "publisher": "isomorphismes.tumblr.com", "url": "http://isomorphismes.tumblr.com/post/22940787200/netflix", "can_send_in_message": true, "summary": "Isomorphismes: I feel vindicated in several ways by the Netflix Engineering team\u2019s...", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "PbhAagtO", "short_url": "https://tmblr.co/ZbIO5yKWPDoM", "excerpt": null, "link_author": null, "id": 22018317462, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Apache Pig 0.10 is out!", "tags": [], "post_url": "http://datasyndrome.com/post/22018317462/apache-pig-010-is-out", "recommended_source": null, "state": "published", "reblog": {"comment": "<p><center>Hortonworks has described the new features <b><a href=\"http://hortonworks.com/blog/new-features-in-apache-pig-0-10/\">here</a></b>.\n<br><br><image src=\"http://research.yahoo.com/files/images/pig_open.gif\"></image></center></p>", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "<center>Hortonworks has described the new features <b><a href=\"http://hortonworks.com/blog/new-features-in-apache-pig-0-10/\">here</a></b>.\n<br/><br/><image src=\"http://research.yahoo.com/files/images/pig_open.gif\"></image></center>", "format": "html", "timestamp": 1335663433, "note_count": 0, "trail": [{"content": "<p>Hortonworks has described the new features <b><a href=\"http://hortonworks.com/blog/new-features-in-apache-pig-0-10/\">here</a></b>.\n<br /><br /></p>", "content_raw": "<p><center>Hortonworks has described the new features <b><a href=\"http://hortonworks.com/blog/new-features-in-apache-pig-0-10/\">here</a></b>.\n<br><br><image src=\"http://research.yahoo.com/files/images/pig_open.gif\"></image></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "22018317462"}}], "date": "2012-04-29 01:37:13 GMT", "slug": "apache-pig-010-is-out", "blog_name": "rjurney", "publisher": "pig.apache.org", "url": "http://pig.apache.org/docs/r0.10.0/", "can_send_in_message": true, "summary": "Apache Pig 0.10 is out!", "can_reblog": true}, {"body": "<p>Data Science: How many hours/week of specific tasks should be assigned to members of data science teams? 1 answer on Quora<br/><br/><span class=\"qlink_container\"><a href=\"http://www.quora.com/Data-Science/How-many-hours-week-of-specific-tasks-should-be-assigned-to-members-of-data-science-teams\" routing=\"q://question/(633178)\">How many hours/week of specific tasks should be assigned to members of data science teams?</a></span></p>", "liked": false, "followed": false, "reblog_key": "3fRYSIrw", "reblog": {"comment": "<p>Data Science: How many hours/week of specific tasks should be assigned to members of data science teams? 1 answer on Quora<br><br><span class=\"qlink_container\"><a href=\"http://www.quora.com/Data-Science/How-many-hours-week-of-specific-tasks-should-be-assigned-to-members-of-data-science-teams\" routing=\"q://question/(633178)\">How many hours/week of specific tasks should be assigned to members of data science teams?</a></span></p>", "tree_html": ""}, "can_send_in_message": true, "id": 21646036205, "display_avatar": true, "can_reply": true, "can_like": false, "title": "How many hours/week of specific tasks should be assigned to members of data science teams?", "tags": [], "post_url": "http://datasyndrome.com/post/21646036205/how-many-hoursweek-of-specific-tasks-should-be", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yKAD4pj", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1335189791, "note_count": 1, "trail": [{"content": "<p>Data Science: How many hours/week of specific tasks should be assigned to members of data science teams? 1 answer on Quora<br /><br /><a href=\"http://www.quora.com/Data-Science/How-many-hours-week-of-specific-tasks-should-be-assigned-to-members-of-data-science-teams\">How many hours/week of specific tasks should be assigned to members of data science teams?</a></p>", "content_raw": "<p>Data Science: How many hours/week of specific tasks should be assigned to members of data science teams? 1 answer on Quora<br><br><span class=\"qlink_container\"><a href=\"http://www.quora.com/Data-Science/How-many-hours-week-of-specific-tasks-should-be-assigned-to-members-of-data-science-teams\" routing=\"q://question/(633178)\">How many hours/week of specific tasks should be assigned to members of data science teams?</a></span></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "21646036205"}}], "date": "2012-04-23 14:03:11 GMT", "slug": "how-many-hoursweek-of-specific-tasks-should-be", "blog_name": "rjurney", "summary": "How many hours/week of specific tasks should be assigned to members of data science teams?", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "W5FM2zeP", "short_url": "https://tmblr.co/ZbIO5yJr0hbA", "excerpt": null, "link_author": null, "id": 21290465610, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Kickstarter - Light Table - A Better IDE", "tags": [], "post_url": "http://datasyndrome.com/post/21290465610/kickstarter-light-table-a-better-ide", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>I call on everyone to support the <a href=\"http://kck.st/J6mgBL\">Light Table Kickstarter project</a>. The goal is $200,000 and it is not yet met.\n\n<b>Light Table is a huge step forward in Integrated Development Environments.  \n</b>\n\n<p style=\"margin-left: 40px;\"><i>Light Table is based on a very simple idea: we need a real work surface to code on, not just an editor and a project explorer. We need to be able to move things around, keep clutter down, and bring information to the foreground in the places we need it most.</i></p>\n\nPlease <a href=\"http://kck.st/J6mgBL\">give</a>.</p>", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "I call on everyone to support the <a href=\"http://kck.st/J6mgBL\">Light Table Kickstarter project</a>. The goal is $200,000 and it is not yet met.\n\n<b>Light Table is a huge step forward in Integrated Development Environments.  \n</b>\n\n<p style=\"margin-left: 40px;\"><i>Light Table is based on a very simple idea: we need a real work surface to code on, not just an editor and a project explorer. We need to be able to move things around, keep clutter down, and bring information to the foreground in the places we need it most.</i></p>\n\nPlease <a href=\"http://kck.st/J6mgBL\">give</a>.", "format": "html", "timestamp": 1334703240, "note_count": 3, "trail": [{"content": "<p><p>I call on everyone to support the <a href=\"http://kck.st/J6mgBL\">Light Table Kickstarter project</a>. The goal is $200,000 and it is not yet met.\n\n<b>Light Table is a huge step forward in Integrated Development Environments.  \n</b>\n\n</p><p><i>Light Table is based on a very simple idea: we need a real work surface to code on, not just an editor and a project explorer. We need to be able to move things around, keep clutter down, and bring information to the foreground in the places we need it most.</i></p>\n\nPlease <a href=\"http://kck.st/J6mgBL\">give</a>.</p>", "content_raw": "<p>I call on everyone to support the <a href=\"http://kck.st/J6mgBL\">Light Table Kickstarter project</a>. The goal is $200,000 and it is not yet met.\n\n<b>Light Table is a huge step forward in Integrated Development Environments.  \n</b>\n\n<p style=\"margin-left: 40px;\"><i>Light Table is based on a very simple idea: we need a real work surface to code on, not just an editor and a project explorer. We need to be able to move things around, keep clutter down, and bring information to the foreground in the places we need it most.</i></p>\n\nPlease <a href=\"http://kck.st/J6mgBL\">give</a>.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "21290465610"}}], "date": "2012-04-17 22:54:00 GMT", "slug": "kickstarter-light-table-a-better-ide", "blog_name": "rjurney", "publisher": "kck.st", "url": "http://kck.st/J6mgBL", "can_send_in_message": true, "summary": "Kickstarter - Light Table - A Better IDE", "can_reblog": true, "bookmarklet": true}, {"body": "<p>Data Science: Where does research end and development begin? Write an answer on Quora<br/><br/><span class=\"qlink_container\"><a href=\"http://www.quora.com/Data-Science/Where-does-research-end-and-development-begin\" routing=\"q://question/(624022)\">Where does research end and development begin?</a></span></p>", "liked": false, "followed": false, "reblog_key": "s1006oR4", "reblog": {"comment": "<p>Data Science: Where does research end and development begin? Write an answer on Quora<br><br><span class=\"qlink_container\"><a href=\"http://www.quora.com/Data-Science/Where-does-research-end-and-development-begin\" routing=\"q://question/(624022)\">Where does research end and development begin?</a></span></p>", "tree_html": ""}, "can_send_in_message": true, "id": 20834468464, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Where does research end and development begin?", "tags": [], "post_url": "http://datasyndrome.com/post/20834468464/where-does-research-end-and-development-begin", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yJPrC9m", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1334047987, "note_count": 0, "trail": [{"content": "<p>Data Science: Where does research end and development begin? Write an answer on Quora<br /><br /><a href=\"http://www.quora.com/Data-Science/Where-does-research-end-and-development-begin\">Where does research end and development begin?</a></p>", "content_raw": "<p>Data Science: Where does research end and development begin? Write an answer on Quora<br><br><span class=\"qlink_container\"><a href=\"http://www.quora.com/Data-Science/Where-does-research-end-and-development-begin\" routing=\"q://question/(624022)\">Where does research end and development begin?</a></span></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "20834468464"}}], "date": "2012-04-10 08:53:07 GMT", "slug": "where-does-research-end-and-development-begin", "blog_name": "rjurney", "summary": "Where does research end and development begin?", "can_reblog": true}, {"body": "<p>Apache Pig is now a LinkedIn Skill: \n  <a href=\"http://www.linkedin.com/skills/skill/Pig\">http://www.linkedin.com/skills/skill/Pig</a>. Be sure and add it to your profile, and to network with other Piggies!\n</p>\n\n\n<center><img src=\"https://s3.amazonaws.com/rjurney_public_web/images/pig.skill.png\"/></center>", "liked": false, "followed": false, "reblog_key": "cXc0EhYQ", "reblog": {"comment": "<p><p>Apache Pig is now a LinkedIn Skill: \n  <a href=\"http://www.linkedin.com/skills/skill/Pig\">http://www.linkedin.com/skills/skill/Pig</a>. Be sure and add it to your profile, and to network with other Piggies!\n</p>\n\n\n<center><img src=\"https://s3.amazonaws.com/rjurney_public_web/images/pig.skill.png\"></center></p>", "tree_html": ""}, "can_send_in_message": true, "id": 20389317188, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Apache Pig is now a LinkedIn Skill", "tags": [], "post_url": "http://datasyndrome.com/post/20389317188/apache-pig-is-now-a-linkedin-skill", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yI-J4f4", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1333421819, "note_count": 0, "trail": [{"content": "<p><p>Apache Pig is now a LinkedIn Skill: \n  <a href=\"http://www.linkedin.com/skills/skill/Pig\">http://www.linkedin.com/skills/skill/Pig</a>. Be sure and add it to your profile, and to network with other Piggies!\n</p>\n\n\n<div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://s3.amazonaws.com/rjurney_public_web/images/pig.skill.png\">External image</div></p>", "content_raw": "<p><p>Apache Pig is now a LinkedIn Skill: \n  <a href=\"http://www.linkedin.com/skills/skill/Pig\">http://www.linkedin.com/skills/skill/Pig</a>. Be sure and add it to your profile, and to network with other Piggies!\n</p>\n\n\n<center><img src=\"https://s3.amazonaws.com/rjurney_public_web/images/pig.skill.png\"></center></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "20389317188"}}], "date": "2012-04-03 02:56:59 GMT", "slug": "apache-pig-is-now-a-linkedin-skill", "blog_name": "rjurney", "summary": "Apache Pig is now a LinkedIn Skill", "can_reblog": true}, {"body": "<p>In August, 2007 <a href=\"http://blog.weatherby.net/2007/08/free-iphone-arr.html#comment-164860470\">commented</a> on a post on <a href=\"http://blog.weatherby.net\">Lance Weatherby&rsquo;s Blog</a>.</p>\n\n<p>I spoke thus:</p>\n\n<p style=\"margin-left: 30px;\"><i><bq>The iPhone is a toy and a cell phone compared to what it will become: The next dominant computing platform. Finally someone capable of wrapping advances in GPS location, bluetooth personal area networks, wireless communications, artificial intelligence, digital speech/voice recognition and web services has released a computing platform to take advantage of them all.<br/><br/>\n\nYou are walking down a city street. You have your iPhone 2.0 in your pocket, and a tiny Apple bluetooth headset on. You want coffee and wifi. Your personal digital assistant&rsquo;s name is Cleo. &ldquo;Cleo, find me coffee with wifi access.&rdquo; Cleo queries Google Maps for you and then tells you, in your bluetooth headset, the names of 5 of the nearest coffee shops with wifi, starting with the nearest. You pick the first one. &ldquo;Cleo, directions to Javaology.&rdquo; Cleo gives you directions, and tells you when you take a wrong turn.<br/><br/>\n\nOn the way, you find you love the neighborhood you are in. &ldquo;Cleo, find me an apartment in this area.&rdquo; Cleo does. She starts rattling off listings. Pick one and she&rsquo;ll give you directions.<br/><br/>\n\nYou glance in a store window and see a new book called &lsquo;Gary Potter Volume 11,&rsquo; and you have 1-10. &ldquo;Cleo, order Kama Sutra Volume 11 from Amazon to my home.&rdquo;\nFeeling scared? &ldquo;Cleo, what is the crime rate in this area?&rdquo; Cleo tells you.\nCleo will announce the names of other people you meet and will exchange cards between your iPhones.<br/><br/>\n\nWe&rsquo;ll all start doing things like this in the next few years. The step after that will be glasses which will coordinate with GPS and cell location to overlay 3D imagery on the street, in malls, etc. A la Spook Country, a highly recommended read.\nI know that we&rsquo;ll be doing this, because if nobody else does&hellip; I&rsquo;ll start a company to build this. But I suspect apple will do it for us.</bq></i><br/></p>\n\nAnd, before there was a dev kit:<br/><br/><p style=\"margin-left: 30px;\"><i><bq>Heh, fortunately there is a complete dev toolkit for the iPhone and it would require some platform integration.</bq></i></p>", "liked": false, "followed": false, "reblog_key": "xnQ50Lc2", "reblog": {"comment": "<p>In August, 2007 <a href=\"http://blog.weatherby.net/2007/08/free-iphone-arr.html#comment-164860470\">commented</a> on a post on <a href=\"http://blog.weatherby.net\">Lance Weatherby\u2019s Blog</a>.</p>\n\n<p>I spoke thus:</p>\n\n<p style=\"margin-left: 30px;\"><i><bq>The iPhone is a toy and a cell phone compared to what it will become: The next dominant computing platform. Finally someone capable of wrapping advances in GPS location, bluetooth personal area networks, wireless communications, artificial intelligence, digital speech/voice recognition and web services has released a computing platform to take advantage of them all.<br><br>\n\nYou are walking down a city street. You have your iPhone 2.0 in your pocket, and a tiny Apple bluetooth headset on. You want coffee and wifi. Your personal digital assistant\u2019s name is Cleo. \u201cCleo, find me coffee with wifi access.\u201d Cleo queries Google Maps for you and then tells you, in your bluetooth headset, the names of 5 of the nearest coffee shops with wifi, starting with the nearest. You pick the first one. \u201cCleo, directions to Javaology.\u201d Cleo gives you directions, and tells you when you take a wrong turn.<br><br>\n\nOn the way, you find you love the neighborhood you are in. \u201cCleo, find me an apartment in this area.\u201d Cleo does. She starts rattling off listings. Pick one and she\u2019ll give you directions.<br><br>\n\nYou glance in a store window and see a new book called \u2018Gary Potter Volume 11,\u2019 and you have 1-10. \u201cCleo, order Kama Sutra Volume 11 from Amazon to my home.\u201d\nFeeling scared? \u201cCleo, what is the crime rate in this area?\u201d Cleo tells you.\nCleo will announce the names of other people you meet and will exchange cards between your iPhones.<br><br>\n\nWe\u2019ll all start doing things like this in the next few years. The step after that will be glasses which will coordinate with GPS and cell location to overlay 3D imagery on the street, in malls, etc. A la Spook Country, a highly recommended read.\nI know that we\u2019ll be doing this, because if nobody else does\u2026 I\u2019ll start a company to build this. But I suspect apple will do it for us.</bq></i><br></p>\n\nAnd, before there was a dev kit:<br><br><p style=\"margin-left: 30px;\"><i><bq>Heh, fortunately there is a complete dev toolkit for the iPhone and it would require some platform integration.</bq></i></p>", "tree_html": ""}, "can_send_in_message": true, "id": 19646944562, "display_avatar": true, "can_reply": true, "can_like": false, "title": "I predicted the iPhone 4S in August, 2007", "tags": [], "post_url": "http://datasyndrome.com/post/19646944562/i-predicted-the-iphone-4s-in-august-2007", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yIJ39Ko", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1332283394, "note_count": 0, "trail": [{"content": "<p>In August, 2007 <a href=\"http://blog.weatherby.net/2007/08/free-iphone-arr.html#comment-164860470\">commented</a> on a post on <a href=\"http://blog.weatherby.net\">Lance Weatherby&rsquo;s Blog</a>.</p>\n\n<p>I spoke thus:</p>\n\n<p><i>The iPhone is a toy and a cell phone compared to what it will become: The next dominant computing platform. Finally someone capable of wrapping advances in GPS location, bluetooth personal area networks, wireless communications, artificial intelligence, digital speech/voice recognition and web services has released a computing platform to take advantage of them all.<br /><br />\n\nYou are walking down a city street. You have your iPhone 2.0 in your pocket, and a tiny Apple bluetooth headset on. You want coffee and wifi. Your personal digital assistant&rsquo;s name is Cleo. &ldquo;Cleo, find me coffee with wifi access.&rdquo; Cleo queries Google Maps for you and then tells you, in your bluetooth headset, the names of 5 of the nearest coffee shops with wifi, starting with the nearest. You pick the first one. &ldquo;Cleo, directions to Javaology.&rdquo; Cleo gives you directions, and tells you when you take a wrong turn.<br /><br />\n\nOn the way, you find you love the neighborhood you are in. &ldquo;Cleo, find me an apartment in this area.&rdquo; Cleo does. She starts rattling off listings. Pick one and she&rsquo;ll give you directions.<br /><br />\n\nYou glance in a store window and see a new book called &lsquo;Gary Potter Volume 11,&rsquo; and you have 1-10. &ldquo;Cleo, order Kama Sutra Volume 11 from Amazon to my home.&rdquo;\nFeeling scared? &ldquo;Cleo, what is the crime rate in this area?&rdquo; Cleo tells you.\nCleo will announce the names of other people you meet and will exchange cards between your iPhones.<br /><br />\n\nWe&rsquo;ll all start doing things like this in the next few years. The step after that will be glasses which will coordinate with GPS and cell location to overlay 3D imagery on the street, in malls, etc. A la Spook Country, a highly recommended read.\nI know that we&rsquo;ll be doing this, because if nobody else does&hellip; I&rsquo;ll start a company to build this. But I suspect apple will do it for us.</i><br /></p>\n\nAnd, before there was a dev kit:<br /><br /><p><i>Heh, fortunately there is a complete dev toolkit for the iPhone and it would require some platform integration.</i></p>", "content_raw": "<p>In August, 2007 <a href=\"http://blog.weatherby.net/2007/08/free-iphone-arr.html#comment-164860470\">commented</a> on a post on <a href=\"http://blog.weatherby.net\">Lance Weatherby\u2019s Blog</a>.</p>\n\n<p>I spoke thus:</p>\n\n<p style=\"margin-left: 30px;\"><i><bq>The iPhone is a toy and a cell phone compared to what it will become: The next dominant computing platform. Finally someone capable of wrapping advances in GPS location, bluetooth personal area networks, wireless communications, artificial intelligence, digital speech/voice recognition and web services has released a computing platform to take advantage of them all.<br><br>\n\nYou are walking down a city street. You have your iPhone 2.0 in your pocket, and a tiny Apple bluetooth headset on. You want coffee and wifi. Your personal digital assistant\u2019s name is Cleo. \u201cCleo, find me coffee with wifi access.\u201d Cleo queries Google Maps for you and then tells you, in your bluetooth headset, the names of 5 of the nearest coffee shops with wifi, starting with the nearest. You pick the first one. \u201cCleo, directions to Javaology.\u201d Cleo gives you directions, and tells you when you take a wrong turn.<br><br>\n\nOn the way, you find you love the neighborhood you are in. \u201cCleo, find me an apartment in this area.\u201d Cleo does. She starts rattling off listings. Pick one and she\u2019ll give you directions.<br><br>\n\nYou glance in a store window and see a new book called \u2018Gary Potter Volume 11,\u2019 and you have 1-10. \u201cCleo, order Kama Sutra Volume 11 from Amazon to my home.\u201d\nFeeling scared? \u201cCleo, what is the crime rate in this area?\u201d Cleo tells you.\nCleo will announce the names of other people you meet and will exchange cards between your iPhones.<br><br>\n\nWe\u2019ll all start doing things like this in the next few years. The step after that will be glasses which will coordinate with GPS and cell location to overlay 3D imagery on the street, in malls, etc. A la Spook Country, a highly recommended read.\nI know that we\u2019ll be doing this, because if nobody else does\u2026 I\u2019ll start a company to build this. But I suspect apple will do it for us.</bq></i><br></p>\n\nAnd, before there was a dev kit:<br><br><p style=\"margin-left: 30px;\"><i><bq>Heh, fortunately there is a complete dev toolkit for the iPhone and it would require some platform integration.</bq></i></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "19646944562"}}], "date": "2012-03-20 22:43:14 GMT", "slug": "i-predicted-the-iphone-4s-in-august-2007", "blog_name": "rjurney", "summary": "I predicted the iPhone 4S in August, 2007", "can_reblog": true}, {"body": "<p>Today Y Combinator announced that they&rsquo;re funding teams without an idea.  This is another step in pushing seed funding towards its ultimate destination: a credit card application.  Web form, attach video, check social networks, get back to you soon, ship a card!\n\n</p><center><img src=\"https://lh3.googleusercontent.com/-HONnwRCExRM/T2ANnr7IIPI/AAAAAAAAAD0/DgcfkMxzZ8E/s400/YC-Amex.png\"/></center>\n\n<i>* This isn&rsquo;t a bad thing. This is a good thing. Obviously the mentoring that comes with the platinum card is worth more than the cash. This is humor :)</i>", "liked": false, "followed": false, "reblog_key": "7dd41zzJ", "reblog": {"comment": "<p><p>Today Y Combinator announced that they\u2019re funding teams without an idea.  This is another step in pushing seed funding towards its ultimate destination: a credit card application.  Web form, attach video, check social networks, get back to you soon, ship a card!\n\n</p><center><img src=\"https://lh3.googleusercontent.com/-HONnwRCExRM/T2ANnr7IIPI/AAAAAAAAAD0/DgcfkMxzZ8E/s400/YC-Amex.png\"></center>\n\n<i>* This isn\u2019t a bad thing. This is a good thing. Obviously the mentoring that comes with the platinum card is worth more than the cash. This is humor :)</i></p>", "tree_html": ""}, "can_send_in_message": true, "id": 19274060089, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Y Combinator Amex", "tags": [], "post_url": "http://datasyndrome.com/post/19274060089/y-combinator-amex", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yHyqj4v", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1331695320, "note_count": 0, "trail": [{"content": "<p><p>Today Y Combinator announced that they&rsquo;re funding teams without an idea.  This is another step in pushing seed funding towards its ultimate destination: a credit card application.  Web form, attach video, check social networks, get back to you soon, ship a card!\n\n</p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://lh3.googleusercontent.com/-HONnwRCExRM/T2ANnr7IIPI/AAAAAAAAAD0/DgcfkMxzZ8E/s400/YC-Amex.png\">External image</div>\n\n<i>* This isn&rsquo;t a bad thing. This is a good thing. Obviously the mentoring that comes with the platinum card is worth more than the cash. This is humor :)</i></p>", "content_raw": "<p><p>Today Y Combinator announced that they\u2019re funding teams without an idea.  This is another step in pushing seed funding towards its ultimate destination: a credit card application.  Web form, attach video, check social networks, get back to you soon, ship a card!\n\n</p><center><img src=\"https://lh3.googleusercontent.com/-HONnwRCExRM/T2ANnr7IIPI/AAAAAAAAAD0/DgcfkMxzZ8E/s400/YC-Amex.png\"></center>\n\n<i>* This isn\u2019t a bad thing. This is a good thing. Obviously the mentoring that comes with the platinum card is worth more than the cash. This is humor :)</i></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "19274060089"}}], "date": "2012-03-14 03:22:00 GMT", "slug": "y-combinator-amex", "blog_name": "rjurney", "summary": "Y Combinator Amex", "can_reblog": true}, {"body": "<p>It took a month of platform work, but I just used Amazon&rsquo;s Elastic MapReduce to read data from Amazon S3 in Avro format, process it in pig on a 3 node Hadoop cluster and store it in MongoHQ.</p>\n\n<p>I did not anticipate such difficulties in doing this, but as I labored to make it work&hellip; and as friends of mine labored with similar problems with Hadoop I/O as I did, it reminded me:</p>\n\n<p>Every data science team needs an embedded platform engineer that spends a good deal of her time responding to issues data scientists and developers have.  And resolving them.</p>", "liked": false, "followed": false, "reblog_key": "I73muiZF", "reblog": {"comment": "<p>It took a month of platform work, but I just used Amazon\u2019s Elastic MapReduce to read data from Amazon S3 in Avro format, process it in pig on a 3 node Hadoop cluster and store it in MongoHQ.</p>\n\n<p>I did not anticipate such difficulties in doing this, but as I labored to make it work\u2026 and as friends of mine labored with similar problems with Hadoop I/O as I did, it reminded me:</p>\n\n<p>Every data science team needs an embedded platform engineer that spends a good deal of her time responding to issues data scientists and developers have.  And resolving them.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 18568298737, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Dedicated Platform Engineers OR Elastic MapReduce::Pig.execute( S3/Avro -> MongoHQ)", "tags": [], "post_url": "http://datasyndrome.com/post/18568298737/dedicated-platform-engineers-or-elastic", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yHImS3n", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1330638840, "note_count": 1, "trail": [{"content": "<p>It took a month of platform work, but I just used Amazon&rsquo;s Elastic MapReduce to read data from Amazon S3 in Avro format, process it in pig on a 3 node Hadoop cluster and store it in MongoHQ.</p>\n\n<p>I did not anticipate such difficulties in doing this, but as I labored to make it work&hellip; and as friends of mine labored with similar problems with Hadoop I/O as I did, it reminded me:</p>\n\n<p>Every data science team needs an embedded platform engineer that spends a good deal of her time responding to issues data scientists and developers have.  And resolving them.</p>", "content_raw": "<p>It took a month of platform work, but I just used Amazon\u2019s Elastic MapReduce to read data from Amazon S3 in Avro format, process it in pig on a 3 node Hadoop cluster and store it in MongoHQ.</p>\n\n<p>I did not anticipate such difficulties in doing this, but as I labored to make it work\u2026 and as friends of mine labored with similar problems with Hadoop I/O as I did, it reminded me:</p>\n\n<p>Every data science team needs an embedded platform engineer that spends a good deal of her time responding to issues data scientists and developers have.  And resolving them.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "18568298737"}}], "date": "2012-03-01 21:54:00 GMT", "slug": "dedicated-platform-engineers-or-elastic", "blog_name": "rjurney", "summary": "Dedicated Platform Engineers OR Elastic MapReduce::Pig.execute( S3/Avro -> MongoHQ)", "can_reblog": true}, {"body": "<p>Alchemy was the quest of transmuting lead into gold.  Data Science is the journey of minting data into money.</p>\n\n<p>Alchemy was immature chemistry.  Data Science is immature&hellip;?</p>", "liked": false, "followed": false, "reblog_key": "97T6qgKI", "reblog": {"comment": "<p>Alchemy was the quest of transmuting lead into gold.  Data Science is the journey of minting data into money.</p>\n\n<p>Alchemy was immature chemistry.  Data Science is immature\u2026?</p>", "tree_html": ""}, "can_send_in_message": true, "id": 18491351118, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Alchemy", "tags": [], "post_url": "http://datasyndrome.com/post/18491351118/alchemy", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yHEAw1E", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1330517359, "note_count": 0, "trail": [{"content": "<p>Alchemy was the quest of transmuting lead into gold.  Data Science is the journey of minting data into money.</p>\n\n<p>Alchemy was immature chemistry.  Data Science is immature&hellip;?</p>", "content_raw": "<p>Alchemy was the quest of transmuting lead into gold.  Data Science is the journey of minting data into money.</p>\n\n<p>Alchemy was immature chemistry.  Data Science is immature\u2026?</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "18491351118"}}], "date": "2012-02-29 12:09:19 GMT", "slug": "alchemy", "blog_name": "rjurney", "summary": "Alchemy", "can_reblog": true}, {"body": "This makes me very, very happy.  I got Pig AvroStorage working on S3 from EMR.\n\n<pre><code>grunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\ngrunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\ngrunt&gt; REGISTER /me/pig/contrib/piggybank/java/piggybank.jar\ngrunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\ngrunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\ngrunt&gt; \ngrunt&gt; DEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\ngrunt&gt; a = LOAD 's3n://agile.data/again_inbox' USING AvroStorage();\n2012-02-29 09:49:13,022 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\ngrunt&gt; describe a\n2012-02-29 09:49:19,951 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\na: {message_id: chararray,from: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},cc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},bcc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},in_reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},subject: chararray,body: chararray,date: chararray}</code></pre>", "liked": false, "followed": false, "reblog_key": "INhZBUXP", "reblog": {"comment": "<p>This makes me very, very happy.  I got Pig AvroStorage working on S3 from EMR.\n\n<pre><code>grunt> REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\ngrunt> REGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\ngrunt> REGISTER /me/pig/contrib/piggybank/java/piggybank.jar\ngrunt> REGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\ngrunt> REGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\ngrunt> \ngrunt> DEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\ngrunt> a = LOAD 's3n://agile.data/again_inbox' USING AvroStorage();\n2012-02-29 09:49:13,022 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\ngrunt> describe a\n2012-02-29 09:49:19,951 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\na: {message_id: chararray,from: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},cc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},bcc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},in_reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},subject: chararray,body: chararray,date: chararray}</code></pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 18489178195, "display_avatar": true, "can_reply": true, "can_like": false, "title": "AvroStorage on S3 from EMR", "tags": [], "post_url": "http://datasyndrome.com/post/18489178195/avrostorage-on-s3-from-emr", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yHE2dXJ", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1330509079, "note_count": 0, "trail": [{"content": "<p><p>This makes me very, very happy.  I got Pig AvroStorage working on S3 from EMR.\n\n</p><pre><code>grunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\ngrunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\ngrunt&gt; REGISTER /me/pig/contrib/piggybank/java/piggybank.jar\ngrunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\ngrunt&gt; REGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\ngrunt&gt; \ngrunt&gt; DEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\ngrunt&gt; a = LOAD 's3n://agile.data/again_inbox' USING AvroStorage();\n2012-02-29 09:49:13,022 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\ngrunt&gt; describe a\n2012-02-29 09:49:19,951 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\na: {message_id: chararray,from: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},cc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},bcc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},in_reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},subject: chararray,body: chararray,date: chararray}</code></pre></p>", "content_raw": "<p>This makes me very, very happy.  I got Pig AvroStorage working on S3 from EMR.\n\n<pre><code>grunt> REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\ngrunt> REGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\ngrunt> REGISTER /me/pig/contrib/piggybank/java/piggybank.jar\ngrunt> REGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\ngrunt> REGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\ngrunt> \ngrunt> DEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\ngrunt> a = LOAD 's3n://agile.data/again_inbox' USING AvroStorage();\n2012-02-29 09:49:13,022 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\ngrunt> describe a\n2012-02-29 09:49:19,951 [main] INFO  org.apache.hadoop.fs.s3native.NativeS3FileSystem - Opening 's3n://agile.data/again_inbox/part-4-0.avro' for reading\na: {message_id: chararray,from: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},cc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},bcc: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},in_reply_to: {PIG_WRAPPER: (ARRAY_ELEM: chararray)},subject: chararray,body: chararray,date: chararray}</code></pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "18489178195"}}], "date": "2012-02-29 09:51:19 GMT", "slug": "avrostorage-on-s3-from-emr", "blog_name": "rjurney", "summary": "AvroStorage on S3 from EMR", "can_reblog": true}, {"body": "<p><i>This post represents the author&rsquo;s opinion alone, and not any other organization, project or company.</i></p>\n\n<p>Submitting text files via a form to update an Apache software project is the modern-day technology equivalent of medieval doctors bleeding patients while administering laxatives to cure Cholera.  </p>\n\n<p>And yet that is the process of updating the open-source infrastructure driving the data revolution.  Compared to the simplicity of github pull requests, using a JIRA web form to submit text patches against a monolithic subversion database is extremely difficult.  Not 10x difficult.  Closer to 100x difficult for new, would-be contributors.  </p>\n\n<p>The result is that a very high bar is set for contributors.  Which is anti-community.  And since open source relies on community&hellip; it is anti-open source.</p>\n\n<p>We live in a post-github world.  Git enabled social coding, and it is past time that Apache caught up.</p>", "liked": false, "followed": false, "reblog_key": "Byqbh1dw", "reblog": {"comment": "<p><i>This post represents the author\u2019s opinion alone, and not any other organization, project or company.</i></p>\n\n<p>Submitting text files via a form to update an Apache software project is the modern-day technology equivalent of medieval doctors bleeding patients while administering laxatives to cure Cholera.  </p>\n\n<p>And yet that is the process of updating the open-source infrastructure driving the data revolution.  Compared to the simplicity of github pull requests, using a JIRA web form to submit text patches against a monolithic subversion database is extremely difficult.  Not 10x difficult.  Closer to 100x difficult for new, would-be contributors.  </p>\n\n<p>The result is that a very high bar is set for contributors.  Which is anti-community.  And since open source relies on community\u2026 it is anti-open source.</p>\n\n<p>We live in a post-github world.  Git enabled social coding, and it is past time that Apache caught up.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 18472926718, "display_avatar": true, "can_reply": true, "can_like": false, "title": "JIRA and Text Patches are Anti-Open-Source", "tags": [], "post_url": "http://datasyndrome.com/post/18472926718/jira-and-text-patches-are-anti-open-source", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yHD4dt_", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1330482540, "note_count": 1, "trail": [{"content": "<p><i>This post represents the author&rsquo;s opinion alone, and not any other organization, project or company.</i></p>\n\n<p>Submitting text files via a form to update an Apache software project is the modern-day technology equivalent of medieval doctors bleeding patients while administering laxatives to cure Cholera.  </p>\n\n<p>And yet that is the process of updating the open-source infrastructure driving the data revolution.  Compared to the simplicity of github pull requests, using a JIRA web form to submit text patches against a monolithic subversion database is extremely difficult.  Not 10x difficult.  Closer to 100x difficult for new, would-be contributors.  </p>\n\n<p>The result is that a very high bar is set for contributors.  Which is anti-community.  And since open source relies on community&hellip; it is anti-open source.</p>\n\n<p>We live in a post-github world.  Git enabled social coding, and it is past time that Apache caught up.</p>", "content_raw": "<p><i>This post represents the author\u2019s opinion alone, and not any other organization, project or company.</i></p>\n\n<p>Submitting text files via a form to update an Apache software project is the modern-day technology equivalent of medieval doctors bleeding patients while administering laxatives to cure Cholera.  </p>\n\n<p>And yet that is the process of updating the open-source infrastructure driving the data revolution.  Compared to the simplicity of github pull requests, using a JIRA web form to submit text patches against a monolithic subversion database is extremely difficult.  Not 10x difficult.  Closer to 100x difficult for new, would-be contributors.  </p>\n\n<p>The result is that a very high bar is set for contributors.  Which is anti-community.  And since open source relies on community\u2026 it is anti-open source.</p>\n\n<p>We live in a post-github world.  Git enabled social coding, and it is past time that Apache caught up.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "18472926718"}}], "date": "2012-02-29 02:29:00 GMT", "slug": "jira-and-text-patches-are-anti-open-source", "blog_name": "rjurney", "summary": "JIRA and Text Patches are Anti-Open-Source", "can_reblog": true}, {"body": "<center><bq>&ldquo;the more powerful the language, the shorter the program&rdquo;</bq></center>\n<div class=\"credit\" align=\"right\" style=\"margin-right: 50px;\"><small>Source:\n<cite><a href=\"http://www.paulgraham.com/icad.html\">Paul Graham, Revenge of the Nerds</a></cite>.</small></div>\n<br/><br/><p><a href=\"http://pig.apache.org/docs/r0.9.2/udf.html#python-udfs\">Jython UDFs</a> were added to Pig in version 0.8, and are pretty stable in the current version, 0.9.2.  They are highly convenient, and a major timesaver.</p>\n\nUsing <a href=\"http://pig.apache.org/docs/r0.9.2/udf.html\">Jython UDFs</a> is simple.  Create a UDF in <code>udfs.py</code>:\n\n<pre><code># Extracts the hour from an iso8601 datetime string\n@outputSchema(\"hour:chararray\")\ndef hour(iso_string):\n  tuple_time = time.strptime(iso_string, \"%Y-%m-%dT%H:%M:%S\")\n  return str(tuple_time[2])</code></pre>\n\nImport and run the UDF in Pig via:\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\n\n2012-02-13 16:19:33,325 [main] INFO  org.apache.pig.scripting.jython.JythonScriptEngine - Register scripting UDF: myfuncs.hour\n\ngrunt&gt; describe times;                                                        \ntimes: {date: chararray}\ngrunt&gt; hours = foreach times generate date, myfuncs.hour(date) as hour;\ngrunt&gt; dump hours\n\n(2011-12-08T00:03:07-08:00,8)\n(2011-12-08T00:08:05-08:00,8)\n(2011-12-08T07:33:40+00:00,8)\n(2011-12-08T08:28:32+00:00,8)\n(2011-12-08T09:26:25+01:00,8)\n(2011-12-08T13:02:32+05:30,8)\n(2011-12-08T13:20:27+05:30,8)\n(2011-12-08T13:40:44+05:30,8)\n(2011-12-08T13:54:54+05:30,8)\n(2011-12-08T13:59:47+05:30,8)\n</code></pre>\n\n<p>Jython can operate on complex types as well.  Lets prepare a grouped relation, containing email subjects between pairs of email addresses, and then run it through a Jython UDF to get a word count.</p>\n\n<p>The UDF computes word counts given a bag of subjects and a tuple of (from, to) pairs:</p>\n\n<pre><code># Given from, to email address pairs and a bag of their subjects, return from, to and a bag of word counts\n# Input format: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n@outputSchema(\"t:(from:chararray, to:chararray, word_counts:bag{t2:(word:chararray, total:int)})\")\ndef word_count_subjects(group, subjects):\n  to = group[0]\n  _from = group[1]\n  word_counts = {}\n  for subject in subjects:\n    words = subject[0].split()\n    for word in words:\n      word_counts[word] = word_counts.get(word, 0) + 1\n  return to, _from, sorted(word_counts.items(), key=lambda word_count: word_count[1], reverse=True)\n</code></pre>\n\n<p>Import the UDF in Pig and run it against our grouped relation:</p>\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\ngrunt&gt; emails = limit emails 100;\ngrunt&gt; emails = filter emails by (from is not null) and (to is not null);\ngrunt&gt; pairs = foreach emails generate flatten(from) as from, flatten(to) as to, subject;\ngrunt&gt; gft = group pairs by (from, to);\ngrunt&gt; gft = foreach gft generate group, pairs.(subject) as subjects;\ngrunt&gt; describe gft\n<br/>\ngft: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n<br/>\ngrunt&gt; to_from_word_counts = foreach gft generate myfuncs.word_count_subjects(group, subjects);\ngrunt&gt; store to_from_word_counts into '/tmp/jython_test.txt';</code></pre>\n\nOur result:\n\n<pre><code>(tim@nada1.de,user@jruby.codehaus.org,{(file,2),([jruby-user],2),(.so,2),(a,2),(Problems,2),(Re:,2),(loading,2)})\n(victor@x.com,user@avro.apache.org,{(in,1),(avdl,1),(of,1),(classpath,1),(Importing,1),(RE:,1),(from,1),(project,1)})\n(info@meetup.com,russell.jurney@gmail.com,{(Dave,1),(Stories,1),(comment,1),(a,1),(War,1),(posted,1),(Data,1),(Big,1),(for,1),(Nielsen,1)})\n(jira@apache.org,russell.jurney@gmail.com,{([jira],8),(in,8),(a,8),(bag,6),(fails,6),(Avro,4),(as,4),(of,4),(STORE,4),(single-field,4),((PIG-2411),4),(tuples,4),(to,4),(UDF,4),(AvroStorage,4),(PiggyBank,4),(when,4),(arrays,4),([Updated],3),([Commented],3),(UDF),2),(used,2),(SQL,2),(with,2),(java.lang.NullPointerException,2),(interface,2),(Util.getSchemaFromString,2),([Created],2),(MongoStorage,2),(for,2),(name,2),(tuple,2),((as,2),(Pig,2),((PIG-824),2),(no,2),(has,2),((PIG-2509),2)})</code></pre>\n\nOnce you get the hang of processing tuples in Jython, any UDF is a breeze!", "liked": false, "followed": false, "reblog_key": "VKnf03pd", "reblog": {"comment": "<p><center><bq>\u201cthe more powerful the language, the shorter the program\u201d</bq></center>\n<div class=\"credit\" align=\"right\" style=\"margin-right: 50px;\"><small>Source:\n<cite><a href=\"http://www.paulgraham.com/icad.html\">Paul Graham, Revenge of the Nerds</a></cite>.</small></div>\n<br><br><p><a href=\"http://pig.apache.org/docs/r0.9.2/udf.html#python-udfs\">Jython UDFs</a> were added to Pig in version 0.8, and are pretty stable in the current version, 0.9.2.  They are highly convenient, and a major timesaver.</p>\n\nUsing <a href=\"http://pig.apache.org/docs/r0.9.2/udf.html\">Jython UDFs</a> is simple.  Create a UDF in <code>udfs.py</code>:\n\n<pre><code># Extracts the hour from an iso8601 datetime string\n@outputSchema(\"hour:chararray\")\ndef hour(iso_string):\n  tuple_time = time.strptime(iso_string, \"%Y-%m-%dT%H:%M:%S\")\n  return str(tuple_time[2])</code></pre>\n\nImport and run the UDF in Pig via:\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\n\n2012-02-13 16:19:33,325 [main] INFO  org.apache.pig.scripting.jython.JythonScriptEngine - Register scripting UDF: myfuncs.hour\n\ngrunt&gt; describe times;                                                        \ntimes: {date: chararray}\ngrunt&gt; hours = foreach times generate date, myfuncs.hour(date) as hour;\ngrunt&gt; dump hours\n\n(2011-12-08T00:03:07-08:00,8)\n(2011-12-08T00:08:05-08:00,8)\n(2011-12-08T07:33:40+00:00,8)\n(2011-12-08T08:28:32+00:00,8)\n(2011-12-08T09:26:25+01:00,8)\n(2011-12-08T13:02:32+05:30,8)\n(2011-12-08T13:20:27+05:30,8)\n(2011-12-08T13:40:44+05:30,8)\n(2011-12-08T13:54:54+05:30,8)\n(2011-12-08T13:59:47+05:30,8)\n</code></pre>\n\n<p>Jython can operate on complex types as well.  Lets prepare a grouped relation, containing email subjects between pairs of email addresses, and then run it through a Jython UDF to get a word count.</p>\n\n<p>The UDF computes word counts given a bag of subjects and a tuple of (from, to) pairs:</p>\n\n<pre><code># Given from, to email address pairs and a bag of their subjects, return from, to and a bag of word counts\n# Input format: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n@outputSchema(\"t:(from:chararray, to:chararray, word_counts:bag{t2:(word:chararray, total:int)})\")\ndef word_count_subjects(group, subjects):\n  to = group[0]\n  _from = group[1]\n  word_counts = {}\n  for subject in subjects:\n    words = subject[0].split()\n    for word in words:\n      word_counts[word] = word_counts.get(word, 0) + 1\n  return to, _from, sorted(word_counts.items(), key=lambda word_count: word_count[1], reverse=True)\n</code></pre>\n\n<p>Import the UDF in Pig and run it against our grouped relation:</p>\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\ngrunt&gt; emails = limit emails 100;\ngrunt&gt; emails = filter emails by (from is not null) and (to is not null);\ngrunt&gt; pairs = foreach emails generate flatten(from) as from, flatten(to) as to, subject;\ngrunt&gt; gft = group pairs by (from, to);\ngrunt&gt; gft = foreach gft generate group, pairs.(subject) as subjects;\ngrunt&gt; describe gft\n<br>\ngft: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n<br>\ngrunt&gt; to_from_word_counts = foreach gft generate myfuncs.word_count_subjects(group, subjects);\ngrunt&gt; store to_from_word_counts into '/tmp/jython_test.txt';</code></pre>\n\nOur result:\n\n<pre><code>(tim@nada1.de,user@jruby.codehaus.org,{(file,2),([jruby-user],2),(.so,2),(a,2),(Problems,2),(Re:,2),(loading,2)})\n(victor@x.com,user@avro.apache.org,{(in,1),(avdl,1),(of,1),(classpath,1),(Importing,1),(RE:,1),(from,1),(project,1)})\n(info@meetup.com,russell.jurney@gmail.com,{(Dave,1),(Stories,1),(comment,1),(a,1),(War,1),(posted,1),(Data,1),(Big,1),(for,1),(Nielsen,1)})\n(jira@apache.org,russell.jurney@gmail.com,{([jira],8),(in,8),(a,8),(bag,6),(fails,6),(Avro,4),(as,4),(of,4),(STORE,4),(single-field,4),((PIG-2411),4),(tuples,4),(to,4),(UDF,4),(AvroStorage,4),(PiggyBank,4),(when,4),(arrays,4),([Updated],3),([Commented],3),(UDF),2),(used,2),(SQL,2),(with,2),(java.lang.NullPointerException,2),(interface,2),(Util.getSchemaFromString,2),([Created],2),(MongoStorage,2),(for,2),(name,2),(tuple,2),((as,2),(Pig,2),((PIG-824),2),(no,2),(has,2),((PIG-2509),2)})</code></pre>\n\nOnce you get the hang of processing tuples in Jython, any UDF is a breeze!</p>", "tree_html": ""}, "can_send_in_message": true, "id": 17584921570, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Jython UDFs in Pig", "tags": [], "post_url": "http://datasyndrome.com/post/17584921570/jython-udfs-in-pig", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yGO99lY", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1329184998, "note_count": 0, "trail": [{"content": "<p>&ldquo;the more powerful the language, the shorter the program&rdquo;\n<small>Source:\n<a href=\"http://www.paulgraham.com/icad.html\">Paul Graham, Revenge of the Nerds</a>.</small>\n<br /><br /><p><a href=\"http://pig.apache.org/docs/r0.9.2/udf.html#python-udfs\">Jython UDFs</a> were added to Pig in version 0.8, and are pretty stable in the current version, 0.9.2.  They are highly convenient, and a major timesaver.</p>\n\nUsing <a href=\"http://pig.apache.org/docs/r0.9.2/udf.html\">Jython UDFs</a> is simple.  Create a UDF in <code>udfs.py</code>:\n\n<pre><code># Extracts the hour from an iso8601 datetime string\n@outputSchema(\"hour:chararray\")\ndef hour(iso_string):\n  tuple_time = time.strptime(iso_string, \"%Y-%m-%dT%H:%M:%S\")\n  return str(tuple_time[2])</code></pre>\n\nImport and run the UDF in Pig via:\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\n\n2012-02-13 16:19:33,325 [main] INFO  org.apache.pig.scripting.jython.JythonScriptEngine - Register scripting UDF: myfuncs.hour\n\ngrunt&gt; describe times;                                                        \ntimes: {date: chararray}\ngrunt&gt; hours = foreach times generate date, myfuncs.hour(date) as hour;\ngrunt&gt; dump hours\n\n(2011-12-08T00:03:07-08:00,8)\n(2011-12-08T00:08:05-08:00,8)\n(2011-12-08T07:33:40+00:00,8)\n(2011-12-08T08:28:32+00:00,8)\n(2011-12-08T09:26:25+01:00,8)\n(2011-12-08T13:02:32+05:30,8)\n(2011-12-08T13:20:27+05:30,8)\n(2011-12-08T13:40:44+05:30,8)\n(2011-12-08T13:54:54+05:30,8)\n(2011-12-08T13:59:47+05:30,8)\n</code></pre>\n\n<p>Jython can operate on complex types as well.  Lets prepare a grouped relation, containing email subjects between pairs of email addresses, and then run it through a Jython UDF to get a word count.</p>\n\n<p>The UDF computes word counts given a bag of subjects and a tuple of (from, to) pairs:</p>\n\n<pre><code># Given from, to email address pairs and a bag of their subjects, return from, to and a bag of word counts\n# Input format: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n@outputSchema(\"t:(from:chararray, to:chararray, word_counts:bag{t2:(word:chararray, total:int)})\")\ndef word_count_subjects(group, subjects):\n  to = group[0]\n  _from = group[1]\n  word_counts = {}\n  for subject in subjects:\n    words = subject[0].split()\n    for word in words:\n      word_counts[word] = word_counts.get(word, 0) + 1\n  return to, _from, sorted(word_counts.items(), key=lambda word_count: word_count[1], reverse=True)\n</code></pre>\n\n<p>Import the UDF in Pig and run it against our grouped relation:</p>\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\ngrunt&gt; emails = limit emails 100;\ngrunt&gt; emails = filter emails by (from is not null) and (to is not null);\ngrunt&gt; pairs = foreach emails generate flatten(from) as from, flatten(to) as to, subject;\ngrunt&gt; gft = group pairs by (from, to);\ngrunt&gt; gft = foreach gft generate group, pairs.(subject) as subjects;\ngrunt&gt; describe gft\n<br />\ngft: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n<br />\ngrunt&gt; to_from_word_counts = foreach gft generate myfuncs.word_count_subjects(group, subjects);\ngrunt&gt; store to_from_word_counts into '/tmp/jython_test.txt';</code></pre>\n\nOur result:\n\n<pre><code>(tim@nada1.de,user@jruby.codehaus.org,{(file,2),([jruby-user],2),(.so,2),(a,2),(Problems,2),(Re:,2),(loading,2)})\n(victor@x.com,user@avro.apache.org,{(in,1),(avdl,1),(of,1),(classpath,1),(Importing,1),(RE:,1),(from,1),(project,1)})\n(info@meetup.com,russell.jurney@gmail.com,{(Dave,1),(Stories,1),(comment,1),(a,1),(War,1),(posted,1),(Data,1),(Big,1),(for,1),(Nielsen,1)})\n(jira@apache.org,russell.jurney@gmail.com,{([jira],8),(in,8),(a,8),(bag,6),(fails,6),(Avro,4),(as,4),(of,4),(STORE,4),(single-field,4),((PIG-2411),4),(tuples,4),(to,4),(UDF,4),(AvroStorage,4),(PiggyBank,4),(when,4),(arrays,4),([Updated],3),([Commented],3),(UDF),2),(used,2),(SQL,2),(with,2),(java.lang.NullPointerException,2),(interface,2),(Util.getSchemaFromString,2),([Created],2),(MongoStorage,2),(for,2),(name,2),(tuple,2),((as,2),(Pig,2),((PIG-824),2),(no,2),(has,2),((PIG-2509),2)})</code></pre>\n\nOnce you get the hang of processing tuples in Jython, any UDF is a breeze!</p>", "content_raw": "<p><center><bq>\u201cthe more powerful the language, the shorter the program\u201d</bq></center>\n<div class=\"credit\" align=\"right\" style=\"margin-right: 50px;\"><small>Source:\n<cite><a href=\"http://www.paulgraham.com/icad.html\">Paul Graham, Revenge of the Nerds</a></cite>.</small></div>\n<br><br><p><a href=\"http://pig.apache.org/docs/r0.9.2/udf.html#python-udfs\">Jython UDFs</a> were added to Pig in version 0.8, and are pretty stable in the current version, 0.9.2.  They are highly convenient, and a major timesaver.</p>\n\nUsing <a href=\"http://pig.apache.org/docs/r0.9.2/udf.html\">Jython UDFs</a> is simple.  Create a UDF in <code>udfs.py</code>:\n\n<pre><code># Extracts the hour from an iso8601 datetime string\n@outputSchema(\"hour:chararray\")\ndef hour(iso_string):\n  tuple_time = time.strptime(iso_string, \"%Y-%m-%dT%H:%M:%S\")\n  return str(tuple_time[2])</code></pre>\n\nImport and run the UDF in Pig via:\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\n\n2012-02-13 16:19:33,325 [main] INFO  org.apache.pig.scripting.jython.JythonScriptEngine - Register scripting UDF: myfuncs.hour\n\ngrunt&gt; describe times;                                                        \ntimes: {date: chararray}\ngrunt&gt; hours = foreach times generate date, myfuncs.hour(date) as hour;\ngrunt&gt; dump hours\n\n(2011-12-08T00:03:07-08:00,8)\n(2011-12-08T00:08:05-08:00,8)\n(2011-12-08T07:33:40+00:00,8)\n(2011-12-08T08:28:32+00:00,8)\n(2011-12-08T09:26:25+01:00,8)\n(2011-12-08T13:02:32+05:30,8)\n(2011-12-08T13:20:27+05:30,8)\n(2011-12-08T13:40:44+05:30,8)\n(2011-12-08T13:54:54+05:30,8)\n(2011-12-08T13:59:47+05:30,8)\n</code></pre>\n\n<p>Jython can operate on complex types as well.  Lets prepare a grouped relation, containing email subjects between pairs of email addresses, and then run it through a Jython UDF to get a word count.</p>\n\n<p>The UDF computes word counts given a bag of subjects and a tuple of (from, to) pairs:</p>\n\n<pre><code># Given from, to email address pairs and a bag of their subjects, return from, to and a bag of word counts\n# Input format: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n@outputSchema(\"t:(from:chararray, to:chararray, word_counts:bag{t2:(word:chararray, total:int)})\")\ndef word_count_subjects(group, subjects):\n  to = group[0]\n  _from = group[1]\n  word_counts = {}\n  for subject in subjects:\n    words = subject[0].split()\n    for word in words:\n      word_counts[word] = word_counts.get(word, 0) + 1\n  return to, _from, sorted(word_counts.items(), key=lambda word_count: word_count[1], reverse=True)\n</code></pre>\n\n<p>Import the UDF in Pig and run it against our grouped relation:</p>\n\n<pre><code>grunt&gt; register 'udfs.py' using jython as myfuncs;\ngrunt&gt; emails = limit emails 100;\ngrunt&gt; emails = filter emails by (from is not null) and (to is not null);\ngrunt&gt; pairs = foreach emails generate flatten(from) as from, flatten(to) as to, subject;\ngrunt&gt; gft = group pairs by (from, to);\ngrunt&gt; gft = foreach gft generate group, pairs.(subject) as subjects;\ngrunt&gt; describe gft\n<br>\ngft: {group: (from: chararray,to: chararray),subjects: {(subject: chararray)}}\n<br>\ngrunt&gt; to_from_word_counts = foreach gft generate myfuncs.word_count_subjects(group, subjects);\ngrunt&gt; store to_from_word_counts into '/tmp/jython_test.txt';</code></pre>\n\nOur result:\n\n<pre><code>(tim@nada1.de,user@jruby.codehaus.org,{(file,2),([jruby-user],2),(.so,2),(a,2),(Problems,2),(Re:,2),(loading,2)})\n(victor@x.com,user@avro.apache.org,{(in,1),(avdl,1),(of,1),(classpath,1),(Importing,1),(RE:,1),(from,1),(project,1)})\n(info@meetup.com,russell.jurney@gmail.com,{(Dave,1),(Stories,1),(comment,1),(a,1),(War,1),(posted,1),(Data,1),(Big,1),(for,1),(Nielsen,1)})\n(jira@apache.org,russell.jurney@gmail.com,{([jira],8),(in,8),(a,8),(bag,6),(fails,6),(Avro,4),(as,4),(of,4),(STORE,4),(single-field,4),((PIG-2411),4),(tuples,4),(to,4),(UDF,4),(AvroStorage,4),(PiggyBank,4),(when,4),(arrays,4),([Updated],3),([Commented],3),(UDF),2),(used,2),(SQL,2),(with,2),(java.lang.NullPointerException,2),(interface,2),(Util.getSchemaFromString,2),([Created],2),(MongoStorage,2),(for,2),(name,2),(tuple,2),((as,2),(Pig,2),((PIG-824),2),(no,2),(has,2),((PIG-2509),2)})</code></pre>\n\nOnce you get the hang of processing tuples in Jython, any UDF is a breeze!</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "17584921570"}}], "date": "2012-02-14 02:03:18 GMT", "slug": "jython-udfs-in-pig", "blog_name": "rjurney", "summary": "Jython UDFs in Pig", "can_reblog": true}, {"body": "<p>Note: <i>Several people requested this Techdrawl post from 2009, a time when early stage funding in the southeast was non-existant following the banking crisis of 2008.</i></p>\n\n<p>There is a model of startup propagated on the internet and in books, mostly from west-coast authors, and it goes like this:  &ldquo;I will conceive of an idea utilizing technology to address a need in a market, I will write a business plan, I will raise money in stages corresponding to the product development cycle, culminating in a product launch in which I will release the next &lsquo;Big Thing&rsquo; and we will be the next Google.&rdquo;  This is the California state of mind.  It involves many, many assumptions about how to found and grow a new technology venture.</p>\n\n<p>Having seen 'the Promised Land,&rsquo; I will begin by saying point blank: It is better than anything I could have conceived or imagined.  Silicon Valley is a theme park for startups.  At every stage, there is an overwhelmingly nurturing environment to help a young entrepreneurs, from the world&rsquo;s largest network of successful entrepreneurs clustered around industries and interest groups who are all aggressively interested in helping one another, to lawyers that not only back-bill, but will directly invest in a startup, to a network of every kind of service provider that provide world class service for the early stage startup to allow it to remain as lean as possible.  There is an abundance of funding for exceptional individuals at every stage, including the napkin, and there is enough backup funding to allow repeated iterations through multiple product concepts until a winning product is arrived at.  Every imaginable idea across all technology industries is funded many times in parallel.  What is more, there is very little risk to founding a startup: there is every chance that your idea, if it has merit and you are a true entrepreneur, will be funded, and there is an abundance of high paying jobs with a high turnover rate, such that you can have a new job tomorrow if your startup shuts down tonight.  This will likely be a job where you will develop skills that you can use in your next startup.  Its a self-perpetuation cycle.  Nobody retires in Silicon Valley, they become investors.  It is the natural thing to do.  Stanford has an aggressive program to teach entrepreneurship, and there are an overwhelming amount of opportunities to mingle with high net-worth and successful individuals with expertise in every imaginable problem domain and technology area.  </p>\n\n<p>Disneyland is less toddler supportive than is Silicon Valley entrepreneurial supportive.</p>\n\n<p>In that environment, the &ldquo;California State of Mind&rdquo; makes perfect sense.  It is the basis of the success of their economy, and it is based on a unique history going back 100 years to the founding of Stanford University as a center of idealism and top-shelf education, where doing the new and innovative thing was the default course of action.  </p>\n\n<p>Through the icons of our age, Steve Jobs and Google, we have learned that the 'California State of Mind&rsquo; is the true model of success for technology ventures.  This belief is pervasive throughout our community in persons under 30, who cut their teeth reading 'Crossing the Chasm&rsquo; and Guy Kawasaki.  It is the unspoken common knowledge filling the head of any new startup entrepreneur.  </p>\n\n<p>There is just one problem: In Atlanta, The 'California State of Mind&rsquo; is a Cancer.  It is a disease.  It has no applicability here and it destroys lives.  The commonly stated idea that the differences between Silicon Valley and Atlanta is one purely of scale is false, and the implication of these differences cannot be understated.</p>\n\n<p>I can&rsquo;t say that strongly enough.  In Georgia, the California State of Mind will try to kill you and will ruin your life.  Its not like us.  It wants to kill your family.  It belongs on the terrorist watch list.  Without the supportive environment of the Valley, the valley game-plan has disastrous effects on human lives.  Time and again I see twenty something entrepreneurs (only one of which was me) following the product development and valley funding cycle.  They create a business plan and pursue funding, which is not available without a working product and traction with customers, so they start using their credit cards.  As the prototype nears completion, they start demoing customers.  They find that the customer&rsquo;s requirements are not precisely in line with what they have built, or that the market for their innovation is not the one they assumed it would be.  By now the credit cards are maxed, and so they desperately pursue funding and try to sell what they have, which nobody wants to buy.  It is common at this stage for founders to bail on the venture, including key developers, making product iteration impossible.</p>\n\n<p>When a startup reaches this phase, there is a look in the founders eyes that foretells the coming crash months before they will publicly admit it.  Atlanta startups go zombie long before they die.  When the crash finally happens, founders drop out for a year or two, and work like dogs to dig themselves out of the debt they have accumulated.  This usually involves great sacrifice for their families.</p>\n\n<p>In Georgia, the repeated operation of this cycle, with a few notable exceptions who pull the jackpot handle and come up roses, is the reason for the embittered attitude that many in the Atlanta startup community hold.  In the absence of a culture composed of several million persons obsessed with nurturing new ventures, the product development cycle, and the 'Valley venture funding model is inapplicable.  </p>\n\n<p>In contrast, executed en mass in that supportive environment, the California state of mind still produces products that nobody wants, and terrible failures en mass.  Funding for an idea and a supportive environment in no way ensures the success of the product, but it does mean that the life of the founder is not destroyed by failure.  As a result, the valley model can be executed repeatedly with few dire consequences.</p>\n\n<p>Nobody wants to openly admit it, but the number of early stage ventures happening in Atlanta this year is very near to ZERO.  The entire angel community just got slaughtered in the stock and real estate markets.  Early stage investment is therefore a completely inviable model for startups in Atlanta.  Unless you have a very good reason to believe otherwise, like you just sold a company for $30 million and you don&rsquo;t need my advice, you should assume that no investment capital is available.  The first stage to reaching the next step for Atlanta is to accept this fact, to drop the bullshit and deal with it, because there is a solution to the problem.  </p>\n\n<p>The solution to this problem is called Customer Driven Development.  </p>\n\n<p>There are organizations in Atlanta that will fund new ventures, and they don&rsquo;t hang out at Angel Lounge.  They&rsquo;re called customers.  They&rsquo;re called companies.  We have 11 fortune 100 companies headquartered in the Atlanta metro area.  If the de facto product for an Atlanta startup founded by twenty something hackers arose not from social media developments in California, but from early and aggressive contact with Atlanta&rsquo;s economic powerhouses, who actively participated in the creation of the solution because it solves a serious problem they are having, our funding problem would not matter.  We wouldn&rsquo;t have a funding problem.  The 'funding problem&rsquo; is only an issue because we are infected by the California State of Mind, which has no applicability here.  If the defacto path for a startup was customer driven development, our corporations would fund our startups by purchasing minimum viable products that solve fundamental pain for their company.</p>\n\n<p>To achieve this we need two things:</p>\n\n<p>1) If you haven&rsquo;t read it, purchase Steve Blank&rsquo;s book, '4 Steps to the Epiphany&rsquo; immediately and read it cover to cover.  If you&rsquo;ve ever tanked a startup, it will shock and awe you.  Steve outlines a step-by-step framework of check-points that even the most pencil-necked geek can follow to iterate through concepts with real customers, all of which live outside the building.</p>\n\n<p>Steve Blank is no less than the startup messiah.  He will save your next venture.  If you don&rsquo;t read and learn his book, you are missing out.</p>\n\n<p>2) We need an open forum where young founders can learn about problems that our large enterprises are facing, where potential enterprise customers can present problems they are facing that they would be likely to purchase a product from a startup to solve.  </p>\n\n<p>This is going to happen.  I look forward to seeing this, and I hope that we can draw in organizations like TAG and the Atlanta CEO Council to be more engaged with Atlanta startups through these forums.</p>\n\n<p>In my next post I will talk about Atlanta&rsquo;s vertical markets, and how we need to address problems in those areas if we want to grow as a micro-economy in this city and region.</p>", "liked": false, "followed": false, "reblog_key": "HwlKjM0x", "reblog": {"comment": "<p>Note: <i>Several people requested this Techdrawl post from 2009, a time when early stage funding in the southeast was non-existant following the banking crisis of 2008.</i></p>\n\n<p>There is a model of startup propagated on the internet and in books, mostly from west-coast authors, and it goes like this:  \u201cI will conceive of an idea utilizing technology to address a need in a market, I will write a business plan, I will raise money in stages corresponding to the product development cycle, culminating in a product launch in which I will release the next \u2018Big Thing\u2019 and we will be the next Google.\u201d  This is the California state of mind.  It involves many, many assumptions about how to found and grow a new technology venture.</p>\n\n<p>Having seen 'the Promised Land,\u2019 I will begin by saying point blank: It is better than anything I could have conceived or imagined.  Silicon Valley is a theme park for startups.  At every stage, there is an overwhelmingly nurturing environment to help a young entrepreneurs, from the world\u2019s largest network of successful entrepreneurs clustered around industries and interest groups who are all aggressively interested in helping one another, to lawyers that not only back-bill, but will directly invest in a startup, to a network of every kind of service provider that provide world class service for the early stage startup to allow it to remain as lean as possible.  There is an abundance of funding for exceptional individuals at every stage, including the napkin, and there is enough backup funding to allow repeated iterations through multiple product concepts until a winning product is arrived at.  Every imaginable idea across all technology industries is funded many times in parallel.  What is more, there is very little risk to founding a startup: there is every chance that your idea, if it has merit and you are a true entrepreneur, will be funded, and there is an abundance of high paying jobs with a high turnover rate, such that you can have a new job tomorrow if your startup shuts down tonight.  This will likely be a job where you will develop skills that you can use in your next startup.  Its a self-perpetuation cycle.  Nobody retires in Silicon Valley, they become investors.  It is the natural thing to do.  Stanford has an aggressive program to teach entrepreneurship, and there are an overwhelming amount of opportunities to mingle with high net-worth and successful individuals with expertise in every imaginable problem domain and technology area.  </p>\n\n<p>Disneyland is less toddler supportive than is Silicon Valley entrepreneurial supportive.</p>\n\n<p>In that environment, the \u201cCalifornia State of Mind\u201d makes perfect sense.  It is the basis of the success of their economy, and it is based on a unique history going back 100 years to the founding of Stanford University as a center of idealism and top-shelf education, where doing the new and innovative thing was the default course of action.  </p>\n\n<p>Through the icons of our age, Steve Jobs and Google, we have learned that the 'California State of Mind\u2019 is the true model of success for technology ventures.  This belief is pervasive throughout our community in persons under 30, who cut their teeth reading 'Crossing the Chasm\u2019 and Guy Kawasaki.  It is the unspoken common knowledge filling the head of any new startup entrepreneur.  </p>\n\n<p>There is just one problem: In Atlanta, The 'California State of Mind\u2019 is a Cancer.  It is a disease.  It has no applicability here and it destroys lives.  The commonly stated idea that the differences between Silicon Valley and Atlanta is one purely of scale is false, and the implication of these differences cannot be understated.</p>\n\n<p>I can\u2019t say that strongly enough.  In Georgia, the California State of Mind will try to kill you and will ruin your life.  Its not like us.  It wants to kill your family.  It belongs on the terrorist watch list.  Without the supportive environment of the Valley, the valley game-plan has disastrous effects on human lives.  Time and again I see twenty something entrepreneurs (only one of which was me) following the product development and valley funding cycle.  They create a business plan and pursue funding, which is not available without a working product and traction with customers, so they start using their credit cards.  As the prototype nears completion, they start demoing customers.  They find that the customer\u2019s requirements are not precisely in line with what they have built, or that the market for their innovation is not the one they assumed it would be.  By now the credit cards are maxed, and so they desperately pursue funding and try to sell what they have, which nobody wants to buy.  It is common at this stage for founders to bail on the venture, including key developers, making product iteration impossible.</p>\n\n<p>When a startup reaches this phase, there is a look in the founders eyes that foretells the coming crash months before they will publicly admit it.  Atlanta startups go zombie long before they die.  When the crash finally happens, founders drop out for a year or two, and work like dogs to dig themselves out of the debt they have accumulated.  This usually involves great sacrifice for their families.</p>\n\n<p>In Georgia, the repeated operation of this cycle, with a few notable exceptions who pull the jackpot handle and come up roses, is the reason for the embittered attitude that many in the Atlanta startup community hold.  In the absence of a culture composed of several million persons obsessed with nurturing new ventures, the product development cycle, and the 'Valley venture funding model is inapplicable.  </p>\n\n<p>In contrast, executed en mass in that supportive environment, the California state of mind still produces products that nobody wants, and terrible failures en mass.  Funding for an idea and a supportive environment in no way ensures the success of the product, but it does mean that the life of the founder is not destroyed by failure.  As a result, the valley model can be executed repeatedly with few dire consequences.</p>\n\n<p>Nobody wants to openly admit it, but the number of early stage ventures happening in Atlanta this year is very near to ZERO.  The entire angel community just got slaughtered in the stock and real estate markets.  Early stage investment is therefore a completely inviable model for startups in Atlanta.  Unless you have a very good reason to believe otherwise, like you just sold a company for $30 million and you don\u2019t need my advice, you should assume that no investment capital is available.  The first stage to reaching the next step for Atlanta is to accept this fact, to drop the bullshit and deal with it, because there is a solution to the problem.  </p>\n\n<p>The solution to this problem is called Customer Driven Development.  </p>\n\n<p>There are organizations in Atlanta that will fund new ventures, and they don\u2019t hang out at Angel Lounge.  They\u2019re called customers.  They\u2019re called companies.  We have 11 fortune 100 companies headquartered in the Atlanta metro area.  If the de facto product for an Atlanta startup founded by twenty something hackers arose not from social media developments in California, but from early and aggressive contact with Atlanta\u2019s economic powerhouses, who actively participated in the creation of the solution because it solves a serious problem they are having, our funding problem would not matter.  We wouldn\u2019t have a funding problem.  The 'funding problem\u2019 is only an issue because we are infected by the California State of Mind, which has no applicability here.  If the defacto path for a startup was customer driven development, our corporations would fund our startups by purchasing minimum viable products that solve fundamental pain for their company.</p>\n\n<p>To achieve this we need two things:</p>\n\n<p>1) If you haven\u2019t read it, purchase Steve Blank\u2019s book, '4 Steps to the Epiphany\u2019 immediately and read it cover to cover.  If you\u2019ve ever tanked a startup, it will shock and awe you.  Steve outlines a step-by-step framework of check-points that even the most pencil-necked geek can follow to iterate through concepts with real customers, all of which live outside the building.</p>\n\n<p>Steve Blank is no less than the startup messiah.  He will save your next venture.  If you don\u2019t read and learn his book, you are missing out.</p>\n\n<p>2) We need an open forum where young founders can learn about problems that our large enterprises are facing, where potential enterprise customers can present problems they are facing that they would be likely to purchase a product from a startup to solve.  </p>\n\n<p>This is going to happen.  I look forward to seeing this, and I hope that we can draw in organizations like TAG and the Atlanta CEO Council to be more engaged with Atlanta startups through these forums.</p>\n\n<p>In my next post I will talk about Atlanta\u2019s vertical markets, and how we need to address problems in those areas if we want to grow as a micro-economy in this city and region.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 17330873751, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Blast from the past: A California State of Mind (6/18/09)", "tags": [], "post_url": "http://datasyndrome.com/post/17330873751/blast-from-the-past-a-california-state-of-mind", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yG902MN", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1328819922, "note_count": 0, "trail": [{"content": "<p>Note: <i>Several people requested this Techdrawl post from 2009, a time when early stage funding in the southeast was non-existant following the banking crisis of 2008.</i></p>\n\n<p>There is a model of startup propagated on the internet and in books, mostly from west-coast authors, and it goes like this:  &ldquo;I will conceive of an idea utilizing technology to address a need in a market, I will write a business plan, I will raise money in stages corresponding to the product development cycle, culminating in a product launch in which I will release the next &lsquo;Big Thing&rsquo; and we will be the next Google.&rdquo;  This is the California state of mind.  It involves many, many assumptions about how to found and grow a new technology venture.</p>\n\n<p>Having seen 'the Promised Land,&rsquo; I will begin by saying point blank: It is better than anything I could have conceived or imagined.  Silicon Valley is a theme park for startups.  At every stage, there is an overwhelmingly nurturing environment to help a young entrepreneurs, from the world&rsquo;s largest network of successful entrepreneurs clustered around industries and interest groups who are all aggressively interested in helping one another, to lawyers that not only back-bill, but will directly invest in a startup, to a network of every kind of service provider that provide world class service for the early stage startup to allow it to remain as lean as possible.  There is an abundance of funding for exceptional individuals at every stage, including the napkin, and there is enough backup funding to allow repeated iterations through multiple product concepts until a winning product is arrived at.  Every imaginable idea across all technology industries is funded many times in parallel.  What is more, there is very little risk to founding a startup: there is every chance that your idea, if it has merit and you are a true entrepreneur, will be funded, and there is an abundance of high paying jobs with a high turnover rate, such that you can have a new job tomorrow if your startup shuts down tonight.  This will likely be a job where you will develop skills that you can use in your next startup.  Its a self-perpetuation cycle.  Nobody retires in Silicon Valley, they become investors.  It is the natural thing to do.  Stanford has an aggressive program to teach entrepreneurship, and there are an overwhelming amount of opportunities to mingle with high net-worth and successful individuals with expertise in every imaginable problem domain and technology area.  </p>\n\n<p>Disneyland is less toddler supportive than is Silicon Valley entrepreneurial supportive.</p>\n\n<p>In that environment, the &ldquo;California State of Mind&rdquo; makes perfect sense.  It is the basis of the success of their economy, and it is based on a unique history going back 100 years to the founding of Stanford University as a center of idealism and top-shelf education, where doing the new and innovative thing was the default course of action.  </p>\n\n<p>Through the icons of our age, Steve Jobs and Google, we have learned that the 'California State of Mind&rsquo; is the true model of success for technology ventures.  This belief is pervasive throughout our community in persons under 30, who cut their teeth reading 'Crossing the Chasm&rsquo; and Guy Kawasaki.  It is the unspoken common knowledge filling the head of any new startup entrepreneur.  </p>\n\n<p>There is just one problem: In Atlanta, The 'California State of Mind&rsquo; is a Cancer.  It is a disease.  It has no applicability here and it destroys lives.  The commonly stated idea that the differences between Silicon Valley and Atlanta is one purely of scale is false, and the implication of these differences cannot be understated.</p>\n\n<p>I can&rsquo;t say that strongly enough.  In Georgia, the California State of Mind will try to kill you and will ruin your life.  Its not like us.  It wants to kill your family.  It belongs on the terrorist watch list.  Without the supportive environment of the Valley, the valley game-plan has disastrous effects on human lives.  Time and again I see twenty something entrepreneurs (only one of which was me) following the product development and valley funding cycle.  They create a business plan and pursue funding, which is not available without a working product and traction with customers, so they start using their credit cards.  As the prototype nears completion, they start demoing customers.  They find that the customer&rsquo;s requirements are not precisely in line with what they have built, or that the market for their innovation is not the one they assumed it would be.  By now the credit cards are maxed, and so they desperately pursue funding and try to sell what they have, which nobody wants to buy.  It is common at this stage for founders to bail on the venture, including key developers, making product iteration impossible.</p>\n\n<p>When a startup reaches this phase, there is a look in the founders eyes that foretells the coming crash months before they will publicly admit it.  Atlanta startups go zombie long before they die.  When the crash finally happens, founders drop out for a year or two, and work like dogs to dig themselves out of the debt they have accumulated.  This usually involves great sacrifice for their families.</p>\n\n<p>In Georgia, the repeated operation of this cycle, with a few notable exceptions who pull the jackpot handle and come up roses, is the reason for the embittered attitude that many in the Atlanta startup community hold.  In the absence of a culture composed of several million persons obsessed with nurturing new ventures, the product development cycle, and the 'Valley venture funding model is inapplicable.  </p>\n\n<p>In contrast, executed en mass in that supportive environment, the California state of mind still produces products that nobody wants, and terrible failures en mass.  Funding for an idea and a supportive environment in no way ensures the success of the product, but it does mean that the life of the founder is not destroyed by failure.  As a result, the valley model can be executed repeatedly with few dire consequences.</p>\n\n<p>Nobody wants to openly admit it, but the number of early stage ventures happening in Atlanta this year is very near to ZERO.  The entire angel community just got slaughtered in the stock and real estate markets.  Early stage investment is therefore a completely inviable model for startups in Atlanta.  Unless you have a very good reason to believe otherwise, like you just sold a company for $30 million and you don&rsquo;t need my advice, you should assume that no investment capital is available.  The first stage to reaching the next step for Atlanta is to accept this fact, to drop the bullshit and deal with it, because there is a solution to the problem.  </p>\n\n<p>The solution to this problem is called Customer Driven Development.  </p>\n\n<p>There are organizations in Atlanta that will fund new ventures, and they don&rsquo;t hang out at Angel Lounge.  They&rsquo;re called customers.  They&rsquo;re called companies.  We have 11 fortune 100 companies headquartered in the Atlanta metro area.  If the de facto product for an Atlanta startup founded by twenty something hackers arose not from social media developments in California, but from early and aggressive contact with Atlanta&rsquo;s economic powerhouses, who actively participated in the creation of the solution because it solves a serious problem they are having, our funding problem would not matter.  We wouldn&rsquo;t have a funding problem.  The 'funding problem&rsquo; is only an issue because we are infected by the California State of Mind, which has no applicability here.  If the defacto path for a startup was customer driven development, our corporations would fund our startups by purchasing minimum viable products that solve fundamental pain for their company.</p>\n\n<p>To achieve this we need two things:</p>\n\n<p>1) If you haven&rsquo;t read it, purchase Steve Blank&rsquo;s book, '4 Steps to the Epiphany&rsquo; immediately and read it cover to cover.  If you&rsquo;ve ever tanked a startup, it will shock and awe you.  Steve outlines a step-by-step framework of check-points that even the most pencil-necked geek can follow to iterate through concepts with real customers, all of which live outside the building.</p>\n\n<p>Steve Blank is no less than the startup messiah.  He will save your next venture.  If you don&rsquo;t read and learn his book, you are missing out.</p>\n\n<p>2) We need an open forum where young founders can learn about problems that our large enterprises are facing, where potential enterprise customers can present problems they are facing that they would be likely to purchase a product from a startup to solve.  </p>\n\n<p>This is going to happen.  I look forward to seeing this, and I hope that we can draw in organizations like TAG and the Atlanta CEO Council to be more engaged with Atlanta startups through these forums.</p>\n\n<p>In my next post I will talk about Atlanta&rsquo;s vertical markets, and how we need to address problems in those areas if we want to grow as a micro-economy in this city and region.</p>", "content_raw": "<p>Note: <i>Several people requested this Techdrawl post from 2009, a time when early stage funding in the southeast was non-existant following the banking crisis of 2008.</i></p>\n\n<p>There is a model of startup propagated on the internet and in books, mostly from west-coast authors, and it goes like this:  \u201cI will conceive of an idea utilizing technology to address a need in a market, I will write a business plan, I will raise money in stages corresponding to the product development cycle, culminating in a product launch in which I will release the next \u2018Big Thing\u2019 and we will be the next Google.\u201d  This is the California state of mind.  It involves many, many assumptions about how to found and grow a new technology venture.</p>\n\n<p>Having seen 'the Promised Land,\u2019 I will begin by saying point blank: It is better than anything I could have conceived or imagined.  Silicon Valley is a theme park for startups.  At every stage, there is an overwhelmingly nurturing environment to help a young entrepreneurs, from the world\u2019s largest network of successful entrepreneurs clustered around industries and interest groups who are all aggressively interested in helping one another, to lawyers that not only back-bill, but will directly invest in a startup, to a network of every kind of service provider that provide world class service for the early stage startup to allow it to remain as lean as possible.  There is an abundance of funding for exceptional individuals at every stage, including the napkin, and there is enough backup funding to allow repeated iterations through multiple product concepts until a winning product is arrived at.  Every imaginable idea across all technology industries is funded many times in parallel.  What is more, there is very little risk to founding a startup: there is every chance that your idea, if it has merit and you are a true entrepreneur, will be funded, and there is an abundance of high paying jobs with a high turnover rate, such that you can have a new job tomorrow if your startup shuts down tonight.  This will likely be a job where you will develop skills that you can use in your next startup.  Its a self-perpetuation cycle.  Nobody retires in Silicon Valley, they become investors.  It is the natural thing to do.  Stanford has an aggressive program to teach entrepreneurship, and there are an overwhelming amount of opportunities to mingle with high net-worth and successful individuals with expertise in every imaginable problem domain and technology area.  </p>\n\n<p>Disneyland is less toddler supportive than is Silicon Valley entrepreneurial supportive.</p>\n\n<p>In that environment, the \u201cCalifornia State of Mind\u201d makes perfect sense.  It is the basis of the success of their economy, and it is based on a unique history going back 100 years to the founding of Stanford University as a center of idealism and top-shelf education, where doing the new and innovative thing was the default course of action.  </p>\n\n<p>Through the icons of our age, Steve Jobs and Google, we have learned that the 'California State of Mind\u2019 is the true model of success for technology ventures.  This belief is pervasive throughout our community in persons under 30, who cut their teeth reading 'Crossing the Chasm\u2019 and Guy Kawasaki.  It is the unspoken common knowledge filling the head of any new startup entrepreneur.  </p>\n\n<p>There is just one problem: In Atlanta, The 'California State of Mind\u2019 is a Cancer.  It is a disease.  It has no applicability here and it destroys lives.  The commonly stated idea that the differences between Silicon Valley and Atlanta is one purely of scale is false, and the implication of these differences cannot be understated.</p>\n\n<p>I can\u2019t say that strongly enough.  In Georgia, the California State of Mind will try to kill you and will ruin your life.  Its not like us.  It wants to kill your family.  It belongs on the terrorist watch list.  Without the supportive environment of the Valley, the valley game-plan has disastrous effects on human lives.  Time and again I see twenty something entrepreneurs (only one of which was me) following the product development and valley funding cycle.  They create a business plan and pursue funding, which is not available without a working product and traction with customers, so they start using their credit cards.  As the prototype nears completion, they start demoing customers.  They find that the customer\u2019s requirements are not precisely in line with what they have built, or that the market for their innovation is not the one they assumed it would be.  By now the credit cards are maxed, and so they desperately pursue funding and try to sell what they have, which nobody wants to buy.  It is common at this stage for founders to bail on the venture, including key developers, making product iteration impossible.</p>\n\n<p>When a startup reaches this phase, there is a look in the founders eyes that foretells the coming crash months before they will publicly admit it.  Atlanta startups go zombie long before they die.  When the crash finally happens, founders drop out for a year or two, and work like dogs to dig themselves out of the debt they have accumulated.  This usually involves great sacrifice for their families.</p>\n\n<p>In Georgia, the repeated operation of this cycle, with a few notable exceptions who pull the jackpot handle and come up roses, is the reason for the embittered attitude that many in the Atlanta startup community hold.  In the absence of a culture composed of several million persons obsessed with nurturing new ventures, the product development cycle, and the 'Valley venture funding model is inapplicable.  </p>\n\n<p>In contrast, executed en mass in that supportive environment, the California state of mind still produces products that nobody wants, and terrible failures en mass.  Funding for an idea and a supportive environment in no way ensures the success of the product, but it does mean that the life of the founder is not destroyed by failure.  As a result, the valley model can be executed repeatedly with few dire consequences.</p>\n\n<p>Nobody wants to openly admit it, but the number of early stage ventures happening in Atlanta this year is very near to ZERO.  The entire angel community just got slaughtered in the stock and real estate markets.  Early stage investment is therefore a completely inviable model for startups in Atlanta.  Unless you have a very good reason to believe otherwise, like you just sold a company for $30 million and you don\u2019t need my advice, you should assume that no investment capital is available.  The first stage to reaching the next step for Atlanta is to accept this fact, to drop the bullshit and deal with it, because there is a solution to the problem.  </p>\n\n<p>The solution to this problem is called Customer Driven Development.  </p>\n\n<p>There are organizations in Atlanta that will fund new ventures, and they don\u2019t hang out at Angel Lounge.  They\u2019re called customers.  They\u2019re called companies.  We have 11 fortune 100 companies headquartered in the Atlanta metro area.  If the de facto product for an Atlanta startup founded by twenty something hackers arose not from social media developments in California, but from early and aggressive contact with Atlanta\u2019s economic powerhouses, who actively participated in the creation of the solution because it solves a serious problem they are having, our funding problem would not matter.  We wouldn\u2019t have a funding problem.  The 'funding problem\u2019 is only an issue because we are infected by the California State of Mind, which has no applicability here.  If the defacto path for a startup was customer driven development, our corporations would fund our startups by purchasing minimum viable products that solve fundamental pain for their company.</p>\n\n<p>To achieve this we need two things:</p>\n\n<p>1) If you haven\u2019t read it, purchase Steve Blank\u2019s book, '4 Steps to the Epiphany\u2019 immediately and read it cover to cover.  If you\u2019ve ever tanked a startup, it will shock and awe you.  Steve outlines a step-by-step framework of check-points that even the most pencil-necked geek can follow to iterate through concepts with real customers, all of which live outside the building.</p>\n\n<p>Steve Blank is no less than the startup messiah.  He will save your next venture.  If you don\u2019t read and learn his book, you are missing out.</p>\n\n<p>2) We need an open forum where young founders can learn about problems that our large enterprises are facing, where potential enterprise customers can present problems they are facing that they would be likely to purchase a product from a startup to solve.  </p>\n\n<p>This is going to happen.  I look forward to seeing this, and I hope that we can draw in organizations like TAG and the Atlanta CEO Council to be more engaged with Atlanta startups through these forums.</p>\n\n<p>In my next post I will talk about Atlanta\u2019s vertical markets, and how we need to address problems in those areas if we want to grow as a micro-economy in this city and region.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "17330873751"}}], "date": "2012-02-09 20:38:42 GMT", "slug": "blast-from-the-past-a-california-state-of-mind", "blog_name": "rjurney", "summary": "Blast from the past: A California State of Mind (6/18/09)", "can_reblog": true}, {"body": "When using Pig, one frequently applies a filter to data in a pipeline.  The next question is: how many records were filtered?  The following macro answers this question for you.\n\n<pre><code>/* Get a count of records, return the name of the relation and . */\nDEFINE total_count(relation) RETURNS total {\n  $total = FOREACH (group $relation all) generate '$relation' as label, COUNT_STAR($relation) as total;\n};\n\n/* Get totals on 2 relations, union and return them with labels */\nDEFINE compare_totals(r1, r2) RETURNS totals {\n  total1 = total_count($r1);\n  total2 = total_count($r2);\n  $totals = union total1, total2;\n};\n\n/* See how many records from a relation are removed by a filter, given a condition */\nDEFINE test_filter(original, condition) RETURNS result {\n  filtered = filter $original by $condition;\n  $result = compare_totals($original, filtered);\n};</code></pre>\n\nExample usage:\n\n<pre><code>emails = load '/me/tmp/inbox' using AvroStorage();\nout = test_filter(emails, 'date is not null');\ndump out</code></pre>\n\n<pre>(filtered,70013)\n(emails,70013)\n</pre>", "liked": false, "followed": false, "reblog_key": "qusnI7Tg", "reblog": {"comment": "<p>When using Pig, one frequently applies a filter to data in a pipeline.  The next question is: how many records were filtered?  The following macro answers this question for you.\n\n<pre><code>/* Get a count of records, return the name of the relation and . */\nDEFINE total_count(relation) RETURNS total {\n  $total = FOREACH (group $relation all) generate '$relation' as label, COUNT_STAR($relation) as total;\n};\n\n/* Get totals on 2 relations, union and return them with labels */\nDEFINE compare_totals(r1, r2) RETURNS totals {\n  total1 = total_count($r1);\n  total2 = total_count($r2);\n  $totals = union total1, total2;\n};\n\n/* See how many records from a relation are removed by a filter, given a condition */\nDEFINE test_filter(original, condition) RETURNS result {\n  filtered = filter $original by $condition;\n  $result = compare_totals($original, filtered);\n};</code></pre>\n\nExample usage:\n\n<pre><code>emails = load '/me/tmp/inbox' using AvroStorage();\nout = test_filter(emails, 'date is not null');\ndump out</code></pre>\n\n<pre>(filtered,70013)\n(emails,70013)\n</pre></p>", "tree_html": ""}, "can_send_in_message": true, "id": 17186084960, "display_avatar": true, "can_reply": true, "can_like": false, "title": "The power of Pig Macros", "tags": [], "post_url": "http://datasyndrome.com/post/17186084960/the-power-of-pig-macros", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yG0NjXW", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1328579607, "note_count": 0, "trail": [{"content": "<p><p>When using Pig, one frequently applies a filter to data in a pipeline.  The next question is: how many records were filtered?  The following macro answers this question for you.\n\n</p><pre><code>/* Get a count of records, return the name of the relation and . */\nDEFINE total_count(relation) RETURNS total {\n  $total = FOREACH (group $relation all) generate '$relation' as label, COUNT_STAR($relation) as total;\n};\n\n/* Get totals on 2 relations, union and return them with labels */\nDEFINE compare_totals(r1, r2) RETURNS totals {\n  total1 = total_count($r1);\n  total2 = total_count($r2);\n  $totals = union total1, total2;\n};\n\n/* See how many records from a relation are removed by a filter, given a condition */\nDEFINE test_filter(original, condition) RETURNS result {\n  filtered = filter $original by $condition;\n  $result = compare_totals($original, filtered);\n};</code></pre>\n\nExample usage:\n\n<pre><code>emails = load '/me/tmp/inbox' using AvroStorage();\nout = test_filter(emails, 'date is not null');\ndump out</code></pre>\n\n<pre>(filtered,70013)\n(emails,70013)\n</pre></p>", "content_raw": "<p>When using Pig, one frequently applies a filter to data in a pipeline.  The next question is: how many records were filtered?  The following macro answers this question for you.\n\n<pre><code>/* Get a count of records, return the name of the relation and . */\nDEFINE total_count(relation) RETURNS total {\n  $total = FOREACH (group $relation all) generate '$relation' as label, COUNT_STAR($relation) as total;\n};\n\n/* Get totals on 2 relations, union and return them with labels */\nDEFINE compare_totals(r1, r2) RETURNS totals {\n  total1 = total_count($r1);\n  total2 = total_count($r2);\n  $totals = union total1, total2;\n};\n\n/* See how many records from a relation are removed by a filter, given a condition */\nDEFINE test_filter(original, condition) RETURNS result {\n  filtered = filter $original by $condition;\n  $result = compare_totals($original, filtered);\n};</code></pre>\n\nExample usage:\n\n<pre><code>emails = load '/me/tmp/inbox' using AvroStorage();\nout = test_filter(emails, 'date is not null');\ndump out</code></pre>\n\n<pre>(filtered,70013)\n(emails,70013)\n</pre></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "17186084960"}}], "date": "2012-02-07 01:53:27 GMT", "slug": "the-power-of-pig-macros", "blog_name": "rjurney", "summary": "The power of Pig Macros", "can_reblog": true}, {"body": "<p>Thanks to <a href=\"https://twitter.com/#!/joecrobak\">Joe Crobak</a> for the tip, I have patched the Python library for Avro to build under Mac OS X by removing its python-snappy dependency.  This has been bugging a lot of people, and while the patch removes snappy compression&hellip; I have no idea what that is, and I don&rsquo;t need it :)</p>\n\n<p>The patch is available here: <a href=\"https://issues.apache.org/jira/browse/AVRO-981\">AVRO-981</a>.</p>\n\n<p>To build Avro, you&rsquo;ll need to clone trunk from <a href=\"https://github.com/apache/avro.git\">https://github.com/apache/avro.git</a>, apply the patch and then build and install the python library.</p>\n\n<p>Update: it seems the problem was that Snappy is a dependency.  Install it from here: <a href=\"http://code.google.com/p/snappy/\">http://code.google.com/p/snappy/</a> and python-snappy and python avro should work :)</p>", "liked": false, "followed": false, "reblog_key": "JeCkkmJf", "reblog": {"comment": "<p>Thanks to <a href=\"https://twitter.com/#!/joecrobak\">Joe Crobak</a> for the tip, I have patched the Python library for Avro to build under Mac OS X by removing its python-snappy dependency.  This has been bugging a lot of people, and while the patch removes snappy compression\u2026 I have no idea what that is, and I don\u2019t need it :)</p>\n\n<p>The patch is available here: <a href=\"https://issues.apache.org/jira/browse/AVRO-981\">AVRO-981</a>.</p>\n\n<p>To build Avro, you\u2019ll need to clone trunk from <a href=\"https://github.com/apache/avro.git\">https://github.com/apache/avro.git</a>, apply the patch and then build and install the python library.</p>\n\n<p>Update: it seems the problem was that Snappy is a dependency.  Install it from here: <a href=\"http://code.google.com/p/snappy/\">http://code.google.com/p/snappy/</a> and python-snappy and python avro should work :)</p>", "tree_html": ""}, "can_send_in_message": true, "id": 16393016380, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Avro now works with Python on Mac OS X", "tags": [], "post_url": "http://datasyndrome.com/post/16393016380/avro-now-works-with-python-on-mac-os-x", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yFH6PGy", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1327408155, "note_count": 0, "trail": [{"content": "<p>Thanks to <a href=\"https://twitter.com/#!/joecrobak\">Joe Crobak</a> for the tip, I have patched the Python library for Avro to build under Mac OS X by removing its python-snappy dependency.  This has been bugging a lot of people, and while the patch removes snappy compression&hellip; I have no idea what that is, and I don&rsquo;t need it :)</p>\n\n<p>The patch is available here: <a href=\"https://issues.apache.org/jira/browse/AVRO-981\">AVRO-981</a>.</p>\n\n<p>To build Avro, you&rsquo;ll need to clone trunk from <a href=\"https://github.com/apache/avro.git\">https://github.com/apache/avro.git</a>, apply the patch and then build and install the python library.</p>\n\n<p>Update: it seems the problem was that Snappy is a dependency.  Install it from here: <a href=\"http://code.google.com/p/snappy/\">http://code.google.com/p/snappy/</a> and python-snappy and python avro should work :)</p>", "content_raw": "<p>Thanks to <a href=\"https://twitter.com/#!/joecrobak\">Joe Crobak</a> for the tip, I have patched the Python library for Avro to build under Mac OS X by removing its python-snappy dependency.  This has been bugging a lot of people, and while the patch removes snappy compression\u2026 I have no idea what that is, and I don\u2019t need it :)</p>\n\n<p>The patch is available here: <a href=\"https://issues.apache.org/jira/browse/AVRO-981\">AVRO-981</a>.</p>\n\n<p>To build Avro, you\u2019ll need to clone trunk from <a href=\"https://github.com/apache/avro.git\">https://github.com/apache/avro.git</a>, apply the patch and then build and install the python library.</p>\n\n<p>Update: it seems the problem was that Snappy is a dependency.  Install it from here: <a href=\"http://code.google.com/p/snappy/\">http://code.google.com/p/snappy/</a> and python-snappy and python avro should work :)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "16393016380"}}], "date": "2012-01-24 12:29:15 GMT", "slug": "avro-now-works-with-python-on-mac-os-x", "blog_name": "rjurney", "summary": "Avro now works with Python on Mac OS X", "can_reblog": true}, {"body": "<p><a href=\"http://bailando.sims.berkeley.edu/enron/old_enron_email.html\">UC Berkeley Enron Email Analysis</a> has a mysql store of Enron emails.\n\n</p><blockquote>A database representation(219 MB compressed) of the Enron email collection, built by Andrew Fiore and Jeff Heer, containing the enron email messages. This version contains many but not all of the tables used in the search tool, as well as special tables to be used with the Enronic visualization tool. Andrew did a substantial amount of processing on the contents of the database to remove duplicates, normalize names, and so on. This has been tested only on mysql.</blockquote>\n\nI&rsquo;ve update this mysqldump to work with MySQL 5.5.  It is available <a href=\"https://s3.amazonaws.com/rjurney_public_web/images/enron.mysql.5.5.20.sql.gz\">here</a>.", "liked": false, "followed": false, "reblog_key": "zjeFlH1w", "reblog": {"comment": "<p><p><a href=\"http://bailando.sims.berkeley.edu/enron/old_enron_email.html\">UC Berkeley Enron Email Analysis</a> has a mysql store of Enron emails.\n\n</p><blockquote>A database representation(219 MB compressed) of the Enron email collection, built by Andrew Fiore and Jeff Heer, containing the enron email messages. This version contains many but not all of the tables used in the search tool, as well as special tables to be used with the Enronic visualization tool. Andrew did a substantial amount of processing on the contents of the database to remove duplicates, normalize names, and so on. This has been tested only on mysql.</blockquote>\n\nI\u2019ve update this mysqldump to work with MySQL 5.5.  It is available <a href=\"https://s3.amazonaws.com/rjurney_public_web/images/enron.mysql.5.5.20.sql.gz\">here</a>.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 16057676437, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Berkeley Enron database updated for MySQL 5.5", "tags": [], "post_url": "http://datasyndrome.com/post/16057676437/berkeley-enron-database-updated-for-mysql-55", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yEz7BAL", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1326885180, "note_count": 0, "trail": [{"content": "<p><p><a href=\"http://bailando.sims.berkeley.edu/enron/old_enron_email.html\">UC Berkeley Enron Email Analysis</a> has a mysql store of Enron emails.\n\n</p><blockquote><p>A database representation(219 MB compressed) of the Enron email collection, built by Andrew Fiore and Jeff Heer, containing the enron email messages. This version contains many but not all of the tables used in the search tool, as well as special tables to be used with the Enronic visualization tool. Andrew did a substantial amount of processing on the contents of the database to remove duplicates, normalize names, and so on. This has been tested only on mysql.</p></blockquote>\n\nI&rsquo;ve update this mysqldump to work with MySQL 5.5.  It is available <a href=\"https://s3.amazonaws.com/rjurney_public_web/images/enron.mysql.5.5.20.sql.gz\">here</a>.</p>", "content_raw": "<p><p><a href=\"http://bailando.sims.berkeley.edu/enron/old_enron_email.html\">UC Berkeley Enron Email Analysis</a> has a mysql store of Enron emails.\n\n</p><blockquote>A database representation(219 MB compressed) of the Enron email collection, built by Andrew Fiore and Jeff Heer, containing the enron email messages. This version contains many but not all of the tables used in the search tool, as well as special tables to be used with the Enronic visualization tool. Andrew did a substantial amount of processing on the contents of the database to remove duplicates, normalize names, and so on. This has been tested only on mysql.</blockquote>\n\nI\u2019ve update this mysqldump to work with MySQL 5.5.  It is available <a href=\"https://s3.amazonaws.com/rjurney_public_web/images/enron.mysql.5.5.20.sql.gz\">here</a>.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "16057676437"}}], "date": "2012-01-18 11:13:00 GMT", "slug": "berkeley-enron-database-updated-for-mysql-55", "blog_name": "rjurney", "summary": "Berkeley Enron database updated for MySQL 5.5", "can_reblog": true}, {"body": "<p>I was a bit hasty in my posts about MongoStorage for Pig.  It seems that complex types are not supported - which limits the value of Pig/Mongo integration.  What one wants to do is to process data on Hadoop, and then group it for serving via MongoDB.  Without BAGs and TUPLEs, you can&rsquo;t do this.<br/><br/>\n\nSo, I used <a href=\"https://twitter.com/#!/alanfgates\">Alan Gates&rsquo;</a> awesome book <a href=\"http://www.amazon.com/gp/product/1449302645/ref=as_li_ss_tl?ie=UTF8&amp;tag=datasynd-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1449302645\">Programming Pig</a> as a guide, and added bags and tuples to MongoStorage (part of <a href=\"https://github.com/mongodb/mongo-hadoop\">mongo-hadoop</a>).<br/><br/>\n\nThe gist is here: <a href=\"https://gist.github.com/1546174\">https://gist.github.com/1546174</a><br/><br/>\n\nThe pull request is here: <a href=\"https://github.com/mongodb/mongo-hadoop/pull/29\">https://github.com/mongodb/mongo-hadoop/pull/29</a></p>", "liked": false, "followed": false, "reblog_key": "c5p9eJ6E", "reblog": {"comment": "<p>I was a bit hasty in my posts about MongoStorage for Pig.  It seems that complex types are not supported - which limits the value of Pig/Mongo integration.  What one wants to do is to process data on Hadoop, and then group it for serving via MongoDB.  Without BAGs and TUPLEs, you can\u2019t do this.<br><br>\n\nSo, I used <a href=\"https://twitter.com/#!/alanfgates\">Alan Gates\u2019</a> awesome book <a href=\"http://www.amazon.com/gp/product/1449302645/ref=as_li_ss_tl?ie=UTF8&amp;tag=datasynd-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1449302645\">Programming Pig</a> as a guide, and added bags and tuples to MongoStorage (part of <a href=\"https://github.com/mongodb/mongo-hadoop\">mongo-hadoop</a>).<br><br>\n\nThe gist is here: <a href=\"https://gist.github.com/1546174\">https://gist.github.com/1546174</a><br><br>\n\nThe pull request is here: <a href=\"https://github.com/mongodb/mongo-hadoop/pull/29\">https://github.com/mongodb/mongo-hadoop/pull/29</a></p>", "tree_html": ""}, "can_send_in_message": true, "id": 15148183502, "display_avatar": true, "can_reply": true, "can_like": false, "title": "MongoStorage now supports complex types", "tags": [], "post_url": "http://datasyndrome.com/post/15148183502/mongostorage-now-supports-complex-types", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yE6vk-E", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1325460733, "note_count": 0, "trail": [{"content": "<p>I was a bit hasty in my posts about MongoStorage for Pig.  It seems that complex types are not supported - which limits the value of Pig/Mongo integration.  What one wants to do is to process data on Hadoop, and then group it for serving via MongoDB.  Without BAGs and TUPLEs, you can&rsquo;t do this.<br /><br />\n\nSo, I used <a href=\"https://twitter.com/#!/alanfgates\">Alan Gates&rsquo;</a> awesome book <a href=\"http://www.amazon.com/gp/product/1449302645/ref=as_li_ss_tl?ie=UTF8&amp;tag=datasynd-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1449302645\">Programming Pig</a> as a guide, and added bags and tuples to MongoStorage (part of <a href=\"https://github.com/mongodb/mongo-hadoop\">mongo-hadoop</a>).<br /><br />\n\nThe gist is here: <a href=\"https://gist.github.com/1546174\">https://gist.github.com/1546174</a><br /><br />\n\nThe pull request is here: <a href=\"https://github.com/mongodb/mongo-hadoop/pull/29\">https://github.com/mongodb/mongo-hadoop/pull/29</a></p>", "content_raw": "<p>I was a bit hasty in my posts about MongoStorage for Pig.  It seems that complex types are not supported - which limits the value of Pig/Mongo integration.  What one wants to do is to process data on Hadoop, and then group it for serving via MongoDB.  Without BAGs and TUPLEs, you can\u2019t do this.<br><br>\n\nSo, I used <a href=\"https://twitter.com/#!/alanfgates\">Alan Gates\u2019</a> awesome book <a href=\"http://www.amazon.com/gp/product/1449302645/ref=as_li_ss_tl?ie=UTF8&amp;tag=datasynd-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1449302645\">Programming Pig</a> as a guide, and added bags and tuples to MongoStorage (part of <a href=\"https://github.com/mongodb/mongo-hadoop\">mongo-hadoop</a>).<br><br>\n\nThe gist is here: <a href=\"https://gist.github.com/1546174\">https://gist.github.com/1546174</a><br><br>\n\nThe pull request is here: <a href=\"https://github.com/mongodb/mongo-hadoop/pull/29\">https://github.com/mongodb/mongo-hadoop/pull/29</a></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "15148183502"}}], "date": "2012-01-01 23:32:13 GMT", "slug": "mongostorage-now-supports-complex-types", "blog_name": "rjurney", "summary": "MongoStorage now supports complex types", "can_reblog": true}, {"body": "I often get lost among terminals in OS X.  I forget which is which, or I have trouble resuming a session the next day after a break.  To reduce this &lsquo;contextual overhead&rsquo;, it is nice to name terminals.<br/><br/>\n\nPut this in <code>~/.bash_profile</code>:\n\n<pre><code>function settitle() { echo -n -e \"\\033]0;$1\\007\"; }\nexport -f settitle</code></pre>\n\nNow to set the title of the current terminal:\n\n<pre><code>settitle 'Apache Pig'</code></pre>\n\nAnd wallah:<br/><br/><center><img src=\"https://68.media.tumblr.com/tumblr_lx3btk1eXY1qdyhha.png\"/></center><br/>\n\nHigh fives to <a href=\"http://www.tech-recipes.com/rx/705/mac-os-x-change-the-terminal-window-title/\">this</a> and <a href=\"http://hints.macworld.com/article.php?story=20060502160527780\">this</a>.", "liked": false, "followed": false, "reblog_key": "gBV3h9HY", "reblog": {"comment": "<p>I often get lost among terminals in OS X.  I forget which is which, or I have trouble resuming a session the next day after a break.  To reduce this \u2018contextual overhead\u2019, it is nice to name terminals.<br><br>\n\nPut this in <code>~/.bash_profile</code>:\n\n<pre><code>function settitle() { echo -n -e \"\\033]0;$1\\007\"; }\nexport -f settitle</code></pre>\n\nNow to set the title of the current terminal:\n\n<pre><code>settitle 'Apache Pig'</code></pre>\n\nAnd wallah:<br><br><center><img src=\"https://68.media.tumblr.com/tumblr_lx3btk1eXY1qdyhha.png\"></center><br>\n\nHigh fives to <a href=\"http://www.tech-recipes.com/rx/705/mac-os-x-change-the-terminal-window-title/\">this</a> and <a href=\"http://hints.macworld.com/article.php?story=20060502160527780\">this</a>.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 15102113013, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Set the title on bash terminals", "tags": [], "post_url": "http://datasyndrome.com/post/15102113013/set-the-title-on-bash-terminals", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yE49-Jr", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1325372400, "note_count": 2, "trail": [{"content": "<p><p>I often get lost among terminals in OS X.  I forget which is which, or I have trouble resuming a session the next day after a break.  To reduce this &lsquo;contextual overhead&rsquo;, it is nice to name terminals.<br /><br />\n\nPut this in <code>~/.bash_profile</code>:\n\n</p><pre><code>function settitle() { echo -n -e \"\\033]0;$1\\007\"; }\nexport -f settitle</code></pre>\n\nNow to set the title of the current terminal:\n\n<pre><code>settitle 'Apache Pig'</code></pre>\n\nAnd wallah:<br /><br /><p><img src=\"https://68.media.tumblr.com/tumblr_lx3btk1eXY1qdyhha.png\" class=\"toggle_inline_image inline_image constrained_image\"/></p><br />\n\nHigh fives to <a href=\"http://www.tech-recipes.com/rx/705/mac-os-x-change-the-terminal-window-title/\">this</a> and <a href=\"http://hints.macworld.com/article.php?story=20060502160527780\">this</a>.</p>", "content_raw": "<p>I often get lost among terminals in OS X.  I forget which is which, or I have trouble resuming a session the next day after a break.  To reduce this \u2018contextual overhead\u2019, it is nice to name terminals.<br><br>\n\nPut this in <code>~/.bash_profile</code>:\n\n<pre><code>function settitle() { echo -n -e \"\\033]0;$1\\007\"; }\nexport -f settitle</code></pre>\n\nNow to set the title of the current terminal:\n\n<pre><code>settitle 'Apache Pig'</code></pre>\n\nAnd wallah:<br><br><center><img src=\"https://68.media.tumblr.com/tumblr_lx3btk1eXY1qdyhha.png\"></center><br>\n\nHigh fives to <a href=\"http://www.tech-recipes.com/rx/705/mac-os-x-change-the-terminal-window-title/\">this</a> and <a href=\"http://hints.macworld.com/article.php?story=20060502160527780\">this</a>.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "15102113013"}}], "date": "2011-12-31 23:00:00 GMT", "slug": "set-the-title-on-bash-terminals", "blog_name": "rjurney", "summary": "Set the title on bash terminals", "can_reblog": true}, {"body": "<p><a href=\"https://twitter.com/#!/arnabdotorg\">@arnabotorg</a> tweeted an interesting paper called &rsquo;<a href=\"http://vldb.org/pvldb/vol5/p346_yaelamsterdamer_vldb2012.pdf\">Putting Lipstick on Pig: Enabling Database-style Work\ufb02ow Provenance</a>.&rsquo;<br/><br/>\n\nWhat the heck is workflow provenance?<br/><br/>\n\nIt seems that visual programming (sort of like <a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen</a>) has become popular for scientific workflows: \n\n</p><ul><li><a href=\"http://www.taverna.org.uk/\">Tavera</a></li>\n<li><a href=\"https://kepler-project.org/users/sample-workflows\">Kepler</a></li>\n<li><a href=\"http://www.vistrails.org/index.php/Main_Page\">VisTrails</a></li>\n</ul><br/><br/>\n\nAnd while results are logged, there is no standard way to log how results were arrived at:<br/><br/><bq>&ldquo;<a href=\"http://sites.computer.org/debull/A07dec/susan.pdf\">A given work\ufb02ow may be executed multiple times in the context of a single project, generating a large amount of \ufb01nal and intermediate data products of interest to the user [9]. When such analyses are carried out by hand or automated using general-purpose scripting languages, the means by which results are produced are typically not recorded automatically, and often not even recorded manually.</a>&rdquo;</bq><br/><br/>\n\nLipstick uses Pig Latin to provide a SQLish provenance record:<br/><br/><bq>&ldquo;We present a novel provenance framework that marries database-style and work\ufb02ow-style provenance, by using Pig Latin to expose the functionality of modules, thus capturing internal state and \ufb01ne-grained dependencies.&rdquo;</bq><br/><br/>\n\nVery cool.  Data-workflows are increasingly important in many areas, and Pig Latin is positioned to become the duct-tape for all of them.", "liked": false, "followed": false, "reblog_key": "klUSiW0a", "reblog": {"comment": "<p><p><a href=\"https://twitter.com/#!/arnabdotorg\">@arnabotorg</a> tweeted an interesting paper called \u2019<a href=\"http://vldb.org/pvldb/vol5/p346_yaelamsterdamer_vldb2012.pdf\">Putting Lipstick on Pig: Enabling Database-style Work\ufb02ow Provenance</a>.\u2019<br><br>\n\nWhat the heck is workflow provenance?<br><br>\n\nIt seems that visual programming (sort of like <a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen</a>) has become popular for scientific workflows: \n\n</p><ul><li><a href=\"http://www.taverna.org.uk/\">Tavera</a></li>\n<li><a href=\"https://kepler-project.org/users/sample-workflows\">Kepler</a></li>\n<li><a href=\"http://www.vistrails.org/index.php/Main_Page\">VisTrails</a></li>\n</ul><br><br>\n\nAnd while results are logged, there is no standard way to log how results were arrived at:<br><br><bq>\u201c<a href=\"http://sites.computer.org/debull/A07dec/susan.pdf\">A given work\ufb02ow may be executed multiple times in the context of a single project, generating a large amount of \ufb01nal and intermediate data products of interest to the user [9]. When such analyses are carried out by hand or automated using general-purpose scripting languages, the means by which results are produced are typically not recorded automatically, and often not even recorded manually.</a>\u201d</bq><br><br>\n\nLipstick uses Pig Latin to provide a SQLish provenance record:<br><br><bq>\u201cWe present a novel provenance framework that marries database-style and work\ufb02ow-style provenance, by using Pig Latin to expose the functionality of modules, thus capturing internal state and \ufb01ne-grained dependencies.\u201d</bq><br><br>\n\nVery cool.  Data-workflows are increasingly important in many areas, and Pig Latin is positioned to become the duct-tape for all of them.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 15053472107, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Cool Paper - Putting Lipstick on Pig: Enabling Database-style Work\ufb02ow Provenance", "tags": [], "post_url": "http://datasyndrome.com/post/15053472107/cool-paper-putting-lipstick-on-pig-enabling", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yE1GS5h", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1325291700, "note_count": 1, "trail": [{"content": "<p><p><a href=\"https://twitter.com/#!/arnabdotorg\">@arnabotorg</a> tweeted an interesting paper called &rsquo;<a href=\"http://vldb.org/pvldb/vol5/p346_yaelamsterdamer_vldb2012.pdf\">Putting Lipstick on Pig: Enabling Database-style Work&#64258;ow Provenance</a>.&rsquo;<br /><br />\n\nWhat the heck is workflow provenance?<br /><br />\n\nIt seems that visual programming (sort of like <a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen</a>) has become popular for scientific workflows: \n\n</p><ul><li><a href=\"http://www.taverna.org.uk/\">Tavera</a></li>\n<li><a href=\"https://kepler-project.org/users/sample-workflows\">Kepler</a></li>\n<li><a href=\"http://www.vistrails.org/index.php/Main_Page\">VisTrails</a></li>\n</ul><br /><br />\n\nAnd while results are logged, there is no standard way to log how results were arrived at:<br /><br />&ldquo;<a href=\"http://sites.computer.org/debull/A07dec/susan.pdf\">A given work&#64258;ow may be executed multiple times in the context of a single project, generating a large amount of &#64257;nal and intermediate data products of interest to the user [9]. When such analyses are carried out by hand or automated using general-purpose scripting languages, the means by which results are produced are typically not recorded automatically, and often not even recorded manually.</a>&rdquo;<br /><br />\n\nLipstick uses Pig Latin to provide a SQLish provenance record:<br /><br />&ldquo;We present a novel provenance framework that marries database-style and work&#64258;ow-style provenance, by using Pig Latin to expose the functionality of modules, thus capturing internal state and &#64257;ne-grained dependencies.&rdquo;<br /><br />\n\nVery cool.  Data-workflows are increasingly important in many areas, and Pig Latin is positioned to become the duct-tape for all of them.</p>", "content_raw": "<p><p><a href=\"https://twitter.com/#!/arnabdotorg\">@arnabotorg</a> tweeted an interesting paper called \u2019<a href=\"http://vldb.org/pvldb/vol5/p346_yaelamsterdamer_vldb2012.pdf\">Putting Lipstick on Pig: Enabling Database-style Work\ufb02ow Provenance</a>.\u2019<br><br>\n\nWhat the heck is workflow provenance?<br><br>\n\nIt seems that visual programming (sort of like <a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen</a>) has become popular for scientific workflows: \n\n</p><ul><li><a href=\"http://www.taverna.org.uk/\">Tavera</a></li>\n<li><a href=\"https://kepler-project.org/users/sample-workflows\">Kepler</a></li>\n<li><a href=\"http://www.vistrails.org/index.php/Main_Page\">VisTrails</a></li>\n</ul><br><br>\n\nAnd while results are logged, there is no standard way to log how results were arrived at:<br><br><bq>\u201c<a href=\"http://sites.computer.org/debull/A07dec/susan.pdf\">A given work\ufb02ow may be executed multiple times in the context of a single project, generating a large amount of \ufb01nal and intermediate data products of interest to the user [9]. When such analyses are carried out by hand or automated using general-purpose scripting languages, the means by which results are produced are typically not recorded automatically, and often not even recorded manually.</a>\u201d</bq><br><br>\n\nLipstick uses Pig Latin to provide a SQLish provenance record:<br><br><bq>\u201cWe present a novel provenance framework that marries database-style and work\ufb02ow-style provenance, by using Pig Latin to expose the functionality of modules, thus capturing internal state and \ufb01ne-grained dependencies.\u201d</bq><br><br>\n\nVery cool.  Data-workflows are increasingly important in many areas, and Pig Latin is positioned to become the duct-tape for all of them.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "15053472107"}}], "date": "2011-12-31 00:35:00 GMT", "slug": "cool-paper-putting-lipstick-on-pig-enabling", "blog_name": "rjurney", "summary": "Cool Paper - Putting Lipstick on Pig: Enabling Database-style Work\ufb02ow Provenance", "can_reblog": true}, {"body": "<p>MongoDB is <a href=\"http://www.mongodb-is-web-scale.com/\">Web Scale</a>.  Lulz, right?  Turns out, Mongo is the first NoSQL to nail painless Hadoop and Pig integration&hellip; thus becoming the first &lsquo;web scale&rsquo; database.</p>\n\n<p><b>Proof</b>:</p>\n\n<p>Install Mongo &amp; run it: <a href=\"http://www.mongodb.org/display/DOCS/Quickstart\">http://www.mongodb.org/display/DOCS/Quickstart</a></p>\n\n<p>Install Mongo&rsquo;s hadoop integration:</p>\n\n<pre><code>git clone <a href=\"https://github.com/mongodb/mongo-hadoop\">https://github.com/mongodb/mongo-hadoop</a>\ncd mongo-hadoop\nmvn install\ncd examples\nmvn install # Then check out pigtutorial/\ncd ..\nwget <a href=\"https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar\">https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar</a></code></pre>\n\n<pre><code>REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER /me/pig/contrib/piggybank/java/piggybank.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\n\n\n<b>REGISTER /me/mongo-hadoop/mongo-2.3.jar\nREGISTER /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0-SNAPSHOT.jar\nREGISTER /me/mongo-hadoop/pig/target/mongo-pig-1.0-SNAPSHOT.jar\n</b>\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\nsh rm -rf '/tmp/sent_counts.avro' /* Workaround for PIG-2441 */\n\nmessages = LOAD '/tmp/10000_emails.avro' USING AvroStorage();\nmessages = FILTER messages BY from IS NOT NULL AND to IS NOT NULL;\nsmaller = FOREACH messages GENERATE from, to;\npairs = FOREACH smaller GENERATE from, FLATTEN(to) AS to:chararray;\npairs = FOREACH pairs GENERATE LOWER(from) AS from, LOWER(to) AS to;\n\nfroms = GROUP pairs BY (from, to);\nsent_counts = FOREACH froms GENERATE FLATTEN(group) AS (from, to), SIZE(pairs) AS total;\n-- STORE sent_counts INTO '/tmp/sent_counts.avro' USING AvroStorage();\nSTORE sent_counts INTO 'mongodb://localhost/test.pig' USING com.mongodb.hadoop.pig.MongoStorage;</code></pre>\n\n<p>Note that the use of Avro is optional, but is fun too.</p>\n\n<p>Check out your data:</p>\n\n<pre><code>bash$ mongo pig\n\n\n&gt; show collections\npig\n\n\n&gt; db.pig.find()\n\n\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414133e522\"), \"from\" : \"dwr@touk.pl\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414233e522\"), \"from\" : \"brad@bing.com\", \"to\" : \"common-user@hadoop.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414333e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"dev@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414433e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(2) }</code></pre>\n\n<p><b>MongoDB is web scale.</b>  Who would have thought?  Usability matters.  90% there is not enough.  ;)</p>", "liked": false, "followed": false, "reblog_key": "72Lc8HGf", "reblog": {"comment": "<p>MongoDB is <a href=\"http://www.mongodb-is-web-scale.com/\">Web Scale</a>.  Lulz, right?  Turns out, Mongo is the first NoSQL to nail painless Hadoop and Pig integration\u2026 thus becoming the first \u2018web scale\u2019 database.</p>\n\n<p><b>Proof</b>:</p>\n\n<p>Install Mongo &amp; run it: <a href=\"http://www.mongodb.org/display/DOCS/Quickstart\">http://www.mongodb.org/display/DOCS/Quickstart</a></p>\n\n<p>Install Mongo\u2019s hadoop integration:</p>\n\n<pre><code>git clone <a href=\"https://github.com/mongodb/mongo-hadoop\">https://github.com/mongodb/mongo-hadoop</a>\ncd mongo-hadoop\nmvn install\ncd examples\nmvn install # Then check out pigtutorial/\ncd ..\nwget <a href=\"https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar\">https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar</a></code></pre>\n\n<pre><code>REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER /me/pig/contrib/piggybank/java/piggybank.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\n\n\n<b>REGISTER /me/mongo-hadoop/mongo-2.3.jar\nREGISTER /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0-SNAPSHOT.jar\nREGISTER /me/mongo-hadoop/pig/target/mongo-pig-1.0-SNAPSHOT.jar\n</b>\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\nsh rm -rf '/tmp/sent_counts.avro' /* Workaround for PIG-2441 */\n\nmessages = LOAD '/tmp/10000_emails.avro' USING AvroStorage();\nmessages = FILTER messages BY from IS NOT NULL AND to IS NOT NULL;\nsmaller = FOREACH messages GENERATE from, to;\npairs = FOREACH smaller GENERATE from, FLATTEN(to) AS to:chararray;\npairs = FOREACH pairs GENERATE LOWER(from) AS from, LOWER(to) AS to;\n\nfroms = GROUP pairs BY (from, to);\nsent_counts = FOREACH froms GENERATE FLATTEN(group) AS (from, to), SIZE(pairs) AS total;\n-- STORE sent_counts INTO '/tmp/sent_counts.avro' USING AvroStorage();\nSTORE sent_counts INTO 'mongodb://localhost/test.pig' USING com.mongodb.hadoop.pig.MongoStorage;</code></pre>\n\n<p>Note that the use of Avro is optional, but is fun too.</p>\n\n<p>Check out your data:</p>\n\n<pre><code>bash$ mongo pig\n\n\n&gt; show collections\npig\n\n\n&gt; db.pig.find()\n\n\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414133e522\"), \"from\" : \"dwr@touk.pl\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414233e522\"), \"from\" : \"brad@bing.com\", \"to\" : \"common-user@hadoop.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414333e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"dev@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414433e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(2) }</code></pre>\n\n<p><b>MongoDB is web scale.</b>  Who would have thought?  Usability matters.  90% there is not enough.  ;)</p>", "tree_html": ""}, "can_send_in_message": true, "id": 14631249157, "display_avatar": true, "can_reply": true, "can_like": false, "title": "mongodb IS web scale: hadoop-mongodb", "tags": [], "post_url": "http://datasyndrome.com/post/14631249157/mongodb-is-web-scale-hadoop-mongodb", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yDe5oK5", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1324587060, "note_count": 6, "trail": [{"content": "<p>MongoDB is <a href=\"http://www.mongodb-is-web-scale.com/\">Web Scale</a>.  Lulz, right?  Turns out, Mongo is the first NoSQL to nail painless Hadoop and Pig integration&hellip; thus becoming the first &lsquo;web scale&rsquo; database.</p>\n\n<p><b>Proof</b>:</p>\n\n<p>Install Mongo &amp; run it: <a href=\"http://www.mongodb.org/display/DOCS/Quickstart\">http://www.mongodb.org/display/DOCS/Quickstart</a></p>\n\n<p>Install Mongo&rsquo;s hadoop integration:</p>\n\n<pre><code>git clone <a href=\"https://github.com/mongodb/mongo-hadoop\">https://github.com/mongodb/mongo-hadoop</a>\ncd mongo-hadoop\nmvn install\ncd examples\nmvn install # Then check out pigtutorial/\ncd ..\nwget <a href=\"https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar\">https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar</a></code></pre>\n\n<pre><code>REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER /me/pig/contrib/piggybank/java/piggybank.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\n\n\n<b>REGISTER /me/mongo-hadoop/mongo-2.3.jar\nREGISTER /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0-SNAPSHOT.jar\nREGISTER /me/mongo-hadoop/pig/target/mongo-pig-1.0-SNAPSHOT.jar\n</b>\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\nsh rm -rf '/tmp/sent_counts.avro' /* Workaround for PIG-2441 */\n\nmessages = LOAD '/tmp/10000_emails.avro' USING AvroStorage();\nmessages = FILTER messages BY from IS NOT NULL AND to IS NOT NULL;\nsmaller = FOREACH messages GENERATE from, to;\npairs = FOREACH smaller GENERATE from, FLATTEN(to) AS to:chararray;\npairs = FOREACH pairs GENERATE LOWER(from) AS from, LOWER(to) AS to;\n\nfroms = GROUP pairs BY (from, to);\nsent_counts = FOREACH froms GENERATE FLATTEN(group) AS (from, to), SIZE(pairs) AS total;\n-- STORE sent_counts INTO '/tmp/sent_counts.avro' USING AvroStorage();\nSTORE sent_counts INTO 'mongodb://localhost/test.pig' USING com.mongodb.hadoop.pig.MongoStorage;</code></pre>\n\n<p>Note that the use of Avro is optional, but is fun too.</p>\n\n<p>Check out your data:</p>\n\n<pre><code>bash$ mongo pig\n\n\n&gt; show collections\npig\n\n\n&gt; db.pig.find()\n\n\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414133e522\"), \"from\" : \"dwr@touk.pl\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414233e522\"), \"from\" : \"brad@bing.com\", \"to\" : \"common-user@hadoop.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414333e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"dev@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414433e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(2) }</code></pre>\n\n<p><b>MongoDB is web scale.</b>  Who would have thought?  Usability matters.  90% there is not enough.  ;)</p>", "content_raw": "<p>MongoDB is <a href=\"http://www.mongodb-is-web-scale.com/\">Web Scale</a>.  Lulz, right?  Turns out, Mongo is the first NoSQL to nail painless Hadoop and Pig integration\u2026 thus becoming the first \u2018web scale\u2019 database.</p>\n\n<p><b>Proof</b>:</p>\n\n<p>Install Mongo &amp; run it: <a href=\"http://www.mongodb.org/display/DOCS/Quickstart\">http://www.mongodb.org/display/DOCS/Quickstart</a></p>\n\n<p>Install Mongo\u2019s hadoop integration:</p>\n\n<pre><code>git clone <a href=\"https://github.com/mongodb/mongo-hadoop\">https://github.com/mongodb/mongo-hadoop</a>\ncd mongo-hadoop\nmvn install\ncd examples\nmvn install # Then check out pigtutorial/\ncd ..\nwget <a href=\"https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar\">https://github.com/downloads/mongodb/mongo-java-driver/mongo-2.3.jar</a></code></pre>\n\n<pre><code>REGISTER /me/pig/build/ivy/lib/Pig/avro-1.5.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER /me/pig/contrib/piggybank/java/piggybank.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-core-asl-1.7.3.jar\nREGISTER /me/pig/build/ivy/lib/Pig/jackson-mapper-asl-1.7.3.jar\n\n\n<b>REGISTER /me/mongo-hadoop/mongo-2.3.jar\nREGISTER /me/mongo-hadoop/core/target/mongo-hadoop-core-1.0-SNAPSHOT.jar\nREGISTER /me/mongo-hadoop/pig/target/mongo-pig-1.0-SNAPSHOT.jar\n</b>\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\nsh rm -rf '/tmp/sent_counts.avro' /* Workaround for PIG-2441 */\n\nmessages = LOAD '/tmp/10000_emails.avro' USING AvroStorage();\nmessages = FILTER messages BY from IS NOT NULL AND to IS NOT NULL;\nsmaller = FOREACH messages GENERATE from, to;\npairs = FOREACH smaller GENERATE from, FLATTEN(to) AS to:chararray;\npairs = FOREACH pairs GENERATE LOWER(from) AS from, LOWER(to) AS to;\n\nfroms = GROUP pairs BY (from, to);\nsent_counts = FOREACH froms GENERATE FLATTEN(group) AS (from, to), SIZE(pairs) AS total;\n-- STORE sent_counts INTO '/tmp/sent_counts.avro' USING AvroStorage();\nSTORE sent_counts INTO 'mongodb://localhost/test.pig' USING com.mongodb.hadoop.pig.MongoStorage;</code></pre>\n\n<p>Note that the use of Avro is optional, but is fun too.</p>\n\n<p>Check out your data:</p>\n\n<pre><code>bash$ mongo pig\n\n\n&gt; show collections\npig\n\n\n&gt; db.pig.find()\n\n\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414133e522\"), \"from\" : \"dwr@touk.pl\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414233e522\"), \"from\" : \"brad@bing.com\", \"to\" : \"common-user@hadoop.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414333e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"dev@hive.apache.org\", \"total\" : NumberLong(1) }\n{ \"_id\" : ObjectId(\"4ef2dc29f37d4e414433e522\"), \"from\" : \"jsichi@fb.com\", \"to\" : \"user@hive.apache.org\", \"total\" : NumberLong(2) }</code></pre>\n\n<p><b>MongoDB is web scale.</b>  Who would have thought?  Usability matters.  90% there is not enough.  ;)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "14631249157"}}], "date": "2011-12-22 20:51:00 GMT", "slug": "mongodb-is-web-scale-hadoop-mongodb", "blog_name": "rjurney", "summary": "mongodb IS web scale: hadoop-mongodb", "can_reblog": true}, {"body": "<p>Complete working code for this example is available at <a href=\"https://github.com/rjurney/Booting-the-Analytics-Application\">https://github.com/rjurney/Booting-the-Analytics-Application</a></p>\n\n<p>The first step to building analytics applications with Hadoop is to plumb your application from end to end: from collecting raw data to displaying something on the users&rsquo; screen.  This is important, because models can get complex fast, and you need user feedback plugged into the equation from the start.</p>\n\n<p>Collecting data in Avro is convenient, because a simple JSON schema is included with each pile of records.  <a href=\"http://avro.apache.org/\">Apache Avro</a> is a data serialization system with rich formats, simple integration with dynamic languages and support in Apache Pig.</p>\n\n<p>Using Avro with Ruby and Pig is easy:</p>\n\n<p>Install the avro ruby gem.  Works in <a href=\"http://jruby.org/\">JRuby</a> too.</p>\n<pre><code>gem install avro</code></pre>\n\n<p>Get and build Pig 0.9.1 and then piggybank (takes a while)</p>\n<pre><code>cd\nwget <a href=\"http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz\">http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz</a>\ntar -xvzf pig-0.9.1.tar.gz\ncd pig-0.9.1\nant\ncd contrib/piggybank/java\nant\ncd ../../..</code></pre>\n\n<p>Decide on a schema for your records and create some avro records in your application.</p>\n<pre><code>require 'rubygems'\nrequire 'avro'\n\n\nSCHEMA = &lt;&lt;-JSON\n{ \"type\": \"record\",\n  \"name\": \"Email\",\n  \"fields\" : [\n    {\"name\": \"message_id\", \"type\": \"int\"},\n    {\"name\": \"topic\", \"type\": \"string\"},\n    {\"name\": \"user_id\", \"type\": \"int\"}\n  ]}\nJSON\n\n\nfile = File.open('~/tmp/messages.avro', 'wb')\nschema = Avro::Schema.parse(SCHEMA)\nwriter = Avro::IO::DatumWriter.new(schema)\ndw = Avro::DataFile::Writer.new(file, writer, schema)\ndw &lt;&lt; {\"message_id\" =&gt; 11, \"topic\" =&gt; \"Hello World\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 12, \"topic\" =&gt; \"Jim is silly!\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 13, \"topic\" =&gt; \"I like apples.\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 24, \"topic\" =&gt; \"Round the world...\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 35, \"topic\" =&gt; \"How do I sent a message?\", \"user_id\" =&gt; 45}\ndw.close\n</code></pre> \n\n<p>To setup your environment, add these lines to .bash_profile:</p>\n<pre><code>pig_version=0.9.1\nexport CLASSPATH=$CLASSPATH:~/pig-${pig_version}/build/ivy/lib/Pig/avro-1.4.1.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/json-simple-1.1.jar\\\n:~/pig-${pig_version}/contrib/piggybank/java/piggybank.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n</code></pre>\nAnd re-run it via:\n<pre><code>source ~/.bash_profile</code></pre>\n\n<p>This script via &lsquo;bin/pig -l /tmp -x local&rsquo; will get you working with your records:</p>\n<pre><code>REGISTER ./build/ivy/lib/Pig/avro-1.4.1.jar\nREGISTER ./build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER  contrib/piggybank/java/piggybank.jar\nREGISTER ./build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\nREGISTER ./build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n\nmessages = LOAD '/tmp/messages.avro' USING AvroStorage();\n</code></pre>\n\n<p><a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DESCRIBE\">DESCRIBE</a> lists the schema of your data - if it is known.  When you&rsquo;re winging it, sometimes you might not have a schema.  Remember: 'Pigs eat anything,&rsquo; so no schema required!  In practice, you&rsquo;ll usually want schemas for application development.</p>\n\n<pre><code>grunt&gt; DESCRIBE messages\n\navros: {message_id: int,topic: chararray}\n\n</code></pre>\n\n<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DUMP\">DUMP</a> is simple, but be careful: 'big data&rsquo; across your screen is not always useful, and you&rsquo;ll have to ctrl-c to stop it, which ends your grunt session.\n\n<pre><code>grunt&gt; DUMP messages\n(11,Hello World,1)\n(12,Jim is silly!,1)\n(13,I like apples.,2)\n(24,Round the world...,2)\n(35,How do I sent a message?,45)\n</code></pre>\n\nIn practice, you&rsquo;ll often want to <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#SAMPLE\">SAMPLE</a>/<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#LIMIT\">LIMIT</a>/DUMP\n\n<pre><code>grunt&gt; A = SAMPLE messages 0.5;\ngrunt&gt; B = LIMIT messages 2;\ngrunt&gt; DUMP B\n(11,Hello World,1)\n(12,Jim is silly!,1)\n\n</code></pre>\n\n<p>Or better yet&hellip; <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#ILLUSTRATE\">ILLUSTRATE</a>!  <b>I &lt;3 ILLUSTRATE.</b></p>\n\n<pre><code>\ngrunt&gt; ILLUSTRATE messages\n-----------------------------------------------------\n| avros     | message_id:int   | topic:chararray    | \n-----------------------------------------------------\n|           | 12               | Jim is silly!     | \n-----------------------------------------------------\n\n</code></pre>\n\n<p>ILLUSTRATE is useful because it generates sample data for your pig script immediately, without waiting on a hadoop batch job.  Debugging code while waiting minutes or hours on Hadoop jobs during test runs will tank productivity fast.  ILLUSTRATE&rsquo;s sample data &rsquo;<a href=\"http://infolab.stanford.edu/~olston/publications/sigmod09.pdf\">illustrates the semantics of the operators while keeping the example data small.</a>&rsquo;   This makes Pig very powerful.</p>\n\n<p>Lets try some Pig operations on our data, to see what I&rsquo;m talking about.  Suppose we want to look at messages per user, but only active users&hellip; say those that have posted more than one message:</p>\n\n<pre><code>\ngrunt&gt; user_groups = GROUP messages by user_id;\ngrunt&gt; per_user = FOREACH user_groups GENERATE group AS user_id, \n       SIZE($1) AS message_count;\ngrunt&gt; gt_one = FILTER per_user BY message_count &gt; 1;\ngrunt&gt; active_users = FOREACH gt_one GENERATE user_id;\n\ngrunt&gt; DESCRIBE active_users\nactive_users: {user_id: int}\n</code></pre>\n\nNow lets employ ILLUSTRATE to see what happened as records flowed through our simple data pipeline:\n\n<pre><code>grunt&gt; ILLUSTRATE active_users\n-----------------------------------------------------------------------------\n| messages     | message_id:int     | topic:chararray     | user_id:int     | \n-----------------------------------------------------------------------------\n|              | 24                 | Round the world...  | 2               | \n|              | 13                 | I like apples.      | 2               | \n-----------------------------------------------------------------------------\n--------------------------------------------------------------------------------------------------------------------------\n| user_groups     | group:int     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------\n|                 | 2             | {(24, Round the world..., 2), (13, I like apples., 2)}                               | \n--------------------------------------------------------------------------------------------------------------------------\n-----------------------------------------------------------\n| per_user     | user_id:int     | message_count:long     | \n-----------------------------------------------------------\n|              | 2               | 2                      | \n-----------------------------------------------------------\n---------------------------------------------------------\n| gt_one     | user_id:int     | message_count:long     | \n---------------------------------------------------------\n|            | 2               | 2                      | \n---------------------------------------------------------\n--------------------------------------\n| active_users     | user_id:int     | \n--------------------------------------\n|                  | 2               | \n--------------------------------------\n</code></pre>\n\n<p>Note how we can see the changes happening to the data as it flows through our pig script, without waiting on Hadoop to execute it.  Note also, that the answer ILLUSTRATE gives is not definitive, but is there to guide us as we write code: our DUMP has two records in <i>active_users</i>, not one.</p>\n\n<pre><code>grunt&gt; DUMP active_users\n(1)\n(2)\n</code></pre>\n\n<p>Now lets try creating something we&rsquo;d like to actually consume in a web app, via a key/value store.  Say we want to access all messages per user, sorted newest to oldest.  Lets create a suitable key and create these records:</p>\n\n<pre><code>grunt&gt; user_groups = GROUP messages by user_id;\nper_user = FOREACH user_groups {                \n    sorted = ORDER messages BY message_id DESC;     \n    GENERATE CONCAT('messages_per_user_id:', (chararray)group) AS user_key, sorted.$0 AS messages;\n}\ngrunt&gt; DESCRIBE per_user\nper_user: {user_key: chararray,messages: {(message_id: int)}}\n</code></pre>\n\n<p><b>Note: There was a six hour detour at this point to fix a bug in the AvroStorage UDF for persisting these kinds of records.  JIRA created and patch submitted here: <a href=\"https://issues.apache.org/jira/browse/PIG-2411\">https://issues.apache.org/jira/browse/PIG-2411</a></b>.  This kind of detour is common when you first setup an app, and you just have to bare the Java and fight through it.</p>\n\n<pre><code>grunt&gt; STORE per_user INTO '/tmp/per_user.avro' USING AvroStorage();\n</code></pre>\n\nIt works!\n\nNote how ILLUSTRATE has become more useful, as it displays the result of our casting the user_id from integer to chararray, and concatenating it with a record identifier to create a voldemort key that allows sharing the store with other record types:\n\n<pre><code>ILLUSTRATE per_user\n\n...\n\n--------------------------------------------------------------------------------------------------------------------------------\n| per_user     | user_key:chararray     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------------\n|              | messages_per_user_id:1 | {(12, Jim is silly!, 1), (11, Hello World, 1)}                                       | \n--------------------------------------------------------------------------------------------------------------------------------</code></pre>\n\n<p>This works for EvalFunc UDFs (User Defined Functions) too, which is really helpful.</p>\n\n<p>Our processed data is ready to go.  How do we publish it to a key/value store for consumption?</p>\n\n<p>With a few records, we care about ease of use.  As our data grows, we care about scaling.  <a href=\"http://project-voldemort.com/\">Project Voldemort</a> is distributed key/value storage system which is easy to use and which scales well too.  Voldemort <a href=\"http://sna-projects.com/blog/2009/06/voldemort-and-hadoop/\">supports building read-only stores on Hadoop and loading them directly</a> from the hadoop cluster to the voldemort cluster.</p>\n\n<p>Initially, we will write individual records to a Voldemort BDB store.  As our data grows, we can build and push entire read-only stores from hadoop to an operational cluster with a few commands.</p>\n\n<p>Download and unpack voldemort:</p><pre><code>cd\nwget --no-check-certificate <a href=\"https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz\">https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz</a>\ntar -xvzf voldemort-0.90.1.tar.gz\ncd voldemort-0.90.1\n</code></pre>\n\n<p>Follow the instructions <a href=\"http://project-voldemort.com/quickstart.php\">here</a> to start voldemort:</p>\n\n<pre><code>bin/voldemort-server.sh config/single_node_cluster &gt; /tmp/voldemort.log &amp;</code></pre>\n\n<p>Install the voldemort-rb gem.  Works with JRuby too:</p>\n\n<pre><code>gem install nokogiri\ngem install ruby_protobuf\ngem install voldemort-rb\n</code></pre>\n\n<p>Now in ruby we connect to our voldemort cluster, loop through our avro records and insert a new entry for each:</p> \n\n<pre><code>\nrequire 'rubygems'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nfile = File.open('/tmp/per_user.avro/part-r-00000.avro', 'r+')\ndr = Avro::DataFile::Reader.new(file, Avro::IO::DatumReader.new)\ndr.each do |record| \n  client.put record[\"user_key\"], JSON(record[\"messages\"])\nend\n</code></pre>\n\n<p>Finally&hellip; we want to see our data in the browser.  A one-page <a href=\"http://www.sinatrarb.com/intro\">Sinatra</a> web app gets us there.  Install Sinatra:</p>\n\n<pre><code>gem install sinatra\n</code></pre>\n\nOur sinatra app looks like:\n\n<pre><code>require 'rubygems'\nrequire 'sinatra'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\n# connect to voldemort\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nget '/messages_per_user_id/:user_id' do |user_id|\n  client.get \"messages_per_user_id:#{user_id}\"\nend\n</code></pre>\n\n<p>We can see our plumbed data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> or <a href=\"http://localhost:4567/messages_per_user_id/2\">http://localhost:4567/messages_per_user_id/2</a></p>\n\n<p>The data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> looks like this: \n\n</p><pre><code>[{\"message_id\":12},{\"message_id\":11}]</code></pre>\n\n<p>Note that we haven&rsquo;t touched Hadoop yet.  :)  It is simply not neccessary to do so, in order to get started using the tools.  We&rsquo;ve made platform choices that will let us aggregate and mine data at scale, and we&rsquo;ve gotten them up and running in a few minutes on our local machines. </p>\n\n<p>In future posts, we&rsquo;ll extend this to work at scale on Amazon Web Services and Heroku.</p>", "liked": false, "followed": false, "reblog_key": "ab7rYs1f", "reblog": {"comment": "<p>Complete working code for this example is available at <a href=\"https://github.com/rjurney/Booting-the-Analytics-Application\">https://github.com/rjurney/Booting-the-Analytics-Application</a></p>\n\n<p>The first step to building analytics applications with Hadoop is to plumb your application from end to end: from collecting raw data to displaying something on the users\u2019 screen.  This is important, because models can get complex fast, and you need user feedback plugged into the equation from the start.</p>\n\n<p>Collecting data in Avro is convenient, because a simple JSON schema is included with each pile of records.  <a href=\"http://avro.apache.org/\">Apache Avro</a> is a data serialization system with rich formats, simple integration with dynamic languages and support in Apache Pig.</p>\n\n<p>Using Avro with Ruby and Pig is easy:</p>\n\n<p>Install the avro ruby gem.  Works in <a href=\"http://jruby.org/\">JRuby</a> too.</p>\n<pre><code>gem install avro</code></pre>\n\n<p>Get and build Pig 0.9.1 and then piggybank (takes a while)</p>\n<pre><code>cd\nwget <a href=\"http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz\">http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz</a>\ntar -xvzf pig-0.9.1.tar.gz\ncd pig-0.9.1\nant\ncd contrib/piggybank/java\nant\ncd ../../..</code></pre>\n\n<p>Decide on a schema for your records and create some avro records in your application.</p>\n<pre><code>require 'rubygems'\nrequire 'avro'\n\n\nSCHEMA = &lt;&lt;-JSON\n{ \"type\": \"record\",\n  \"name\": \"Email\",\n  \"fields\" : [\n    {\"name\": \"message_id\", \"type\": \"int\"},\n    {\"name\": \"topic\", \"type\": \"string\"},\n    {\"name\": \"user_id\", \"type\": \"int\"}\n  ]}\nJSON\n\n\nfile = File.open('~/tmp/messages.avro', 'wb')\nschema = Avro::Schema.parse(SCHEMA)\nwriter = Avro::IO::DatumWriter.new(schema)\ndw = Avro::DataFile::Writer.new(file, writer, schema)\ndw &lt;&lt; {\"message_id\" =&gt; 11, \"topic\" =&gt; \"Hello World\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 12, \"topic\" =&gt; \"Jim is silly!\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 13, \"topic\" =&gt; \"I like apples.\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 24, \"topic\" =&gt; \"Round the world...\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 35, \"topic\" =&gt; \"How do I sent a message?\", \"user_id\" =&gt; 45}\ndw.close\n</code></pre> \n\n<p>To setup your environment, add these lines to .bash_profile:</p>\n<pre><code>pig_version=0.9.1\nexport CLASSPATH=$CLASSPATH:~/pig-${pig_version}/build/ivy/lib/Pig/avro-1.4.1.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/json-simple-1.1.jar\\\n:~/pig-${pig_version}/contrib/piggybank/java/piggybank.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n</code></pre>\nAnd re-run it via:\n<pre><code>source ~/.bash_profile</code></pre>\n\n<p>This script via \u2018bin/pig -l /tmp -x local\u2019 will get you working with your records:</p>\n<pre><code>REGISTER ./build/ivy/lib/Pig/avro-1.4.1.jar\nREGISTER ./build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER  contrib/piggybank/java/piggybank.jar\nREGISTER ./build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\nREGISTER ./build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n\nmessages = LOAD '/tmp/messages.avro' USING AvroStorage();\n</code></pre>\n\n<p><a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DESCRIBE\">DESCRIBE</a> lists the schema of your data - if it is known.  When you\u2019re winging it, sometimes you might not have a schema.  Remember: 'Pigs eat anything,\u2019 so no schema required!  In practice, you\u2019ll usually want schemas for application development.</p>\n\n<pre><code>grunt&gt; DESCRIBE messages\n\navros: {message_id: int,topic: chararray}\n\n</code></pre>\n\n<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DUMP\">DUMP</a> is simple, but be careful: 'big data\u2019 across your screen is not always useful, and you\u2019ll have to ctrl-c to stop it, which ends your grunt session.\n\n<pre><code>grunt&gt; DUMP messages\n(11,Hello World,1)\n(12,Jim is silly!,1)\n(13,I like apples.,2)\n(24,Round the world...,2)\n(35,How do I sent a message?,45)\n</code></pre>\n\nIn practice, you\u2019ll often want to <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#SAMPLE\">SAMPLE</a>/<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#LIMIT\">LIMIT</a>/DUMP\n\n<pre><code>grunt&gt; A = SAMPLE messages 0.5;\ngrunt&gt; B = LIMIT messages 2;\ngrunt&gt; DUMP B\n(11,Hello World,1)\n(12,Jim is silly!,1)\n\n</code></pre>\n\n<p>Or better yet\u2026 <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#ILLUSTRATE\">ILLUSTRATE</a>!  <b>I &lt;3 ILLUSTRATE.</b></p>\n\n<pre><code>\ngrunt&gt; ILLUSTRATE messages\n-----------------------------------------------------\n| avros     | message_id:int   | topic:chararray    | \n-----------------------------------------------------\n|           | 12               | Jim is silly!     | \n-----------------------------------------------------\n\n</code></pre>\n\n<p>ILLUSTRATE is useful because it generates sample data for your pig script immediately, without waiting on a hadoop batch job.  Debugging code while waiting minutes or hours on Hadoop jobs during test runs will tank productivity fast.  ILLUSTRATE\u2019s sample data \u2019<a href=\"http://infolab.stanford.edu/~olston/publications/sigmod09.pdf\">illustrates the semantics of the operators while keeping the example data small.</a>\u2019   This makes Pig very powerful.</p>\n\n<p>Lets try some Pig operations on our data, to see what I\u2019m talking about.  Suppose we want to look at messages per user, but only active users\u2026 say those that have posted more than one message:</p>\n\n<pre><code>\ngrunt&gt; user_groups = GROUP messages by user_id;\ngrunt&gt; per_user = FOREACH user_groups GENERATE group AS user_id, \n       SIZE($1) AS message_count;\ngrunt&gt; gt_one = FILTER per_user BY message_count &gt; 1;\ngrunt&gt; active_users = FOREACH gt_one GENERATE user_id;\n\ngrunt&gt; DESCRIBE active_users\nactive_users: {user_id: int}\n</code></pre>\n\nNow lets employ ILLUSTRATE to see what happened as records flowed through our simple data pipeline:\n\n<pre><code>grunt&gt; ILLUSTRATE active_users\n-----------------------------------------------------------------------------\n| messages     | message_id:int     | topic:chararray     | user_id:int     | \n-----------------------------------------------------------------------------\n|              | 24                 | Round the world...  | 2               | \n|              | 13                 | I like apples.      | 2               | \n-----------------------------------------------------------------------------\n--------------------------------------------------------------------------------------------------------------------------\n| user_groups     | group:int     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------\n|                 | 2             | {(24, Round the world..., 2), (13, I like apples., 2)}                               | \n--------------------------------------------------------------------------------------------------------------------------\n-----------------------------------------------------------\n| per_user     | user_id:int     | message_count:long     | \n-----------------------------------------------------------\n|              | 2               | 2                      | \n-----------------------------------------------------------\n---------------------------------------------------------\n| gt_one     | user_id:int     | message_count:long     | \n---------------------------------------------------------\n|            | 2               | 2                      | \n---------------------------------------------------------\n--------------------------------------\n| active_users     | user_id:int     | \n--------------------------------------\n|                  | 2               | \n--------------------------------------\n</code></pre>\n\n<p>Note how we can see the changes happening to the data as it flows through our pig script, without waiting on Hadoop to execute it.  Note also, that the answer ILLUSTRATE gives is not definitive, but is there to guide us as we write code: our DUMP has two records in <i>active_users</i>, not one.</p>\n\n<pre><code>grunt&gt; DUMP active_users\n(1)\n(2)\n</code></pre>\n\n<p>Now lets try creating something we\u2019d like to actually consume in a web app, via a key/value store.  Say we want to access all messages per user, sorted newest to oldest.  Lets create a suitable key and create these records:</p>\n\n<pre><code>grunt&gt; user_groups = GROUP messages by user_id;\nper_user = FOREACH user_groups {                \n    sorted = ORDER messages BY message_id DESC;     \n    GENERATE CONCAT('messages_per_user_id:', (chararray)group) AS user_key, sorted.$0 AS messages;\n}\ngrunt&gt; DESCRIBE per_user\nper_user: {user_key: chararray,messages: {(message_id: int)}}\n</code></pre>\n\n<p><b>Note: There was a six hour detour at this point to fix a bug in the AvroStorage UDF for persisting these kinds of records.  JIRA created and patch submitted here: <a href=\"https://issues.apache.org/jira/browse/PIG-2411\">https://issues.apache.org/jira/browse/PIG-2411</a></b>.  This kind of detour is common when you first setup an app, and you just have to bare the Java and fight through it.</p>\n\n<pre><code>grunt&gt; STORE per_user INTO '/tmp/per_user.avro' USING AvroStorage();\n</code></pre>\n\nIt works!\n\nNote how ILLUSTRATE has become more useful, as it displays the result of our casting the user_id from integer to chararray, and concatenating it with a record identifier to create a voldemort key that allows sharing the store with other record types:\n\n<pre><code>ILLUSTRATE per_user\n\n...\n\n--------------------------------------------------------------------------------------------------------------------------------\n| per_user     | user_key:chararray     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------------\n|              | messages_per_user_id:1 | {(12, Jim is silly!, 1), (11, Hello World, 1)}                                       | \n--------------------------------------------------------------------------------------------------------------------------------</code></pre>\n\n<p>This works for EvalFunc UDFs (User Defined Functions) too, which is really helpful.</p>\n\n<p>Our processed data is ready to go.  How do we publish it to a key/value store for consumption?</p>\n\n<p>With a few records, we care about ease of use.  As our data grows, we care about scaling.  <a href=\"http://project-voldemort.com/\">Project Voldemort</a> is distributed key/value storage system which is easy to use and which scales well too.  Voldemort <a href=\"http://sna-projects.com/blog/2009/06/voldemort-and-hadoop/\">supports building read-only stores on Hadoop and loading them directly</a> from the hadoop cluster to the voldemort cluster.</p>\n\n<p>Initially, we will write individual records to a Voldemort BDB store.  As our data grows, we can build and push entire read-only stores from hadoop to an operational cluster with a few commands.</p>\n\n<p>Download and unpack voldemort:</p><pre><code>cd\nwget --no-check-certificate <a href=\"https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz\">https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz</a>\ntar -xvzf voldemort-0.90.1.tar.gz\ncd voldemort-0.90.1\n</code></pre>\n\n<p>Follow the instructions <a href=\"http://project-voldemort.com/quickstart.php\">here</a> to start voldemort:</p>\n\n<pre><code>bin/voldemort-server.sh config/single_node_cluster &gt; /tmp/voldemort.log &amp;</code></pre>\n\n<p>Install the voldemort-rb gem.  Works with JRuby too:</p>\n\n<pre><code>gem install nokogiri\ngem install ruby_protobuf\ngem install voldemort-rb\n</code></pre>\n\n<p>Now in ruby we connect to our voldemort cluster, loop through our avro records and insert a new entry for each:</p> \n\n<pre><code>\nrequire 'rubygems'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nfile = File.open('/tmp/per_user.avro/part-r-00000.avro', 'r+')\ndr = Avro::DataFile::Reader.new(file, Avro::IO::DatumReader.new)\ndr.each do |record| \n  client.put record[\"user_key\"], JSON(record[\"messages\"])\nend\n</code></pre>\n\n<p>Finally\u2026 we want to see our data in the browser.  A one-page <a href=\"http://www.sinatrarb.com/intro\">Sinatra</a> web app gets us there.  Install Sinatra:</p>\n\n<pre><code>gem install sinatra\n</code></pre>\n\nOur sinatra app looks like:\n\n<pre><code>require 'rubygems'\nrequire 'sinatra'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\n# connect to voldemort\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nget '/messages_per_user_id/:user_id' do |user_id|\n  client.get \"messages_per_user_id:#{user_id}\"\nend\n</code></pre>\n\n<p>We can see our plumbed data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> or <a href=\"http://localhost:4567/messages_per_user_id/2\">http://localhost:4567/messages_per_user_id/2</a></p>\n\n<p>The data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> looks like this: \n\n</p><pre><code>[{\"message_id\":12},{\"message_id\":11}]</code></pre>\n\n<p>Note that we haven\u2019t touched Hadoop yet.  :)  It is simply not neccessary to do so, in order to get started using the tools.  We\u2019ve made platform choices that will let us aggregate and mine data at scale, and we\u2019ve gotten them up and running in a few minutes on our local machines. </p>\n\n<p>In future posts, we\u2019ll extend this to work at scale on Amazon Web Services and Heroku.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 13707537045, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Booting the Analytics Application: Events -> Ruby -> Avro -> Pig -> Voldemort -> Sinatra -> Web Browser -> User", "tags": [], "post_url": "http://datasyndrome.com/post/13707537045/booting-the-analytics-application-events-ruby", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yCn26gL", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1322965320, "note_count": 1, "trail": [{"content": "<p>Complete working code for this example is available at <a href=\"https://github.com/rjurney/Booting-the-Analytics-Application\">https://github.com/rjurney/Booting-the-Analytics-Application</a></p>\n\n<p>The first step to building analytics applications with Hadoop is to plumb your application from end to end: from collecting raw data to displaying something on the users&rsquo; screen.  This is important, because models can get complex fast, and you need user feedback plugged into the equation from the start.</p>\n\n<p>Collecting data in Avro is convenient, because a simple JSON schema is included with each pile of records.  <a href=\"http://avro.apache.org/\">Apache Avro</a> is a data serialization system with rich formats, simple integration with dynamic languages and support in Apache Pig.</p>\n\n<p>Using Avro with Ruby and Pig is easy:</p>\n\n<p>Install the avro ruby gem.  Works in <a href=\"http://jruby.org/\">JRuby</a> too.</p>\n<pre><code>gem install avro</code></pre>\n\n<p>Get and build Pig 0.9.1 and then piggybank (takes a while)</p>\n<pre><code>cd\nwget <a href=\"http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz\">http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz</a>\ntar -xvzf pig-0.9.1.tar.gz\ncd pig-0.9.1\nant\ncd contrib/piggybank/java\nant\ncd ../../..</code></pre>\n\n<p>Decide on a schema for your records and create some avro records in your application.</p>\n<pre><code>require 'rubygems'\nrequire 'avro'\n\n\nSCHEMA = &lt;&lt;-JSON\n{ \"type\": \"record\",\n  \"name\": \"Email\",\n  \"fields\" : [\n    {\"name\": \"message_id\", \"type\": \"int\"},\n    {\"name\": \"topic\", \"type\": \"string\"},\n    {\"name\": \"user_id\", \"type\": \"int\"}\n  ]}\nJSON\n\n\nfile = File.open('~/tmp/messages.avro', 'wb')\nschema = Avro::Schema.parse(SCHEMA)\nwriter = Avro::IO::DatumWriter.new(schema)\ndw = Avro::DataFile::Writer.new(file, writer, schema)\ndw &lt;&lt; {\"message_id\" =&gt; 11, \"topic\" =&gt; \"Hello World\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 12, \"topic\" =&gt; \"Jim is silly!\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 13, \"topic\" =&gt; \"I like apples.\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 24, \"topic\" =&gt; \"Round the world...\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 35, \"topic\" =&gt; \"How do I sent a message?\", \"user_id\" =&gt; 45}\ndw.close\n</code></pre> \n\n<p>To setup your environment, add these lines to .bash_profile:</p>\n<pre><code>pig_version=0.9.1\nexport CLASSPATH=$CLASSPATH:~/pig-${pig_version}/build/ivy/lib/Pig/avro-1.4.1.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/json-simple-1.1.jar\\\n:~/pig-${pig_version}/contrib/piggybank/java/piggybank.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n</code></pre>\nAnd re-run it via:\n<pre><code>source ~/.bash_profile</code></pre>\n\n<p>This script via &lsquo;bin/pig -l /tmp -x local&rsquo; will get you working with your records:</p>\n<pre><code>REGISTER ./build/ivy/lib/Pig/avro-1.4.1.jar\nREGISTER ./build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER  contrib/piggybank/java/piggybank.jar\nREGISTER ./build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\nREGISTER ./build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n\nmessages = LOAD '/tmp/messages.avro' USING AvroStorage();\n</code></pre>\n\n<p><a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DESCRIBE\">DESCRIBE</a> lists the schema of your data - if it is known.  When you&rsquo;re winging it, sometimes you might not have a schema.  Remember: 'Pigs eat anything,&rsquo; so no schema required!  In practice, you&rsquo;ll usually want schemas for application development.</p>\n\n<pre><code>grunt&gt; DESCRIBE messages\n\navros: {message_id: int,topic: chararray}\n\n</code></pre>\n\n<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DUMP\">DUMP</a> is simple, but be careful: 'big data&rsquo; across your screen is not always useful, and you&rsquo;ll have to ctrl-c to stop it, which ends your grunt session.\n\n<pre><code>grunt&gt; DUMP messages\n(11,Hello World,1)\n(12,Jim is silly!,1)\n(13,I like apples.,2)\n(24,Round the world...,2)\n(35,How do I sent a message?,45)\n</code></pre>\n\nIn practice, you&rsquo;ll often want to <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#SAMPLE\">SAMPLE</a>/<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#LIMIT\">LIMIT</a>/DUMP\n\n<pre><code>grunt&gt; A = SAMPLE messages 0.5;\ngrunt&gt; B = LIMIT messages 2;\ngrunt&gt; DUMP B\n(11,Hello World,1)\n(12,Jim is silly!,1)\n\n</code></pre>\n\n<p>Or better yet&hellip; <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#ILLUSTRATE\">ILLUSTRATE</a>!  <b>I &lt;3 ILLUSTRATE.</b></p>\n\n<pre><code>\ngrunt&gt; ILLUSTRATE messages\n-----------------------------------------------------\n| avros     | message_id:int   | topic:chararray    | \n-----------------------------------------------------\n|           | 12               | Jim is silly!     | \n-----------------------------------------------------\n\n</code></pre>\n\n<p>ILLUSTRATE is useful because it generates sample data for your pig script immediately, without waiting on a hadoop batch job.  Debugging code while waiting minutes or hours on Hadoop jobs during test runs will tank productivity fast.  ILLUSTRATE&rsquo;s sample data &rsquo;<a href=\"http://infolab.stanford.edu/~olston/publications/sigmod09.pdf\">illustrates the semantics of the operators while keeping the example data small.</a>&rsquo;   This makes Pig very powerful.</p>\n\n<p>Lets try some Pig operations on our data, to see what I&rsquo;m talking about.  Suppose we want to look at messages per user, but only active users&hellip; say those that have posted more than one message:</p>\n\n<pre><code>\ngrunt&gt; user_groups = GROUP messages by user_id;\ngrunt&gt; per_user = FOREACH user_groups GENERATE group AS user_id, \n       SIZE($1) AS message_count;\ngrunt&gt; gt_one = FILTER per_user BY message_count &gt; 1;\ngrunt&gt; active_users = FOREACH gt_one GENERATE user_id;\n\ngrunt&gt; DESCRIBE active_users\nactive_users: {user_id: int}\n</code></pre>\n\nNow lets employ ILLUSTRATE to see what happened as records flowed through our simple data pipeline:\n\n<pre><code>grunt&gt; ILLUSTRATE active_users\n-----------------------------------------------------------------------------\n| messages     | message_id:int     | topic:chararray     | user_id:int     | \n-----------------------------------------------------------------------------\n|              | 24                 | Round the world...  | 2               | \n|              | 13                 | I like apples.      | 2               | \n-----------------------------------------------------------------------------\n--------------------------------------------------------------------------------------------------------------------------\n| user_groups     | group:int     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------\n|                 | 2             | {(24, Round the world..., 2), (13, I like apples., 2)}                               | \n--------------------------------------------------------------------------------------------------------------------------\n-----------------------------------------------------------\n| per_user     | user_id:int     | message_count:long     | \n-----------------------------------------------------------\n|              | 2               | 2                      | \n-----------------------------------------------------------\n---------------------------------------------------------\n| gt_one     | user_id:int     | message_count:long     | \n---------------------------------------------------------\n|            | 2               | 2                      | \n---------------------------------------------------------\n--------------------------------------\n| active_users     | user_id:int     | \n--------------------------------------\n|                  | 2               | \n--------------------------------------\n</code></pre>\n\n<p>Note how we can see the changes happening to the data as it flows through our pig script, without waiting on Hadoop to execute it.  Note also, that the answer ILLUSTRATE gives is not definitive, but is there to guide us as we write code: our DUMP has two records in <i>active_users</i>, not one.</p>\n\n<pre><code>grunt&gt; DUMP active_users\n(1)\n(2)\n</code></pre>\n\n<p>Now lets try creating something we&rsquo;d like to actually consume in a web app, via a key/value store.  Say we want to access all messages per user, sorted newest to oldest.  Lets create a suitable key and create these records:</p>\n\n<pre><code>grunt&gt; user_groups = GROUP messages by user_id;\nper_user = FOREACH user_groups {                \n    sorted = ORDER messages BY message_id DESC;     \n    GENERATE CONCAT('messages_per_user_id:', (chararray)group) AS user_key, sorted.$0 AS messages;\n}\ngrunt&gt; DESCRIBE per_user\nper_user: {user_key: chararray,messages: {(message_id: int)}}\n</code></pre>\n\n<p><b>Note: There was a six hour detour at this point to fix a bug in the AvroStorage UDF for persisting these kinds of records.  JIRA created and patch submitted here: <a href=\"https://issues.apache.org/jira/browse/PIG-2411\">https://issues.apache.org/jira/browse/PIG-2411</a></b>.  This kind of detour is common when you first setup an app, and you just have to bare the Java and fight through it.</p>\n\n<pre><code>grunt&gt; STORE per_user INTO '/tmp/per_user.avro' USING AvroStorage();\n</code></pre>\n\nIt works!\n\nNote how ILLUSTRATE has become more useful, as it displays the result of our casting the user_id from integer to chararray, and concatenating it with a record identifier to create a voldemort key that allows sharing the store with other record types:\n\n<pre><code>ILLUSTRATE per_user\n\n...\n\n--------------------------------------------------------------------------------------------------------------------------------\n| per_user     | user_key:chararray     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------------\n|              | messages_per_user_id:1 | {(12, Jim is silly!, 1), (11, Hello World, 1)}                                       | \n--------------------------------------------------------------------------------------------------------------------------------</code></pre>\n\n<p>This works for EvalFunc UDFs (User Defined Functions) too, which is really helpful.</p>\n\n<p>Our processed data is ready to go.  How do we publish it to a key/value store for consumption?</p>\n\n<p>With a few records, we care about ease of use.  As our data grows, we care about scaling.  <a href=\"http://project-voldemort.com/\">Project Voldemort</a> is distributed key/value storage system which is easy to use and which scales well too.  Voldemort <a href=\"http://sna-projects.com/blog/2009/06/voldemort-and-hadoop/\">supports building read-only stores on Hadoop and loading them directly</a> from the hadoop cluster to the voldemort cluster.</p>\n\n<p>Initially, we will write individual records to a Voldemort BDB store.  As our data grows, we can build and push entire read-only stores from hadoop to an operational cluster with a few commands.</p>\n\n<p>Download and unpack voldemort:</p><pre><code>cd\nwget --no-check-certificate <a href=\"https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz\">https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz</a>\ntar -xvzf voldemort-0.90.1.tar.gz\ncd voldemort-0.90.1\n</code></pre>\n\n<p>Follow the instructions <a href=\"http://project-voldemort.com/quickstart.php\">here</a> to start voldemort:</p>\n\n<pre><code>bin/voldemort-server.sh config/single_node_cluster &gt; /tmp/voldemort.log &amp;</code></pre>\n\n<p>Install the voldemort-rb gem.  Works with JRuby too:</p>\n\n<pre><code>gem install nokogiri\ngem install ruby_protobuf\ngem install voldemort-rb\n</code></pre>\n\n<p>Now in ruby we connect to our voldemort cluster, loop through our avro records and insert a new entry for each:</p> \n\n<pre><code>\nrequire 'rubygems'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nfile = File.open('/tmp/per_user.avro/part-r-00000.avro', 'r+')\ndr = Avro::DataFile::Reader.new(file, Avro::IO::DatumReader.new)\ndr.each do |record| \n  client.put record[\"user_key\"], JSON(record[\"messages\"])\nend\n</code></pre>\n\n<p>Finally&hellip; we want to see our data in the browser.  A one-page <a href=\"http://www.sinatrarb.com/intro\">Sinatra</a> web app gets us there.  Install Sinatra:</p>\n\n<pre><code>gem install sinatra\n</code></pre>\n\nOur sinatra app looks like:\n\n<pre><code>require 'rubygems'\nrequire 'sinatra'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\n# connect to voldemort\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nget '/messages_per_user_id/:user_id' do |user_id|\n  client.get \"messages_per_user_id:#{user_id}\"\nend\n</code></pre>\n\n<p>We can see our plumbed data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> or <a href=\"http://localhost:4567/messages_per_user_id/2\">http://localhost:4567/messages_per_user_id/2</a></p>\n\n<p>The data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> looks like this: \n\n</p><pre><code>[{\"message_id\":12},{\"message_id\":11}]</code></pre>\n\n<p>Note that we haven&rsquo;t touched Hadoop yet.  :)  It is simply not neccessary to do so, in order to get started using the tools.  We&rsquo;ve made platform choices that will let us aggregate and mine data at scale, and we&rsquo;ve gotten them up and running in a few minutes on our local machines. </p>\n\n<p>In future posts, we&rsquo;ll extend this to work at scale on Amazon Web Services and Heroku.</p>", "content_raw": "<p>Complete working code for this example is available at <a href=\"https://github.com/rjurney/Booting-the-Analytics-Application\">https://github.com/rjurney/Booting-the-Analytics-Application</a></p>\n\n<p>The first step to building analytics applications with Hadoop is to plumb your application from end to end: from collecting raw data to displaying something on the users\u2019 screen.  This is important, because models can get complex fast, and you need user feedback plugged into the equation from the start.</p>\n\n<p>Collecting data in Avro is convenient, because a simple JSON schema is included with each pile of records.  <a href=\"http://avro.apache.org/\">Apache Avro</a> is a data serialization system with rich formats, simple integration with dynamic languages and support in Apache Pig.</p>\n\n<p>Using Avro with Ruby and Pig is easy:</p>\n\n<p>Install the avro ruby gem.  Works in <a href=\"http://jruby.org/\">JRuby</a> too.</p>\n<pre><code>gem install avro</code></pre>\n\n<p>Get and build Pig 0.9.1 and then piggybank (takes a while)</p>\n<pre><code>cd\nwget <a href=\"http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz\">http://mirror.olnevhost.net/pub/apache//pig/pig-0.9.1/pig-0.9.1.tar.gz</a>\ntar -xvzf pig-0.9.1.tar.gz\ncd pig-0.9.1\nant\ncd contrib/piggybank/java\nant\ncd ../../..</code></pre>\n\n<p>Decide on a schema for your records and create some avro records in your application.</p>\n<pre><code>require 'rubygems'\nrequire 'avro'\n\n\nSCHEMA = &lt;&lt;-JSON\n{ \"type\": \"record\",\n  \"name\": \"Email\",\n  \"fields\" : [\n    {\"name\": \"message_id\", \"type\": \"int\"},\n    {\"name\": \"topic\", \"type\": \"string\"},\n    {\"name\": \"user_id\", \"type\": \"int\"}\n  ]}\nJSON\n\n\nfile = File.open('~/tmp/messages.avro', 'wb')\nschema = Avro::Schema.parse(SCHEMA)\nwriter = Avro::IO::DatumWriter.new(schema)\ndw = Avro::DataFile::Writer.new(file, writer, schema)\ndw &lt;&lt; {\"message_id\" =&gt; 11, \"topic\" =&gt; \"Hello World\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 12, \"topic\" =&gt; \"Jim is silly!\", \"user_id\" =&gt; 1}\ndw &lt;&lt; {\"message_id\" =&gt; 13, \"topic\" =&gt; \"I like apples.\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 24, \"topic\" =&gt; \"Round the world...\", \"user_id\" =&gt; 2}\ndw &lt;&lt; {\"message_id\" =&gt; 35, \"topic\" =&gt; \"How do I sent a message?\", \"user_id\" =&gt; 45}\ndw.close\n</code></pre> \n\n<p>To setup your environment, add these lines to .bash_profile:</p>\n<pre><code>pig_version=0.9.1\nexport CLASSPATH=$CLASSPATH:~/pig-${pig_version}/build/ivy/lib/Pig/avro-1.4.1.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/json-simple-1.1.jar\\\n:~/pig-${pig_version}/contrib/piggybank/java/piggybank.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\\\n:~/pig-${pig_version}/build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n</code></pre>\nAnd re-run it via:\n<pre><code>source ~/.bash_profile</code></pre>\n\n<p>This script via \u2018bin/pig -l /tmp -x local\u2019 will get you working with your records:</p>\n<pre><code>REGISTER ./build/ivy/lib/Pig/avro-1.4.1.jar\nREGISTER ./build/ivy/lib/Pig/json-simple-1.1.jar\nREGISTER  contrib/piggybank/java/piggybank.jar\nREGISTER ./build/ivy/lib/Pig/jackson-core-asl-1.6.0.jar\nREGISTER ./build/ivy/lib/Pig/jackson-mapper-asl-1.6.0.jar\n\n\nDEFINE AvroStorage org.apache.pig.piggybank.storage.avro.AvroStorage();\n\n\nmessages = LOAD '/tmp/messages.avro' USING AvroStorage();\n</code></pre>\n\n<p><a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DESCRIBE\">DESCRIBE</a> lists the schema of your data - if it is known.  When you\u2019re winging it, sometimes you might not have a schema.  Remember: 'Pigs eat anything,\u2019 so no schema required!  In practice, you\u2019ll usually want schemas for application development.</p>\n\n<pre><code>grunt&gt; DESCRIBE messages\n\navros: {message_id: int,topic: chararray}\n\n</code></pre>\n\n<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#DUMP\">DUMP</a> is simple, but be careful: 'big data\u2019 across your screen is not always useful, and you\u2019ll have to ctrl-c to stop it, which ends your grunt session.\n\n<pre><code>grunt&gt; DUMP messages\n(11,Hello World,1)\n(12,Jim is silly!,1)\n(13,I like apples.,2)\n(24,Round the world...,2)\n(35,How do I sent a message?,45)\n</code></pre>\n\nIn practice, you\u2019ll often want to <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#SAMPLE\">SAMPLE</a>/<a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#LIMIT\">LIMIT</a>/DUMP\n\n<pre><code>grunt&gt; A = SAMPLE messages 0.5;\ngrunt&gt; B = LIMIT messages 2;\ngrunt&gt; DUMP B\n(11,Hello World,1)\n(12,Jim is silly!,1)\n\n</code></pre>\n\n<p>Or better yet\u2026 <a href=\"http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#ILLUSTRATE\">ILLUSTRATE</a>!  <b>I &lt;3 ILLUSTRATE.</b></p>\n\n<pre><code>\ngrunt&gt; ILLUSTRATE messages\n-----------------------------------------------------\n| avros     | message_id:int   | topic:chararray    | \n-----------------------------------------------------\n|           | 12               | Jim is silly!     | \n-----------------------------------------------------\n\n</code></pre>\n\n<p>ILLUSTRATE is useful because it generates sample data for your pig script immediately, without waiting on a hadoop batch job.  Debugging code while waiting minutes or hours on Hadoop jobs during test runs will tank productivity fast.  ILLUSTRATE\u2019s sample data \u2019<a href=\"http://infolab.stanford.edu/~olston/publications/sigmod09.pdf\">illustrates the semantics of the operators while keeping the example data small.</a>\u2019   This makes Pig very powerful.</p>\n\n<p>Lets try some Pig operations on our data, to see what I\u2019m talking about.  Suppose we want to look at messages per user, but only active users\u2026 say those that have posted more than one message:</p>\n\n<pre><code>\ngrunt&gt; user_groups = GROUP messages by user_id;\ngrunt&gt; per_user = FOREACH user_groups GENERATE group AS user_id, \n       SIZE($1) AS message_count;\ngrunt&gt; gt_one = FILTER per_user BY message_count &gt; 1;\ngrunt&gt; active_users = FOREACH gt_one GENERATE user_id;\n\ngrunt&gt; DESCRIBE active_users\nactive_users: {user_id: int}\n</code></pre>\n\nNow lets employ ILLUSTRATE to see what happened as records flowed through our simple data pipeline:\n\n<pre><code>grunt&gt; ILLUSTRATE active_users\n-----------------------------------------------------------------------------\n| messages     | message_id:int     | topic:chararray     | user_id:int     | \n-----------------------------------------------------------------------------\n|              | 24                 | Round the world...  | 2               | \n|              | 13                 | I like apples.      | 2               | \n-----------------------------------------------------------------------------\n--------------------------------------------------------------------------------------------------------------------------\n| user_groups     | group:int     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------\n|                 | 2             | {(24, Round the world..., 2), (13, I like apples., 2)}                               | \n--------------------------------------------------------------------------------------------------------------------------\n-----------------------------------------------------------\n| per_user     | user_id:int     | message_count:long     | \n-----------------------------------------------------------\n|              | 2               | 2                      | \n-----------------------------------------------------------\n---------------------------------------------------------\n| gt_one     | user_id:int     | message_count:long     | \n---------------------------------------------------------\n|            | 2               | 2                      | \n---------------------------------------------------------\n--------------------------------------\n| active_users     | user_id:int     | \n--------------------------------------\n|                  | 2               | \n--------------------------------------\n</code></pre>\n\n<p>Note how we can see the changes happening to the data as it flows through our pig script, without waiting on Hadoop to execute it.  Note also, that the answer ILLUSTRATE gives is not definitive, but is there to guide us as we write code: our DUMP has two records in <i>active_users</i>, not one.</p>\n\n<pre><code>grunt&gt; DUMP active_users\n(1)\n(2)\n</code></pre>\n\n<p>Now lets try creating something we\u2019d like to actually consume in a web app, via a key/value store.  Say we want to access all messages per user, sorted newest to oldest.  Lets create a suitable key and create these records:</p>\n\n<pre><code>grunt&gt; user_groups = GROUP messages by user_id;\nper_user = FOREACH user_groups {                \n    sorted = ORDER messages BY message_id DESC;     \n    GENERATE CONCAT('messages_per_user_id:', (chararray)group) AS user_key, sorted.$0 AS messages;\n}\ngrunt&gt; DESCRIBE per_user\nper_user: {user_key: chararray,messages: {(message_id: int)}}\n</code></pre>\n\n<p><b>Note: There was a six hour detour at this point to fix a bug in the AvroStorage UDF for persisting these kinds of records.  JIRA created and patch submitted here: <a href=\"https://issues.apache.org/jira/browse/PIG-2411\">https://issues.apache.org/jira/browse/PIG-2411</a></b>.  This kind of detour is common when you first setup an app, and you just have to bare the Java and fight through it.</p>\n\n<pre><code>grunt&gt; STORE per_user INTO '/tmp/per_user.avro' USING AvroStorage();\n</code></pre>\n\nIt works!\n\nNote how ILLUSTRATE has become more useful, as it displays the result of our casting the user_id from integer to chararray, and concatenating it with a record identifier to create a voldemort key that allows sharing the store with other record types:\n\n<pre><code>ILLUSTRATE per_user\n\n...\n\n--------------------------------------------------------------------------------------------------------------------------------\n| per_user     | user_key:chararray     | messages:bag{:tuple(message_id:int,topic:chararray,user_id:int)}                     | \n--------------------------------------------------------------------------------------------------------------------------------\n|              | messages_per_user_id:1 | {(12, Jim is silly!, 1), (11, Hello World, 1)}                                       | \n--------------------------------------------------------------------------------------------------------------------------------</code></pre>\n\n<p>This works for EvalFunc UDFs (User Defined Functions) too, which is really helpful.</p>\n\n<p>Our processed data is ready to go.  How do we publish it to a key/value store for consumption?</p>\n\n<p>With a few records, we care about ease of use.  As our data grows, we care about scaling.  <a href=\"http://project-voldemort.com/\">Project Voldemort</a> is distributed key/value storage system which is easy to use and which scales well too.  Voldemort <a href=\"http://sna-projects.com/blog/2009/06/voldemort-and-hadoop/\">supports building read-only stores on Hadoop and loading them directly</a> from the hadoop cluster to the voldemort cluster.</p>\n\n<p>Initially, we will write individual records to a Voldemort BDB store.  As our data grows, we can build and push entire read-only stores from hadoop to an operational cluster with a few commands.</p>\n\n<p>Download and unpack voldemort:</p><pre><code>cd\nwget --no-check-certificate <a href=\"https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz\">https://github.com/downloads/voldemort/voldemort/voldemort-0.90.1.tar.gz</a>\ntar -xvzf voldemort-0.90.1.tar.gz\ncd voldemort-0.90.1\n</code></pre>\n\n<p>Follow the instructions <a href=\"http://project-voldemort.com/quickstart.php\">here</a> to start voldemort:</p>\n\n<pre><code>bin/voldemort-server.sh config/single_node_cluster &gt; /tmp/voldemort.log &amp;</code></pre>\n\n<p>Install the voldemort-rb gem.  Works with JRuby too:</p>\n\n<pre><code>gem install nokogiri\ngem install ruby_protobuf\ngem install voldemort-rb\n</code></pre>\n\n<p>Now in ruby we connect to our voldemort cluster, loop through our avro records and insert a new entry for each:</p> \n\n<pre><code>\nrequire 'rubygems'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nfile = File.open('/tmp/per_user.avro/part-r-00000.avro', 'r+')\ndr = Avro::DataFile::Reader.new(file, Avro::IO::DatumReader.new)\ndr.each do |record| \n  client.put record[\"user_key\"], JSON(record[\"messages\"])\nend\n</code></pre>\n\n<p>Finally\u2026 we want to see our data in the browser.  A one-page <a href=\"http://www.sinatrarb.com/intro\">Sinatra</a> web app gets us there.  Install Sinatra:</p>\n\n<pre><code>gem install sinatra\n</code></pre>\n\nOur sinatra app looks like:\n\n<pre><code>require 'rubygems'\nrequire 'sinatra'\nrequire 'avro'\nrequire 'voldemort-rb'\nrequire 'json'\n\n# connect to voldemort\nclient = VoldemortClient.new(\"test\", \"localhost:6666\")\n\nget '/messages_per_user_id/:user_id' do |user_id|\n  client.get \"messages_per_user_id:#{user_id}\"\nend\n</code></pre>\n\n<p>We can see our plumbed data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> or <a href=\"http://localhost:4567/messages_per_user_id/2\">http://localhost:4567/messages_per_user_id/2</a></p>\n\n<p>The data at <a href=\"http://localhost:4567/messages_per_user_id/1\">http://localhost:4567/messages_per_user_id/1</a> looks like this: \n\n</p><pre><code>[{\"message_id\":12},{\"message_id\":11}]</code></pre>\n\n<p>Note that we haven\u2019t touched Hadoop yet.  :)  It is simply not neccessary to do so, in order to get started using the tools.  We\u2019ve made platform choices that will let us aggregate and mine data at scale, and we\u2019ve gotten them up and running in a few minutes on our local machines. </p>\n\n<p>In future posts, we\u2019ll extend this to work at scale on Amazon Web Services and Heroku.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "13707537045"}}], "date": "2011-12-04 02:22:00 GMT", "slug": "booting-the-analytics-application-events-ruby", "blog_name": "rjurney", "summary": "Booting the Analytics Application: Events -> Ruby -> Avro -> Pig -> Voldemort -> Sinatra -> Web Browser -> User", "can_reblog": true}, {"body": "<p>Rows of cubicles like cells of a hive.  Overbooked conference rooms camped and decamped.  Microsoft Outlook a modern punchcard.  <a href=\"http://money.cnn.com/2006/03/09/magazines/fortune/cubicle_howiwork_fortune/\">Monolithic insanity</a>.  A sea of cubes.</p>\n\n<p>Deadlines interrupted by oscillating cacophonies of rumors shouted, spread like waves uninterrupted by naked desks.  Headphone budgets.  Not working, close together.  Decibal induced telecommuting.  The open plan.</p>\n\n<p>Competing monstrosities seeking productivity.</p>\n\n<blockquote>\n  <p>Before very long, people get very confused that the process is the content. That&rsquo;s ultimately the downfall of IBM. IBM has the best process people in the world. They just forgot about the content.\n  &ndash; <a href=\"http://www.cbsnews.com/8301-505124_162-57321289/5-lessons-from-steve-jobs-lost-interview/\">Steve Jobs</a></p>\n</blockquote>\n\n<p>We can do better.  We should do better.  It costs more, but it is inexpensive.</p>\n\n<blockquote>\n  <p>Many enterprises limit their productivity enhancement of employees to the acquisition of skills.  However, about 86% of productivity problems reside in the work environment of organizations. The work environment has effect on the performance of employees. The type of work environment in which employees operate determines the way in which such enterprises prosper. \n  &ndash; <a href=\"http://www.academicjournals.org/Ajbm/PDF/pdf2010/Mar/Taiwo.pdf\">Akinyele Samuel Taiwo</a></p>\n  \n  <p>It is much higher cost to employ people then it is to maintain and operate a building, hence spending money on improving the work environment is the most cost effective way of improving productivity because of small percentage increase in productivity of 0.1% to 2% can have dramatic effects on the profitability of the company.\n  &ndash; <a href=\"http://www.senseair.se/Articles/A8_104.pdf\">Derek Clements-Croome and Li Baizhan</a></p>\n</blockquote>\n\n<h2>The Sane Workspace</h2>\n\n<p>Creative workers need three kinds of spaces to collaborate and build together.  From open to closed, they are: <b>collaboration space</b>, <b>personal space</b> and <b>private space</b>.</p>\n\n<h3><b>Collaboration Space</b></h3>\n\n<p>Collaboration space is where ideas are hatched.</p>\n\n<p>Situated along main thoroughfares and between departments, collaborative spaces are bright, open, comfortable and inviting.  They have no walls.  They are flexible and reconfigurable.  They are ever changing, always rearranged.  Bean bags, pillows and comfortable chairs.</p>\n\n<p>Collaboration space is where you feel the energy of your company: laughter, big conversations, excited voices talking over one another.  Invest in and showcase these areas.</p>\n\n<p>Real, not plastic, plants keep sound from carrying and they make air :)</p>\n\n<h3><b>Private Space</b></h3>\n\n<p>Private space is where deadlines get met.</p>\n\n<p>Enclosed and <a href=\"http://www.foambymail.com/acoustical-pyramid-foam.html\">soundproof</a>, private spaces are libraries.  There is no talking.  Private space minimizes distractions.  Dim light, white noise.</p>\n\n<p>There are bean bags, couches and chairs, but ergonomics demand proper workstations too.  Separated sit/stand desks with docking stations behind (bead) curtains with 30&quot; LCDs.</p>\n\n<h3><b>Personal Space</b></h3>\n\n<p>Personal space is where people call home.</p>\n\n<p>In between collaboration and private space in its degree of openness, personal space should be personalized by each individual to suit his or her needs.  Shared office or open desks, half or whole cube.  Personal space should come with a menu and a budget.  Themes and plant-life should be encouraged.</p>\n\n<p>For some people, this is where you spend most of your time.  For others&hellip; given adequate collaborative and private space, a notebook and mobile device, some people don&rsquo;t need personal space at all.</p>", "liked": false, "followed": false, "reblog_key": "bpwXBxCS", "reblog": {"comment": "<p>Rows of cubicles like cells of a hive.  Overbooked conference rooms camped and decamped.  Microsoft Outlook a modern punchcard.  <a href=\"http://money.cnn.com/2006/03/09/magazines/fortune/cubicle_howiwork_fortune/\">Monolithic insanity</a>.  A sea of cubes.</p>\n\n<p>Deadlines interrupted by oscillating cacophonies of rumors shouted, spread like waves uninterrupted by naked desks.  Headphone budgets.  Not working, close together.  Decibal induced telecommuting.  The open plan.</p>\n\n<p>Competing monstrosities seeking productivity.</p>\n\n<blockquote>\n  <p>Before very long, people get very confused that the process is the content. That\u2019s ultimately the downfall of IBM. IBM has the best process people in the world. They just forgot about the content.\n  \u2013 <a href=\"http://www.cbsnews.com/8301-505124_162-57321289/5-lessons-from-steve-jobs-lost-interview/\">Steve Jobs</a></p>\n</blockquote>\n\n<p>We can do better.  We should do better.  It costs more, but it is inexpensive.</p>\n\n<blockquote>\n  <p>Many enterprises limit their productivity enhancement of employees to the acquisition of skills.  However, about 86% of productivity problems reside in the work environment of organizations. The work environment has effect on the performance of employees. The type of work environment in which employees operate determines the way in which such enterprises prosper. \n  \u2013 <a href=\"http://www.academicjournals.org/Ajbm/PDF/pdf2010/Mar/Taiwo.pdf\">Akinyele Samuel Taiwo</a></p>\n  \n  <p>It is much higher cost to employ people then it is to maintain and operate a building, hence spending money on improving the work environment is the most cost effective way of improving productivity because of small percentage increase in productivity of 0.1% to 2% can have dramatic effects on the profitability of the company.\n  \u2013 <a href=\"http://www.senseair.se/Articles/A8_104.pdf\">Derek Clements-Croome and Li Baizhan</a></p>\n</blockquote>\n\n<h2>The Sane Workspace</h2>\n\n<p>Creative workers need three kinds of spaces to collaborate and build together.  From open to closed, they are: <b>collaboration space</b>, <b>personal space</b> and <b>private space</b>.</p>\n\n<h3><b>Collaboration Space</b></h3>\n\n<p>Collaboration space is where ideas are hatched.</p>\n\n<p>Situated along main thoroughfares and between departments, collaborative spaces are bright, open, comfortable and inviting.  They have no walls.  They are flexible and reconfigurable.  They are ever changing, always rearranged.  Bean bags, pillows and comfortable chairs.</p>\n\n<p>Collaboration space is where you feel the energy of your company: laughter, big conversations, excited voices talking over one another.  Invest in and showcase these areas.</p>\n\n<p>Real, not plastic, plants keep sound from carrying and they make air :)</p>\n\n<h3><b>Private Space</b></h3>\n\n<p>Private space is where deadlines get met.</p>\n\n<p>Enclosed and <a href=\"http://www.foambymail.com/acoustical-pyramid-foam.html\">soundproof</a>, private spaces are libraries.  There is no talking.  Private space minimizes distractions.  Dim light, white noise.</p>\n\n<p>There are bean bags, couches and chairs, but ergonomics demand proper workstations too.  Separated sit/stand desks with docking stations behind (bead) curtains with 30\" LCDs.</p>\n\n<h3><b>Personal Space</b></h3>\n\n<p>Personal space is where people call home.</p>\n\n<p>In between collaboration and private space in its degree of openness, personal space should be personalized by each individual to suit his or her needs.  Shared office or open desks, half or whole cube.  Personal space should come with a menu and a budget.  Themes and plant-life should be encouraged.</p>\n\n<p>For some people, this is where you spend most of your time.  For others\u2026 given adequate collaborative and private space, a notebook and mobile device, some people don\u2019t need personal space at all.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 13576301996, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Engineering Productivity", "tags": [], "post_url": "http://datasyndrome.com/post/13576301996/engineering-productivity", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yCfDUsi", "type": "text", "recommended_color": null, "format": "markdown", "timestamp": 1322711640, "note_count": 4, "trail": [{"content": "<p>Rows of cubicles like cells of a hive.  Overbooked conference rooms camped and decamped.  Microsoft Outlook a modern punchcard.  <a href=\"http://money.cnn.com/2006/03/09/magazines/fortune/cubicle_howiwork_fortune/\">Monolithic insanity</a>.  A sea of cubes.</p>\n\n<p>Deadlines interrupted by oscillating cacophonies of rumors shouted, spread like waves uninterrupted by naked desks.  Headphone budgets.  Not working, close together.  Decibal induced telecommuting.  The open plan.</p>\n\n<p>Competing monstrosities seeking productivity.</p>\n\n<blockquote>\n  <p>Before very long, people get very confused that the process is the content. That&rsquo;s ultimately the downfall of IBM. IBM has the best process people in the world. They just forgot about the content.\n  &ndash; <a href=\"http://www.cbsnews.com/8301-505124_162-57321289/5-lessons-from-steve-jobs-lost-interview/\">Steve Jobs</a></p>\n</blockquote>\n\n<p>We can do better.  We should do better.  It costs more, but it is inexpensive.</p>\n\n<blockquote>\n  <p>Many enterprises limit their productivity enhancement of employees to the acquisition of skills.  However, about 86% of productivity problems reside in the work environment of organizations. The work environment has effect on the performance of employees. The type of work environment in which employees operate determines the way in which such enterprises prosper. \n  &ndash; <a href=\"http://www.academicjournals.org/Ajbm/PDF/pdf2010/Mar/Taiwo.pdf\">Akinyele Samuel Taiwo</a></p>\n  \n  <p>It is much higher cost to employ people then it is to maintain and operate a building, hence spending money on improving the work environment is the most cost effective way of improving productivity because of small percentage increase in productivity of 0.1% to 2% can have dramatic effects on the profitability of the company.\n  &ndash; <a href=\"http://www.senseair.se/Articles/A8_104.pdf\">Derek Clements-Croome and Li Baizhan</a></p>\n</blockquote>\n\n<h2>The Sane Workspace</h2>\n\n<p>Creative workers need three kinds of spaces to collaborate and build together.  From open to closed, they are: <b>collaboration space</b>, <b>personal space</b> and <b>private space</b>.</p>\n\n<h3><b>Collaboration Space</b></h3>\n\n<p>Collaboration space is where ideas are hatched.</p>\n\n<p>Situated along main thoroughfares and between departments, collaborative spaces are bright, open, comfortable and inviting.  They have no walls.  They are flexible and reconfigurable.  They are ever changing, always rearranged.  Bean bags, pillows and comfortable chairs.</p>\n\n<p>Collaboration space is where you feel the energy of your company: laughter, big conversations, excited voices talking over one another.  Invest in and showcase these areas.</p>\n\n<p>Real, not plastic, plants keep sound from carrying and they make air :)</p>\n\n<h3><b>Private Space</b></h3>\n\n<p>Private space is where deadlines get met.</p>\n\n<p>Enclosed and <a href=\"http://www.foambymail.com/acoustical-pyramid-foam.html\">soundproof</a>, private spaces are libraries.  There is no talking.  Private space minimizes distractions.  Dim light, white noise.</p>\n\n<p>There are bean bags, couches and chairs, but ergonomics demand proper workstations too.  Separated sit/stand desks with docking stations behind (bead) curtains with 30\" LCDs.</p>\n\n<h3><b>Personal Space</b></h3>\n\n<p>Personal space is where people call home.</p>\n\n<p>In between collaboration and private space in its degree of openness, personal space should be personalized by each individual to suit his or her needs.  Shared office or open desks, half or whole cube.  Personal space should come with a menu and a budget.  Themes and plant-life should be encouraged.</p>\n\n<p>For some people, this is where you spend most of your time.  For others&hellip; given adequate collaborative and private space, a notebook and mobile device, some people don&rsquo;t need personal space at all.</p>", "content_raw": "<p>Rows of cubicles like cells of a hive.  Overbooked conference rooms camped and decamped.  Microsoft Outlook a modern punchcard.  <a href=\"http://money.cnn.com/2006/03/09/magazines/fortune/cubicle_howiwork_fortune/\">Monolithic insanity</a>.  A sea of cubes.</p>\n\n<p>Deadlines interrupted by oscillating cacophonies of rumors shouted, spread like waves uninterrupted by naked desks.  Headphone budgets.  Not working, close together.  Decibal induced telecommuting.  The open plan.</p>\n\n<p>Competing monstrosities seeking productivity.</p>\n\n<blockquote>\n  <p>Before very long, people get very confused that the process is the content. That\u2019s ultimately the downfall of IBM. IBM has the best process people in the world. They just forgot about the content.\n  \u2013 <a href=\"http://www.cbsnews.com/8301-505124_162-57321289/5-lessons-from-steve-jobs-lost-interview/\">Steve Jobs</a></p>\n</blockquote>\n\n<p>We can do better.  We should do better.  It costs more, but it is inexpensive.</p>\n\n<blockquote>\n  <p>Many enterprises limit their productivity enhancement of employees to the acquisition of skills.  However, about 86% of productivity problems reside in the work environment of organizations. The work environment has effect on the performance of employees. The type of work environment in which employees operate determines the way in which such enterprises prosper. \n  \u2013 <a href=\"http://www.academicjournals.org/Ajbm/PDF/pdf2010/Mar/Taiwo.pdf\">Akinyele Samuel Taiwo</a></p>\n  \n  <p>It is much higher cost to employ people then it is to maintain and operate a building, hence spending money on improving the work environment is the most cost effective way of improving productivity because of small percentage increase in productivity of 0.1% to 2% can have dramatic effects on the profitability of the company.\n  \u2013 <a href=\"http://www.senseair.se/Articles/A8_104.pdf\">Derek Clements-Croome and Li Baizhan</a></p>\n</blockquote>\n\n<h2>The Sane Workspace</h2>\n\n<p>Creative workers need three kinds of spaces to collaborate and build together.  From open to closed, they are: <b>collaboration space</b>, <b>personal space</b> and <b>private space</b>.</p>\n\n<h3><b>Collaboration Space</b></h3>\n\n<p>Collaboration space is where ideas are hatched.</p>\n\n<p>Situated along main thoroughfares and between departments, collaborative spaces are bright, open, comfortable and inviting.  They have no walls.  They are flexible and reconfigurable.  They are ever changing, always rearranged.  Bean bags, pillows and comfortable chairs.</p>\n\n<p>Collaboration space is where you feel the energy of your company: laughter, big conversations, excited voices talking over one another.  Invest in and showcase these areas.</p>\n\n<p>Real, not plastic, plants keep sound from carrying and they make air :)</p>\n\n<h3><b>Private Space</b></h3>\n\n<p>Private space is where deadlines get met.</p>\n\n<p>Enclosed and <a href=\"http://www.foambymail.com/acoustical-pyramid-foam.html\">soundproof</a>, private spaces are libraries.  There is no talking.  Private space minimizes distractions.  Dim light, white noise.</p>\n\n<p>There are bean bags, couches and chairs, but ergonomics demand proper workstations too.  Separated sit/stand desks with docking stations behind (bead) curtains with 30\" LCDs.</p>\n\n<h3><b>Personal Space</b></h3>\n\n<p>Personal space is where people call home.</p>\n\n<p>In between collaboration and private space in its degree of openness, personal space should be personalized by each individual to suit his or her needs.  Shared office or open desks, half or whole cube.  Personal space should come with a menu and a budget.  Themes and plant-life should be encouraged.</p>\n\n<p>For some people, this is where you spend most of your time.  For others\u2026 given adequate collaborative and private space, a notebook and mobile device, some people don\u2019t need personal space at all.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "13576301996"}}], "date": "2011-12-01 03:54:00 GMT", "slug": "engineering-productivity", "blog_name": "rjurney", "summary": "Engineering Productivity", "can_reblog": true}, {"body": "<p><em>Note: the term Agile Data was probably coined by <a href=\"https://twitter.com/#!/peteskomoroch\">Pete Skomoroch</a>.  I remember saying it a month before him, but jumble ups happen and its probably his, GREAT word and summarizes my entire worldview.</em></p>\n\n<p>There two ways of recruiting for data teams.</p>\n\n<p>Candidates can come from: broad search via job listings on home page/job boards, targeted search through community participation (attending user groups and events - in person, on line), targeted ads, and internal/external referrals - with or without bounties.</p>\n\n<ul><li>Method 1. (Classic) Hire by search and evaluation.  Evaluate basic competence to minimum requirements through method of choice (whiteboard hell, take-home exercises, arbitrary chats and first-impressions), and then evaluation of specific areas and  &lsquo;cultural fit&rsquo;.  Meet as a group, and hire the guy or don&rsquo;t.<br/><br/>Assign him to his team, and start putting folders on his desk according to tasks already setup on the project.<br/><br/></li>\n\n<li>Method 2. (Agile Data) Only hire open-source committers.  Then, make it the job of each employee, team member, manager and recruiter to actively engage with and give back to the open-source communities whose tools you are using.  Don&rsquo;t just sell to these groups - sponsor events, pay for pizza, get speakers, push patches and liase with leaders.  Learn the needs of the group, and the passions and interests of possible candidates, and how they might intersect your project.  This requires technical expertise, so teams and recruiters must keep in touch about what is needed and what is relevant for new candidates - beyond a skills list in the requisition.<br/><br/>\nIt may seem like like 'pounding the pavement&rsquo; to recruit doesn&rsquo;t scale - but it does.  People that show up to events are rich in 10x engineers.<br/><br/>\nWrite your requisition as a success story, along with the traditional format (for SEO).  Do not say 'ninja&rsquo; or 'rockstar.&rsquo;<br/><br/><b>Hiring engineers that get to scratch a series of itches he/she already has, in your project, is how you get 10x and 100x engineers.</b>  Guys that work too much.  Regardless of qualifications.  The right guy with the right basic skills and itches to scratch will beat the crap of a traditionally trained expert in any area more often than not.  And they&rsquo;re hungrier, too.  As a team lead, you are looking for an overlap in itches that get your vision built.  &ldquo;I am really into X, and I&rsquo;d like to work with a front-end guy into Y.&rdquo;\n</li> \n</ul><p><em><strong><em>Consequences</em></strong></em></p>\n\n<p><i>Agile development ain&rsquo;t optional.</i>  You don&rsquo;t get to decide your precise product form from the top level, because you will need to alter your working specification or prototype (the best spec!) such that it scratches enough of the itches of the best candidates in your pool such that they are motivated.  The candidate with the most <i>edge</i> and the most overlapping itch that combines with other team members.</p>\n\n<p>Using this method, you may hire more junior developers than you had planned.  Foster a culture where more senior developers help more junior ones, who aren&rsquo;t afraid of being fired while they get up to speed.</p>\n\n<p><img src=\"http://farm7.static.flickr.com/6211/6216012290_756931063f.jpg\"/></p>\n\n<p><em><strong><em>Motivation</em></strong></em></p>\n\n<p><b>Bored developers are the most dangerous thing an organization can have.</b>  They will increase the complexity of a project such that it scratches their itches, sliding it by product managers and the rest of the team as essential, regardless of the actual project fit for any technology/technique.  They will increase technical debt.  This isn&rsquo;t always intentional, and it is often not planned.  It just happens.  The bored mind will engage itself with inside or outside interests.  <i>If you recruit, hire and compose teams accordingly, and you&rsquo;ll have 10x teams kicking ass, instead of teams that seem to slow down after a few months as boredom sets in.</i></p>", "liked": false, "followed": false, "reblog_key": "V750f6PS", "reblog": {"comment": "<p><em>Note: the term Agile Data was probably coined by <a href=\"https://twitter.com/#!/peteskomoroch\">Pete Skomoroch</a>.  I remember saying it a month before him, but jumble ups happen and its probably his, GREAT word and summarizes my entire worldview.</em></p>\n\n<p>There two ways of recruiting for data teams.</p>\n\n<p>Candidates can come from: broad search via job listings on home page/job boards, targeted search through community participation (attending user groups and events - in person, on line), targeted ads, and internal/external referrals - with or without bounties.</p>\n\n<ul><li>Method 1. (Classic) Hire by search and evaluation.  Evaluate basic competence to minimum requirements through method of choice (whiteboard hell, take-home exercises, arbitrary chats and first-impressions), and then evaluation of specific areas and  \u2018cultural fit\u2019.  Meet as a group, and hire the guy or don\u2019t.<br><br>Assign him to his team, and start putting folders on his desk according to tasks already setup on the project.<br><br></li>\n\n<li>Method 2. (Agile Data) Only hire open-source committers.  Then, make it the job of each employee, team member, manager and recruiter to actively engage with and give back to the open-source communities whose tools you are using.  Don\u2019t just sell to these groups - sponsor events, pay for pizza, get speakers, push patches and liase with leaders.  Learn the needs of the group, and the passions and interests of possible candidates, and how they might intersect your project.  This requires technical expertise, so teams and recruiters must keep in touch about what is needed and what is relevant for new candidates - beyond a skills list in the requisition.<br><br>\nIt may seem like like 'pounding the pavement\u2019 to recruit doesn\u2019t scale - but it does.  People that show up to events are rich in 10x engineers.<br><br>\nWrite your requisition as a success story, along with the traditional format (for SEO).  Do not say 'ninja\u2019 or 'rockstar.\u2019<br><br><b>Hiring engineers that get to scratch a series of itches he/she already has, in your project, is how you get 10x and 100x engineers.</b>  Guys that work too much.  Regardless of qualifications.  The right guy with the right basic skills and itches to scratch will beat the crap of a traditionally trained expert in any area more often than not.  And they\u2019re hungrier, too.  As a team lead, you are looking for an overlap in itches that get your vision built.  \u201cI am really into X, and I\u2019d like to work with a front-end guy into Y.\u201d\n</li> \n</ul><p><em><strong><em>Consequences</em></strong></em></p>\n\n<p><i>Agile development ain\u2019t optional.</i>  You don\u2019t get to decide your precise product form from the top level, because you will need to alter your working specification or prototype (the best spec!) such that it scratches enough of the itches of the best candidates in your pool such that they are motivated.  The candidate with the most <i>edge</i> and the most overlapping itch that combines with other team members.</p>\n\n<p>Using this method, you may hire more junior developers than you had planned.  Foster a culture where more senior developers help more junior ones, who aren\u2019t afraid of being fired while they get up to speed.</p>\n\n<p><img src=\"http://farm7.static.flickr.com/6211/6216012290_756931063f.jpg\"></p>\n\n<p><em><strong><em>Motivation</em></strong></em></p>\n\n<p><b>Bored developers are the most dangerous thing an organization can have.</b>  They will increase the complexity of a project such that it scratches their itches, sliding it by product managers and the rest of the team as essential, regardless of the actual project fit for any technology/technique.  They will increase technical debt.  This isn\u2019t always intentional, and it is often not planned.  It just happens.  The bored mind will engage itself with inside or outside interests.  <i>If you recruit, hire and compose teams accordingly, and you\u2019ll have 10x teams kicking ass, instead of teams that seem to slow down after a few months as boredom sets in.</i></p>", "tree_html": ""}, "can_send_in_message": true, "id": 11080711748, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Agile Data Recruiting: By Passion, Composition", "tags": [], "post_url": "http://datasyndrome.com/post/11080711748/agile-data-recruiting-by-passion-composition", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yAKTZv4", "type": "text", "recommended_color": null, "format": "markdown", "timestamp": 1317860820, "note_count": 2, "trail": [{"content": "<p><em>Note: the term Agile Data was probably coined by <a href=\"https://twitter.com/#!/peteskomoroch\">Pete Skomoroch</a>.  I remember saying it a month before him, but jumble ups happen and its probably his, GREAT word and summarizes my entire worldview.</em></p>\n\n<p>There two ways of recruiting for data teams.</p>\n\n<p>Candidates can come from: broad search via job listings on home page/job boards, targeted search through community participation (attending user groups and events - in person, on line), targeted ads, and internal/external referrals - with or without bounties.</p>\n\n<ul><li>Method 1. (Classic) Hire by search and evaluation.  Evaluate basic competence to minimum requirements through method of choice (whiteboard hell, take-home exercises, arbitrary chats and first-impressions), and then evaluation of specific areas and  &lsquo;cultural fit&rsquo;.  Meet as a group, and hire the guy or don&rsquo;t.<br /><br />Assign him to his team, and start putting folders on his desk according to tasks already setup on the project.<br /><br /></li>\n\n<li>Method 2. (Agile Data) Only hire open-source committers.  Then, make it the job of each employee, team member, manager and recruiter to actively engage with and give back to the open-source communities whose tools you are using.  Don&rsquo;t just sell to these groups - sponsor events, pay for pizza, get speakers, push patches and liase with leaders.  Learn the needs of the group, and the passions and interests of possible candidates, and how they might intersect your project.  This requires technical expertise, so teams and recruiters must keep in touch about what is needed and what is relevant for new candidates - beyond a skills list in the requisition.<br /><br />\nIt may seem like like 'pounding the pavement&rsquo; to recruit doesn&rsquo;t scale - but it does.  People that show up to events are rich in 10x engineers.<br /><br />\nWrite your requisition as a success story, along with the traditional format (for SEO).  Do not say 'ninja&rsquo; or 'rockstar.&rsquo;<br /><br /><b>Hiring engineers that get to scratch a series of itches he/she already has, in your project, is how you get 10x and 100x engineers.</b>  Guys that work too much.  Regardless of qualifications.  The right guy with the right basic skills and itches to scratch will beat the crap of a traditionally trained expert in any area more often than not.  And they&rsquo;re hungrier, too.  As a team lead, you are looking for an overlap in itches that get your vision built.  &ldquo;I am really into X, and I&rsquo;d like to work with a front-end guy into Y.&rdquo;\n</li> \n</ul><p><em><strong><em>Consequences</em></strong></em></p>\n\n<p><i>Agile development ain&rsquo;t optional.</i>  You don&rsquo;t get to decide your precise product form from the top level, because you will need to alter your working specification or prototype (the best spec!) such that it scratches enough of the itches of the best candidates in your pool such that they are motivated.  The candidate with the most <i>edge</i> and the most overlapping itch that combines with other team members.</p>\n\n<p>Using this method, you may hire more junior developers than you had planned.  Foster a culture where more senior developers help more junior ones, who aren&rsquo;t afraid of being fired while they get up to speed.</p>\n\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6211/6216012290_756931063f.jpg\">External image</div></p>\n\n<p><em><strong><em>Motivation</em></strong></em></p>\n\n<p><b>Bored developers are the most dangerous thing an organization can have.</b>  They will increase the complexity of a project such that it scratches their itches, sliding it by product managers and the rest of the team as essential, regardless of the actual project fit for any technology/technique.  They will increase technical debt.  This isn&rsquo;t always intentional, and it is often not planned.  It just happens.  The bored mind will engage itself with inside or outside interests.  <i>If you recruit, hire and compose teams accordingly, and you&rsquo;ll have 10x teams kicking ass, instead of teams that seem to slow down after a few months as boredom sets in.</i></p>", "content_raw": "<p><em>Note: the term Agile Data was probably coined by <a href=\"https://twitter.com/#!/peteskomoroch\">Pete Skomoroch</a>.  I remember saying it a month before him, but jumble ups happen and its probably his, GREAT word and summarizes my entire worldview.</em></p>\n\n<p>There two ways of recruiting for data teams.</p>\n\n<p>Candidates can come from: broad search via job listings on home page/job boards, targeted search through community participation (attending user groups and events - in person, on line), targeted ads, and internal/external referrals - with or without bounties.</p>\n\n<ul><li>Method 1. (Classic) Hire by search and evaluation.  Evaluate basic competence to minimum requirements through method of choice (whiteboard hell, take-home exercises, arbitrary chats and first-impressions), and then evaluation of specific areas and  \u2018cultural fit\u2019.  Meet as a group, and hire the guy or don\u2019t.<br><br>Assign him to his team, and start putting folders on his desk according to tasks already setup on the project.<br><br></li>\n\n<li>Method 2. (Agile Data) Only hire open-source committers.  Then, make it the job of each employee, team member, manager and recruiter to actively engage with and give back to the open-source communities whose tools you are using.  Don\u2019t just sell to these groups - sponsor events, pay for pizza, get speakers, push patches and liase with leaders.  Learn the needs of the group, and the passions and interests of possible candidates, and how they might intersect your project.  This requires technical expertise, so teams and recruiters must keep in touch about what is needed and what is relevant for new candidates - beyond a skills list in the requisition.<br><br>\nIt may seem like like 'pounding the pavement\u2019 to recruit doesn\u2019t scale - but it does.  People that show up to events are rich in 10x engineers.<br><br>\nWrite your requisition as a success story, along with the traditional format (for SEO).  Do not say 'ninja\u2019 or 'rockstar.\u2019<br><br><b>Hiring engineers that get to scratch a series of itches he/she already has, in your project, is how you get 10x and 100x engineers.</b>  Guys that work too much.  Regardless of qualifications.  The right guy with the right basic skills and itches to scratch will beat the crap of a traditionally trained expert in any area more often than not.  And they\u2019re hungrier, too.  As a team lead, you are looking for an overlap in itches that get your vision built.  \u201cI am really into X, and I\u2019d like to work with a front-end guy into Y.\u201d\n</li> \n</ul><p><em><strong><em>Consequences</em></strong></em></p>\n\n<p><i>Agile development ain\u2019t optional.</i>  You don\u2019t get to decide your precise product form from the top level, because you will need to alter your working specification or prototype (the best spec!) such that it scratches enough of the itches of the best candidates in your pool such that they are motivated.  The candidate with the most <i>edge</i> and the most overlapping itch that combines with other team members.</p>\n\n<p>Using this method, you may hire more junior developers than you had planned.  Foster a culture where more senior developers help more junior ones, who aren\u2019t afraid of being fired while they get up to speed.</p>\n\n<p><img src=\"http://farm7.static.flickr.com/6211/6216012290_756931063f.jpg\"></p>\n\n<p><em><strong><em>Motivation</em></strong></em></p>\n\n<p><b>Bored developers are the most dangerous thing an organization can have.</b>  They will increase the complexity of a project such that it scratches their itches, sliding it by product managers and the rest of the team as essential, regardless of the actual project fit for any technology/technique.  They will increase technical debt.  This isn\u2019t always intentional, and it is often not planned.  It just happens.  The bored mind will engage itself with inside or outside interests.  <i>If you recruit, hire and compose teams accordingly, and you\u2019ll have 10x teams kicking ass, instead of teams that seem to slow down after a few months as boredom sets in.</i></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "11080711748"}}], "date": "2011-10-06 00:27:00 GMT", "slug": "agile-data-recruiting-by-passion-composition", "blog_name": "rjurney", "summary": "Agile Data Recruiting: By Passion, Composition", "can_reblog": true}, {"body": "<p>Hadoop is maturing, with <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> and <img src=\"http://farm7.static.flickr.com/6159/6205546214_875f6c02f4_m.jpg\" align=\"right\"/><a href=\"http://zookeeper.apache.org/\">ZooKeeper</a> acting as the foundation for forms of bulk computation beyond <a href=\"http://hadoop.apache.org/mapreduce/\">MapReduce</a>.  This, and other developments, represent a significant change from the &lsquo;plumbing&rsquo; focused discussions of the last few years.</p>\n\n<p>Only a couple of years ago, nearly every Hadoop shop built its own ETL, high-level MapReduce language, scheduler, custom Java MapReduce jobs, and the development team often ran the cluster.  Furthermore, many types of data processing were ineffective, inefficient or impossible for Hadoop developers.</p>\n\n<p><b>All of this has changed.  Here&rsquo;s how:</b></p>\n\n<p>Getting Data onto HDFS is easy:</p>\n\n<ul><li><a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> - If you&rsquo;re playing around with Hadoop and want to throw a database table onto HDFS, <a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> does so in a one-liner.</li>\n<li><a href=\"https://github.com/facebook/scribe\">Scribe</a> - Facebook has put a lot of work into maturing <a href=\"https://github.com/facebook/scribe\">Scribe</a> into a solid log aggregator - to get log files from server farms onto HDFS.</li>\n<li><a href=\"https://github.com/cloudera/flume\">Flume</a> - Flume can get anything onto HDFS in a reliable manner.\n</li></ul><p>At the storage level, <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> has proven its generic utility.</p>\n\n<ul><li><a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> is a big data <a href=\"http://en.wikipedia.org/wiki/Network_File_System_(protocol)\">NFS</a>.</li>\n</ul><p><a href=\"http://zookeeper.apache.org/\">ZooKeeper&rsquo;s</a> distributed coordination has enabled efficient implementation of different types of bulk synchronous computation on top of HDFS, extending the capabilities of Hadoop into new areas, exposing new opportunities for research and commercialization.  Hadoop now excels at processing both <b>log</b> and <b>graph</b> data.</p>\n\n<ul><li><a href=\"http://incubator.apache.org/projects/giraph.html\">Apache Giraph</a> enables rapid implementation of graph algorithms that are awkward and inefficient when written in raw MapReduce.</li>\n<li><a href=\"http://www.goldenorbos.org/\">GoldenOrb</a> offers a Java-based Pregel clone for graph processing from the perspective of a graph&rsquo;s vertices.</li>\n</ul><p>High level languages for MapReduce data processing have become the dominant form of Hadoop computations.</p>\n\n<ul><li><b><a href=\"http://hive.apache.org/\">HIVE</a></b> has served as a simple and familiar SQL-based introduction to data processing on Hadoop.<br/><br/>\n\nIn the business intelligence sphere, <a href=\"http://hive.apache.org/\">HIVE</a> has eliminated the exponential increase in the cost of analyzing atomic metrics once data volume exceeds the capacity of one large commodity machine, necessitating costly proprietary network storage solutions and the accompanying massive 'Oracle tax&rsquo; on the enterprise.  The development of <a href=\"http://www.karmasphere.com/\">tools</a> to work with semi-structured and un-structured data alongside SQL tables has amplified HIVE&rsquo;s value for the analyst.</li>\n\n<li>Better integration with relational databases makes getting data off Hadoop simpler.  This has amplified the value of Hadoop&rsquo;s Java-based data-processing model by enabling rapid ad hoc analysis in SQL on a RDBMS of the output of complex operations coded more easily on the JVM in Hadoop.</li>\n\n<li>As <a href=\"http://pig.apache.org/\">Apache Pig</a> approaches version 1.0, it has matured into a turing-complete language ideally suited to harness the power of the data-flow oriented MapReduce model of computation.  With UDFs in many languages, and the unique, predictive power of a functional ILLUSTRATE command and associated tools, Pig is becoming the default method of ETL as well as more complex algorithmic implementation for data pipelines.  \n\nIt is hoped that in the near future, the development of tools for Pig will parallel those for HIVE, or that existing open source ETL tools will fill this gap.</li>\n</ul><p><img src=\"http://farm7.static.flickr.com/6011/6205061547_28f47d51de_m.jpg\" align=\"left\"/>Tighter integration with key/value stores has enabled the rapid deployment of mined data from HDFS into a production environment for easily scalable consumption by end users.</p>\n\n<ul><li><a href=\"http://hbase.apache.org/\">HBase</a>, the Hadoop database and <a href=\"http://project-voldemort.com/\">Project Voldemort</a> are both highly available NoSQL solutions with tight integration with Hadoop.\n</li>\n</ul><p>In sum: the Hadoop Pantheon continues to branch and grow, creating opportunities for new kinds of applications and ventures as each tool is applied to different application domains.<br/></p>\n\n<ul><li>Update: The key development here is that <b>Hadoop&rsquo;s plumbing has matured, and that Hadoop now works well on graph and network data</b>.  However, a number of deserving projects not including here are:</li>\n</ul><ul><li>MongoDB - has added Hadoop integration</li>\n<li>Mahout - command-line machine learning on hadoop with working examples example data-sets.  Damned good way to get you started leveraging machine learning in your data processing.</li>\n</ul><p>Please continue to submit updates and corrections and I will continue to update the post.</p>", "liked": false, "followed": false, "reblog_key": "6nZ6M17k", "reblog": {"comment": "<p>Hadoop is maturing, with <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> and <img src=\"http://farm7.static.flickr.com/6159/6205546214_875f6c02f4_m.jpg\" align=\"right\"><a href=\"http://zookeeper.apache.org/\">ZooKeeper</a> acting as the foundation for forms of bulk computation beyond <a href=\"http://hadoop.apache.org/mapreduce/\">MapReduce</a>.  This, and other developments, represent a significant change from the \u2018plumbing\u2019 focused discussions of the last few years.</p>\n\n<p>Only a couple of years ago, nearly every Hadoop shop built its own ETL, high-level MapReduce language, scheduler, custom Java MapReduce jobs, and the development team often ran the cluster.  Furthermore, many types of data processing were ineffective, inefficient or impossible for Hadoop developers.</p>\n\n<p><b>All of this has changed.  Here\u2019s how:</b></p>\n\n<p>Getting Data onto HDFS is easy:</p>\n\n<ul><li><a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> - If you\u2019re playing around with Hadoop and want to throw a database table onto HDFS, <a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> does so in a one-liner.</li>\n<li><a href=\"https://github.com/facebook/scribe\">Scribe</a> - Facebook has put a lot of work into maturing <a href=\"https://github.com/facebook/scribe\">Scribe</a> into a solid log aggregator - to get log files from server farms onto HDFS.</li>\n<li><a href=\"https://github.com/cloudera/flume\">Flume</a> - Flume can get anything onto HDFS in a reliable manner.\n</li></ul><p>At the storage level, <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> has proven its generic utility.</p>\n\n<ul><li><a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> is a big data <a href=\"http://en.wikipedia.org/wiki/Network_File_System_(protocol)\">NFS</a>.</li>\n</ul><p><a href=\"http://zookeeper.apache.org/\">ZooKeeper\u2019s</a> distributed coordination has enabled efficient implementation of different types of bulk synchronous computation on top of HDFS, extending the capabilities of Hadoop into new areas, exposing new opportunities for research and commercialization.  Hadoop now excels at processing both <b>log</b> and <b>graph</b> data.</p>\n\n<ul><li><a href=\"http://incubator.apache.org/projects/giraph.html\">Apache Giraph</a> enables rapid implementation of graph algorithms that are awkward and inefficient when written in raw MapReduce.</li>\n<li><a href=\"http://www.goldenorbos.org/\">GoldenOrb</a> offers a Java-based Pregel clone for graph processing from the perspective of a graph\u2019s vertices.</li>\n</ul><p>High level languages for MapReduce data processing have become the dominant form of Hadoop computations.</p>\n\n<ul><li><b><a href=\"http://hive.apache.org/\">HIVE</a></b> has served as a simple and familiar SQL-based introduction to data processing on Hadoop.<br><br>\n\nIn the business intelligence sphere, <a href=\"http://hive.apache.org/\">HIVE</a> has eliminated the exponential increase in the cost of analyzing atomic metrics once data volume exceeds the capacity of one large commodity machine, necessitating costly proprietary network storage solutions and the accompanying massive 'Oracle tax\u2019 on the enterprise.  The development of <a href=\"http://www.karmasphere.com/\">tools</a> to work with semi-structured and un-structured data alongside SQL tables has amplified HIVE\u2019s value for the analyst.</li>\n\n<li>Better integration with relational databases makes getting data off Hadoop simpler.  This has amplified the value of Hadoop\u2019s Java-based data-processing model by enabling rapid ad hoc analysis in SQL on a RDBMS of the output of complex operations coded more easily on the JVM in Hadoop.</li>\n\n<li>As <a href=\"http://pig.apache.org/\">Apache Pig</a> approaches version 1.0, it has matured into a turing-complete language ideally suited to harness the power of the data-flow oriented MapReduce model of computation.  With UDFs in many languages, and the unique, predictive power of a functional ILLUSTRATE command and associated tools, Pig is becoming the default method of ETL as well as more complex algorithmic implementation for data pipelines.  \n\nIt is hoped that in the near future, the development of tools for Pig will parallel those for HIVE, or that existing open source ETL tools will fill this gap.</li>\n</ul><p><img src=\"http://farm7.static.flickr.com/6011/6205061547_28f47d51de_m.jpg\" align=\"left\">Tighter integration with key/value stores has enabled the rapid deployment of mined data from HDFS into a production environment for easily scalable consumption by end users.</p>\n\n<ul><li><a href=\"http://hbase.apache.org/\">HBase</a>, the Hadoop database and <a href=\"http://project-voldemort.com/\">Project Voldemort</a> are both highly available NoSQL solutions with tight integration with Hadoop.\n</li>\n</ul><p>In sum: the Hadoop Pantheon continues to branch and grow, creating opportunities for new kinds of applications and ventures as each tool is applied to different application domains.<br></p>\n\n<ul><li>Update: The key development here is that <b>Hadoop\u2019s plumbing has matured, and that Hadoop now works well on graph and network data</b>.  However, a number of deserving projects not including here are:</li>\n</ul><ul><li>MongoDB - has added Hadoop integration</li>\n<li>Mahout - command-line machine learning on hadoop with working examples example data-sets.  Damned good way to get you started leveraging machine learning in your data processing.</li>\n</ul><p>Please continue to submit updates and corrections and I will continue to update the post.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 10955413699, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Consorts of Ganesha: The Hadoop Pantheon", "tags": [], "post_url": "http://datasyndrome.com/post/10955413699/consorts-of-ganesha-the-hadoop-pantheon", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yAC-bZ3", "type": "text", "recommended_color": null, "format": "markdown", "timestamp": 1317596100, "note_count": 4, "trail": [{"content": "<p>Hadoop is maturing, with <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> and <div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6159/6205546214_875f6c02f4_m.jpg\">External image</div><a href=\"http://zookeeper.apache.org/\">ZooKeeper</a> acting as the foundation for forms of bulk computation beyond <a href=\"http://hadoop.apache.org/mapreduce/\">MapReduce</a>.  This, and other developments, represent a significant change from the &lsquo;plumbing&rsquo; focused discussions of the last few years.</p>\n\n<p>Only a couple of years ago, nearly every Hadoop shop built its own ETL, high-level MapReduce language, scheduler, custom Java MapReduce jobs, and the development team often ran the cluster.  Furthermore, many types of data processing were ineffective, inefficient or impossible for Hadoop developers.</p>\n\n<p><b>All of this has changed.  Here&rsquo;s how:</b></p>\n\n<p>Getting Data onto HDFS is easy:</p>\n\n<ul><li><a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> - If you&rsquo;re playing around with Hadoop and want to throw a database table onto HDFS, <a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> does so in a one-liner.</li>\n<li><a href=\"https://github.com/facebook/scribe\">Scribe</a> - Facebook has put a lot of work into maturing <a href=\"https://github.com/facebook/scribe\">Scribe</a> into a solid log aggregator - to get log files from server farms onto HDFS.</li>\n<li><a href=\"https://github.com/cloudera/flume\">Flume</a> - Flume can get anything onto HDFS in a reliable manner.\n</li></ul><p>At the storage level, <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> has proven its generic utility.</p>\n\n<ul><li><a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> is a big data <a href=\"http://en.wikipedia.org/wiki/Network_File_System_(protocol)\">NFS</a>.</li>\n</ul><p><a href=\"http://zookeeper.apache.org/\">ZooKeeper&rsquo;s</a> distributed coordination has enabled efficient implementation of different types of bulk synchronous computation on top of HDFS, extending the capabilities of Hadoop into new areas, exposing new opportunities for research and commercialization.  Hadoop now excels at processing both <b>log</b> and <b>graph</b> data.</p>\n\n<ul><li><a href=\"http://incubator.apache.org/projects/giraph.html\">Apache Giraph</a> enables rapid implementation of graph algorithms that are awkward and inefficient when written in raw MapReduce.</li>\n<li><a href=\"http://www.goldenorbos.org/\">GoldenOrb</a> offers a Java-based Pregel clone for graph processing from the perspective of a graph&rsquo;s vertices.</li>\n</ul><p>High level languages for MapReduce data processing have become the dominant form of Hadoop computations.</p>\n\n<ul><li><b><a href=\"http://hive.apache.org/\">HIVE</a></b> has served as a simple and familiar SQL-based introduction to data processing on Hadoop.<br /><br />\n\nIn the business intelligence sphere, <a href=\"http://hive.apache.org/\">HIVE</a> has eliminated the exponential increase in the cost of analyzing atomic metrics once data volume exceeds the capacity of one large commodity machine, necessitating costly proprietary network storage solutions and the accompanying massive 'Oracle tax&rsquo; on the enterprise.  The development of <a href=\"http://www.karmasphere.com/\">tools</a> to work with semi-structured and un-structured data alongside SQL tables has amplified HIVE&rsquo;s value for the analyst.</li>\n\n<li>Better integration with relational databases makes getting data off Hadoop simpler.  This has amplified the value of Hadoop&rsquo;s Java-based data-processing model by enabling rapid ad hoc analysis in SQL on a RDBMS of the output of complex operations coded more easily on the JVM in Hadoop.</li>\n\n<li>As <a href=\"http://pig.apache.org/\">Apache Pig</a> approaches version 1.0, it has matured into a turing-complete language ideally suited to harness the power of the data-flow oriented MapReduce model of computation.  With UDFs in many languages, and the unique, predictive power of a functional ILLUSTRATE command and associated tools, Pig is becoming the default method of ETL as well as more complex algorithmic implementation for data pipelines.  \n\nIt is hoped that in the near future, the development of tools for Pig will parallel those for HIVE, or that existing open source ETL tools will fill this gap.</li>\n</ul><p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6011/6205061547_28f47d51de_m.jpg\">External image</div>Tighter integration with key/value stores has enabled the rapid deployment of mined data from HDFS into a production environment for easily scalable consumption by end users.</p>\n\n<ul><li><a href=\"http://hbase.apache.org/\">HBase</a>, the Hadoop database and <a href=\"http://project-voldemort.com/\">Project Voldemort</a> are both highly available NoSQL solutions with tight integration with Hadoop.\n</li>\n</ul><p>In sum: the Hadoop Pantheon continues to branch and grow, creating opportunities for new kinds of applications and ventures as each tool is applied to different application domains.<br /></p>\n\n<ul><li>Update: The key development here is that <b>Hadoop&rsquo;s plumbing has matured, and that Hadoop now works well on graph and network data</b>.  However, a number of deserving projects not including here are:</li>\n</ul><ul><li>MongoDB - has added Hadoop integration</li>\n<li>Mahout - command-line machine learning on hadoop with working examples example data-sets.  Damned good way to get you started leveraging machine learning in your data processing.</li>\n</ul><p>Please continue to submit updates and corrections and I will continue to update the post.</p>", "content_raw": "<p>Hadoop is maturing, with <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> and <img src=\"http://farm7.static.flickr.com/6159/6205546214_875f6c02f4_m.jpg\" align=\"right\"><a href=\"http://zookeeper.apache.org/\">ZooKeeper</a> acting as the foundation for forms of bulk computation beyond <a href=\"http://hadoop.apache.org/mapreduce/\">MapReduce</a>.  This, and other developments, represent a significant change from the \u2018plumbing\u2019 focused discussions of the last few years.</p>\n\n<p>Only a couple of years ago, nearly every Hadoop shop built its own ETL, high-level MapReduce language, scheduler, custom Java MapReduce jobs, and the development team often ran the cluster.  Furthermore, many types of data processing were ineffective, inefficient or impossible for Hadoop developers.</p>\n\n<p><b>All of this has changed.  Here\u2019s how:</b></p>\n\n<p>Getting Data onto HDFS is easy:</p>\n\n<ul><li><a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> - If you\u2019re playing around with Hadoop and want to throw a database table onto HDFS, <a href=\"https://github.com/cloudera/sqoop/wiki\">Sqoop</a> does so in a one-liner.</li>\n<li><a href=\"https://github.com/facebook/scribe\">Scribe</a> - Facebook has put a lot of work into maturing <a href=\"https://github.com/facebook/scribe\">Scribe</a> into a solid log aggregator - to get log files from server farms onto HDFS.</li>\n<li><a href=\"https://github.com/cloudera/flume\">Flume</a> - Flume can get anything onto HDFS in a reliable manner.\n</li></ul><p>At the storage level, <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> has proven its generic utility.</p>\n\n<ul><li><a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a> is a big data <a href=\"http://en.wikipedia.org/wiki/Network_File_System_(protocol)\">NFS</a>.</li>\n</ul><p><a href=\"http://zookeeper.apache.org/\">ZooKeeper\u2019s</a> distributed coordination has enabled efficient implementation of different types of bulk synchronous computation on top of HDFS, extending the capabilities of Hadoop into new areas, exposing new opportunities for research and commercialization.  Hadoop now excels at processing both <b>log</b> and <b>graph</b> data.</p>\n\n<ul><li><a href=\"http://incubator.apache.org/projects/giraph.html\">Apache Giraph</a> enables rapid implementation of graph algorithms that are awkward and inefficient when written in raw MapReduce.</li>\n<li><a href=\"http://www.goldenorbos.org/\">GoldenOrb</a> offers a Java-based Pregel clone for graph processing from the perspective of a graph\u2019s vertices.</li>\n</ul><p>High level languages for MapReduce data processing have become the dominant form of Hadoop computations.</p>\n\n<ul><li><b><a href=\"http://hive.apache.org/\">HIVE</a></b> has served as a simple and familiar SQL-based introduction to data processing on Hadoop.<br><br>\n\nIn the business intelligence sphere, <a href=\"http://hive.apache.org/\">HIVE</a> has eliminated the exponential increase in the cost of analyzing atomic metrics once data volume exceeds the capacity of one large commodity machine, necessitating costly proprietary network storage solutions and the accompanying massive 'Oracle tax\u2019 on the enterprise.  The development of <a href=\"http://www.karmasphere.com/\">tools</a> to work with semi-structured and un-structured data alongside SQL tables has amplified HIVE\u2019s value for the analyst.</li>\n\n<li>Better integration with relational databases makes getting data off Hadoop simpler.  This has amplified the value of Hadoop\u2019s Java-based data-processing model by enabling rapid ad hoc analysis in SQL on a RDBMS of the output of complex operations coded more easily on the JVM in Hadoop.</li>\n\n<li>As <a href=\"http://pig.apache.org/\">Apache Pig</a> approaches version 1.0, it has matured into a turing-complete language ideally suited to harness the power of the data-flow oriented MapReduce model of computation.  With UDFs in many languages, and the unique, predictive power of a functional ILLUSTRATE command and associated tools, Pig is becoming the default method of ETL as well as more complex algorithmic implementation for data pipelines.  \n\nIt is hoped that in the near future, the development of tools for Pig will parallel those for HIVE, or that existing open source ETL tools will fill this gap.</li>\n</ul><p><img src=\"http://farm7.static.flickr.com/6011/6205061547_28f47d51de_m.jpg\" align=\"left\">Tighter integration with key/value stores has enabled the rapid deployment of mined data from HDFS into a production environment for easily scalable consumption by end users.</p>\n\n<ul><li><a href=\"http://hbase.apache.org/\">HBase</a>, the Hadoop database and <a href=\"http://project-voldemort.com/\">Project Voldemort</a> are both highly available NoSQL solutions with tight integration with Hadoop.\n</li>\n</ul><p>In sum: the Hadoop Pantheon continues to branch and grow, creating opportunities for new kinds of applications and ventures as each tool is applied to different application domains.<br></p>\n\n<ul><li>Update: The key development here is that <b>Hadoop\u2019s plumbing has matured, and that Hadoop now works well on graph and network data</b>.  However, a number of deserving projects not including here are:</li>\n</ul><ul><li>MongoDB - has added Hadoop integration</li>\n<li>Mahout - command-line machine learning on hadoop with working examples example data-sets.  Damned good way to get you started leveraging machine learning in your data processing.</li>\n</ul><p>Please continue to submit updates and corrections and I will continue to update the post.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "10955413699"}}], "date": "2011-10-02 22:55:00 GMT", "slug": "consorts-of-ganesha-the-hadoop-pantheon", "blog_name": "rjurney", "summary": "Consorts of Ganesha: The Hadoop Pantheon", "can_reblog": true}, {"body": "<p>Note: if you like this post, you&rsquo;ll want to learn more about the <a target=\"_blank\" href=\"http://tinkerpop.com\">Tinkerpop</a> stack.</p><p>A few months ago, my health improved for a bit, and I was able to do some thinking about email. \u00a0I believe your most valuable, <strong>untapped</strong> social network is in your <strong>inbox</strong>. \u00a0I thought about competing with Xobni, Rapportive, etc. from a more analytics-intensive, social network analysis perspective. \u00a0More than that, I wanted to create a new kind of social network based on a new kind of sharing.</p>\n<p>So I set about slurping gmail and yahoo via <a target=\"_blank\" href=\"http://code.google.com/apis/gmail/oauth/\">OAuth IMAP</a>. \u00a0To grab a few emails is trivial. \u00a0To reliably get the entire mailbox - often 100s of thousands of messages, is actually hard. \u00a0Many exceptions can crop at many levels of the stack, and you&rsquo;ve got to catch all you can and resume on failure. \u00a0And who the fuck knew that Ruby has Error in addition to Exception as a base level Error/Exception thingy? \u00a0Not me, for about a week of debugging.</p>\n<ul><li>Slurping data can be exhaustively time-consuming. \u00a0Plan for it.</li>\n<li>Consider - maybe you don&rsquo;t need all the data to ship your first version.</li>\n</ul><p>I built an in-ram, <a target=\"_blank\" href=\"http://project-voldemort.com/\">Voldemort</a>-backed summary of your inbox social network in real-time using <a target=\"_blank\" href=\"http://jruby.org/\">JRuby</a> and <a target=\"_blank\" href=\"https://github.com/pangloss/pacer\">Pacer</a>. \u00a0Then I set about visualizing it to see where I was at.</p>\n<ul><li>Visualize first, or you cannot product manage your analytics product. \u00a0Remember, there&rsquo;s an extra variable here: what is possible to derive from the data. \u00a0You want to be informed and surprised. \u00a0Plan for epiphany.</li>\n</ul><p>This is a print of an early iteration of a visualization of an inbox using the OpenORD layout in <a href=\"http://gephi.org/\" target=\"_blank\">Gephi</a>. \u00a0Grey lines are unreciprocated, the blue lines are reciprocated. \u00a0I thought about improving and selling these for ramen profitability.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6177/6199936166_1c388e066e.jpg\" align=\"middle\"/></p>\n<p>The problem here in thinking about what kind of features to build into a simpler, list-based HTML interface is that there is way too much noise. \u00a0You can&rsquo;t easily make inferences about your own network. \u00a0So I looked at all the filters in <a target=\"_blank\" href=\"http://www.amazon.com/Social-Network-Analysis-Applications-Structural/dp/0521387078\">Wasserman</a> and the literature. \u00a0The first one I tried was the <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Degeneracy_(graph_theory)#k-Cores\">k-core</a>, which works great in social graphs. \u00a0</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6174/6199938982_f01afd6f34.jpg\" align=\"middle\"/></p>\n<p>It turns out though, that k-cores are pretty terrible in <strong>weighted</strong> social <strong>networks</strong>. \u00a0There are several implementations of weighted k-cores for social networks. \u00a0After some searching, I found one that worked reasonably well and implemented it in Pacer.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6159/6199427171_00d7c3d360.jpg\" align=\"middle\"/></p>\n<p>After I had these really clear summaries of social networks, I started doing simple <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Natural_language_processing\">NLP</a> of the emails themselves as they streamed in: splitting emails into significant n-grams (2 and 3-grams mostly) and doing a TF-IDF summarization of its content. \u00a0This enables topic-specific maps, and it enables you to track the flow of n-grams across your network, and all kinds of interesting things.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6138/6199428409_333a963e03.jpg\" align=\"middle\"/></p>\n<p>What I was doing next was the point of the entire thing, and just in case&hellip; I&rsquo;m not telling. \u00a0It is really cool, and if I had my health I&rsquo;d be kicking ass with this idea. \u00a0Or it would have flopped. \u00a0But I would have known.</p>\n<p>Then my pain got bad again and I fell on my ass. \u00a0I have an application up at <a href=\"http://kontexa.com\">http://kontexa.com</a> that will OAuth into your gmail. \u00a0If I fire off a command, I can make you a poster and with a little fine tuning, email it to you, or print it and mail it in one of those tubes taking up so much space in my office. \u00a0Thats as far as I got before I flared.</p>\n<p>Now I&rsquo;m able to work part time, and I need to pay the bills&hellip; you can&rsquo;t part-time a startup. \u00a0I got a part-time gig with a very cool company. \u00a0So this whole thing is shelved. \u00a0But this is the direction of what I was doing. \u00a0I thought I would share.</p>\n<p>Can you guess the cleverness from the picture above?</p>", "liked": false, "followed": false, "reblog_key": "05LqmQBo", "reblog": {"comment": "<p>Note: if you like this post, you\u2019ll want to learn more about the <a target=\"_blank\" href=\"http://tinkerpop.com\">Tinkerpop</a> stack.</p><p>A few months ago, my health improved for a bit, and I was able to do some thinking about email. \u00a0I believe your most valuable, <strong>untapped</strong> social network is in your <strong>inbox</strong>. \u00a0I thought about competing with Xobni, Rapportive, etc. from a more analytics-intensive, social network analysis perspective. \u00a0More than that, I wanted to create a new kind of social network based on a new kind of sharing.</p>\n<p>So I set about slurping gmail and yahoo via <a target=\"_blank\" href=\"http://code.google.com/apis/gmail/oauth/\">OAuth IMAP</a>. \u00a0To grab a few emails is trivial. \u00a0To reliably get the entire mailbox - often 100s of thousands of messages, is actually hard. \u00a0Many exceptions can crop at many levels of the stack, and you\u2019ve got to catch all you can and resume on failure. \u00a0And who the fuck knew that Ruby has Error in addition to Exception as a base level Error/Exception thingy? \u00a0Not me, for about a week of debugging.</p>\n<ul><li>Slurping data can be exhaustively time-consuming. \u00a0Plan for it.</li>\n<li>Consider - maybe you don\u2019t need all the data to ship your first version.</li>\n</ul><p>I built an in-ram, <a target=\"_blank\" href=\"http://project-voldemort.com/\">Voldemort</a>-backed summary of your inbox social network in real-time using <a target=\"_blank\" href=\"http://jruby.org/\">JRuby</a> and <a target=\"_blank\" href=\"https://github.com/pangloss/pacer\">Pacer</a>. \u00a0Then I set about visualizing it to see where I was at.</p>\n<ul><li>Visualize first, or you cannot product manage your analytics product. \u00a0Remember, there\u2019s an extra variable here: what is possible to derive from the data. \u00a0You want to be informed and surprised. \u00a0Plan for epiphany.</li>\n</ul><p>This is a print of an early iteration of a visualization of an inbox using the OpenORD layout in <a href=\"http://gephi.org/\" target=\"_blank\">Gephi</a>. \u00a0Grey lines are unreciprocated, the blue lines are reciprocated. \u00a0I thought about improving and selling these for ramen profitability.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6177/6199936166_1c388e066e.jpg\" align=\"middle\"></p>\n<p>The problem here in thinking about what kind of features to build into a simpler, list-based HTML interface is that there is way too much noise. \u00a0You can\u2019t easily make inferences about your own network. \u00a0So I looked at all the filters in <a target=\"_blank\" href=\"http://www.amazon.com/Social-Network-Analysis-Applications-Structural/dp/0521387078\">Wasserman</a> and the literature. \u00a0The first one I tried was the <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Degeneracy_(graph_theory)#k-Cores\">k-core</a>, which works great in social graphs. \u00a0</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6174/6199938982_f01afd6f34.jpg\" align=\"middle\"></p>\n<p>It turns out though, that k-cores are pretty terrible in <strong>weighted</strong> social <strong>networks</strong>. \u00a0There are several implementations of weighted k-cores for social networks. \u00a0After some searching, I found one that worked reasonably well and implemented it in Pacer.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6159/6199427171_00d7c3d360.jpg\" align=\"middle\"></p>\n<p>After I had these really clear summaries of social networks, I started doing simple <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Natural_language_processing\">NLP</a> of the emails themselves as they streamed in: splitting emails into significant n-grams (2 and 3-grams mostly) and doing a TF-IDF summarization of its content. \u00a0This enables topic-specific maps, and it enables you to track the flow of n-grams across your network, and all kinds of interesting things.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6138/6199428409_333a963e03.jpg\" align=\"middle\"></p>\n<p>What I was doing next was the point of the entire thing, and just in case\u2026 I\u2019m not telling. \u00a0It is really cool, and if I had my health I\u2019d be kicking ass with this idea. \u00a0Or it would have flopped. \u00a0But I would have known.</p>\n<p>Then my pain got bad again and I fell on my ass. \u00a0I have an application up at <a href=\"http://kontexa.com\">http://kontexa.com</a> that will OAuth into your gmail. \u00a0If I fire off a command, I can make you a poster and with a little fine tuning, email it to you, or print it and mail it in one of those tubes taking up so much space in my office. \u00a0Thats as far as I got before I flared.</p>\n<p>Now I\u2019m able to work part time, and I need to pay the bills\u2026 you can\u2019t part-time a startup. \u00a0I got a part-time gig with a very cool company. \u00a0So this whole thing is shelved. \u00a0But this is the direction of what I was doing. \u00a0I thought I would share.</p>\n<p>Can you guess the cleverness from the picture above?</p>", "tree_html": ""}, "can_send_in_message": true, "id": 10879633053, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Thinking about email: Implied social networks in the inbox", "tags": [], "post_url": "http://datasyndrome.com/post/10879633053/thinking-about-email-implied-social-networks-in", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yA8UWQT", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1317448740, "note_count": 1, "trail": [{"content": "<p>Note: if you like this post, you&rsquo;ll want to learn more about the <a target=\"_blank\" href=\"http://tinkerpop.com\">Tinkerpop</a> stack.</p><p>A few months ago, my health improved for a bit, and I was able to do some thinking about email. &nbsp;I believe your most valuable, <strong>untapped</strong> social network is in your <strong>inbox</strong>. &nbsp;I thought about competing with Xobni, Rapportive, etc. from a more analytics-intensive, social network analysis perspective. &nbsp;More than that, I wanted to create a new kind of social network based on a new kind of sharing.</p>\n<p>So I set about slurping gmail and yahoo via <a target=\"_blank\" href=\"http://code.google.com/apis/gmail/oauth/\">OAuth IMAP</a>. &nbsp;To grab a few emails is trivial. &nbsp;To reliably get the entire mailbox - often 100s of thousands of messages, is actually hard. &nbsp;Many exceptions can crop at many levels of the stack, and you&rsquo;ve got to catch all you can and resume on failure. &nbsp;And who the fuck knew that Ruby has Error in addition to Exception as a base level Error/Exception thingy? &nbsp;Not me, for about a week of debugging.</p>\n<ul><li>Slurping data can be exhaustively time-consuming. &nbsp;Plan for it.</li>\n<li>Consider - maybe you don&rsquo;t need all the data to ship your first version.</li>\n</ul><p>I built an in-ram, <a target=\"_blank\" href=\"http://project-voldemort.com/\">Voldemort</a>-backed summary of your inbox social network in real-time using <a target=\"_blank\" href=\"http://jruby.org/\">JRuby</a> and <a target=\"_blank\" href=\"https://github.com/pangloss/pacer\">Pacer</a>. &nbsp;Then I set about visualizing it to see where I was at.</p>\n<ul><li>Visualize first, or you cannot product manage your analytics product. &nbsp;Remember, there&rsquo;s an extra variable here: what is possible to derive from the data. &nbsp;You want to be informed and surprised. &nbsp;Plan for epiphany.</li>\n</ul><p>This is a print of an early iteration of a visualization of an inbox using the OpenORD layout in <a href=\"http://gephi.org/\" target=\"_blank\">Gephi</a>. &nbsp;Grey lines are unreciprocated, the blue lines are reciprocated. &nbsp;I thought about improving and selling these for ramen profitability.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6177/6199936166_1c388e066e.jpg\">External image</div></p>\n<p>The problem here in thinking about what kind of features to build into a simpler, list-based HTML interface is that there is way too much noise. &nbsp;You can&rsquo;t easily make inferences about your own network. &nbsp;So I looked at all the filters in <a target=\"_blank\" href=\"http://www.amazon.com/Social-Network-Analysis-Applications-Structural/dp/0521387078\">Wasserman</a> and the literature. &nbsp;The first one I tried was the <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Degeneracy_(graph_theory)#k-Cores\">k-core</a>, which works great in social graphs. &nbsp;</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6174/6199938982_f01afd6f34.jpg\">External image</div></p>\n<p>It turns out though, that k-cores are pretty terrible in <strong>weighted</strong> social <strong>networks</strong>. &nbsp;There are several implementations of weighted k-cores for social networks. &nbsp;After some searching, I found one that worked reasonably well and implemented it in Pacer.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6159/6199427171_00d7c3d360.jpg\">External image</div></p>\n<p>After I had these really clear summaries of social networks, I started doing simple <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Natural_language_processing\">NLP</a> of the emails themselves as they streamed in: splitting emails into significant n-grams (2 and 3-grams mostly) and doing a TF-IDF summarization of its content. &nbsp;This enables topic-specific maps, and it enables you to track the flow of n-grams across your network, and all kinds of interesting things.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6138/6199428409_333a963e03.jpg\">External image</div></p>\n<p>What I was doing next was the point of the entire thing, and just in case&hellip; I&rsquo;m not telling. &nbsp;It is really cool, and if I had my health I&rsquo;d be kicking ass with this idea. &nbsp;Or it would have flopped. &nbsp;But I would have known.</p>\n<p>Then my pain got bad again and I fell on my ass. &nbsp;I have an application up at <a href=\"http://kontexa.com\">http://kontexa.com</a> that will OAuth into your gmail. &nbsp;If I fire off a command, I can make you a poster and with a little fine tuning, email it to you, or print it and mail it in one of those tubes taking up so much space in my office. &nbsp;Thats as far as I got before I flared.</p>\n<p>Now I&rsquo;m able to work part time, and I need to pay the bills&hellip; you can&rsquo;t part-time a startup. &nbsp;I got a part-time gig with a very cool company. &nbsp;So this whole thing is shelved. &nbsp;But this is the direction of what I was doing. &nbsp;I thought I would share.</p>\n<p>Can you guess the cleverness from the picture above?</p>", "content_raw": "<p>Note: if you like this post, you\u2019ll want to learn more about the <a target=\"_blank\" href=\"http://tinkerpop.com\">Tinkerpop</a> stack.</p><p>A few months ago, my health improved for a bit, and I was able to do some thinking about email. \u00a0I believe your most valuable, <strong>untapped</strong> social network is in your <strong>inbox</strong>. \u00a0I thought about competing with Xobni, Rapportive, etc. from a more analytics-intensive, social network analysis perspective. \u00a0More than that, I wanted to create a new kind of social network based on a new kind of sharing.</p>\n<p>So I set about slurping gmail and yahoo via <a target=\"_blank\" href=\"http://code.google.com/apis/gmail/oauth/\">OAuth IMAP</a>. \u00a0To grab a few emails is trivial. \u00a0To reliably get the entire mailbox - often 100s of thousands of messages, is actually hard. \u00a0Many exceptions can crop at many levels of the stack, and you\u2019ve got to catch all you can and resume on failure. \u00a0And who the fuck knew that Ruby has Error in addition to Exception as a base level Error/Exception thingy? \u00a0Not me, for about a week of debugging.</p>\n<ul><li>Slurping data can be exhaustively time-consuming. \u00a0Plan for it.</li>\n<li>Consider - maybe you don\u2019t need all the data to ship your first version.</li>\n</ul><p>I built an in-ram, <a target=\"_blank\" href=\"http://project-voldemort.com/\">Voldemort</a>-backed summary of your inbox social network in real-time using <a target=\"_blank\" href=\"http://jruby.org/\">JRuby</a> and <a target=\"_blank\" href=\"https://github.com/pangloss/pacer\">Pacer</a>. \u00a0Then I set about visualizing it to see where I was at.</p>\n<ul><li>Visualize first, or you cannot product manage your analytics product. \u00a0Remember, there\u2019s an extra variable here: what is possible to derive from the data. \u00a0You want to be informed and surprised. \u00a0Plan for epiphany.</li>\n</ul><p>This is a print of an early iteration of a visualization of an inbox using the OpenORD layout in <a href=\"http://gephi.org/\" target=\"_blank\">Gephi</a>. \u00a0Grey lines are unreciprocated, the blue lines are reciprocated. \u00a0I thought about improving and selling these for ramen profitability.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6177/6199936166_1c388e066e.jpg\" align=\"middle\"></p>\n<p>The problem here in thinking about what kind of features to build into a simpler, list-based HTML interface is that there is way too much noise. \u00a0You can\u2019t easily make inferences about your own network. \u00a0So I looked at all the filters in <a target=\"_blank\" href=\"http://www.amazon.com/Social-Network-Analysis-Applications-Structural/dp/0521387078\">Wasserman</a> and the literature. \u00a0The first one I tried was the <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Degeneracy_(graph_theory)#k-Cores\">k-core</a>, which works great in social graphs. \u00a0</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6174/6199938982_f01afd6f34.jpg\" align=\"middle\"></p>\n<p>It turns out though, that k-cores are pretty terrible in <strong>weighted</strong> social <strong>networks</strong>. \u00a0There are several implementations of weighted k-cores for social networks. \u00a0After some searching, I found one that worked reasonably well and implemented it in Pacer.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6159/6199427171_00d7c3d360.jpg\" align=\"middle\"></p>\n<p>After I had these really clear summaries of social networks, I started doing simple <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Natural_language_processing\">NLP</a> of the emails themselves as they streamed in: splitting emails into significant n-grams (2 and 3-grams mostly) and doing a TF-IDF summarization of its content. \u00a0This enables topic-specific maps, and it enables you to track the flow of n-grams across your network, and all kinds of interesting things.</p>\n<p><img height=\"500\" width=\"500\" src=\"http://farm7.static.flickr.com/6138/6199428409_333a963e03.jpg\" align=\"middle\"></p>\n<p>What I was doing next was the point of the entire thing, and just in case\u2026 I\u2019m not telling. \u00a0It is really cool, and if I had my health I\u2019d be kicking ass with this idea. \u00a0Or it would have flopped. \u00a0But I would have known.</p>\n<p>Then my pain got bad again and I fell on my ass. \u00a0I have an application up at <a href=\"http://kontexa.com\">http://kontexa.com</a> that will OAuth into your gmail. \u00a0If I fire off a command, I can make you a poster and with a little fine tuning, email it to you, or print it and mail it in one of those tubes taking up so much space in my office. \u00a0Thats as far as I got before I flared.</p>\n<p>Now I\u2019m able to work part time, and I need to pay the bills\u2026 you can\u2019t part-time a startup. \u00a0I got a part-time gig with a very cool company. \u00a0So this whole thing is shelved. \u00a0But this is the direction of what I was doing. \u00a0I thought I would share.</p>\n<p>Can you guess the cleverness from the picture above?</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "10879633053"}}], "date": "2011-10-01 05:59:00 GMT", "slug": "thinking-about-email-implied-social-networks-in", "blog_name": "rjurney", "summary": "Thinking about email: Implied social networks in the inbox", "can_reblog": true}, {"body": "<blockquote>\n<p><span>Greek\u00a0<em>technologia</em>\u00a0systematic treatment of an art, from\u00a0<em>techn\u0113</em>\u00a0art, skill +\u00a0<em>-o-</em>\u00a0+\u00a0<em>-logia</em>\u00a0-logy</span></p>\nFirst Known Use: 1859</blockquote>\n<p>Engineers are technologists. \u00a0They hold an implicit belief that the development and application of new technology to alter the world around them is a good thing. \u00a0A thing worth doing for its own sake. \u00a0'I built that,&rsquo; is a very satisfying statement, just as &lsquo;I hunted that&rsquo; was before it.</p>\n<p>Not everyone believes this. \u00a0Many people don&rsquo;t want you inventing new things, they want to go back to a simpler time - the ideal one they experienced during their childhood and early\u00a0adolescence.</p>\n<p>The engineering culture is defined by cliques. \u00a0In the absence of social\u00a0queues\u00a0on the internet and owing to the lack of empathy of the engineering population, 'brand loyalty&rsquo; to different languages, tools and techniques can lead to bitter conflict inside companies and within and between communities. \u00a0If you&rsquo;ve ever fought for the use of new technology inside a company, you know what I mean.</p>\n<p>This makes for a\u00a0<a href=\"http://localhost:4567/graph/5\">great joke</a>:</p>\n<blockquote>\n<p><strong>C</strong> would be\u00a0<span>Judaism</span></p>\n<p><span><span>Java</span>\u00a0would be\u00a0<span>Fundamentalist Christianity</span></span></p>\n<p><span><span><span><strong><span><span>C++</span>\u00a0would be\u00a0<span>Islam</span></span></strong></span></span></span></p>\n<p><span><span><span><strong><span><span><span><span>C#</span>\u00a0would be\u00a0<span>Mormonism</span></span></span></span></strong></span></span></span></p>\n<p><span><span><span><strong><span><span><span><span><span><span>Lisp</span>\u00a0would be\u00a0<span>Zen Buddhism</span></span></span></span></span></span></strong></span></span></span></p>\n<p><span><strong><span><strong>Perl</strong>\u00a0would be\u00a0<strong>Voodoo</strong></span></strong></span></p>\n<p><span><strong><span><strong><span><strong>Ruby\u00a0</strong>would be\u00a0<strong>Neo-Paganism</strong></span></strong></span></strong></span></p>\n</blockquote>\n<p>But it isn&rsquo;t a joke. \u00a0Technology as religion is real, as are contentions between devotees, and this isn&rsquo;t new. \u00a0It started in the 6th century BC with Pythagoras and his worshippers, the Pythagoreans. \u00a0</p>\n<blockquote>\n<p><span>The early evidence suggests, however, that Pythagoras presented a cosmos that was structured according to moral principles and significant numerical relationships</span></p>\n</blockquote>\n<p>Pythagorus would eventually be credited with the Pythagorean\u00a0theorem, and everything else his cult came up with in the next few hundred years. \u00a0They had this habit&hellip; kind of like IRC, of throwing heretics off of cliffs.</p>\n<p>I wonder if we realize how much we deify as technologists. \u00a0Mike Driscoll touched on this in his <a target=\"_blank\" href=\"http://medriscoll.com/post/9117396231/the-guild-of-silicon-valley\">post</a> about fat guys knowing C++. \u00a0Mike gets it, as the talent of his team attests.</p>\n<p>I wonder how often we are aware of the cults at work as we navigate organizations with overlapping networks of belief. \u00a0If you cultivate and yield influence, change minds and shape opinions, are you more prophet than leader?</p>\n<p>I think you are.</p>", "liked": false, "followed": false, "reblog_key": "k5HPDlNK", "reblog": {"comment": "<p><blockquote>\n<p><span>Greek\u00a0<em>technologia</em>\u00a0systematic treatment of an art, from\u00a0<em>techn\u0113</em>\u00a0art, skill +\u00a0<em>-o-</em>\u00a0+\u00a0<em>-logia</em>\u00a0-logy</span></p>\nFirst Known Use: 1859</blockquote>\n<p>Engineers are technologists. \u00a0They hold an implicit belief that the development and application of new technology to alter the world around them is a good thing. \u00a0A thing worth doing for its own sake. \u00a0'I built that,\u2019 is a very satisfying statement, just as \u2018I hunted that\u2019 was before it.</p>\n<p>Not everyone believes this. \u00a0Many people don\u2019t want you inventing new things, they want to go back to a simpler time - the ideal one they experienced during their childhood and early\u00a0adolescence.</p>\n<p>The engineering culture is defined by cliques. \u00a0In the absence of social\u00a0queues\u00a0on the internet and owing to the lack of empathy of the engineering population, 'brand loyalty\u2019 to different languages, tools and techniques can lead to bitter conflict inside companies and within and between communities. \u00a0If you\u2019ve ever fought for the use of new technology inside a company, you know what I mean.</p>\n<p>This makes for a\u00a0<a href=\"http://localhost:4567/graph/5\">great joke</a>:</p>\n<blockquote>\n<p><strong>C</strong> would be\u00a0<span>Judaism</span></p>\n<p><span><span>Java</span>\u00a0would be\u00a0<span>Fundamentalist Christianity</span></span></p>\n<p><span><span><span><strong><span><span>C++</span>\u00a0would be\u00a0<span>Islam</span></span></strong></span></span></span></p>\n<p><span><span><span><strong><span><span><span><span>C#</span>\u00a0would be\u00a0<span>Mormonism</span></span></span></span></strong></span></span></span></p>\n<p><span><span><span><strong><span><span><span><span><span><span>Lisp</span>\u00a0would be\u00a0<span>Zen Buddhism</span></span></span></span></span></span></strong></span></span></span></p>\n<p><span><strong><span><strong>Perl</strong>\u00a0would be\u00a0<strong>Voodoo</strong></span></strong></span></p>\n<p><span><strong><span><strong><span><strong>Ruby\u00a0</strong>would be\u00a0<strong>Neo-Paganism</strong></span></strong></span></strong></span></p>\n</blockquote>\n<p>But it isn\u2019t a joke. \u00a0Technology as religion is real, as are contentions between devotees, and this isn\u2019t new. \u00a0It started in the 6th century BC with Pythagoras and his worshippers, the Pythagoreans. \u00a0</p>\n<blockquote>\n<p><span>The early evidence suggests, however, that Pythagoras presented a cosmos that was structured according to moral principles and significant numerical relationships</span></p>\n</blockquote>\n<p>Pythagorus would eventually be credited with the Pythagorean\u00a0theorem, and everything else his cult came up with in the next few hundred years. \u00a0They had this habit\u2026 kind of like IRC, of throwing heretics off of cliffs.</p>\n<p>I wonder if we realize how much we deify as technologists. \u00a0Mike Driscoll touched on this in his <a target=\"_blank\" href=\"http://medriscoll.com/post/9117396231/the-guild-of-silicon-valley\">post</a> about fat guys knowing C++. \u00a0Mike gets it, as the talent of his team attests.</p>\n<p>I wonder how often we are aware of the cults at work as we navigate organizations with overlapping networks of belief. \u00a0If you cultivate and yield influence, change minds and shape opinions, are you more prophet than leader?</p>\n<p>I think you are.</p></p>", "tree_html": ""}, "can_send_in_message": true, "id": 10842672340, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Pythagorean Internetworks", "tags": [], "post_url": "http://datasyndrome.com/post/10842672340/pythagorean-internetworks", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yA6HWpK", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1317374520, "note_count": 0, "trail": [{"content": "<p><blockquote>\n<p>Greek&nbsp;<em>technologia</em>&nbsp;systematic treatment of an art, from&nbsp;<em>techn&#275;</em>&nbsp;art, skill +&nbsp;<em>-o-</em>&nbsp;+&nbsp;<em>-logia</em>&nbsp;-logy</p><p>\nFirst Known Use: 1859</p></blockquote>\n<p>Engineers are technologists. &nbsp;They hold an implicit belief that the development and application of new technology to alter the world around them is a good thing. &nbsp;A thing worth doing for its own sake. &nbsp;'I built that,&rsquo; is a very satisfying statement, just as &lsquo;I hunted that&rsquo; was before it.</p>\n<p>Not everyone believes this. &nbsp;Many people don&rsquo;t want you inventing new things, they want to go back to a simpler time - the ideal one they experienced during their childhood and early&nbsp;adolescence.</p>\n<p>The engineering culture is defined by cliques. &nbsp;In the absence of social&nbsp;queues&nbsp;on the internet and owing to the lack of empathy of the engineering population, 'brand loyalty&rsquo; to different languages, tools and techniques can lead to bitter conflict inside companies and within and between communities. &nbsp;If you&rsquo;ve ever fought for the use of new technology inside a company, you know what I mean.</p>\n<p>This makes for a&nbsp;<a href=\"http://localhost:4567/graph/5\">great joke</a>:</p>\n<blockquote>\n<p><strong>C</strong> would be&nbsp;Judaism</p>\n<p>Java&nbsp;would be&nbsp;Fundamentalist Christianity</p>\n<p><strong>C++&nbsp;would be&nbsp;Islam</strong></p>\n<p><strong>C#&nbsp;would be&nbsp;Mormonism</strong></p>\n<p><strong>Lisp&nbsp;would be&nbsp;Zen Buddhism</strong></p>\n<p><strong><strong>Perl</strong>&nbsp;would be&nbsp;<strong>Voodoo</strong></strong></p>\n<p><strong><strong><strong>Ruby&nbsp;</strong>would be&nbsp;<strong>Neo-Paganism</strong></strong></strong></p>\n</blockquote>\n<p>But it isn&rsquo;t a joke. &nbsp;Technology as religion is real, as are contentions between devotees, and this isn&rsquo;t new. &nbsp;It started in the 6th century BC with Pythagoras and his worshippers, the Pythagoreans. &nbsp;</p>\n<blockquote>\n<p>The early evidence suggests, however, that Pythagoras presented a cosmos that was structured according to moral principles and significant numerical relationships</p>\n</blockquote>\n<p>Pythagorus would eventually be credited with the Pythagorean&nbsp;theorem, and everything else his cult came up with in the next few hundred years. &nbsp;They had this habit&hellip; kind of like IRC, of throwing heretics off of cliffs.</p>\n<p>I wonder if we realize how much we deify as technologists. &nbsp;Mike Driscoll touched on this in his <a target=\"_blank\" href=\"http://medriscoll.com/post/9117396231/the-guild-of-silicon-valley\">post</a> about fat guys knowing C++. &nbsp;Mike gets it, as the talent of his team attests.</p>\n<p>I wonder how often we are aware of the cults at work as we navigate organizations with overlapping networks of belief. &nbsp;If you cultivate and yield influence, change minds and shape opinions, are you more prophet than leader?</p>\n<p>I think you are.</p></p>", "content_raw": "<p><blockquote>\n<p><span>Greek\u00a0<em>technologia</em>\u00a0systematic treatment of an art, from\u00a0<em>techn\u0113</em>\u00a0art, skill +\u00a0<em>-o-</em>\u00a0+\u00a0<em>-logia</em>\u00a0-logy</span></p>\nFirst Known Use: 1859</blockquote>\n<p>Engineers are technologists. \u00a0They hold an implicit belief that the development and application of new technology to alter the world around them is a good thing. \u00a0A thing worth doing for its own sake. \u00a0'I built that,\u2019 is a very satisfying statement, just as \u2018I hunted that\u2019 was before it.</p>\n<p>Not everyone believes this. \u00a0Many people don\u2019t want you inventing new things, they want to go back to a simpler time - the ideal one they experienced during their childhood and early\u00a0adolescence.</p>\n<p>The engineering culture is defined by cliques. \u00a0In the absence of social\u00a0queues\u00a0on the internet and owing to the lack of empathy of the engineering population, 'brand loyalty\u2019 to different languages, tools and techniques can lead to bitter conflict inside companies and within and between communities. \u00a0If you\u2019ve ever fought for the use of new technology inside a company, you know what I mean.</p>\n<p>This makes for a\u00a0<a href=\"http://localhost:4567/graph/5\">great joke</a>:</p>\n<blockquote>\n<p><strong>C</strong> would be\u00a0<span>Judaism</span></p>\n<p><span><span>Java</span>\u00a0would be\u00a0<span>Fundamentalist Christianity</span></span></p>\n<p><span><span><span><strong><span><span>C++</span>\u00a0would be\u00a0<span>Islam</span></span></strong></span></span></span></p>\n<p><span><span><span><strong><span><span><span><span>C#</span>\u00a0would be\u00a0<span>Mormonism</span></span></span></span></strong></span></span></span></p>\n<p><span><span><span><strong><span><span><span><span><span><span>Lisp</span>\u00a0would be\u00a0<span>Zen Buddhism</span></span></span></span></span></span></strong></span></span></span></p>\n<p><span><strong><span><strong>Perl</strong>\u00a0would be\u00a0<strong>Voodoo</strong></span></strong></span></p>\n<p><span><strong><span><strong><span><strong>Ruby\u00a0</strong>would be\u00a0<strong>Neo-Paganism</strong></span></strong></span></strong></span></p>\n</blockquote>\n<p>But it isn\u2019t a joke. \u00a0Technology as religion is real, as are contentions between devotees, and this isn\u2019t new. \u00a0It started in the 6th century BC with Pythagoras and his worshippers, the Pythagoreans. \u00a0</p>\n<blockquote>\n<p><span>The early evidence suggests, however, that Pythagoras presented a cosmos that was structured according to moral principles and significant numerical relationships</span></p>\n</blockquote>\n<p>Pythagorus would eventually be credited with the Pythagorean\u00a0theorem, and everything else his cult came up with in the next few hundred years. \u00a0They had this habit\u2026 kind of like IRC, of throwing heretics off of cliffs.</p>\n<p>I wonder if we realize how much we deify as technologists. \u00a0Mike Driscoll touched on this in his <a target=\"_blank\" href=\"http://medriscoll.com/post/9117396231/the-guild-of-silicon-valley\">post</a> about fat guys knowing C++. \u00a0Mike gets it, as the talent of his team attests.</p>\n<p>I wonder how often we are aware of the cults at work as we navigate organizations with overlapping networks of belief. \u00a0If you cultivate and yield influence, change minds and shape opinions, are you more prophet than leader?</p>\n<p>I think you are.</p></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "10842672340"}}], "date": "2011-09-30 09:22:00 GMT", "slug": "pythagorean-internetworks", "blog_name": "rjurney", "summary": "Pythagorean Internetworks", "can_reblog": true}, {"body": "<p><strong>Disclaimer</strong></p>\n<p><em>I am not a doctor. \u00a0I didn&rsquo;t even finish my biology degree. \u00a0I failed out of a state school with a scarred liver,\u00a0severe\u00a0hemorrhoids and a working knowledge of Rooskie mat (Russian cursing). \u00a0I am not giving medical advice. \u00a0I&rsquo;m just going to the beach. \u00a0In fact, you should consider this entire post pure fantasy - a &lsquo;what if&rsquo; scenario, if I could go swimming again! \u00a0If you listen to me, instead of your doctor, and act out anything documented in this blog post, you are the worst kind of fool. \u00a0<strong>Do not try this at home.<br/><br/>This post was a dead end treatment path for pain. Injecting your muscles to numb them is a bad idea. You need to learn to live with your pain, as I have since this post.</strong></em></p>\n<p><strong>Prolog (Head :- Body)</strong></p>\n<p>I wrote a story in first grade called <em>My Trip to the Vet.</em> \u00a0It won some low level award for its use of big words and long sentences. \u00a0This tid-bit of encouragement got me,\u00a0eventually,\u00a0into F. Scott Fitzgerald and the like. \u00a0It took years of globetrotting Hemingway literary therapy for the short-sentence cure. \u00a0Which was then destroyed by Kerouac and his endless benzedrine fueled run-ons. \u00a0It didn&rsquo;t hurt that I was reading him while medicated with Adderall (dextroamphetamine and amphetamine) for my Attention Deficit Disorder, so in his nonsense I felt a special kinship.</p>\n<p><strong>This story is like that one, just 25 years later. \u00a0I&rsquo;ve changed little.</strong></p>\n<p><strong>One thing has changed over the last year:</strong></p>\n<p>I hurt all the time. \u00a0My pain scale is different than yours. \u00a0It goes to 11. \u00a0Moving makes it worse. \u00a0<img height=\"240\" width=\"240\" src=\"http://farm6.static.flickr.com/5177/5512129551_d692b05754_m.jpg\" align=\"left\"/>Something is bad wrong with the facet joints in my neck. \u00a0The nerves that innervate my entire upper back and arms run right by these joints. \u00a0This renders me unable to use my arms for sustained periods without my pain going off the scale. \u00a0To address this problem, I&rsquo;ve tried (4x) medial branch blocks and (2x) pulsed radio-frequency ablation, oral and topical non-steroidal anti-inflamatory drugs, corticosteroids, COX inhibitors, anticonvulsants, muscle relaxers, high-dose selective seratonin-norepinephrine reuptake inhibitors, heat, ice, transcutaneous electrical nerve stimulation, electrical muscle stimulation, traction, herbs, chinese medicine, tiger balms, capsaicin patches and creams, opiates, acupuncture,\u00a0pain psychology,\u00a0restorative yoga, vitamins and supplements, massage therapy, physical therapy, bed rest, feldenkrais, pain classes, self-help books, and via lidocaine injections - <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Prolotherapy\">prolotheraphy</a>.</p>\n<p>The current drug regimen looks like this:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6169/6196827616_96db54421f_m.jpg\" align=\"middle\"/></p>\n<p>All the medicine and the backup regimens, plus the medical waste, look like this:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6030/6196830626_99651e8b70_m.jpg\" align=\"middle\"/></p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6013/6196877900_b398b8debd_m.jpg\" align=\"middle\"/></p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6002/6196478737_8314d587e4_m.jpg\" align=\"middle\"/></p>\n<p>Or even:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6177/6196501715_a102fbb730_m.jpg\" align=\"middle\"/></p>\n<p>Thats a long way of saying that my quality of life sucks, and that I&rsquo;m looking for a cure. \u00a0Boo hoo. \u00a0Starving children and all that. \u00a0At least I don&rsquo;t have cancer. \u00a0I&rsquo;m not dying. It just feels like I&rsquo;m dying. \u00a0</p>\n<p>The severe pain that won&rsquo;t go away tells my brain I&rsquo;m terribly injured, and just like a house cat that runs off into the woods to die in a nook or cranny, there&rsquo;s a tendency to not want to move. \u00a0Pain avoidance. \u00a0Each day is consciousness over instinct. \u00a0Knowing what my body is telling me isn&rsquo;t real and overcoming it. \u00a0</p>\n<p>Regardless, I take extreme measures to enjoy the little things.</p>\n<p><strong>My trip to the beach</strong></p>\n<p>We started by numbing the terminal nociceptors in the upper half of my neck and back with 180mg of liquid Ropivacaine\u00a0(most of 10ml @ 2%). \u00a0This involves alcohol prep of the entire area, and between 20 and 30 intramuscular injections with\u00a01/2&quot;, 28 gauge insulin needles, in those muscles innervated by the cervical nerves C3 through C7. \u00a0I&rsquo;ll spare you a shot of my hairy back, but you can use your imagination via this chart:</p>\n<p><a target=\"_blank\" href=\"http://farm7.static.flickr.com/6179/6197207058_7569552bbd_o.png\"><img height=\"170\" width=\"240\" src=\"http://farm7.static.flickr.com/6179/6197207058_b6ebf79d3d_m.jpg\" align=\"middle\"/></a></p>\n<p>Before:</p>\n<p><img height=\"240\" width=\"240\" alt=\"Applying Ropivacaine\" src=\"http://farm7.static.flickr.com/6179/6196221061_bb6d7bdd21_m.jpg\" align=\"middle\"/></p>\n<p>After:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6173/6196306461_3ce12508c2_m.jpg\" align=\"middle\"/></p>\n<p>I&rsquo;ve been using lidocaine patches for almost a year, and lidocaine injections for a few months. \u00a0Lidocaine is great, but patches aren&rsquo;t very effective for neuropathy (or swimming), and injections only last 2-3 hours - with some lingering effect. \u00a0That means between 5 and 8 rounds of injections a day, for a total of between 100 and 240 pokes per day. \u00a0This might be a great solution if I had a nurse on hand to inject my back all day. \u00a0But I can only get so far without help, so the short half-life of lidocaine is a problem. \u00a0By the time I got home from the beach, the lidocaine would be wearing off, and I&rsquo;d be in a world of pain all night - injecting over and over again, every few hours, or shaved and covered in patches and creams.\u00a0</p>\n<p>Lidocaine is harmless stuff compared to longer acting alternatives. \u00a0You&rsquo;re probably familiar with Xylocaine (lidocaine) at your Dentist&rsquo;s office, and you&rsquo;ve probably asked for more of the stuff through a nitrous mask.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6126/6196664727_67d64bb24a_m.jpg\" align=\"middle\"/></p>\n<p>Marcaine (bupivacaine) lasts about 12 hours, and is used extensively in epidurals and nerve blocks. \u00a0It is markedly cardiotoxic when it enters the bloodstream, and can occasionally cause life-threatening complications to patients when accidentally injected intravenously. \u00a0In my case, with daily injections, an accidental intravenous injection is inevitable. \u00a0So a safer, longer acting agent is required.</p>\n<p>Naropin (ropivacaine) is a pure S-(-) enantiomer, an alternative to bupivacaine\u00a0engineered to be\u00a0less cardiotoxic. It can last as long as 24 hours. \u00a0It is new, and expensive. \u00a0And its only ever killed one person. \u00a0And I got some. \u00a0So I can go to the beach. \u00a0Without Ropivacaine, last time I went to the beach I called the emergency line at my pain clinic for an emergency prescription and stormed the aisles of the nearest pharmacy, applying topical medicine after topical medicine before paying, in an attempt to find relief. \u00a0One gets tired of going to urgent care or the ER, which looks like this after hours of waiting:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm6.static.flickr.com/5102/5578452839_1729696ac1_m.jpg\" align=\"middle\"/></p>\n<p>It takes about 15 minutes to saturate my lats, rear delt, neck, rhomboids (pull out your anatomy book), and several strange, scary, ropy bastards I can&rsquo;t identify except in this picture and by when they are 'on&rsquo; - OW - or 'off&rsquo; - not there.</p>\n<p><img height=\"173\" width=\"240\" src=\"http://farm7.static.flickr.com/6012/6196763408_fbbcb7ebce_m.jpg\" align=\"middle\"/></p>\n<p><strong>No, REALLY, my trip to the beach</strong></p>\n<p>I found my wetsuit in the back of my closet and threw it in the car.<img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6166/6196978754_b59f868b44_m.jpg\" align=\"middle\"/></p>\n<p>I drove to the beach. \u00a0I haven&rsquo;t been able to drive for a while because I was on pain medication that prevented it. \u00a0This Ropivacaine business is a trick to get round that. \u00a0Linda Mar is a few miles by Hwy 1.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6134/6196390555_df7acc2f2c_m.jpg\" align=\"middle\"/></p>\n<p>The clouds blocked the sun. \u00a0It was dark by the time I got there. \u00a0Pedro&rsquo;s point looks just like\u00a0<em>Goonies</em>, huh? \u00a0In this highly medicated 80s flashback, I am Chunk and the ship is rounding Pedro&rsquo;s point as the kids scream and the adults stand open mouth and dumb-founded.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6160/6196401119_d3f623c04c_m.jpg\" align=\"middle\"/></p>\n<p>I donned my wetsuit and hit the water. \u00a0It was very low tide. \u00a0I body surfed a little, jumping off the sand into each wave. \u00a0I&rsquo;m not very good at that, or surfing at all, but I&rsquo;m a decent swimmer. \u00a0When I&rsquo;m in practice. \u00a0The water was warm - for Linda Mar. \u00a0Which means it was still freezing. \u00a0I got ice cream headache. \u00a0I love ice cream headache.</p>\n<p>I came back in, washed the salt off under the outdoor showers that dispense mere mililiters of water per button push (push, push, push, push, push&hellip;), and went home feeling myself again. \u00a0</p>\n<p>If only for a little while.</p>", "liked": false, "followed": false, "reblog_key": "r3M7MWq6", "reblog": {"comment": "<p><strong>Disclaimer</strong></p>\n<p><em>I am not a doctor. \u00a0I didn\u2019t even finish my biology degree. \u00a0I failed out of a state school with a scarred liver,\u00a0severe\u00a0hemorrhoids and a working knowledge of Rooskie mat (Russian cursing). \u00a0I am not giving medical advice. \u00a0I\u2019m just going to the beach. \u00a0In fact, you should consider this entire post pure fantasy - a \u2018what if\u2019 scenario, if I could go swimming again! \u00a0If you listen to me, instead of your doctor, and act out anything documented in this blog post, you are the worst kind of fool. \u00a0<strong>Do not try this at home.<br><br>This post was a dead end treatment path for pain. Injecting your muscles to numb them is a bad idea. You need to learn to live with your pain, as I have since this post.</strong></em></p>\n<p><strong>Prolog (Head :- Body)</strong></p>\n<p>I wrote a story in first grade called <em>My Trip to the Vet.</em> \u00a0It won some low level award for its use of big words and long sentences. \u00a0This tid-bit of encouragement got me,\u00a0eventually,\u00a0into F. Scott Fitzgerald and the like. \u00a0It took years of globetrotting Hemingway literary therapy for the short-sentence cure. \u00a0Which was then destroyed by Kerouac and his endless benzedrine fueled run-ons. \u00a0It didn\u2019t hurt that I was reading him while medicated with Adderall (dextroamphetamine and amphetamine) for my Attention Deficit Disorder, so in his nonsense I felt a special kinship.</p>\n<p><strong>This story is like that one, just 25 years later. \u00a0I\u2019ve changed little.</strong></p>\n<p><strong>One thing has changed over the last year:</strong></p>\n<p>I hurt all the time. \u00a0My pain scale is different than yours. \u00a0It goes to 11. \u00a0Moving makes it worse. \u00a0<img height=\"240\" width=\"240\" src=\"http://farm6.static.flickr.com/5177/5512129551_d692b05754_m.jpg\" align=\"left\">Something is bad wrong with the facet joints in my neck. \u00a0The nerves that innervate my entire upper back and arms run right by these joints. \u00a0This renders me unable to use my arms for sustained periods without my pain going off the scale. \u00a0To address this problem, I\u2019ve tried (4x) medial branch blocks and (2x) pulsed radio-frequency ablation, oral and topical non-steroidal anti-inflamatory drugs, corticosteroids, COX inhibitors, anticonvulsants, muscle relaxers, high-dose selective seratonin-norepinephrine reuptake inhibitors, heat, ice, transcutaneous electrical nerve stimulation, electrical muscle stimulation, traction, herbs, chinese medicine, tiger balms, capsaicin patches and creams, opiates, acupuncture,\u00a0pain psychology,\u00a0restorative yoga, vitamins and supplements, massage therapy, physical therapy, bed rest, feldenkrais, pain classes, self-help books, and via lidocaine injections - <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Prolotherapy\">prolotheraphy</a>.</p>\n<p>The current drug regimen looks like this:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6169/6196827616_96db54421f_m.jpg\" align=\"middle\"></p>\n<p>All the medicine and the backup regimens, plus the medical waste, look like this:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6030/6196830626_99651e8b70_m.jpg\" align=\"middle\"></p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6013/6196877900_b398b8debd_m.jpg\" align=\"middle\"></p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6002/6196478737_8314d587e4_m.jpg\" align=\"middle\"></p>\n<p>Or even:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6177/6196501715_a102fbb730_m.jpg\" align=\"middle\"></p>\n<p>Thats a long way of saying that my quality of life sucks, and that I\u2019m looking for a cure. \u00a0Boo hoo. \u00a0Starving children and all that. \u00a0At least I don\u2019t have cancer. \u00a0I\u2019m not dying. It just feels like I\u2019m dying. \u00a0</p>\n<p>The severe pain that won\u2019t go away tells my brain I\u2019m terribly injured, and just like a house cat that runs off into the woods to die in a nook or cranny, there\u2019s a tendency to not want to move. \u00a0Pain avoidance. \u00a0Each day is consciousness over instinct. \u00a0Knowing what my body is telling me isn\u2019t real and overcoming it. \u00a0</p>\n<p>Regardless, I take extreme measures to enjoy the little things.</p>\n<p><strong>My trip to the beach</strong></p>\n<p>We started by numbing the terminal nociceptors in the upper half of my neck and back with 180mg of liquid Ropivacaine\u00a0(most of 10ml @ 2%). \u00a0This involves alcohol prep of the entire area, and between 20 and 30 intramuscular injections with\u00a01/2\", 28 gauge insulin needles, in those muscles innervated by the cervical nerves C3 through C7. \u00a0I\u2019ll spare you a shot of my hairy back, but you can use your imagination via this chart:</p>\n<p><a target=\"_blank\" href=\"http://farm7.static.flickr.com/6179/6197207058_7569552bbd_o.png\"><img height=\"170\" width=\"240\" src=\"http://farm7.static.flickr.com/6179/6197207058_b6ebf79d3d_m.jpg\" align=\"middle\"></a></p>\n<p>Before:</p>\n<p><img height=\"240\" width=\"240\" alt=\"Applying Ropivacaine\" src=\"http://farm7.static.flickr.com/6179/6196221061_bb6d7bdd21_m.jpg\" align=\"middle\"></p>\n<p>After:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6173/6196306461_3ce12508c2_m.jpg\" align=\"middle\"></p>\n<p>I\u2019ve been using lidocaine patches for almost a year, and lidocaine injections for a few months. \u00a0Lidocaine is great, but patches aren\u2019t very effective for neuropathy (or swimming), and injections only last 2-3 hours - with some lingering effect. \u00a0That means between 5 and 8 rounds of injections a day, for a total of between 100 and 240 pokes per day. \u00a0This might be a great solution if I had a nurse on hand to inject my back all day. \u00a0But I can only get so far without help, so the short half-life of lidocaine is a problem. \u00a0By the time I got home from the beach, the lidocaine would be wearing off, and I\u2019d be in a world of pain all night - injecting over and over again, every few hours, or shaved and covered in patches and creams.\u00a0</p>\n<p>Lidocaine is harmless stuff compared to longer acting alternatives. \u00a0You\u2019re probably familiar with Xylocaine (lidocaine) at your Dentist\u2019s office, and you\u2019ve probably asked for more of the stuff through a nitrous mask.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6126/6196664727_67d64bb24a_m.jpg\" align=\"middle\"></p>\n<p>Marcaine (bupivacaine) lasts about 12 hours, and is used extensively in epidurals and nerve blocks. \u00a0It is markedly cardiotoxic when it enters the bloodstream, and can occasionally cause life-threatening complications to patients when accidentally injected intravenously. \u00a0In my case, with daily injections, an accidental intravenous injection is inevitable. \u00a0So a safer, longer acting agent is required.</p>\n<p>Naropin (ropivacaine) is a pure S-(-) enantiomer, an alternative to bupivacaine\u00a0engineered to be\u00a0less cardiotoxic. It can last as long as 24 hours. \u00a0It is new, and expensive. \u00a0And its only ever killed one person. \u00a0And I got some. \u00a0So I can go to the beach. \u00a0Without Ropivacaine, last time I went to the beach I called the emergency line at my pain clinic for an emergency prescription and stormed the aisles of the nearest pharmacy, applying topical medicine after topical medicine before paying, in an attempt to find relief. \u00a0One gets tired of going to urgent care or the ER, which looks like this after hours of waiting:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm6.static.flickr.com/5102/5578452839_1729696ac1_m.jpg\" align=\"middle\"></p>\n<p>It takes about 15 minutes to saturate my lats, rear delt, neck, rhomboids (pull out your anatomy book), and several strange, scary, ropy bastards I can\u2019t identify except in this picture and by when they are 'on\u2019 - OW - or 'off\u2019 - not there.</p>\n<p><img height=\"173\" width=\"240\" src=\"http://farm7.static.flickr.com/6012/6196763408_fbbcb7ebce_m.jpg\" align=\"middle\"></p>\n<p><strong>No, REALLY, my trip to the beach</strong></p>\n<p>I found my wetsuit in the back of my closet and threw it in the car.<img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6166/6196978754_b59f868b44_m.jpg\" align=\"middle\"></p>\n<p>I drove to the beach. \u00a0I haven\u2019t been able to drive for a while because I was on pain medication that prevented it. \u00a0This Ropivacaine business is a trick to get round that. \u00a0Linda Mar is a few miles by Hwy 1.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6134/6196390555_df7acc2f2c_m.jpg\" align=\"middle\"></p>\n<p>The clouds blocked the sun. \u00a0It was dark by the time I got there. \u00a0Pedro\u2019s point looks just like\u00a0<em>Goonies</em>, huh? \u00a0In this highly medicated 80s flashback, I am Chunk and the ship is rounding Pedro\u2019s point as the kids scream and the adults stand open mouth and dumb-founded.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6160/6196401119_d3f623c04c_m.jpg\" align=\"middle\"></p>\n<p>I donned my wetsuit and hit the water. \u00a0It was very low tide. \u00a0I body surfed a little, jumping off the sand into each wave. \u00a0I\u2019m not very good at that, or surfing at all, but I\u2019m a decent swimmer. \u00a0When I\u2019m in practice. \u00a0The water was warm - for Linda Mar. \u00a0Which means it was still freezing. \u00a0I got ice cream headache. \u00a0I love ice cream headache.</p>\n<p>I came back in, washed the salt off under the outdoor showers that dispense mere mililiters of water per button push (push, push, push, push, push\u2026), and went home feeling myself again. \u00a0</p>\n<p>If only for a little while.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 10840025976, "display_avatar": true, "can_reply": true, "can_like": false, "title": "My Trip to the Beach", "tags": [], "post_url": "http://datasyndrome.com/post/10840025976/my-trip-to-the-beach", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5yA67Qju", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1317362760, "note_count": 0, "trail": [{"content": "<p><strong>Disclaimer</strong></p>\n<p><em>I am not a doctor. &nbsp;I didn&rsquo;t even finish my biology degree. &nbsp;I failed out of a state school with a scarred liver,&nbsp;severe&nbsp;hemorrhoids and a working knowledge of Rooskie mat (Russian cursing). &nbsp;I am not giving medical advice. &nbsp;I&rsquo;m just going to the beach. &nbsp;In fact, you should consider this entire post pure fantasy - a &lsquo;what if&rsquo; scenario, if I could go swimming again! &nbsp;If you listen to me, instead of your doctor, and act out anything documented in this blog post, you are the worst kind of fool. &nbsp;<strong>Do not try this at home.<br /><br />This post was a dead end treatment path for pain. Injecting your muscles to numb them is a bad idea. You need to learn to live with your pain, as I have since this post.</strong></em></p>\n<p><strong>Prolog (Head :- Body)</strong></p>\n<p>I wrote a story in first grade called <em>My Trip to the Vet.</em> &nbsp;It won some low level award for its use of big words and long sentences. &nbsp;This tid-bit of encouragement got me,&nbsp;eventually,&nbsp;into F. Scott Fitzgerald and the like. &nbsp;It took years of globetrotting Hemingway literary therapy for the short-sentence cure. &nbsp;Which was then destroyed by Kerouac and his endless benzedrine fueled run-ons. &nbsp;It didn&rsquo;t hurt that I was reading him while medicated with Adderall (dextroamphetamine and amphetamine) for my Attention Deficit Disorder, so in his nonsense I felt a special kinship.</p>\n<p><strong>This story is like that one, just 25 years later. &nbsp;I&rsquo;ve changed little.</strong></p>\n<p><strong>One thing has changed over the last year:</strong></p>\n<p>I hurt all the time. &nbsp;My pain scale is different than yours. &nbsp;It goes to 11. &nbsp;Moving makes it worse. &nbsp;<div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm6.static.flickr.com/5177/5512129551_d692b05754_m.jpg\">External image</div>Something is bad wrong with the facet joints in my neck. &nbsp;The nerves that innervate my entire upper back and arms run right by these joints. &nbsp;This renders me unable to use my arms for sustained periods without my pain going off the scale. &nbsp;To address this problem, I&rsquo;ve tried (4x) medial branch blocks and (2x) pulsed radio-frequency ablation, oral and topical non-steroidal anti-inflamatory drugs, corticosteroids, COX inhibitors, anticonvulsants, muscle relaxers, high-dose selective seratonin-norepinephrine reuptake inhibitors, heat, ice, transcutaneous electrical nerve stimulation, electrical muscle stimulation, traction, herbs, chinese medicine, tiger balms, capsaicin patches and creams, opiates, acupuncture,&nbsp;pain psychology,&nbsp;restorative yoga, vitamins and supplements, massage therapy, physical therapy, bed rest, feldenkrais, pain classes, self-help books, and via lidocaine injections - <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Prolotherapy\">prolotheraphy</a>.</p>\n<p>The current drug regimen looks like this:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6169/6196827616_96db54421f_m.jpg\">External image</div></p>\n<p>All the medicine and the backup regimens, plus the medical waste, look like this:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6030/6196830626_99651e8b70_m.jpg\">External image</div></p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6013/6196877900_b398b8debd_m.jpg\">External image</div></p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6002/6196478737_8314d587e4_m.jpg\">External image</div></p>\n<p>Or even:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6177/6196501715_a102fbb730_m.jpg\">External image</div></p>\n<p>Thats a long way of saying that my quality of life sucks, and that I&rsquo;m looking for a cure. &nbsp;Boo hoo. &nbsp;Starving children and all that. &nbsp;At least I don&rsquo;t have cancer. &nbsp;I&rsquo;m not dying. It just feels like I&rsquo;m dying. &nbsp;</p>\n<p>The severe pain that won&rsquo;t go away tells my brain I&rsquo;m terribly injured, and just like a house cat that runs off into the woods to die in a nook or cranny, there&rsquo;s a tendency to not want to move. &nbsp;Pain avoidance. &nbsp;Each day is consciousness over instinct. &nbsp;Knowing what my body is telling me isn&rsquo;t real and overcoming it. &nbsp;</p>\n<p>Regardless, I take extreme measures to enjoy the little things.</p>\n<p><strong>My trip to the beach</strong></p>\n<p>We started by numbing the terminal nociceptors in the upper half of my neck and back with 180mg of liquid Ropivacaine&nbsp;(most of 10ml @ 2%). &nbsp;This involves alcohol prep of the entire area, and between 20 and 30 intramuscular injections with&nbsp;1/2\", 28 gauge insulin needles, in those muscles innervated by the cervical nerves C3 through C7. &nbsp;I&rsquo;ll spare you a shot of my hairy back, but you can use your imagination via this chart:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6179/6197207058_b6ebf79d3d_m.jpg\">External image</div></p>\n<p>Before:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6179/6196221061_bb6d7bdd21_m.jpg\">External image</div></p>\n<p>After:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6173/6196306461_3ce12508c2_m.jpg\">External image</div></p>\n<p>I&rsquo;ve been using lidocaine patches for almost a year, and lidocaine injections for a few months. &nbsp;Lidocaine is great, but patches aren&rsquo;t very effective for neuropathy (or swimming), and injections only last 2-3 hours - with some lingering effect. &nbsp;That means between 5 and 8 rounds of injections a day, for a total of between 100 and 240 pokes per day. &nbsp;This might be a great solution if I had a nurse on hand to inject my back all day. &nbsp;But I can only get so far without help, so the short half-life of lidocaine is a problem. &nbsp;By the time I got home from the beach, the lidocaine would be wearing off, and I&rsquo;d be in a world of pain all night - injecting over and over again, every few hours, or shaved and covered in patches and creams.&nbsp;</p>\n<p>Lidocaine is harmless stuff compared to longer acting alternatives. &nbsp;You&rsquo;re probably familiar with Xylocaine (lidocaine) at your Dentist&rsquo;s office, and you&rsquo;ve probably asked for more of the stuff through a nitrous mask.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6126/6196664727_67d64bb24a_m.jpg\">External image</div></p>\n<p>Marcaine (bupivacaine) lasts about 12 hours, and is used extensively in epidurals and nerve blocks. &nbsp;It is markedly cardiotoxic when it enters the bloodstream, and can occasionally cause life-threatening complications to patients when accidentally injected intravenously. &nbsp;In my case, with daily injections, an accidental intravenous injection is inevitable. &nbsp;So a safer, longer acting agent is required.</p>\n<p>Naropin (ropivacaine) is a pure S-(-) enantiomer, an alternative to bupivacaine&nbsp;engineered to be&nbsp;less cardiotoxic. It can last as long as 24 hours. &nbsp;It is new, and expensive. &nbsp;And its only ever killed one person. &nbsp;And I got some. &nbsp;So I can go to the beach. &nbsp;Without Ropivacaine, last time I went to the beach I called the emergency line at my pain clinic for an emergency prescription and stormed the aisles of the nearest pharmacy, applying topical medicine after topical medicine before paying, in an attempt to find relief. &nbsp;One gets tired of going to urgent care or the ER, which looks like this after hours of waiting:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm6.static.flickr.com/5102/5578452839_1729696ac1_m.jpg\">External image</div></p>\n<p>It takes about 15 minutes to saturate my lats, rear delt, neck, rhomboids (pull out your anatomy book), and several strange, scary, ropy bastards I can&rsquo;t identify except in this picture and by when they are 'on&rsquo; - OW - or 'off&rsquo; - not there.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6012/6196763408_fbbcb7ebce_m.jpg\">External image</div></p>\n<p><strong>No, REALLY, my trip to the beach</strong></p>\n<p>I found my wetsuit in the back of my closet and threw it in the car.<div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6166/6196978754_b59f868b44_m.jpg\">External image</div></p>\n<p>I drove to the beach. &nbsp;I haven&rsquo;t been able to drive for a while because I was on pain medication that prevented it. &nbsp;This Ropivacaine business is a trick to get round that. &nbsp;Linda Mar is a few miles by Hwy 1.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6134/6196390555_df7acc2f2c_m.jpg\">External image</div></p>\n<p>The clouds blocked the sun. &nbsp;It was dark by the time I got there. &nbsp;Pedro&rsquo;s point looks just like&nbsp;<em>Goonies</em>, huh? &nbsp;In this highly medicated 80s flashback, I am Chunk and the ship is rounding Pedro&rsquo;s point as the kids scream and the adults stand open mouth and dumb-founded.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm7.static.flickr.com/6160/6196401119_d3f623c04c_m.jpg\">External image</div></p>\n<p>I donned my wetsuit and hit the water. &nbsp;It was very low tide. &nbsp;I body surfed a little, jumping off the sand into each wave. &nbsp;I&rsquo;m not very good at that, or surfing at all, but I&rsquo;m a decent swimmer. &nbsp;When I&rsquo;m in practice. &nbsp;The water was warm - for Linda Mar. &nbsp;Which means it was still freezing. &nbsp;I got ice cream headache. &nbsp;I love ice cream headache.</p>\n<p>I came back in, washed the salt off under the outdoor showers that dispense mere mililiters of water per button push (push, push, push, push, push&hellip;), and went home feeling myself again. &nbsp;</p>\n<p>If only for a little while.</p>", "content_raw": "<p><strong>Disclaimer</strong></p>\n<p><em>I am not a doctor. \u00a0I didn\u2019t even finish my biology degree. \u00a0I failed out of a state school with a scarred liver,\u00a0severe\u00a0hemorrhoids and a working knowledge of Rooskie mat (Russian cursing). \u00a0I am not giving medical advice. \u00a0I\u2019m just going to the beach. \u00a0In fact, you should consider this entire post pure fantasy - a \u2018what if\u2019 scenario, if I could go swimming again! \u00a0If you listen to me, instead of your doctor, and act out anything documented in this blog post, you are the worst kind of fool. \u00a0<strong>Do not try this at home.<br><br>This post was a dead end treatment path for pain. Injecting your muscles to numb them is a bad idea. You need to learn to live with your pain, as I have since this post.</strong></em></p>\n<p><strong>Prolog (Head :- Body)</strong></p>\n<p>I wrote a story in first grade called <em>My Trip to the Vet.</em> \u00a0It won some low level award for its use of big words and long sentences. \u00a0This tid-bit of encouragement got me,\u00a0eventually,\u00a0into F. Scott Fitzgerald and the like. \u00a0It took years of globetrotting Hemingway literary therapy for the short-sentence cure. \u00a0Which was then destroyed by Kerouac and his endless benzedrine fueled run-ons. \u00a0It didn\u2019t hurt that I was reading him while medicated with Adderall (dextroamphetamine and amphetamine) for my Attention Deficit Disorder, so in his nonsense I felt a special kinship.</p>\n<p><strong>This story is like that one, just 25 years later. \u00a0I\u2019ve changed little.</strong></p>\n<p><strong>One thing has changed over the last year:</strong></p>\n<p>I hurt all the time. \u00a0My pain scale is different than yours. \u00a0It goes to 11. \u00a0Moving makes it worse. \u00a0<img height=\"240\" width=\"240\" src=\"http://farm6.static.flickr.com/5177/5512129551_d692b05754_m.jpg\" align=\"left\">Something is bad wrong with the facet joints in my neck. \u00a0The nerves that innervate my entire upper back and arms run right by these joints. \u00a0This renders me unable to use my arms for sustained periods without my pain going off the scale. \u00a0To address this problem, I\u2019ve tried (4x) medial branch blocks and (2x) pulsed radio-frequency ablation, oral and topical non-steroidal anti-inflamatory drugs, corticosteroids, COX inhibitors, anticonvulsants, muscle relaxers, high-dose selective seratonin-norepinephrine reuptake inhibitors, heat, ice, transcutaneous electrical nerve stimulation, electrical muscle stimulation, traction, herbs, chinese medicine, tiger balms, capsaicin patches and creams, opiates, acupuncture,\u00a0pain psychology,\u00a0restorative yoga, vitamins and supplements, massage therapy, physical therapy, bed rest, feldenkrais, pain classes, self-help books, and via lidocaine injections - <a target=\"_blank\" href=\"http://en.wikipedia.org/wiki/Prolotherapy\">prolotheraphy</a>.</p>\n<p>The current drug regimen looks like this:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6169/6196827616_96db54421f_m.jpg\" align=\"middle\"></p>\n<p>All the medicine and the backup regimens, plus the medical waste, look like this:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6030/6196830626_99651e8b70_m.jpg\" align=\"middle\"></p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6013/6196877900_b398b8debd_m.jpg\" align=\"middle\"></p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6002/6196478737_8314d587e4_m.jpg\" align=\"middle\"></p>\n<p>Or even:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6177/6196501715_a102fbb730_m.jpg\" align=\"middle\"></p>\n<p>Thats a long way of saying that my quality of life sucks, and that I\u2019m looking for a cure. \u00a0Boo hoo. \u00a0Starving children and all that. \u00a0At least I don\u2019t have cancer. \u00a0I\u2019m not dying. It just feels like I\u2019m dying. \u00a0</p>\n<p>The severe pain that won\u2019t go away tells my brain I\u2019m terribly injured, and just like a house cat that runs off into the woods to die in a nook or cranny, there\u2019s a tendency to not want to move. \u00a0Pain avoidance. \u00a0Each day is consciousness over instinct. \u00a0Knowing what my body is telling me isn\u2019t real and overcoming it. \u00a0</p>\n<p>Regardless, I take extreme measures to enjoy the little things.</p>\n<p><strong>My trip to the beach</strong></p>\n<p>We started by numbing the terminal nociceptors in the upper half of my neck and back with 180mg of liquid Ropivacaine\u00a0(most of 10ml @ 2%). \u00a0This involves alcohol prep of the entire area, and between 20 and 30 intramuscular injections with\u00a01/2\", 28 gauge insulin needles, in those muscles innervated by the cervical nerves C3 through C7. \u00a0I\u2019ll spare you a shot of my hairy back, but you can use your imagination via this chart:</p>\n<p><a target=\"_blank\" href=\"http://farm7.static.flickr.com/6179/6197207058_7569552bbd_o.png\"><img height=\"170\" width=\"240\" src=\"http://farm7.static.flickr.com/6179/6197207058_b6ebf79d3d_m.jpg\" align=\"middle\"></a></p>\n<p>Before:</p>\n<p><img height=\"240\" width=\"240\" alt=\"Applying Ropivacaine\" src=\"http://farm7.static.flickr.com/6179/6196221061_bb6d7bdd21_m.jpg\" align=\"middle\"></p>\n<p>After:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6173/6196306461_3ce12508c2_m.jpg\" align=\"middle\"></p>\n<p>I\u2019ve been using lidocaine patches for almost a year, and lidocaine injections for a few months. \u00a0Lidocaine is great, but patches aren\u2019t very effective for neuropathy (or swimming), and injections only last 2-3 hours - with some lingering effect. \u00a0That means between 5 and 8 rounds of injections a day, for a total of between 100 and 240 pokes per day. \u00a0This might be a great solution if I had a nurse on hand to inject my back all day. \u00a0But I can only get so far without help, so the short half-life of lidocaine is a problem. \u00a0By the time I got home from the beach, the lidocaine would be wearing off, and I\u2019d be in a world of pain all night - injecting over and over again, every few hours, or shaved and covered in patches and creams.\u00a0</p>\n<p>Lidocaine is harmless stuff compared to longer acting alternatives. \u00a0You\u2019re probably familiar with Xylocaine (lidocaine) at your Dentist\u2019s office, and you\u2019ve probably asked for more of the stuff through a nitrous mask.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6126/6196664727_67d64bb24a_m.jpg\" align=\"middle\"></p>\n<p>Marcaine (bupivacaine) lasts about 12 hours, and is used extensively in epidurals and nerve blocks. \u00a0It is markedly cardiotoxic when it enters the bloodstream, and can occasionally cause life-threatening complications to patients when accidentally injected intravenously. \u00a0In my case, with daily injections, an accidental intravenous injection is inevitable. \u00a0So a safer, longer acting agent is required.</p>\n<p>Naropin (ropivacaine) is a pure S-(-) enantiomer, an alternative to bupivacaine\u00a0engineered to be\u00a0less cardiotoxic. It can last as long as 24 hours. \u00a0It is new, and expensive. \u00a0And its only ever killed one person. \u00a0And I got some. \u00a0So I can go to the beach. \u00a0Without Ropivacaine, last time I went to the beach I called the emergency line at my pain clinic for an emergency prescription and stormed the aisles of the nearest pharmacy, applying topical medicine after topical medicine before paying, in an attempt to find relief. \u00a0One gets tired of going to urgent care or the ER, which looks like this after hours of waiting:</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm6.static.flickr.com/5102/5578452839_1729696ac1_m.jpg\" align=\"middle\"></p>\n<p>It takes about 15 minutes to saturate my lats, rear delt, neck, rhomboids (pull out your anatomy book), and several strange, scary, ropy bastards I can\u2019t identify except in this picture and by when they are 'on\u2019 - OW - or 'off\u2019 - not there.</p>\n<p><img height=\"173\" width=\"240\" src=\"http://farm7.static.flickr.com/6012/6196763408_fbbcb7ebce_m.jpg\" align=\"middle\"></p>\n<p><strong>No, REALLY, my trip to the beach</strong></p>\n<p>I found my wetsuit in the back of my closet and threw it in the car.<img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6166/6196978754_b59f868b44_m.jpg\" align=\"middle\"></p>\n<p>I drove to the beach. \u00a0I haven\u2019t been able to drive for a while because I was on pain medication that prevented it. \u00a0This Ropivacaine business is a trick to get round that. \u00a0Linda Mar is a few miles by Hwy 1.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6134/6196390555_df7acc2f2c_m.jpg\" align=\"middle\"></p>\n<p>The clouds blocked the sun. \u00a0It was dark by the time I got there. \u00a0Pedro\u2019s point looks just like\u00a0<em>Goonies</em>, huh? \u00a0In this highly medicated 80s flashback, I am Chunk and the ship is rounding Pedro\u2019s point as the kids scream and the adults stand open mouth and dumb-founded.</p>\n<p><img height=\"240\" width=\"240\" src=\"http://farm7.static.flickr.com/6160/6196401119_d3f623c04c_m.jpg\" align=\"middle\"></p>\n<p>I donned my wetsuit and hit the water. \u00a0It was very low tide. \u00a0I body surfed a little, jumping off the sand into each wave. \u00a0I\u2019m not very good at that, or surfing at all, but I\u2019m a decent swimmer. \u00a0When I\u2019m in practice. \u00a0The water was warm - for Linda Mar. \u00a0Which means it was still freezing. \u00a0I got ice cream headache. \u00a0I love ice cream headache.</p>\n<p>I came back in, washed the salt off under the outdoor showers that dispense mere mililiters of water per button push (push, push, push, push, push\u2026), and went home feeling myself again. \u00a0</p>\n<p>If only for a little while.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "10840025976"}}], "date": "2011-09-30 06:06:00 GMT", "slug": "my-trip-to-the-beach", "blog_name": "rjurney", "summary": "My Trip to the Beach", "can_reblog": true}, {"body": "<blockquote>\u201cWhenever data sparsity is an issue, smoothing can help performance,and data sparsity is almost always an issue in statistical modeling. <strong>In the\u00a0</strong><strong>extreme case where there is so much training data that all parameters</strong><strong>can be accurately trained without smoothing, one can almost always\u00a0</strong><strong>expand the model, such as by moving to a higher n-gram model, to\u00a0</strong><strong>achieve improved performance.</strong> With more parameters data sparsity becomes an issue again, but with proper smoothing the models areusually more accurate than the original models. Thus, no matter how much data one has, smoothing can almost always help performace, and for a relatively small e\ufb00ort.\u201d<br/>Chen &amp; Goodman (1998)</blockquote>\n<p>From a <a href=\"http://Whenever%20data%20sparsity%20is%20an%20issue,%20smoothing%20can%20help%20performance,%20and%20data%20sparsity%20is%20almost%20always%20an%20issue%20in%20statistical%20modeling.%20In%20the%20extreme%20case%20where%20there%20is%20so%20much%20training%20data%20that%20all%20parameters%20can%20be%20accurately%20trained%20without%20smoothing,%20one%20can%20almost%20always%20expand%20the%20model,%20such%20as%20by%20moving%20to%20a%20higher%20n-gram%20model,%20to%20achieve%20improved%20performance.%20With%20more%20parameters%20data%20sparsity%20becomes%20an%20issue%20again,%20but%20with%20proper%20smoothing%20the%20models%20are%20usually%20more%20accurate%20than%20the%20original%20models.%20Thus,%20no%20matter%20how%20much%20data%20one%20has,%20smoothing%20can%20almost%20always%20help%20performace,%20and%20for%20a%20relatively%20small%20e%EF%AC%80ort.%20Chen%20&amp;%20Goodman%20(1998)\">smoothing tutorial</a>\u00a0at Stanford.</p>", "liked": false, "followed": false, "reblog_key": "8sKp3jSe", "reblog": {"comment": "<p><blockquote>\u201cWhenever data sparsity is an issue, smoothing can help performance,and data sparsity is almost always an issue in statistical modeling. <strong>In the\u00a0</strong><strong>extreme case where there is so much training data that all parameters</strong><strong>can be accurately trained without smoothing, one can almost always\u00a0</strong><strong>expand the model, such as by moving to a higher n-gram model, to\u00a0</strong><strong>achieve improved performance.</strong> With more parameters data sparsity becomes an issue again, but with proper smoothing the models areusually more accurate than the original models. Thus, no matter how much data one has, smoothing can almost always help performace, and for a relatively small e\ufb00ort.\u201d<br>Chen &amp; Goodman (1998)</blockquote>\n<p>From a <a href=\"http://Whenever%20data%20sparsity%20is%20an%20issue,%20smoothing%20can%20help%20performance,%20and%20data%20sparsity%20is%20almost%20always%20an%20issue%20in%20statistical%20modeling.%20In%20the%20extreme%20case%20where%20there%20is%20so%20much%20training%20data%20that%20all%20parameters%20can%20be%20accurately%20trained%20without%20smoothing,%20one%20can%20almost%20always%20expand%20the%20model,%20such%20as%20by%20moving%20to%20a%20higher%20n-gram%20model,%20to%20achieve%20improved%20performance.%20With%20more%20parameters%20data%20sparsity%20becomes%20an%20issue%20again,%20but%20with%20proper%20smoothing%20the%20models%20are%20usually%20more%20accurate%20than%20the%20original%20models.%20Thus,%20no%20matter%20how%20much%20data%20one%20has,%20smoothing%20can%20almost%20always%20help%20performace,%20and%20for%20a%20relatively%20small%20e%EF%AC%80ort.%20Chen%20&amp;%20Goodman%20(1998)\">smoothing tutorial</a>\u00a0at Stanford.</p></p>", "tree_html": ""}, "can_send_in_message": true, "id": 10441815664, "display_avatar": true, "can_reply": true, "can_like": false, "title": "More Data... Liberty of More Complex Model?", "tags": [], "post_url": "http://datasyndrome.com/post/10441815664/more-data-liberty-of-more-complex-model", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y9kONPm", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1316527205, "note_count": 0, "trail": [{"content": "<p><blockquote><p>&ldquo;Whenever data sparsity is an issue, smoothing can help performance,and data sparsity is almost always an issue in statistical modeling. <strong>In the&nbsp;</strong><strong>extreme case where there is so much training data that all parameters</strong><strong>can be accurately trained without smoothing, one can almost always&nbsp;</strong><strong>expand the model, such as by moving to a higher n-gram model, to&nbsp;</strong><strong>achieve improved performance.</strong> With more parameters data sparsity becomes an issue again, but with proper smoothing the models areusually more accurate than the original models. Thus, no matter how much data one has, smoothing can almost always help performace, and for a relatively small e&#64256;ort.&rdquo;<br />Chen &amp; Goodman (1998)</p></blockquote>\n<p>From a <a href=\"http://Whenever%20data%20sparsity%20is%20an%20issue,%20smoothing%20can%20help%20performance,%20and%20data%20sparsity%20is%20almost%20always%20an%20issue%20in%20statistical%20modeling.%20In%20the%20extreme%20case%20where%20there%20is%20so%20much%20training%20data%20that%20all%20parameters%20can%20be%20accurately%20trained%20without%20smoothing,%20one%20can%20almost%20always%20expand%20the%20model,%20such%20as%20by%20moving%20to%20a%20higher%20n-gram%20model,%20to%20achieve%20improved%20performance.%20With%20more%20parameters%20data%20sparsity%20becomes%20an%20issue%20again,%20but%20with%20proper%20smoothing%20the%20models%20are%20usually%20more%20accurate%20than%20the%20original%20models.%20Thus,%20no%20matter%20how%20much%20data%20one%20has,%20smoothing%20can%20almost%20always%20help%20performace,%20and%20for%20a%20relatively%20small%20e%EF%AC%80ort.%20Chen%20&amp;%20Goodman%20(1998)\">smoothing tutorial</a>&nbsp;at Stanford.</p></p>", "content_raw": "<p><blockquote>\u201cWhenever data sparsity is an issue, smoothing can help performance,and data sparsity is almost always an issue in statistical modeling. <strong>In the\u00a0</strong><strong>extreme case where there is so much training data that all parameters</strong><strong>can be accurately trained without smoothing, one can almost always\u00a0</strong><strong>expand the model, such as by moving to a higher n-gram model, to\u00a0</strong><strong>achieve improved performance.</strong> With more parameters data sparsity becomes an issue again, but with proper smoothing the models areusually more accurate than the original models. Thus, no matter how much data one has, smoothing can almost always help performace, and for a relatively small e\ufb00ort.\u201d<br>Chen &amp; Goodman (1998)</blockquote>\n<p>From a <a href=\"http://Whenever%20data%20sparsity%20is%20an%20issue,%20smoothing%20can%20help%20performance,%20and%20data%20sparsity%20is%20almost%20always%20an%20issue%20in%20statistical%20modeling.%20In%20the%20extreme%20case%20where%20there%20is%20so%20much%20training%20data%20that%20all%20parameters%20can%20be%20accurately%20trained%20without%20smoothing,%20one%20can%20almost%20always%20expand%20the%20model,%20such%20as%20by%20moving%20to%20a%20higher%20n-gram%20model,%20to%20achieve%20improved%20performance.%20With%20more%20parameters%20data%20sparsity%20becomes%20an%20issue%20again,%20but%20with%20proper%20smoothing%20the%20models%20are%20usually%20more%20accurate%20than%20the%20original%20models.%20Thus,%20no%20matter%20how%20much%20data%20one%20has,%20smoothing%20can%20almost%20always%20help%20performace,%20and%20for%20a%20relatively%20small%20e%EF%AC%80ort.%20Chen%20&amp;%20Goodman%20(1998)\">smoothing tutorial</a>\u00a0at Stanford.</p></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "10441815664"}}], "date": "2011-09-20 14:00:05 GMT", "slug": "more-data-liberty-of-more-complex-model", "blog_name": "rjurney", "summary": "More Data... Liberty of More Complex Model?", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "3fQiLASd", "text": "Social network analysis textbooks speak of collecting data via clipboards and knocking on doors.  With the rise of the internet, data collection has become easy.  The practice of SNA has not kept pace.  There exists a backlog of techniques not yet employed to extract valuable information from as of yet un-mined social networks, such as the inbox.", "can_send_in_message": true, "id": 8069606251, "display_avatar": true, "can_reply": true, "can_like": false, "source": "&ndash;Mark Twain on Big Data", "tags": [], "post_url": "http://datasyndrome.com/post/8069606251/social-network-analysis-textbooks-speak-of", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y7W-6jh", "type": "quote", "recommended_color": null, "format": "html", "timestamp": 1311649224, "note_count": 0, "date": "2011-07-26 03:00:24 GMT", "slug": "social-network-analysis-textbooks-speak-of", "blog_name": "rjurney", "summary": "\u201cSocial network analysis textbooks speak of collecting data via clipboards and knocking on doors.  With the rise of the...", "reblog": {"comment": "<p>\u2013Mark Twain on Big Data</p>", "tree_html": ""}, "can_reblog": true}, {"body": "<p>There are\u00a0<a href=\"http://www.programmableweb.com/apis\">lots of APIs</a>\u00a0out there. \u00a0And increasingly, new applications are mashups: mixtures of APIs. \u00a0I&rsquo;m interested in patterns of how this works; how APIs are combined along with some secret sauce to present a unique perspective that provides new value to the user.</p>\n<p>The components of API-driven products seem to be:</p>\n<ul><li>Identity - Facebook, Twitter, LinkedIn, Google</li>\n<li>Context - Friends, Contacts, Location, Interests</li>\n<li>Streams - Logs of opinions, links, events, transactions, new things. \u00a0Data.</li>\n<li>Action - Tweeting, Liking, Sharing, Email, SMS, Phone</li>\n</ul><p><strong>Identity</strong></p>\n<p><strong><span><strong><img height=\"188\" width=\"288\" src=\"http://upload.wikimedia.org/wikipedia/commons/7/74/Diplomatic-drivers-license.PNG\" align=\"top\"/></strong></span></strong></p>\n<p>This seems obvious, but a highly available global identifier is relatively new. \u00a0Logging in users via one of the dominant APIs enables access to context, streams and to target actions. \u00a0It opens the gateway to other APIs.</p>\n<p><strong>Context</strong></p>\n<p><strong><span><img height=\"195\" width=\"430\" src=\"http://farm4.static.flickr.com/3630/5834943818_a3a01e71b3_o.png\" align=\"middle\"/></span></strong></p>\n<p>Once a user&rsquo;s identity is known, you can retrieve context about that user via APIs: who they know, what they like and where they are.</p>\n<p><strong>Streams</strong></p>\n<p><strong><img height=\"138\" width=\"200\" src=\"http://farm3.static.flickr.com/2438/5837477534_4f26c05745_o.png\" align=\"middle\"/><br/></strong></p>\n<p>This is log data, broadcast by APIs. \u00a0Tweets, shares, songs, photos, etc. \u00a0Applications provide value by enhancing these streams - by augmenting them to create a unique perspective, by deriving new value from this perspective, by creating new value through increased understanding or enabling new kinds of actions.</p>\n<p><strong>Actions</strong></p>\n<p><img height=\"287\" width=\"360\" src=\"http://upload.wikimedia.org/wikipedia/commons/b/bc/Input-Output.JPG\" align=\"middle\"/></p>\n<p>Streams are input, actions are output. \u00a0They are the payoff - again, via APIs. \u00a0Sharing, posting, viewing, sending, logging.</p>\n<p><strong>Conclusion</strong></p>\n<p>This isn&rsquo;t complete, but using this system one can analyze new applications and determine where and how they add value in this chain. \u00a0I find it useful. \u00a0More later&hellip;</p>", "liked": false, "followed": false, "reblog_key": "wiQDp1ki", "reblog": {"comment": "<p>There are\u00a0<a href=\"http://www.programmableweb.com/apis\">lots of APIs</a>\u00a0out there. \u00a0And increasingly, new applications are mashups: mixtures of APIs. \u00a0I\u2019m interested in patterns of how this works; how APIs are combined along with some secret sauce to present a unique perspective that provides new value to the user.</p>\n<p>The components of API-driven products seem to be:</p>\n<ul><li>Identity - Facebook, Twitter, LinkedIn, Google</li>\n<li>Context - Friends, Contacts, Location, Interests</li>\n<li>Streams - Logs of opinions, links, events, transactions, new things. \u00a0Data.</li>\n<li>Action - Tweeting, Liking, Sharing, Email, SMS, Phone</li>\n</ul><p><strong>Identity</strong></p>\n<p><strong><span><strong><img height=\"188\" width=\"288\" src=\"http://upload.wikimedia.org/wikipedia/commons/7/74/Diplomatic-drivers-license.PNG\" align=\"top\"></strong></span></strong></p>\n<p>This seems obvious, but a highly available global identifier is relatively new. \u00a0Logging in users via one of the dominant APIs enables access to context, streams and to target actions. \u00a0It opens the gateway to other APIs.</p>\n<p><strong>Context</strong></p>\n<p><strong><span><img height=\"195\" width=\"430\" src=\"http://farm4.static.flickr.com/3630/5834943818_a3a01e71b3_o.png\" align=\"middle\"></span></strong></p>\n<p>Once a user\u2019s identity is known, you can retrieve context about that user via APIs: who they know, what they like and where they are.</p>\n<p><strong>Streams</strong></p>\n<p><strong><img height=\"138\" width=\"200\" src=\"http://farm3.static.flickr.com/2438/5837477534_4f26c05745_o.png\" align=\"middle\"><br></strong></p>\n<p>This is log data, broadcast by APIs. \u00a0Tweets, shares, songs, photos, etc. \u00a0Applications provide value by enhancing these streams - by augmenting them to create a unique perspective, by deriving new value from this perspective, by creating new value through increased understanding or enabling new kinds of actions.</p>\n<p><strong>Actions</strong></p>\n<p><img height=\"287\" width=\"360\" src=\"http://upload.wikimedia.org/wikipedia/commons/b/bc/Input-Output.JPG\" align=\"middle\"></p>\n<p>Streams are input, actions are output. \u00a0They are the payoff - again, via APIs. \u00a0Sharing, posting, viewing, sending, logging.</p>\n<p><strong>Conclusion</strong></p>\n<p>This isn\u2019t complete, but using this system one can analyze new applications and determine where and how they add value in this chain. \u00a0I find it useful. \u00a0More later\u2026</p>", "tree_html": ""}, "can_send_in_message": true, "id": 6565130424, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Anatomy of a Mashup", "tags": [], "post_url": "http://datasyndrome.com/post/6565130424/anatomy-of-a-mashup", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y67J-2u", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1308172806, "note_count": 0, "trail": [{"content": "<p>There are&nbsp;<a href=\"http://www.programmableweb.com/apis\">lots of APIs</a>&nbsp;out there. &nbsp;And increasingly, new applications are mashups: mixtures of APIs. &nbsp;I&rsquo;m interested in patterns of how this works; how APIs are combined along with some secret sauce to present a unique perspective that provides new value to the user.</p>\n<p>The components of API-driven products seem to be:</p>\n<ul><li>Identity - Facebook, Twitter, LinkedIn, Google</li>\n<li>Context - Friends, Contacts, Location, Interests</li>\n<li>Streams - Logs of opinions, links, events, transactions, new things. &nbsp;Data.</li>\n<li>Action - Tweeting, Liking, Sharing, Email, SMS, Phone</li>\n</ul><p><strong>Identity</strong></p>\n<p><strong><strong><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://upload.wikimedia.org/wikipedia/commons/7/74/Diplomatic-drivers-license.PNG\">External image</div></strong></strong></p>\n<p>This seems obvious, but a highly available global identifier is relatively new. &nbsp;Logging in users via one of the dominant APIs enables access to context, streams and to target actions. &nbsp;It opens the gateway to other APIs.</p>\n<p><strong>Context</strong></p>\n<p><strong><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm4.static.flickr.com/3630/5834943818_a3a01e71b3_o.png\">External image</div></strong></p>\n<p>Once a user&rsquo;s identity is known, you can retrieve context about that user via APIs: who they know, what they like and where they are.</p>\n<p><strong>Streams</strong></p>\n<p><strong><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm3.static.flickr.com/2438/5837477534_4f26c05745_o.png\">External image</div><br /></strong></p>\n<p>This is log data, broadcast by APIs. &nbsp;Tweets, shares, songs, photos, etc. &nbsp;Applications provide value by enhancing these streams - by augmenting them to create a unique perspective, by deriving new value from this perspective, by creating new value through increased understanding or enabling new kinds of actions.</p>\n<p><strong>Actions</strong></p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://upload.wikimedia.org/wikipedia/commons/b/bc/Input-Output.JPG\">External image</div></p>\n<p>Streams are input, actions are output. &nbsp;They are the payoff - again, via APIs. &nbsp;Sharing, posting, viewing, sending, logging.</p>\n<p><strong>Conclusion</strong></p>\n<p>This isn&rsquo;t complete, but using this system one can analyze new applications and determine where and how they add value in this chain. &nbsp;I find it useful. &nbsp;More later&hellip;</p>", "content_raw": "<p>There are\u00a0<a href=\"http://www.programmableweb.com/apis\">lots of APIs</a>\u00a0out there. \u00a0And increasingly, new applications are mashups: mixtures of APIs. \u00a0I\u2019m interested in patterns of how this works; how APIs are combined along with some secret sauce to present a unique perspective that provides new value to the user.</p>\n<p>The components of API-driven products seem to be:</p>\n<ul><li>Identity - Facebook, Twitter, LinkedIn, Google</li>\n<li>Context - Friends, Contacts, Location, Interests</li>\n<li>Streams - Logs of opinions, links, events, transactions, new things. \u00a0Data.</li>\n<li>Action - Tweeting, Liking, Sharing, Email, SMS, Phone</li>\n</ul><p><strong>Identity</strong></p>\n<p><strong><span><strong><img height=\"188\" width=\"288\" src=\"http://upload.wikimedia.org/wikipedia/commons/7/74/Diplomatic-drivers-license.PNG\" align=\"top\"></strong></span></strong></p>\n<p>This seems obvious, but a highly available global identifier is relatively new. \u00a0Logging in users via one of the dominant APIs enables access to context, streams and to target actions. \u00a0It opens the gateway to other APIs.</p>\n<p><strong>Context</strong></p>\n<p><strong><span><img height=\"195\" width=\"430\" src=\"http://farm4.static.flickr.com/3630/5834943818_a3a01e71b3_o.png\" align=\"middle\"></span></strong></p>\n<p>Once a user\u2019s identity is known, you can retrieve context about that user via APIs: who they know, what they like and where they are.</p>\n<p><strong>Streams</strong></p>\n<p><strong><img height=\"138\" width=\"200\" src=\"http://farm3.static.flickr.com/2438/5837477534_4f26c05745_o.png\" align=\"middle\"><br></strong></p>\n<p>This is log data, broadcast by APIs. \u00a0Tweets, shares, songs, photos, etc. \u00a0Applications provide value by enhancing these streams - by augmenting them to create a unique perspective, by deriving new value from this perspective, by creating new value through increased understanding or enabling new kinds of actions.</p>\n<p><strong>Actions</strong></p>\n<p><img height=\"287\" width=\"360\" src=\"http://upload.wikimedia.org/wikipedia/commons/b/bc/Input-Output.JPG\" align=\"middle\"></p>\n<p>Streams are input, actions are output. \u00a0They are the payoff - again, via APIs. \u00a0Sharing, posting, viewing, sending, logging.</p>\n<p><strong>Conclusion</strong></p>\n<p>This isn\u2019t complete, but using this system one can analyze new applications and determine where and how they add value in this chain. \u00a0I find it useful. \u00a0More later\u2026</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "6565130424"}}], "date": "2011-06-15 21:20:06 GMT", "slug": "anatomy-of-a-mashup", "blog_name": "rjurney", "summary": "Anatomy of a Mashup", "can_reblog": true}, {"body": "<p><a href=\"http://www.flickr.com/photos/rjurney/5583318321/sizes/l/in/photostream/\"><img height=\"383\" width=\"400\" alt=\"Molting\" src=\"http://farm6.static.flickr.com/5140/5583318321_a6865ab2c1.jpg\" align=\"middle\"/></a></p>", "liked": false, "followed": false, "reblog_key": "7gIp0VZZ", "reblog": {"comment": "<p><a href=\"http://www.flickr.com/photos/rjurney/5583318321/sizes/l/in/photostream/\"><img height=\"383\" width=\"400\" alt=\"Molting\" src=\"http://farm6.static.flickr.com/5140/5583318321_a6865ab2c1.jpg\" align=\"middle\"></a></p>", "tree_html": ""}, "can_send_in_message": true, "id": 4298473642, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Status Update: Molting", "tags": [], "post_url": "http://datasyndrome.com/post/4298473642/status-update-molting", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y40DO2g", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1301794678, "note_count": 0, "trail": [{"content": "<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm6.static.flickr.com/5140/5583318321_a6865ab2c1.jpg\">External image</div></p>", "content_raw": "<p><a href=\"http://www.flickr.com/photos/rjurney/5583318321/sizes/l/in/photostream/\"><img height=\"383\" width=\"400\" alt=\"Molting\" src=\"http://farm6.static.flickr.com/5140/5583318321_a6865ab2c1.jpg\" align=\"middle\"></a></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "4298473642"}}], "date": "2011-04-03 01:37:58 GMT", "slug": "status-update-molting", "blog_name": "rjurney", "summary": "Status Update: Molting", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "XuZ9h8k8", "short_url": "https://tmblr.co/ZbIO5y3mIXyL", "excerpt": null, "link_author": null, "id": 4031389461, "display_avatar": true, "can_reply": true, "can_like": false, "title": "My headshot is on the LinkedIn 100 million users post.", "tags": [], "post_url": "http://datasyndrome.com/post/4031389461/my-headshot-is-on-the-linkedin-100-million-users", "recommended_source": null, "state": "published", "reblog": {"comment": "<p>\u00a0\u00a0Middle bottom. \u00a0:)</p>", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "<p>\u00a0\u00a0Middle bottom. \u00a0:)</p>", "format": "html", "timestamp": 1300831980, "note_count": 1, "trail": [{"content": "<p>&nbsp;&nbsp;Middle bottom. &nbsp;:)</p>", "content_raw": "<p>\u00a0\u00a0Middle bottom. \u00a0:)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "4031389461"}}], "date": "2011-03-22 22:13:00 GMT", "slug": "my-headshot-is-on-the-linkedin-100-million-users", "blog_name": "rjurney", "publisher": "blog.linkedin.com", "url": "http://blog.linkedin.com/100million/", "can_send_in_message": true, "summary": "My headshot is on the LinkedIn 100 million users post.", "can_reblog": true}, {"body": "<p><a href=\"https://www.amazon.com/dp/1589482611?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1589482611&amp;adid=1HPWK55V6BF0PJYZXXN6&amp;\"><img height=\"110\" width=\"89\" src=\"https://images-na.ssl-images-amazon.com/images/I/51DvFAoyWML._SL110_.jpg\"/>\u00a0Semiology of Graphics</a> - A classic. I&rsquo;ve just ordered the new printing, but a friend lent me Stanford&rsquo;s copy and I want it on my desk when I&rsquo;m making diagrams of new concepts. \u00a0This is a great reference for coming up with sane and coherent symbol sets when drawing&hellip; just about anything.</p>\n\n\n\n<p><a href=\"https://www.amazon.com/dp/1568987633?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1568987633&amp;adid=1QBNSESXNMSJNPC1D5WX&amp;\"><img height=\"110\" width=\"89\" src=\"https://images-na.ssl-images-amazon.com/images/I/51YWM7To5XL._SL110_.jpg\"/>\u00a0Cartographies of Time: A History of the Timeline</a>\u00a0- Inspirational. \u00a0An essential guide to the timeline. \u00a0This book taught me more about data visualization than any other, by tracing the historic origins and development of visualization from the roots of history itself right up to the modern era.</p>", "liked": false, "followed": false, "reblog_key": "YOPqHG2I", "reblog": {"comment": "<p><a href=\"https://www.amazon.com/dp/1589482611?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1589482611&amp;adid=1HPWK55V6BF0PJYZXXN6&amp;\"><img height=\"110\" width=\"89\" src=\"https://images-na.ssl-images-amazon.com/images/I/51DvFAoyWML._SL110_.jpg\">\u00a0Semiology of Graphics</a> - A classic. I\u2019ve just ordered the new printing, but a friend lent me Stanford\u2019s copy and I want it on my desk when I\u2019m making diagrams of new concepts. \u00a0This is a great reference for coming up with sane and coherent symbol sets when drawing\u2026 just about anything.</p>\n\n\n\n<p><a href=\"https://www.amazon.com/dp/1568987633?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1568987633&amp;adid=1QBNSESXNMSJNPC1D5WX&amp;\"><img height=\"110\" width=\"89\" src=\"https://images-na.ssl-images-amazon.com/images/I/51YWM7To5XL._SL110_.jpg\">\u00a0Cartographies of Time: A History of the Timeline</a>\u00a0- Inspirational. \u00a0An essential guide to the timeline. \u00a0This book taught me more about data visualization than any other, by tracing the historic origins and development of visualization from the roots of history itself right up to the modern era.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 3695480002, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Two Great Books on Information Visualization", "tags": [], "post_url": "http://datasyndrome.com/post/3695480002/two-great-books-on-information-visualization", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y3SH8p2", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1299472381, "note_count": 0, "trail": [{"content": "<p><a href=\"https://www.amazon.com/dp/1589482611?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1589482611&amp;adid=1HPWK55V6BF0PJYZXXN6&amp;\"><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://images-na.ssl-images-amazon.com/images/I/51DvFAoyWML._SL110_.jpg\">External image</div>&nbsp;Semiology of Graphics</a> - A classic. I&rsquo;ve just ordered the new printing, but a friend lent me Stanford&rsquo;s copy and I want it on my desk when I&rsquo;m making diagrams of new concepts. &nbsp;This is a great reference for coming up with sane and coherent symbol sets when drawing&hellip; just about anything.</p>\n\n\n\n<p><a href=\"https://www.amazon.com/dp/1568987633?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1568987633&amp;adid=1QBNSESXNMSJNPC1D5WX&amp;\"><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"https://images-na.ssl-images-amazon.com/images/I/51YWM7To5XL._SL110_.jpg\">External image</div>&nbsp;Cartographies of Time: A History of the Timeline</a>&nbsp;- Inspirational. &nbsp;An essential guide to the timeline. &nbsp;This book taught me more about data visualization than any other, by tracing the historic origins and development of visualization from the roots of history itself right up to the modern era.</p>", "content_raw": "<p><a href=\"https://www.amazon.com/dp/1589482611?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1589482611&amp;adid=1HPWK55V6BF0PJYZXXN6&amp;\"><img height=\"110\" width=\"89\" src=\"https://images-na.ssl-images-amazon.com/images/I/51DvFAoyWML._SL110_.jpg\">\u00a0Semiology of Graphics</a> - A classic. I\u2019ve just ordered the new printing, but a friend lent me Stanford\u2019s copy and I want it on my desk when I\u2019m making diagrams of new concepts. \u00a0This is a great reference for coming up with sane and coherent symbol sets when drawing\u2026 just about anything.</p>\n\n\n\n<p><a href=\"https://www.amazon.com/dp/1568987633?tag=datasynd-20&amp;camp=213381&amp;creative=390973&amp;linkCode=as4&amp;creativeASIN=1568987633&amp;adid=1QBNSESXNMSJNPC1D5WX&amp;\"><img height=\"110\" width=\"89\" src=\"https://images-na.ssl-images-amazon.com/images/I/51YWM7To5XL._SL110_.jpg\">\u00a0Cartographies of Time: A History of the Timeline</a>\u00a0- Inspirational. \u00a0An essential guide to the timeline. \u00a0This book taught me more about data visualization than any other, by tracing the historic origins and development of visualization from the roots of history itself right up to the modern era.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "3695480002"}}], "date": "2011-03-07 04:33:01 GMT", "slug": "two-great-books-on-information-visualization", "blog_name": "rjurney", "summary": "Two Great Books on Information Visualization", "can_reblog": true}, {"body": "<blockquote></blockquote>\n<p>(Repost from last year. Note: Ali, the godfather of InMaps, was in on this post, and we both think simple network diagrams are over-used. Nobody is being made fun of here, except the broader visualization community.  And the Jesus toast.)</p>\n<blockquote>\n<p><strong>God is real. \u00a0He has meatballs. \u00a0I have proof.</strong></p>\n</blockquote>\n<p>Brothers and sisters, behold the Flying Spaghetti Monster in all his glory:</p>\n<p><img height=\"412\" width=\"480\" src=\"http://farm5.static.flickr.com/4084/5085385610_ce5268a054.jpg\" align=\"middle\"/></p>\n<p>Now behold the professional network of\u00a0<a href=\"http://www.linkedin.com/in/aliimam\">Ali Imam</a>, Senior Data Scientist at LinkedIn:</p>\n<p><img height=\"499\" width=\"500\" src=\"http://farm5.static.flickr.com/4086/5085385616_e6a48d10c4.jpg\" align=\"middle\"/></p>\n<p>Now lets look at it again, with CLEAR eyes:</p>\n<p><img height=\"499\" width=\"500\" src=\"http://farm5.static.flickr.com/4083/5085420298_94a9501ce6.jpg\" align=\"middle\"/></p>\n<p>Is that not three of HIS Meatballs linked by delicious Al Dente Spaghetti? \u00a0The truth is undeniable, once you see it.</p>\n<p>And once you see it once&hellip; you can&rsquo;t stop seeing it everywhere. \u00a0His Noodly Appendage makes\u00a0<a href=\"http://twitter.com/#!/hmason/status/27477599345\">appearances</a>\u00a0at developer conferences:</p>\n<p><img height=\"420\" width=\"500\" src=\"http://farm5.static.flickr.com/4151/5084855623_c71a618b3d.jpg\" align=\"middle\"/></p>\n<p>He appears in\u00a0<a href=\"http://projects.forked.de/graph-tool/doc/draw.html\">random data</a>:</p>\n<p><img height=\"500\" width=\"482\" src=\"http://farm5.static.flickr.com/4088/5084873291_15ae0290b9.jpg\" align=\"middle\"/></p>\n<p>And in\u00a0<a href=\"http://www.cs.ubc.ca/labs/imager/tr/2006/Archambault_SPF_InfoVis2006/\">biological data</a>:\u00a0</p>\n<p><img height=\"500\" width=\"468\" src=\"http://farm5.static.flickr.com/4087/5085481650_a69e854d3f.jpg\" align=\"middle\"/></p>\n<p>Regardless of the problem domain, all these graphs look identical! \u00a0Indeed&hellip; the face of god emerges from every kind of force directed graph, thus proving HIS existence. \u00a0Every graph shows us the face of god. \u00a0</p>\n<p>Lets look at what the OTHER guy has to offer&hellip; the Jesus toast:</p>\n<p><img height=\"347\" width=\"317\" src=\"http://cooltoast.com/wp-content/uploads/2010/03/Jesus_Toast_Grilled_Cheese.jpg\" align=\"middle\"/></p>\n<p>Dare I say that there is no science there? \u00a0That given millions of toasts consumed by millions of people every day, that surely Jesus&rsquo; face must emerge on many, every single day? \u00a0The toast is not statistically significant.</p>\n<p>The ordained among the data-driven pastafarians, &lsquo;data scientists,&rsquo; must apply more rigor than toast curation in their study of the universe. \u00a0We are not simpletons. \u00a0We will not worship toast. \u00a0We worship data, where the face of god is manifest in such great frequency that His Word cannot be doubted.</p>\n<p>A formal proof of this theorem is so elementary that it is left as an exercise to the reader.</p>", "liked": false, "followed": false, "reblog_key": "lKqXmXz1", "reblog": {"comment": "<p><blockquote></blockquote>\n<p>(Repost from last year. Note: Ali, the godfather of InMaps, was in on this post, and we both think simple network diagrams are over-used. Nobody is being made fun of here, except the broader visualization community.  And the Jesus toast.)</p>\n<blockquote>\n<p><strong>God is real. \u00a0He has meatballs. \u00a0I have proof.</strong></p>\n</blockquote>\n<p>Brothers and sisters, behold the Flying Spaghetti Monster in all his glory:</p>\n<p><img height=\"412\" width=\"480\" src=\"http://farm5.static.flickr.com/4084/5085385610_ce5268a054.jpg\" align=\"middle\"></p>\n<p>Now behold the professional network of\u00a0<a href=\"http://www.linkedin.com/in/aliimam\">Ali Imam</a>, Senior Data Scientist at LinkedIn:</p>\n<p><img height=\"499\" width=\"500\" src=\"http://farm5.static.flickr.com/4086/5085385616_e6a48d10c4.jpg\" align=\"middle\"></p>\n<p>Now lets look at it again, with CLEAR eyes:</p>\n<p><img height=\"499\" width=\"500\" src=\"http://farm5.static.flickr.com/4083/5085420298_94a9501ce6.jpg\" align=\"middle\"></p>\n<p>Is that not three of HIS Meatballs linked by delicious Al Dente Spaghetti? \u00a0The truth is undeniable, once you see it.</p>\n<p>And once you see it once\u2026 you can\u2019t stop seeing it everywhere. \u00a0His Noodly Appendage makes\u00a0<a href=\"http://twitter.com/#!/hmason/status/27477599345\">appearances</a>\u00a0at developer conferences:</p>\n<p><img height=\"420\" width=\"500\" src=\"http://farm5.static.flickr.com/4151/5084855623_c71a618b3d.jpg\" align=\"middle\"></p>\n<p>He appears in\u00a0<a href=\"http://projects.forked.de/graph-tool/doc/draw.html\">random data</a>:</p>\n<p><img height=\"500\" width=\"482\" src=\"http://farm5.static.flickr.com/4088/5084873291_15ae0290b9.jpg\" align=\"middle\"></p>\n<p>And in\u00a0<a href=\"http://www.cs.ubc.ca/labs/imager/tr/2006/Archambault_SPF_InfoVis2006/\">biological data</a>:\u00a0</p>\n<p><img height=\"500\" width=\"468\" src=\"http://farm5.static.flickr.com/4087/5085481650_a69e854d3f.jpg\" align=\"middle\"></p>\n<p>Regardless of the problem domain, all these graphs look identical! \u00a0Indeed\u2026 the face of god emerges from every kind of force directed graph, thus proving HIS existence. \u00a0Every graph shows us the face of god. \u00a0</p>\n<p>Lets look at what the OTHER guy has to offer\u2026 the Jesus toast:</p>\n<p><img height=\"347\" width=\"317\" src=\"http://cooltoast.com/wp-content/uploads/2010/03/Jesus_Toast_Grilled_Cheese.jpg\" align=\"middle\"></p>\n<p>Dare I say that there is no science there? \u00a0That given millions of toasts consumed by millions of people every day, that surely Jesus\u2019 face must emerge on many, every single day? \u00a0The toast is not statistically significant.</p>\n<p>The ordained among the data-driven pastafarians, \u2018data scientists,\u2019 must apply more rigor than toast curation in their study of the universe. \u00a0We are not simpletons. \u00a0We will not worship toast. \u00a0We worship data, where the face of god is manifest in such great frequency that His Word cannot be doubted.</p>\n<p>A formal proof of this theorem is so elementary that it is left as an exercise to the reader.</p></p>", "tree_html": ""}, "can_send_in_message": true, "id": 3389164742, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Force Directed Pastafarianism", "tags": [], "post_url": "http://datasyndrome.com/post/3389164742/force-directed-pastafarianism", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y3A0ep6", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1298153220, "note_count": 0, "trail": [{"content": "<p><blockquote></blockquote>\n<p>(Repost from last year. Note: Ali, the godfather of InMaps, was in on this post, and we both think simple network diagrams are over-used. Nobody is being made fun of here, except the broader visualization community.  And the Jesus toast.)</p>\n<blockquote>\n<p><strong>God is real. &nbsp;He has meatballs. &nbsp;I have proof.</strong></p>\n</blockquote>\n<p>Brothers and sisters, behold the Flying Spaghetti Monster in all his glory:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm5.static.flickr.com/4084/5085385610_ce5268a054.jpg\">External image</div></p>\n<p>Now behold the professional network of&nbsp;<a href=\"http://www.linkedin.com/in/aliimam\">Ali Imam</a>, Senior Data Scientist at LinkedIn:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm5.static.flickr.com/4086/5085385616_e6a48d10c4.jpg\">External image</div></p>\n<p>Now lets look at it again, with CLEAR eyes:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm5.static.flickr.com/4083/5085420298_94a9501ce6.jpg\">External image</div></p>\n<p>Is that not three of HIS Meatballs linked by delicious Al Dente Spaghetti? &nbsp;The truth is undeniable, once you see it.</p>\n<p>And once you see it once&hellip; you can&rsquo;t stop seeing it everywhere. &nbsp;His Noodly Appendage makes&nbsp;<a href=\"http://twitter.com/#!/hmason/status/27477599345\">appearances</a>&nbsp;at developer conferences:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm5.static.flickr.com/4151/5084855623_c71a618b3d.jpg\">External image</div></p>\n<p>He appears in&nbsp;<a href=\"http://projects.forked.de/graph-tool/doc/draw.html\">random data</a>:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm5.static.flickr.com/4088/5084873291_15ae0290b9.jpg\">External image</div></p>\n<p>And in&nbsp;<a href=\"http://www.cs.ubc.ca/labs/imager/tr/2006/Archambault_SPF_InfoVis2006/\">biological data</a>:&nbsp;</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm5.static.flickr.com/4087/5085481650_a69e854d3f.jpg\">External image</div></p>\n<p>Regardless of the problem domain, all these graphs look identical! &nbsp;Indeed&hellip; the face of god emerges from every kind of force directed graph, thus proving HIS existence. &nbsp;Every graph shows us the face of god. &nbsp;</p>\n<p>Lets look at what the OTHER guy has to offer&hellip; the Jesus toast:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://cooltoast.com/wp-content/uploads/2010/03/Jesus_Toast_Grilled_Cheese.jpg\">External image</div></p>\n<p>Dare I say that there is no science there? &nbsp;That given millions of toasts consumed by millions of people every day, that surely Jesus&rsquo; face must emerge on many, every single day? &nbsp;The toast is not statistically significant.</p>\n<p>The ordained among the data-driven pastafarians, &lsquo;data scientists,&rsquo; must apply more rigor than toast curation in their study of the universe. &nbsp;We are not simpletons. &nbsp;We will not worship toast. &nbsp;We worship data, where the face of god is manifest in such great frequency that His Word cannot be doubted.</p>\n<p>A formal proof of this theorem is so elementary that it is left as an exercise to the reader.</p></p>", "content_raw": "<p><blockquote></blockquote>\n<p>(Repost from last year. Note: Ali, the godfather of InMaps, was in on this post, and we both think simple network diagrams are over-used. Nobody is being made fun of here, except the broader visualization community.  And the Jesus toast.)</p>\n<blockquote>\n<p><strong>God is real. \u00a0He has meatballs. \u00a0I have proof.</strong></p>\n</blockquote>\n<p>Brothers and sisters, behold the Flying Spaghetti Monster in all his glory:</p>\n<p><img height=\"412\" width=\"480\" src=\"http://farm5.static.flickr.com/4084/5085385610_ce5268a054.jpg\" align=\"middle\"></p>\n<p>Now behold the professional network of\u00a0<a href=\"http://www.linkedin.com/in/aliimam\">Ali Imam</a>, Senior Data Scientist at LinkedIn:</p>\n<p><img height=\"499\" width=\"500\" src=\"http://farm5.static.flickr.com/4086/5085385616_e6a48d10c4.jpg\" align=\"middle\"></p>\n<p>Now lets look at it again, with CLEAR eyes:</p>\n<p><img height=\"499\" width=\"500\" src=\"http://farm5.static.flickr.com/4083/5085420298_94a9501ce6.jpg\" align=\"middle\"></p>\n<p>Is that not three of HIS Meatballs linked by delicious Al Dente Spaghetti? \u00a0The truth is undeniable, once you see it.</p>\n<p>And once you see it once\u2026 you can\u2019t stop seeing it everywhere. \u00a0His Noodly Appendage makes\u00a0<a href=\"http://twitter.com/#!/hmason/status/27477599345\">appearances</a>\u00a0at developer conferences:</p>\n<p><img height=\"420\" width=\"500\" src=\"http://farm5.static.flickr.com/4151/5084855623_c71a618b3d.jpg\" align=\"middle\"></p>\n<p>He appears in\u00a0<a href=\"http://projects.forked.de/graph-tool/doc/draw.html\">random data</a>:</p>\n<p><img height=\"500\" width=\"482\" src=\"http://farm5.static.flickr.com/4088/5084873291_15ae0290b9.jpg\" align=\"middle\"></p>\n<p>And in\u00a0<a href=\"http://www.cs.ubc.ca/labs/imager/tr/2006/Archambault_SPF_InfoVis2006/\">biological data</a>:\u00a0</p>\n<p><img height=\"500\" width=\"468\" src=\"http://farm5.static.flickr.com/4087/5085481650_a69e854d3f.jpg\" align=\"middle\"></p>\n<p>Regardless of the problem domain, all these graphs look identical! \u00a0Indeed\u2026 the face of god emerges from every kind of force directed graph, thus proving HIS existence. \u00a0Every graph shows us the face of god. \u00a0</p>\n<p>Lets look at what the OTHER guy has to offer\u2026 the Jesus toast:</p>\n<p><img height=\"347\" width=\"317\" src=\"http://cooltoast.com/wp-content/uploads/2010/03/Jesus_Toast_Grilled_Cheese.jpg\" align=\"middle\"></p>\n<p>Dare I say that there is no science there? \u00a0That given millions of toasts consumed by millions of people every day, that surely Jesus\u2019 face must emerge on many, every single day? \u00a0The toast is not statistically significant.</p>\n<p>The ordained among the data-driven pastafarians, \u2018data scientists,\u2019 must apply more rigor than toast curation in their study of the universe. \u00a0We are not simpletons. \u00a0We will not worship toast. \u00a0We worship data, where the face of god is manifest in such great frequency that His Word cannot be doubted.</p>\n<p>A formal proof of this theorem is so elementary that it is left as an exercise to the reader.</p></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "3389164742"}}], "date": "2011-02-19 22:07:00 GMT", "slug": "force-directed-pastafarianism", "blog_name": "rjurney", "summary": "Force Directed Pastafarianism", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "2JgwQzxa", "short_url": "https://tmblr.co/ZbIO5y32OEqI", "excerpt": null, "link_author": null, "id": 3261132050, "display_avatar": true, "can_reply": true, "can_like": false, "title": "A Nod from All Things Digital (The Next Silicon Valley)", "tags": [], "post_url": "http://datasyndrome.com/post/3261132050/a-nod-from-all-things-digital-the-next-silicon", "recommended_source": null, "state": "published", "reblog": {"comment": "", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "", "format": "html", "timestamp": 1297556538, "note_count": 0, "trail": [], "date": "2011-02-13 00:22:18 GMT", "slug": "a-nod-from-all-things-digital-the-next-silicon", "blog_name": "rjurney", "publisher": "voices.allthingsd.com", "url": "http://voices.allthingsd.com/20100810/the-next-silicon-valley/?mod=ATD_rss", "can_send_in_message": true, "summary": "A Nod from All Things Digital (The Next Silicon Valley)", "can_reblog": true}, {"liked": false, "followed": false, "reblog_key": "74UmVnhz", "short_url": "https://tmblr.co/ZbIO5y32O9u0", "excerpt": null, "link_author": null, "id": 3261111808, "display_avatar": true, "can_reply": true, "can_like": false, "title": "A Nod from Forbes.com (How to build a Data Startup)", "tags": [], "post_url": "http://datasyndrome.com/post/3261111808/a-nod-from-forbescom-how-to-build-a-data", "recommended_source": null, "state": "published", "reblog": {"comment": "", "tree_html": ""}, "type": "link", "recommended_color": null, "description": "", "format": "html", "timestamp": 1297556464, "note_count": 0, "trail": [], "date": "2011-02-13 00:21:04 GMT", "slug": "a-nod-from-forbescom-how-to-build-a-data", "blog_name": "rjurney", "publisher": "forbes.com", "url": "http://www.forbes.com/2010/11/02/startup-facebook-twitter-technology-data.html", "can_send_in_message": true, "summary": "A Nod from Forbes.com (How to build a Data Startup)", "can_reblog": true}, {"body": "<blockquote>\n<p><a href=\"http://www.wordnik.com/words/launch\">launch</a></p>\n<span><ol class=\"def-list\"><span>\u2013verb-transitive</span><br/><span><ol class=\"def-list\"><li>To set going; initiate:\u00a0<em>launch a career; launch a business venture.</em></li>\n<li>To introduce to the public or to a market:\u00a0<em>launched the new perfume with prime-time commercials on the major networks.</em></li>\n</ol></span>\u2013verb-intransitive\n<li>To begin a new venture or phase; embark:\u00a0<em>launch forth on a dangerous mission; launched out on her own after college.</em></li>\n</ol></span></blockquote>\n<p>Which leads us to:</p>\n<blockquote>\n<p><strong>launchism</strong></p>\n<p><span>\u00a0\u00a0 \u00a0-noun<strong><em><span></span></em></strong></span></p>\n<ol><li><span><span>(product development) A product developmental disorder characterized by a focus on creating the perception of success through media manipulation rather than on creating real value for paying customers:\u00a0<em>Startup X died of launchism after getting techcrunch'ed to create hype to get acquired. \u00a0Customers never showed up, now the founders work at Denny&rsquo;s.</em></span></span></li>\n</ol></blockquote>\n<p>A wedding ain&rsquo;t a marriage. \u00a0A launch ain&rsquo;t a product. \u00a0There exists an inverse relationship between launch budget and product success, just as there is an inverse relationship between wedding budget and marital happiness. \u00a0Its about focus. \u00a0Are you focused on creating a perception of success or on creating a repeatable business model?</p>", "liked": false, "followed": false, "reblog_key": "zIoYjUHj", "reblog": {"comment": "<p><blockquote>\n<p><a href=\"http://www.wordnik.com/words/launch\">launch</a></p>\n<span><ol class=\"def-list\"><span>\u2013verb-transitive</span><br><span><ol class=\"def-list\"><li>To set going; initiate:\u00a0<em>launch a career; launch a business venture.</em></li>\n<li>To introduce to the public or to a market:\u00a0<em>launched the new perfume with prime-time commercials on the major networks.</em></li>\n</ol></span>\u2013verb-intransitive\n<li>To begin a new venture or phase; embark:\u00a0<em>launch forth on a dangerous mission; launched out on her own after college.</em></li>\n</ol></span></blockquote>\n<p>Which leads us to:</p>\n<blockquote>\n<p><strong>launchism</strong></p>\n<p><span>\u00a0\u00a0 \u00a0-noun<strong><em><span></span></em></strong></span></p>\n<ol><li><span><span>(product development) A product developmental disorder characterized by a focus on creating the perception of success through media manipulation rather than on creating real value for paying customers:\u00a0<em>Startup X died of launchism after getting techcrunch'ed to create hype to get acquired. \u00a0Customers never showed up, now the founders work at Denny\u2019s.</em></span></span></li>\n</ol></blockquote>\n<p>A wedding ain\u2019t a marriage. \u00a0A launch ain\u2019t a product. \u00a0There exists an inverse relationship between launch budget and product success, just as there is an inverse relationship between wedding budget and marital happiness. \u00a0Its about focus. \u00a0Are you focused on creating a perception of success or on creating a repeatable business model?</p></p>", "tree_html": ""}, "can_send_in_message": true, "id": 3257317561, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Launchism", "tags": [], "post_url": "http://datasyndrome.com/post/3257317561/launchism", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y329hYv", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1297542868, "note_count": 0, "trail": [{"content": "<p><blockquote>\n<p><a href=\"http://www.wordnik.com/words/launch\">launch</a></p>\n<ol><ol><li>To set going; initiate:&nbsp;<em>launch a career; launch a business venture.</em></li>\n<li>To introduce to the public or to a market:&nbsp;<em>launched the new perfume with prime-time commercials on the major networks.</em></li>\n</ol>\n<li>To begin a new venture or phase; embark:&nbsp;<em>launch forth on a dangerous mission; launched out on her own after college.</em></li>\n</ol></blockquote>\n<p>Which leads us to:</p>\n<blockquote>\n<p><strong>launchism</strong></p>\n<p>&nbsp;&nbsp; &nbsp;-noun<strong><em></em></strong></p>\n<ol><li>(product development) A product developmental disorder characterized by a focus on creating the perception of success through media manipulation rather than on creating real value for paying customers:&nbsp;<em>Startup X died of launchism after getting techcrunch'ed to create hype to get acquired. &nbsp;Customers never showed up, now the founders work at Denny&rsquo;s.</em></li>\n</ol></blockquote>\n<p>A wedding ain&rsquo;t a marriage. &nbsp;A launch ain&rsquo;t a product. &nbsp;There exists an inverse relationship between launch budget and product success, just as there is an inverse relationship between wedding budget and marital happiness. &nbsp;Its about focus. &nbsp;Are you focused on creating a perception of success or on creating a repeatable business model?</p></p>", "content_raw": "<p><blockquote>\n<p><a href=\"http://www.wordnik.com/words/launch\">launch</a></p>\n<span><ol class=\"def-list\"><span>\u2013verb-transitive</span><br><span><ol class=\"def-list\"><li>To set going; initiate:\u00a0<em>launch a career; launch a business venture.</em></li>\n<li>To introduce to the public or to a market:\u00a0<em>launched the new perfume with prime-time commercials on the major networks.</em></li>\n</ol></span>\u2013verb-intransitive\n<li>To begin a new venture or phase; embark:\u00a0<em>launch forth on a dangerous mission; launched out on her own after college.</em></li>\n</ol></span></blockquote>\n<p>Which leads us to:</p>\n<blockquote>\n<p><strong>launchism</strong></p>\n<p><span>\u00a0\u00a0 \u00a0-noun<strong><em><span></span></em></strong></span></p>\n<ol><li><span><span>(product development) A product developmental disorder characterized by a focus on creating the perception of success through media manipulation rather than on creating real value for paying customers:\u00a0<em>Startup X died of launchism after getting techcrunch'ed to create hype to get acquired. \u00a0Customers never showed up, now the founders work at Denny\u2019s.</em></span></span></li>\n</ol></blockquote>\n<p>A wedding ain\u2019t a marriage. \u00a0A launch ain\u2019t a product. \u00a0There exists an inverse relationship between launch budget and product success, just as there is an inverse relationship between wedding budget and marital happiness. \u00a0Its about focus. \u00a0Are you focused on creating a perception of success or on creating a repeatable business model?</p></p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "3257317561"}}], "date": "2011-02-12 20:34:28 GMT", "slug": "launchism", "blog_name": "rjurney", "summary": "Launchism", "can_reblog": true}, {"body": "<p>There is the customer&rsquo;s opinion. \u00a0There is the team&rsquo;s opinion. \u00a0And there is the data&rsquo;s opinion. \u00a0<strong>Building successful data products means reconciling these opinions</strong><strong>.</strong>\u00a0There is a right and wrong way to do so.</p>\n<p>The wrong way is called the\u00a0<em>Waterfall Model.</em>\u00a0\u00a0</p>\n<p><img height=\"384\" width=\"500\" src=\"http://farm2.static.flickr.com/1110/5112550728_a62ab241e1.jpg\" align=\"middle\"/></p>\n<p>Wikipedia on the\u00a0<em>Waterfall Method</em>:</p>\n<blockquote>\n<p><span>The\u00a0<strong>waterfall model</strong>\u00a0is a\u00a0<a title=\"Sequence\" href=\"http://en.wikipedia.org/wiki/Sequence\">sequential</a>\u00a0<a title=\"Software development process\" href=\"http://en.wikipedia.org/wiki/Software_development_process\">software development process</a>, in which progress is seen as flowing steadily downwards (like a\u00a0<a title=\"Waterfall\" href=\"http://en.wikipedia.org/wiki/Waterfall\">waterfall</a>) through the phases of Conception, Initiation,\u00a0<a title=\"Analysis\" href=\"http://en.wikipedia.org/wiki/Analysis\">Analysis</a>,\u00a0<a title=\"Software design\" href=\"http://en.wikipedia.org/wiki/Software_design\">Design</a>, Construction,\u00a0<a title=\"Software testing\" href=\"http://en.wikipedia.org/wiki/Software_testing\">Testing</a>\u00a0and\u00a0<a title=\"Software maintenance\" href=\"http://en.wikipedia.org/wiki/Software_maintenance\">Maintenance</a>.</span></p>\n</blockquote>\n<p>The waterfall model\u00a0<strong>doesn&rsquo;t apply</strong>\u00a0to analytic products. \u00a0We may want to\u00a0<strong>design</strong>\u00a0data products, but the data refuses to cooperate. \u00a0The charts we design aren&rsquo;t informative. \u00a0We pick the wrong data sources. \u00a0Our models answer the wrong questions. \u00a0So we fudge it. \u00a0We make the data fit the design, when it wants to be something else. \u00a0When we do so, we undermine the insights we set out to deliver. \u00a0Success this way is unlikely.</p>\n<p>There&rsquo;s a better way. \u00a0A\u00a0<em><a href=\"http://www.startuplessonslearned.com/\">leaner</a></em>\u00a0way. \u00a0And despite being SO hot right now, it is the<a href=\"http://en.wikipedia.org/wiki/Middle_way\">middle path</a>.</p>\n<p><span>Wikipedia on\u00a0<em>Lean Startup</em>:</span></p>\n<blockquote>\n<p><span><strong>Lean Startup</strong>\u00a0is a set of processes used by entrepreneurs to develop products and markets, combining\u00a0<a title=\"Agile Software Development\" href=\"http://en.wikipedia.org/wiki/Agile_Software_Development\">Agile Software Development</a>,\u00a0<a title=\"Steven Gary Blank\" href=\"http://en.wikipedia.org/wiki/Steven_Gary_Blank#Customer_Development\">Customer Development</a>\u00a0and existing software platforms (usually\u00a0<a title=\"FOSS\" href=\"http://en.wikipedia.org/wiki/FOSS\">FOSS</a>).<sup title=\"This claim needs references to reliable sources from October 2010\" class=\"Template-Fact\">[<em><a title=\"Wikipedia:Citation needed\" href=\"http://en.wikipedia.org/wiki/Wikipedia:Citation_needed\">citation needed</a></em>]</sup></span></p>\n<p>Lean Startup initially advocates the creation of rapid prototypes designed to test market assumptions, and uses customer feedback to evolve them much faster than via more traditional software engineering practices, such as\u00a0<a title=\"Waterfall model\" href=\"http://en.wikipedia.org/wiki/Waterfall_model\">the Waterfall model</a>. It is not uncommon to see Lean Startups release new code to production multiple times a day,<sup class=\"reference\" id=\"cite_ref-0\"><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-0\"><span>[</span>1<span>]</span></a></sup>\u00a0often using a practice known as\u00a0<a title=\"Continuous Deployment (page does not exist)\" href=\"http://en.wikipedia.org/w/index.php?title=Continuous_Deployment&amp;action=edit&amp;redlink=1\">Continuous Deployment</a><sup class=\"reference\" id=\"cite_ref-1\"><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-1\"><span>[</span>2<span>]</span></a></sup>.</p>\n</blockquote>\n<p>In an analytic context, what does this mean? \u00a0We&rsquo;ll cover that tomorrow.</p>", "liked": false, "followed": false, "reblog_key": "0wPw2BXK", "reblog": {"comment": "<p>There is the customer\u2019s opinion. \u00a0There is the team\u2019s opinion. \u00a0And there is the data\u2019s opinion. \u00a0<strong>Building successful data products means reconciling these opinions</strong><strong>.</strong>\u00a0There is a right and wrong way to do so.</p>\n<p>The wrong way is called the\u00a0<em>Waterfall Model.</em>\u00a0\u00a0</p>\n<p><img height=\"384\" width=\"500\" src=\"http://farm2.static.flickr.com/1110/5112550728_a62ab241e1.jpg\" align=\"middle\"></p>\n<p>Wikipedia on the\u00a0<em>Waterfall Method</em>:</p>\n<blockquote>\n<p><span>The\u00a0<strong>waterfall model</strong>\u00a0is a\u00a0<a title=\"Sequence\" href=\"http://en.wikipedia.org/wiki/Sequence\">sequential</a>\u00a0<a title=\"Software development process\" href=\"http://en.wikipedia.org/wiki/Software_development_process\">software development process</a>, in which progress is seen as flowing steadily downwards (like a\u00a0<a title=\"Waterfall\" href=\"http://en.wikipedia.org/wiki/Waterfall\">waterfall</a>) through the phases of Conception, Initiation,\u00a0<a title=\"Analysis\" href=\"http://en.wikipedia.org/wiki/Analysis\">Analysis</a>,\u00a0<a title=\"Software design\" href=\"http://en.wikipedia.org/wiki/Software_design\">Design</a>, Construction,\u00a0<a title=\"Software testing\" href=\"http://en.wikipedia.org/wiki/Software_testing\">Testing</a>\u00a0and\u00a0<a title=\"Software maintenance\" href=\"http://en.wikipedia.org/wiki/Software_maintenance\">Maintenance</a>.</span></p>\n</blockquote>\n<p>The waterfall model\u00a0<strong>doesn\u2019t apply</strong>\u00a0to analytic products. \u00a0We may want to\u00a0<strong>design</strong>\u00a0data products, but the data refuses to cooperate. \u00a0The charts we design aren\u2019t informative. \u00a0We pick the wrong data sources. \u00a0Our models answer the wrong questions. \u00a0So we fudge it. \u00a0We make the data fit the design, when it wants to be something else. \u00a0When we do so, we undermine the insights we set out to deliver. \u00a0Success this way is unlikely.</p>\n<p>There\u2019s a better way. \u00a0A\u00a0<em><a href=\"http://www.startuplessonslearned.com/\">leaner</a></em>\u00a0way. \u00a0And despite being SO hot right now, it is the<a href=\"http://en.wikipedia.org/wiki/Middle_way\">middle path</a>.</p>\n<p><span>Wikipedia on\u00a0<em>Lean Startup</em>:</span></p>\n<blockquote>\n<p><span><strong>Lean Startup</strong>\u00a0is a set of processes used by entrepreneurs to develop products and markets, combining\u00a0<a title=\"Agile Software Development\" href=\"http://en.wikipedia.org/wiki/Agile_Software_Development\">Agile Software Development</a>,\u00a0<a title=\"Steven Gary Blank\" href=\"http://en.wikipedia.org/wiki/Steven_Gary_Blank#Customer_Development\">Customer Development</a>\u00a0and existing software platforms (usually\u00a0<a title=\"FOSS\" href=\"http://en.wikipedia.org/wiki/FOSS\">FOSS</a>).<sup title=\"This claim needs references to reliable sources from October 2010\" class=\"Template-Fact\">[<em><a title=\"Wikipedia:Citation needed\" href=\"http://en.wikipedia.org/wiki/Wikipedia:Citation_needed\">citation needed</a></em>]</sup></span></p>\n<p>Lean Startup initially advocates the creation of rapid prototypes designed to test market assumptions, and uses customer feedback to evolve them much faster than via more traditional software engineering practices, such as\u00a0<a title=\"Waterfall model\" href=\"http://en.wikipedia.org/wiki/Waterfall_model\">the Waterfall model</a>. It is not uncommon to see Lean Startups release new code to production multiple times a day,<sup class=\"reference\" id=\"cite_ref-0\"><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-0\"><span>[</span>1<span>]</span></a></sup>\u00a0often using a practice known as\u00a0<a title=\"Continuous Deployment (page does not exist)\" href=\"http://en.wikipedia.org/w/index.php?title=Continuous_Deployment&amp;action=edit&amp;redlink=1\">Continuous Deployment</a><sup class=\"reference\" id=\"cite_ref-1\"><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-1\"><span>[</span>2<span>]</span></a></sup>.</p>\n</blockquote>\n<p>In an analytic context, what does this mean? \u00a0We\u2019ll cover that tomorrow.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 3257303972, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Data is Ruthlessly Opinionated", "tags": [], "post_url": "http://datasyndrome.com/post/3257303972/data-is-ruthlessly-opinionated", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y329eEa", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1297542821, "note_count": 2, "trail": [{"content": "<p>There is the customer&rsquo;s opinion. &nbsp;There is the team&rsquo;s opinion. &nbsp;And there is the data&rsquo;s opinion. &nbsp;<strong>Building successful data products means reconciling these opinions</strong><strong>.</strong>&nbsp;There is a right and wrong way to do so.</p>\n<p>The wrong way is called the&nbsp;<em>Waterfall Model.</em>&nbsp;&nbsp;</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm2.static.flickr.com/1110/5112550728_a62ab241e1.jpg\">External image</div></p>\n<p>Wikipedia on the&nbsp;<em>Waterfall Method</em>:</p>\n<blockquote>\n<p>The&nbsp;<strong>waterfall model</strong>&nbsp;is a&nbsp;<a title=\"Sequence\" href=\"http://en.wikipedia.org/wiki/Sequence\">sequential</a>&nbsp;<a title=\"Software development process\" href=\"http://en.wikipedia.org/wiki/Software_development_process\">software development process</a>, in which progress is seen as flowing steadily downwards (like a&nbsp;<a title=\"Waterfall\" href=\"http://en.wikipedia.org/wiki/Waterfall\">waterfall</a>) through the phases of Conception, Initiation,&nbsp;<a title=\"Analysis\" href=\"http://en.wikipedia.org/wiki/Analysis\">Analysis</a>,&nbsp;<a title=\"Software design\" href=\"http://en.wikipedia.org/wiki/Software_design\">Design</a>, Construction,&nbsp;<a title=\"Software testing\" href=\"http://en.wikipedia.org/wiki/Software_testing\">Testing</a>&nbsp;and&nbsp;<a title=\"Software maintenance\" href=\"http://en.wikipedia.org/wiki/Software_maintenance\">Maintenance</a>.</p>\n</blockquote>\n<p>The waterfall model&nbsp;<strong>doesn&rsquo;t apply</strong>&nbsp;to analytic products. &nbsp;We may want to&nbsp;<strong>design</strong>&nbsp;data products, but the data refuses to cooperate. &nbsp;The charts we design aren&rsquo;t informative. &nbsp;We pick the wrong data sources. &nbsp;Our models answer the wrong questions. &nbsp;So we fudge it. &nbsp;We make the data fit the design, when it wants to be something else. &nbsp;When we do so, we undermine the insights we set out to deliver. &nbsp;Success this way is unlikely.</p>\n<p>There&rsquo;s a better way. &nbsp;A&nbsp;<em><a href=\"http://www.startuplessonslearned.com/\">leaner</a></em>&nbsp;way. &nbsp;And despite being SO hot right now, it is the<a href=\"http://en.wikipedia.org/wiki/Middle_way\">middle path</a>.</p>\n<p>Wikipedia on&nbsp;<em>Lean Startup</em>:</p>\n<blockquote>\n<p><strong>Lean Startup</strong>&nbsp;is a set of processes used by entrepreneurs to develop products and markets, combining&nbsp;<a title=\"Agile Software Development\" href=\"http://en.wikipedia.org/wiki/Agile_Software_Development\">Agile Software Development</a>,&nbsp;<a title=\"Steven Gary Blank\" href=\"http://en.wikipedia.org/wiki/Steven_Gary_Blank#Customer_Development\">Customer Development</a>&nbsp;and existing software platforms (usually&nbsp;<a title=\"FOSS\" href=\"http://en.wikipedia.org/wiki/FOSS\">FOSS</a>).<sup>[<em><a title=\"Wikipedia:Citation needed\" href=\"http://en.wikipedia.org/wiki/Wikipedia:Citation_needed\">citation needed</a></em>]</sup></p>\n<p>Lean Startup initially advocates the creation of rapid prototypes designed to test market assumptions, and uses customer feedback to evolve them much faster than via more traditional software engineering practices, such as&nbsp;<a title=\"Waterfall model\" href=\"http://en.wikipedia.org/wiki/Waterfall_model\">the Waterfall model</a>. It is not uncommon to see Lean Startups release new code to production multiple times a day,<sup><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-0\">[1]</a></sup>&nbsp;often using a practice known as&nbsp;<a title=\"Continuous Deployment (page does not exist)\" href=\"http://en.wikipedia.org/w/index.php?title=Continuous_Deployment&amp;action=edit&amp;redlink=1\">Continuous Deployment</a><sup><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-1\">[2]</a></sup>.</p>\n</blockquote>\n<p>In an analytic context, what does this mean? &nbsp;We&rsquo;ll cover that tomorrow.</p>", "content_raw": "<p>There is the customer\u2019s opinion. \u00a0There is the team\u2019s opinion. \u00a0And there is the data\u2019s opinion. \u00a0<strong>Building successful data products means reconciling these opinions</strong><strong>.</strong>\u00a0There is a right and wrong way to do so.</p>\n<p>The wrong way is called the\u00a0<em>Waterfall Model.</em>\u00a0\u00a0</p>\n<p><img height=\"384\" width=\"500\" src=\"http://farm2.static.flickr.com/1110/5112550728_a62ab241e1.jpg\" align=\"middle\"></p>\n<p>Wikipedia on the\u00a0<em>Waterfall Method</em>:</p>\n<blockquote>\n<p><span>The\u00a0<strong>waterfall model</strong>\u00a0is a\u00a0<a title=\"Sequence\" href=\"http://en.wikipedia.org/wiki/Sequence\">sequential</a>\u00a0<a title=\"Software development process\" href=\"http://en.wikipedia.org/wiki/Software_development_process\">software development process</a>, in which progress is seen as flowing steadily downwards (like a\u00a0<a title=\"Waterfall\" href=\"http://en.wikipedia.org/wiki/Waterfall\">waterfall</a>) through the phases of Conception, Initiation,\u00a0<a title=\"Analysis\" href=\"http://en.wikipedia.org/wiki/Analysis\">Analysis</a>,\u00a0<a title=\"Software design\" href=\"http://en.wikipedia.org/wiki/Software_design\">Design</a>, Construction,\u00a0<a title=\"Software testing\" href=\"http://en.wikipedia.org/wiki/Software_testing\">Testing</a>\u00a0and\u00a0<a title=\"Software maintenance\" href=\"http://en.wikipedia.org/wiki/Software_maintenance\">Maintenance</a>.</span></p>\n</blockquote>\n<p>The waterfall model\u00a0<strong>doesn\u2019t apply</strong>\u00a0to analytic products. \u00a0We may want to\u00a0<strong>design</strong>\u00a0data products, but the data refuses to cooperate. \u00a0The charts we design aren\u2019t informative. \u00a0We pick the wrong data sources. \u00a0Our models answer the wrong questions. \u00a0So we fudge it. \u00a0We make the data fit the design, when it wants to be something else. \u00a0When we do so, we undermine the insights we set out to deliver. \u00a0Success this way is unlikely.</p>\n<p>There\u2019s a better way. \u00a0A\u00a0<em><a href=\"http://www.startuplessonslearned.com/\">leaner</a></em>\u00a0way. \u00a0And despite being SO hot right now, it is the<a href=\"http://en.wikipedia.org/wiki/Middle_way\">middle path</a>.</p>\n<p><span>Wikipedia on\u00a0<em>Lean Startup</em>:</span></p>\n<blockquote>\n<p><span><strong>Lean Startup</strong>\u00a0is a set of processes used by entrepreneurs to develop products and markets, combining\u00a0<a title=\"Agile Software Development\" href=\"http://en.wikipedia.org/wiki/Agile_Software_Development\">Agile Software Development</a>,\u00a0<a title=\"Steven Gary Blank\" href=\"http://en.wikipedia.org/wiki/Steven_Gary_Blank#Customer_Development\">Customer Development</a>\u00a0and existing software platforms (usually\u00a0<a title=\"FOSS\" href=\"http://en.wikipedia.org/wiki/FOSS\">FOSS</a>).<sup title=\"This claim needs references to reliable sources from October 2010\" class=\"Template-Fact\">[<em><a title=\"Wikipedia:Citation needed\" href=\"http://en.wikipedia.org/wiki/Wikipedia:Citation_needed\">citation needed</a></em>]</sup></span></p>\n<p>Lean Startup initially advocates the creation of rapid prototypes designed to test market assumptions, and uses customer feedback to evolve them much faster than via more traditional software engineering practices, such as\u00a0<a title=\"Waterfall model\" href=\"http://en.wikipedia.org/wiki/Waterfall_model\">the Waterfall model</a>. It is not uncommon to see Lean Startups release new code to production multiple times a day,<sup class=\"reference\" id=\"cite_ref-0\"><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-0\"><span>[</span>1<span>]</span></a></sup>\u00a0often using a practice known as\u00a0<a title=\"Continuous Deployment (page does not exist)\" href=\"http://en.wikipedia.org/w/index.php?title=Continuous_Deployment&amp;action=edit&amp;redlink=1\">Continuous Deployment</a><sup class=\"reference\" id=\"cite_ref-1\"><a href=\"http://en.wikipedia.org/wiki/Lean_Startup#cite_note-1\"><span>[</span>2<span>]</span></a></sup>.</p>\n</blockquote>\n<p>In an analytic context, what does this mean? \u00a0We\u2019ll cover that tomorrow.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "3257303972"}}], "date": "2011-02-12 20:33:41 GMT", "slug": "data-is-ruthlessly-opinionated", "blog_name": "rjurney", "summary": "Data is Ruthlessly Opinionated", "can_reblog": true}, {"body": "<p>Surfline&rsquo;s LOLA dashboard is a great example of pretty &lsquo;advanced&rsquo; visualization in the consumer internet space that works well because it matches the user's\u00a0<a href=\"http://portal.acm.org/citation.cfm?id=1044205\">cognitive model</a>.</p>\n<p>Every surfer holds a conceptual model in his/her head for forecasting the quality of waves at their local break involving swell period and height, tides, the ocean bottom, wind, weather, water temperature and more. \u00a0Before sites like <a href=\"http://www.surfline.com\">www.surfline.com</a>, dedicated surfers would devote entire rooms to collecting maps and data on geography and the weather, so they could be on the water when the best waves rolled in. \u00a0</p>\n<p><a href=\"http://upload.wikimedia.org/wikipedia/commons/d/dd/2008_Atlantic_hurricane_season_map.png\"><img align=\"middle\" src=\"http://upload.wikimedia.org/wikipedia/commons/d/dd/2008_Atlantic_hurricane_season_map.png\" width=\"400\" height=\"309\"/></a></p>\n<p>When I lived in Florida, where there are no waves all summer except those created by tropical cyclones, we would pray for hurricanes all summer&hellip; checking the\u00a0<a href=\"http://www.nhc.noaa.gov/\">National Hurricane Center</a>\u00a0site every few days. \u00a0Ike and Josephine made my 2008 (while Ike ruined 2008 for many others). \u00a0Having trained hard for six months, I paddled out into double overhead waves from Ike at\u00a0<a href=\"http://bit.ly/standrewspark\">St. Andrew&rsquo;s Park</a>. \u00a0I wasn&rsquo;t ready. \u00a0The water was crystal clear, schools of dolphins were playing inside multi-story waves and I was on an elevator I could not get off. \u00a0Terrified, I fought the current for an hour, repeating to myself, &ldquo;I just wanna go home, I just wanna go home.&rdquo; \u00a0I didn&rsquo;t get a single wave. \u00a0I drove home.</p>\n<p>Fortunately, when Josephine&rsquo;s swell hit my\u00a0<a href=\"http://www.surfline.com/surf-report/flagler-pier-florida_5302/\">home break</a>\u00a0two weeks later, the merely overhead waves seemed small compared to those of Ike. \u00a0A friend (and witness) talked me into a hundred-yard, overhead right. \u00a0Best wave of my life, complete with bragging rights.</p>\n<p>Surfers take waves pretty seriously, so Surfline developed a predictive model for surfable waves called LOLA. \u00a0It is informed by buoys (swell period, direction and amplitude), weather stations, satellite imagery, user ratings and more. \u00a0It is unmatched in quality for forecasting good waves.</p>\n<p><img align=\"middle\" src=\"http://www.surfline.com/forecasters/blog/dashboard/1.ALLDASH.PNG\" width=\"400\" height=\"296\"/></p>\n<p>A free forecast created by this model is available to all users, but the dashboard costs extra. \u00a0The LOLA model, and its interface are fairly complex. \u00a0Because the data model and the interface match the user&rsquo;s cognitive model, Surfline is able to expose the complexities of the LOLA model as an up-sell under a freemium model. \u00a0I&rsquo;ve been a paying customer on and off for several years. \u00a0It is a great product.</p>\n<p>Predictive models are powerful and compelling. \u00a0They seem magical. \u00a0They tell the future! \u00a0They are essential for canning complex data into simpler forms for mass-consumable web pages, to address a core need or to answer an important question. \u00a0In this case: 'Are there good waves coming? \u00a0Should I plan to go surfing?&rsquo; \u00a0Most users want only a fast, at-a-glance answer to this question, a rating from\u00a0<a href=\"http://www.surfline.com/blogs/forecaster-blog/rating-of-surf-heights-and-quality_31942/\">Poor to Epic</a>. \u00a0But some users&hellip; Surfline&rsquo;s core audience, want the deeper insight that exposing the raw data gives them. \u00a0</p>\n<p>This is an opportunity, and it\u00a0<span>brings us to the point: If a predictive model is likely to address a problem&hellip; you should provide end-users with interactive access to its inputs before you sink a lot of time building the model in the first place. \u00a0If you can&rsquo;t build a dashboard that nails the first five questions a user would ask of your data through interactive visualization&hellip; odds are you are building the wrong model to solve their actual problem. \u00a0That is because unlike academia or other industries, b</span><span>uilding predictive models for the consumer internet is an inherently iterative process. \u00a0At the intersection of data and product, iterative validation isn&rsquo;t optional.</span></p>\n<p>How do you get that? \u00a0<a href=\"http://steveblank.com/2009/10/08/get-out-of-my-building/\">Get out of the building</a>, talk to users (or in surfline&rsquo;s case, be your user), get in their heads, build a small, interactive dashboard\u00a0<strong>fast</strong>, that lets your users touch the data. \u00a0Show it to everyone, get the end-user involved in product development until you nail their first 5 questions in a row with descriptive statistics in simple charts, and then get it on the public internet. \u00a0Collect feedback, and iterate more.</p>\n<p>Now you&rsquo;re ready to build your model. \u00a0And odds are&hellip; its the right one. \u00a0The one that will answer the right question and create the most value. \u00a0And your users will help clean your signals for you ;)</p>", "liked": false, "followed": false, "reblog_key": "kmxjwft1", "reblog": {"comment": "<p>Surfline\u2019s LOLA dashboard is a great example of pretty \u2018advanced\u2019 visualization in the consumer internet space that works well because it matches the user's\u00a0<a href=\"http://portal.acm.org/citation.cfm?id=1044205\">cognitive model</a>.</p>\n<p>Every surfer holds a conceptual model in his/her head for forecasting the quality of waves at their local break involving swell period and height, tides, the ocean bottom, wind, weather, water temperature and more. \u00a0Before sites like <a href=\"http://www.surfline.com\">www.surfline.com</a>, dedicated surfers would devote entire rooms to collecting maps and data on geography and the weather, so they could be on the water when the best waves rolled in. \u00a0</p>\n<p><a href=\"http://upload.wikimedia.org/wikipedia/commons/d/dd/2008_Atlantic_hurricane_season_map.png\"><img align=\"middle\" src=\"http://upload.wikimedia.org/wikipedia/commons/d/dd/2008_Atlantic_hurricane_season_map.png\" width=\"400\" height=\"309\"></a></p>\n<p>When I lived in Florida, where there are no waves all summer except those created by tropical cyclones, we would pray for hurricanes all summer\u2026 checking the\u00a0<a href=\"http://www.nhc.noaa.gov/\">National Hurricane Center</a>\u00a0site every few days. \u00a0Ike and Josephine made my 2008 (while Ike ruined 2008 for many others). \u00a0Having trained hard for six months, I paddled out into double overhead waves from Ike at\u00a0<a href=\"http://bit.ly/standrewspark\">St. Andrew\u2019s Park</a>. \u00a0I wasn\u2019t ready. \u00a0The water was crystal clear, schools of dolphins were playing inside multi-story waves and I was on an elevator I could not get off. \u00a0Terrified, I fought the current for an hour, repeating to myself, \u201cI just wanna go home, I just wanna go home.\u201d \u00a0I didn\u2019t get a single wave. \u00a0I drove home.</p>\n<p>Fortunately, when Josephine\u2019s swell hit my\u00a0<a href=\"http://www.surfline.com/surf-report/flagler-pier-florida_5302/\">home break</a>\u00a0two weeks later, the merely overhead waves seemed small compared to those of Ike. \u00a0A friend (and witness) talked me into a hundred-yard, overhead right. \u00a0Best wave of my life, complete with bragging rights.</p>\n<p>Surfers take waves pretty seriously, so Surfline developed a predictive model for surfable waves called LOLA. \u00a0It is informed by buoys (swell period, direction and amplitude), weather stations, satellite imagery, user ratings and more. \u00a0It is unmatched in quality for forecasting good waves.</p>\n<p><img align=\"middle\" src=\"http://www.surfline.com/forecasters/blog/dashboard/1.ALLDASH.PNG\" width=\"400\" height=\"296\"></p>\n<p>A free forecast created by this model is available to all users, but the dashboard costs extra. \u00a0The LOLA model, and its interface are fairly complex. \u00a0Because the data model and the interface match the user\u2019s cognitive model, Surfline is able to expose the complexities of the LOLA model as an up-sell under a freemium model. \u00a0I\u2019ve been a paying customer on and off for several years. \u00a0It is a great product.</p>\n<p>Predictive models are powerful and compelling. \u00a0They seem magical. \u00a0They tell the future! \u00a0They are essential for canning complex data into simpler forms for mass-consumable web pages, to address a core need or to answer an important question. \u00a0In this case: 'Are there good waves coming? \u00a0Should I plan to go surfing?\u2019 \u00a0Most users want only a fast, at-a-glance answer to this question, a rating from\u00a0<a href=\"http://www.surfline.com/blogs/forecaster-blog/rating-of-surf-heights-and-quality_31942/\">Poor to Epic</a>. \u00a0But some users\u2026 Surfline\u2019s core audience, want the deeper insight that exposing the raw data gives them. \u00a0</p>\n<p>This is an opportunity, and it\u00a0<span>brings us to the point: If a predictive model is likely to address a problem\u2026 you should provide end-users with interactive access to its inputs before you sink a lot of time building the model in the first place. \u00a0If you can\u2019t build a dashboard that nails the first five questions a user would ask of your data through interactive visualization\u2026 odds are you are building the wrong model to solve their actual problem. \u00a0That is because unlike academia or other industries, b</span><span>uilding predictive models for the consumer internet is an inherently iterative process. \u00a0At the intersection of data and product, iterative validation isn\u2019t optional.</span></p>\n<p>How do you get that? \u00a0<a href=\"http://steveblank.com/2009/10/08/get-out-of-my-building/\">Get out of the building</a>, talk to users (or in surfline\u2019s case, be your user), get in their heads, build a small, interactive dashboard\u00a0<strong>fast</strong>, that lets your users touch the data. \u00a0Show it to everyone, get the end-user involved in product development until you nail their first 5 questions in a row with descriptive statistics in simple charts, and then get it on the public internet. \u00a0Collect feedback, and iterate more.</p>\n<p>Now you\u2019re ready to build your model. \u00a0And odds are\u2026 its the right one. \u00a0The one that will answer the right question and create the most value. \u00a0And your users will help clean your signals for you ;)</p>", "tree_html": ""}, "can_send_in_message": true, "id": 3257293331, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Iterative Development of Predictive Models with Interactive Visualization OR The Obese Surfer Problem", "tags": [], "post_url": "http://datasyndrome.com/post/3257293331/iterative-development-of-predictive-models-with", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y329beJ", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1297542783, "note_count": 0, "trail": [{"content": "<p>Surfline&rsquo;s LOLA dashboard is a great example of pretty &lsquo;advanced&rsquo; visualization in the consumer internet space that works well because it matches the user's&nbsp;<a href=\"http://portal.acm.org/citation.cfm?id=1044205\">cognitive model</a>.</p>\n<p>Every surfer holds a conceptual model in his/her head for forecasting the quality of waves at their local break involving swell period and height, tides, the ocean bottom, wind, weather, water temperature and more. &nbsp;Before sites like <a href=\"http://www.surfline.com\">www.surfline.com</a>, dedicated surfers would devote entire rooms to collecting maps and data on geography and the weather, so they could be on the water when the best waves rolled in. &nbsp;</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://upload.wikimedia.org/wikipedia/commons/d/dd/2008_Atlantic_hurricane_season_map.png\">External image</div></p>\n<p>When I lived in Florida, where there are no waves all summer except those created by tropical cyclones, we would pray for hurricanes all summer&hellip; checking the&nbsp;<a href=\"http://www.nhc.noaa.gov/\">National Hurricane Center</a>&nbsp;site every few days. &nbsp;Ike and Josephine made my 2008 (while Ike ruined 2008 for many others). &nbsp;Having trained hard for six months, I paddled out into double overhead waves from Ike at&nbsp;<a href=\"http://bit.ly/standrewspark\">St. Andrew&rsquo;s Park</a>. &nbsp;I wasn&rsquo;t ready. &nbsp;The water was crystal clear, schools of dolphins were playing inside multi-story waves and I was on an elevator I could not get off. &nbsp;Terrified, I fought the current for an hour, repeating to myself, &ldquo;I just wanna go home, I just wanna go home.&rdquo; &nbsp;I didn&rsquo;t get a single wave. &nbsp;I drove home.</p>\n<p>Fortunately, when Josephine&rsquo;s swell hit my&nbsp;<a href=\"http://www.surfline.com/surf-report/flagler-pier-florida_5302/\">home break</a>&nbsp;two weeks later, the merely overhead waves seemed small compared to those of Ike. &nbsp;A friend (and witness) talked me into a hundred-yard, overhead right. &nbsp;Best wave of my life, complete with bragging rights.</p>\n<p>Surfers take waves pretty seriously, so Surfline developed a predictive model for surfable waves called LOLA. &nbsp;It is informed by buoys (swell period, direction and amplitude), weather stations, satellite imagery, user ratings and more. &nbsp;It is unmatched in quality for forecasting good waves.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://www.surfline.com/forecasters/blog/dashboard/1.ALLDASH.PNG\">External image</div></p>\n<p>A free forecast created by this model is available to all users, but the dashboard costs extra. &nbsp;The LOLA model, and its interface are fairly complex. &nbsp;Because the data model and the interface match the user&rsquo;s cognitive model, Surfline is able to expose the complexities of the LOLA model as an up-sell under a freemium model. &nbsp;I&rsquo;ve been a paying customer on and off for several years. &nbsp;It is a great product.</p>\n<p>Predictive models are powerful and compelling. &nbsp;They seem magical. &nbsp;They tell the future! &nbsp;They are essential for canning complex data into simpler forms for mass-consumable web pages, to address a core need or to answer an important question. &nbsp;In this case: 'Are there good waves coming? &nbsp;Should I plan to go surfing?&rsquo; &nbsp;Most users want only a fast, at-a-glance answer to this question, a rating from&nbsp;<a href=\"http://www.surfline.com/blogs/forecaster-blog/rating-of-surf-heights-and-quality_31942/\">Poor to Epic</a>. &nbsp;But some users&hellip; Surfline&rsquo;s core audience, want the deeper insight that exposing the raw data gives them. &nbsp;</p>\n<p>This is an opportunity, and it&nbsp;brings us to the point: If a predictive model is likely to address a problem&hellip; you should provide end-users with interactive access to its inputs before you sink a lot of time building the model in the first place. &nbsp;If you can&rsquo;t build a dashboard that nails the first five questions a user would ask of your data through interactive visualization&hellip; odds are you are building the wrong model to solve their actual problem. &nbsp;That is because unlike academia or other industries, building predictive models for the consumer internet is an inherently iterative process. &nbsp;At the intersection of data and product, iterative validation isn&rsquo;t optional.</p>\n<p>How do you get that? &nbsp;<a href=\"http://steveblank.com/2009/10/08/get-out-of-my-building/\">Get out of the building</a>, talk to users (or in surfline&rsquo;s case, be your user), get in their heads, build a small, interactive dashboard&nbsp;<strong>fast</strong>, that lets your users touch the data. &nbsp;Show it to everyone, get the end-user involved in product development until you nail their first 5 questions in a row with descriptive statistics in simple charts, and then get it on the public internet. &nbsp;Collect feedback, and iterate more.</p>\n<p>Now you&rsquo;re ready to build your model. &nbsp;And odds are&hellip; its the right one. &nbsp;The one that will answer the right question and create the most value. &nbsp;And your users will help clean your signals for you ;)</p>", "content_raw": "<p>Surfline\u2019s LOLA dashboard is a great example of pretty \u2018advanced\u2019 visualization in the consumer internet space that works well because it matches the user's\u00a0<a href=\"http://portal.acm.org/citation.cfm?id=1044205\">cognitive model</a>.</p>\n<p>Every surfer holds a conceptual model in his/her head for forecasting the quality of waves at their local break involving swell period and height, tides, the ocean bottom, wind, weather, water temperature and more. \u00a0Before sites like <a href=\"http://www.surfline.com\">www.surfline.com</a>, dedicated surfers would devote entire rooms to collecting maps and data on geography and the weather, so they could be on the water when the best waves rolled in. \u00a0</p>\n<p><a href=\"http://upload.wikimedia.org/wikipedia/commons/d/dd/2008_Atlantic_hurricane_season_map.png\"><img align=\"middle\" src=\"http://upload.wikimedia.org/wikipedia/commons/d/dd/2008_Atlantic_hurricane_season_map.png\" width=\"400\" height=\"309\"></a></p>\n<p>When I lived in Florida, where there are no waves all summer except those created by tropical cyclones, we would pray for hurricanes all summer\u2026 checking the\u00a0<a href=\"http://www.nhc.noaa.gov/\">National Hurricane Center</a>\u00a0site every few days. \u00a0Ike and Josephine made my 2008 (while Ike ruined 2008 for many others). \u00a0Having trained hard for six months, I paddled out into double overhead waves from Ike at\u00a0<a href=\"http://bit.ly/standrewspark\">St. Andrew\u2019s Park</a>. \u00a0I wasn\u2019t ready. \u00a0The water was crystal clear, schools of dolphins were playing inside multi-story waves and I was on an elevator I could not get off. \u00a0Terrified, I fought the current for an hour, repeating to myself, \u201cI just wanna go home, I just wanna go home.\u201d \u00a0I didn\u2019t get a single wave. \u00a0I drove home.</p>\n<p>Fortunately, when Josephine\u2019s swell hit my\u00a0<a href=\"http://www.surfline.com/surf-report/flagler-pier-florida_5302/\">home break</a>\u00a0two weeks later, the merely overhead waves seemed small compared to those of Ike. \u00a0A friend (and witness) talked me into a hundred-yard, overhead right. \u00a0Best wave of my life, complete with bragging rights.</p>\n<p>Surfers take waves pretty seriously, so Surfline developed a predictive model for surfable waves called LOLA. \u00a0It is informed by buoys (swell period, direction and amplitude), weather stations, satellite imagery, user ratings and more. \u00a0It is unmatched in quality for forecasting good waves.</p>\n<p><img align=\"middle\" src=\"http://www.surfline.com/forecasters/blog/dashboard/1.ALLDASH.PNG\" width=\"400\" height=\"296\"></p>\n<p>A free forecast created by this model is available to all users, but the dashboard costs extra. \u00a0The LOLA model, and its interface are fairly complex. \u00a0Because the data model and the interface match the user\u2019s cognitive model, Surfline is able to expose the complexities of the LOLA model as an up-sell under a freemium model. \u00a0I\u2019ve been a paying customer on and off for several years. \u00a0It is a great product.</p>\n<p>Predictive models are powerful and compelling. \u00a0They seem magical. \u00a0They tell the future! \u00a0They are essential for canning complex data into simpler forms for mass-consumable web pages, to address a core need or to answer an important question. \u00a0In this case: 'Are there good waves coming? \u00a0Should I plan to go surfing?\u2019 \u00a0Most users want only a fast, at-a-glance answer to this question, a rating from\u00a0<a href=\"http://www.surfline.com/blogs/forecaster-blog/rating-of-surf-heights-and-quality_31942/\">Poor to Epic</a>. \u00a0But some users\u2026 Surfline\u2019s core audience, want the deeper insight that exposing the raw data gives them. \u00a0</p>\n<p>This is an opportunity, and it\u00a0<span>brings us to the point: If a predictive model is likely to address a problem\u2026 you should provide end-users with interactive access to its inputs before you sink a lot of time building the model in the first place. \u00a0If you can\u2019t build a dashboard that nails the first five questions a user would ask of your data through interactive visualization\u2026 odds are you are building the wrong model to solve their actual problem. \u00a0That is because unlike academia or other industries, b</span><span>uilding predictive models for the consumer internet is an inherently iterative process. \u00a0At the intersection of data and product, iterative validation isn\u2019t optional.</span></p>\n<p>How do you get that? \u00a0<a href=\"http://steveblank.com/2009/10/08/get-out-of-my-building/\">Get out of the building</a>, talk to users (or in surfline\u2019s case, be your user), get in their heads, build a small, interactive dashboard\u00a0<strong>fast</strong>, that lets your users touch the data. \u00a0Show it to everyone, get the end-user involved in product development until you nail their first 5 questions in a row with descriptive statistics in simple charts, and then get it on the public internet. \u00a0Collect feedback, and iterate more.</p>\n<p>Now you\u2019re ready to build your model. \u00a0And odds are\u2026 its the right one. \u00a0The one that will answer the right question and create the most value. \u00a0And your users will help clean your signals for you ;)</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "3257293331"}}], "date": "2011-02-12 20:33:03 GMT", "slug": "iterative-development-of-predictive-models-with", "blog_name": "rjurney", "summary": "Iterative Development of Predictive Models with Interactive Visualization OR The Obese Surfer Problem", "can_reblog": true}, {"body": "<p>My first startup was called Lucision. \u00a0Thats Lucid + Decision.</p>\n<p>(Never name your startup something weird or clever unless it rolls off the tongue. \u00a0It was like naming a kid\u00a0<a href=\"http://en.wikipedia.org/wiki/The_Outsiders_(novel)\">Soda Pop</a>. \u00a0If you don&rsquo;t know what I mean, go listen to\u00a0<a href=\"http://www.azlyrics.com/lyrics/johnnycash/aboynamedsue.html\">A Boy Named Sue</a>. \u00a0Nobody could remember or pronounce &lsquo;Lucision,&rsquo; and I suffered misunderstanding on sales calls for two years because of it.)</p>\n<p>In its first iteration, Lucision aimed to turn court cases into\u00a0<a href=\"http://en.wikipedia.org/wiki/Decision_tree\">decision trees</a>\u00a0or\u00a0<a href=\"http://en.wikipedia.org/wiki/State_diagram\">state diagrams</a>. \u00a0Most legal cases are predictable, boilerplate stuff, so firms handle many at once, can&rsquo;t remember them, and have to recreate the state of each in their head when they work on them. \u00a0A lawyer friend sketched out a state chart of an eviction on a napkin at the Disco Diner in Atlanta at 2AM, and I was sold. \u00a0I spent a lot of time in legal libraries and I took a job doing IT for her law firm while working for my father building the farmhouse I would later live in. \u00a0I saved up money, and moved to Goa to focus on building a hot prototype. \u00a0I was a Perl hacker and had some bad habits, so it was\u00a0fortunate\u00a0that a computer science PhD was living next door. \u00a0We became friends, and he tutored me. \u00a0I read Design Patterns (and later recovered from it) and Object Oriented Analysis and Design, and built a graph-based document management system using Eclipse.</p>\n<p>Two years ago a friend gave a presentation on Cascading and Hadoop, and why I should care. \u00a0He convinced me. \u00a0I read the\u00a0<a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen paper</a>\u00a0and decided to\u00a0<a href=\"http://github.com/rjurney/Cloud-Stenography\">productize</a>\u00a0it with\u00a0<a href=\"http://neyric.github.com/wireit/\">WireIT</a>. \u00a0Thats when I realized I was into graphs in a big way.</p>\n<p>I learned graph theory and read up on network flows. \u00a0I learned graph layouts. \u00a0I solved analytic problems with interactive graphs in\u00a0<a href=\"http://processing.org/\">Processing</a>. \u00a0Graphs, graphs, graphs! \u00a0<span>I became obsessed with the\u00a0<a href=\"http://www.googlewonderwheel.com/\"><span class=\"s1\">Wonder Wheel</span></a>. \u00a0</span></p>\n<p class=\"p1\">Which brings us full circle to yesterday, where I think I identified a design pattern: Data-Driven Recursive Interfaces. \u00a0</p>\n<p class=\"p1\"><strong>Step 1</strong>) Create interesting, inter-connected records. \u00a0This is your problem, but if you look at it the right way your data is probably a graph. \u00a0Most interesting data is. \u00a0I like to use\u00a0<a href=\"http://hadoop.apache.org/\">Hadoop</a>,\u00a0<a href=\"http://pig.apache.org/\">Pig</a>\u00a0and\u00a0<a href=\"http://www.scipy.org/\">Python</a>\u00a0to do this. \u00a0Shrink the big or medium data into summaries you can serve for people to consume directly.</p>\n<p class=\"p1\"><strong>Step 2</strong>) Store these records as objects in a key/value store, like so:</p>\n<p class=\"p1\">key =&gt; {property1, property2, links =&gt; [key1, key2, key3]}</p>\n<p class=\"p1\">Split records as properties increase and become complex to avoid deep nesting. \u00a0Or go at it as a document. \u00a0Both approaches are valid if they fit your data.</p>\n<p class=\"p1\"><strong>Step 3</strong>) Use a lightweight web framework like\u00a0<a href=\"http://www.sinatrarb.com/\">Sinatra</a>\u00a0to emit the key/value data as JSON, or use a key/value store that returns JSON in the first place.</p>\n<p class=\"p1\">In Ruby/Sinatra with\u00a0<a href=\"http://project-voldemort.com/\">Voldemort</a>, generating JSON to go directly in a protovis chart looks like this (leave my Ruby alone):</p>\n<blockquote>\n<p class=\"p1\">get &rsquo;/experience/:title&rsquo; do |title|</p>\n<p class=\"p1\">\u00a0\u00a0experience = experience_client.get(title)</p>\n<p class=\"p1\">\u00a0\u00a0values = []</p>\n<p class=\"p1\">\u00a0\u00a0experience['by_years&rsquo;].each do |i|</p>\n<p class=\"p1\">\u00a0\u00a0 \u00a0values &lt;&lt; {'x&rsquo; =&gt; i['start_years&rsquo;], 'y&rsquo; =&gt; i['total&rsquo;]}</p>\n<p class=\"p1\">\u00a0\u00a0end</p>\n<p class=\"p1\">\u00a0\u00a0JSON.generate(values)</p>\n<p class=\"p1\">end</p>\n</blockquote>\n<p class=\"p1\"><strong>Step 4</strong>) Construct a single, light-weight interface, that renders the keys into HTML/JS. \u00a0Use visualization:\u00a0<a href=\"http://vis.stanford.edu/protovis/\">Protovis</a>,\u00a0<a href=\"http://raphaeljs.com/\">Raphael</a>,\u00a0<a href=\"http://processingjs.org/\">ProcessingJS</a>, etc. \u00a0Add HTML links between records.</p>\n<p class=\"p2\"><img height=\"360\" width=\"510\" src=\"http://farm2.static.flickr.com/1354/5103245691_26ea3ed91f_z.jpg\" align=\"middle\"/></p>\n<p class=\"p1\"><strong>Result:</strong>\u00a0Using batch processing, a key/value store, and light web and visualization frameworks&hellip; you made one simple type of record and an interface for it that enables endless exploration. \u00a0I call that tremendous bang for the buck, and the technology stack helps you along the way. \u00a0It is opinionated, as though this is the kind of thing you are supposed to be doing because there is such little\u00a0impedance between the model and view.</p>\n<p class=\"p1\">In contrast to relational database systems, Hadoop and NoSQL facilitates graph centric interfaces and enable graph-centric exploration and thinking. \u00a0</p>\n<p class=\"p1\">A record in a table is no longer the base unit. \u00a0Tables aren&rsquo;t real. \u00a0Graphs are real. \u00a0Take note.</p>", "liked": false, "followed": false, "reblog_key": "hNAQvfpC", "reblog": {"comment": "<p>My first startup was called Lucision. \u00a0Thats Lucid + Decision.</p>\n<p>(Never name your startup something weird or clever unless it rolls off the tongue. \u00a0It was like naming a kid\u00a0<a href=\"http://en.wikipedia.org/wiki/The_Outsiders_(novel)\">Soda Pop</a>. \u00a0If you don\u2019t know what I mean, go listen to\u00a0<a href=\"http://www.azlyrics.com/lyrics/johnnycash/aboynamedsue.html\">A Boy Named Sue</a>. \u00a0Nobody could remember or pronounce \u2018Lucision,\u2019 and I suffered misunderstanding on sales calls for two years because of it.)</p>\n<p>In its first iteration, Lucision aimed to turn court cases into\u00a0<a href=\"http://en.wikipedia.org/wiki/Decision_tree\">decision trees</a>\u00a0or\u00a0<a href=\"http://en.wikipedia.org/wiki/State_diagram\">state diagrams</a>. \u00a0Most legal cases are predictable, boilerplate stuff, so firms handle many at once, can\u2019t remember them, and have to recreate the state of each in their head when they work on them. \u00a0A lawyer friend sketched out a state chart of an eviction on a napkin at the Disco Diner in Atlanta at 2AM, and I was sold. \u00a0I spent a lot of time in legal libraries and I took a job doing IT for her law firm while working for my father building the farmhouse I would later live in. \u00a0I saved up money, and moved to Goa to focus on building a hot prototype. \u00a0I was a Perl hacker and had some bad habits, so it was\u00a0fortunate\u00a0that a computer science PhD was living next door. \u00a0We became friends, and he tutored me. \u00a0I read Design Patterns (and later recovered from it) and Object Oriented Analysis and Design, and built a graph-based document management system using Eclipse.</p>\n<p>Two years ago a friend gave a presentation on Cascading and Hadoop, and why I should care. \u00a0He convinced me. \u00a0I read the\u00a0<a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen paper</a>\u00a0and decided to\u00a0<a href=\"http://github.com/rjurney/Cloud-Stenography\">productize</a>\u00a0it with\u00a0<a href=\"http://neyric.github.com/wireit/\">WireIT</a>. \u00a0Thats when I realized I was into graphs in a big way.</p>\n<p>I learned graph theory and read up on network flows. \u00a0I learned graph layouts. \u00a0I solved analytic problems with interactive graphs in\u00a0<a href=\"http://processing.org/\">Processing</a>. \u00a0Graphs, graphs, graphs! \u00a0<span>I became obsessed with the\u00a0<a href=\"http://www.googlewonderwheel.com/\"><span class=\"s1\">Wonder Wheel</span></a>. \u00a0</span></p>\n<p class=\"p1\">Which brings us full circle to yesterday, where I think I identified a design pattern: Data-Driven Recursive Interfaces. \u00a0</p>\n<p class=\"p1\"><strong>Step 1</strong>) Create interesting, inter-connected records. \u00a0This is your problem, but if you look at it the right way your data is probably a graph. \u00a0Most interesting data is. \u00a0I like to use\u00a0<a href=\"http://hadoop.apache.org/\">Hadoop</a>,\u00a0<a href=\"http://pig.apache.org/\">Pig</a>\u00a0and\u00a0<a href=\"http://www.scipy.org/\">Python</a>\u00a0to do this. \u00a0Shrink the big or medium data into summaries you can serve for people to consume directly.</p>\n<p class=\"p1\"><strong>Step 2</strong>) Store these records as objects in a key/value store, like so:</p>\n<p class=\"p1\">key =&gt; {property1, property2, links =&gt; [key1, key2, key3]}</p>\n<p class=\"p1\">Split records as properties increase and become complex to avoid deep nesting. \u00a0Or go at it as a document. \u00a0Both approaches are valid if they fit your data.</p>\n<p class=\"p1\"><strong>Step 3</strong>) Use a lightweight web framework like\u00a0<a href=\"http://www.sinatrarb.com/\">Sinatra</a>\u00a0to emit the key/value data as JSON, or use a key/value store that returns JSON in the first place.</p>\n<p class=\"p1\">In Ruby/Sinatra with\u00a0<a href=\"http://project-voldemort.com/\">Voldemort</a>, generating JSON to go directly in a protovis chart looks like this (leave my Ruby alone):</p>\n<blockquote>\n<p class=\"p1\">get \u2019/experience/:title\u2019 do |title|</p>\n<p class=\"p1\">\u00a0\u00a0experience = experience_client.get(title)</p>\n<p class=\"p1\">\u00a0\u00a0values = []</p>\n<p class=\"p1\">\u00a0\u00a0experience['by_years\u2019].each do |i|</p>\n<p class=\"p1\">\u00a0\u00a0 \u00a0values &lt;&lt; {'x\u2019 =&gt; i['start_years\u2019], 'y\u2019 =&gt; i['total\u2019]}</p>\n<p class=\"p1\">\u00a0\u00a0end</p>\n<p class=\"p1\">\u00a0\u00a0JSON.generate(values)</p>\n<p class=\"p1\">end</p>\n</blockquote>\n<p class=\"p1\"><strong>Step 4</strong>) Construct a single, light-weight interface, that renders the keys into HTML/JS. \u00a0Use visualization:\u00a0<a href=\"http://vis.stanford.edu/protovis/\">Protovis</a>,\u00a0<a href=\"http://raphaeljs.com/\">Raphael</a>,\u00a0<a href=\"http://processingjs.org/\">ProcessingJS</a>, etc. \u00a0Add HTML links between records.</p>\n<p class=\"p2\"><img height=\"360\" width=\"510\" src=\"http://farm2.static.flickr.com/1354/5103245691_26ea3ed91f_z.jpg\" align=\"middle\"></p>\n<p class=\"p1\"><strong>Result:</strong>\u00a0Using batch processing, a key/value store, and light web and visualization frameworks\u2026 you made one simple type of record and an interface for it that enables endless exploration. \u00a0I call that tremendous bang for the buck, and the technology stack helps you along the way. \u00a0It is opinionated, as though this is the kind of thing you are supposed to be doing because there is such little\u00a0impedance between the model and view.</p>\n<p class=\"p1\">In contrast to relational database systems, Hadoop and NoSQL facilitates graph centric interfaces and enable graph-centric exploration and thinking. \u00a0</p>\n<p class=\"p1\">A record in a table is no longer the base unit. \u00a0Tables aren\u2019t real. \u00a0Graphs are real. \u00a0Take note.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 3257282059, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Data-Driven Recursive Interfaces for Graph Data", "tags": [], "post_url": "http://datasyndrome.com/post/3257282059/data-driven-recursive-interfaces-for-graph-data", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y329YuB", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1297542743, "note_count": 0, "trail": [{"content": "<p>My first startup was called Lucision. &nbsp;Thats Lucid + Decision.</p>\n<p>(Never name your startup something weird or clever unless it rolls off the tongue. &nbsp;It was like naming a kid&nbsp;<a href=\"http://en.wikipedia.org/wiki/The_Outsiders_(novel)\">Soda Pop</a>. &nbsp;If you don&rsquo;t know what I mean, go listen to&nbsp;<a href=\"http://www.azlyrics.com/lyrics/johnnycash/aboynamedsue.html\">A Boy Named Sue</a>. &nbsp;Nobody could remember or pronounce &lsquo;Lucision,&rsquo; and I suffered misunderstanding on sales calls for two years because of it.)</p>\n<p>In its first iteration, Lucision aimed to turn court cases into&nbsp;<a href=\"http://en.wikipedia.org/wiki/Decision_tree\">decision trees</a>&nbsp;or&nbsp;<a href=\"http://en.wikipedia.org/wiki/State_diagram\">state diagrams</a>. &nbsp;Most legal cases are predictable, boilerplate stuff, so firms handle many at once, can&rsquo;t remember them, and have to recreate the state of each in their head when they work on them. &nbsp;A lawyer friend sketched out a state chart of an eviction on a napkin at the Disco Diner in Atlanta at 2AM, and I was sold. &nbsp;I spent a lot of time in legal libraries and I took a job doing IT for her law firm while working for my father building the farmhouse I would later live in. &nbsp;I saved up money, and moved to Goa to focus on building a hot prototype. &nbsp;I was a Perl hacker and had some bad habits, so it was&nbsp;fortunate&nbsp;that a computer science PhD was living next door. &nbsp;We became friends, and he tutored me. &nbsp;I read Design Patterns (and later recovered from it) and Object Oriented Analysis and Design, and built a graph-based document management system using Eclipse.</p>\n<p>Two years ago a friend gave a presentation on Cascading and Hadoop, and why I should care. &nbsp;He convinced me. &nbsp;I read the&nbsp;<a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen paper</a>&nbsp;and decided to&nbsp;<a href=\"http://github.com/rjurney/Cloud-Stenography\">productize</a>&nbsp;it with&nbsp;<a href=\"http://neyric.github.com/wireit/\">WireIT</a>. &nbsp;Thats when I realized I was into graphs in a big way.</p>\n<p>I learned graph theory and read up on network flows. &nbsp;I learned graph layouts. &nbsp;I solved analytic problems with interactive graphs in&nbsp;<a href=\"http://processing.org/\">Processing</a>. &nbsp;Graphs, graphs, graphs! &nbsp;I became obsessed with the&nbsp;<a href=\"http://www.googlewonderwheel.com/\">Wonder Wheel</a>. &nbsp;</p>\n<p>Which brings us full circle to yesterday, where I think I identified a design pattern: Data-Driven Recursive Interfaces. &nbsp;</p>\n<p><strong>Step 1</strong>) Create interesting, inter-connected records. &nbsp;This is your problem, but if you look at it the right way your data is probably a graph. &nbsp;Most interesting data is. &nbsp;I like to use&nbsp;<a href=\"http://hadoop.apache.org/\">Hadoop</a>,&nbsp;<a href=\"http://pig.apache.org/\">Pig</a>&nbsp;and&nbsp;<a href=\"http://www.scipy.org/\">Python</a>&nbsp;to do this. &nbsp;Shrink the big or medium data into summaries you can serve for people to consume directly.</p>\n<p><strong>Step 2</strong>) Store these records as objects in a key/value store, like so:</p>\n<p>key =&gt; {property1, property2, links =&gt; [key1, key2, key3]}</p>\n<p>Split records as properties increase and become complex to avoid deep nesting. &nbsp;Or go at it as a document. &nbsp;Both approaches are valid if they fit your data.</p>\n<p><strong>Step 3</strong>) Use a lightweight web framework like&nbsp;<a href=\"http://www.sinatrarb.com/\">Sinatra</a>&nbsp;to emit the key/value data as JSON, or use a key/value store that returns JSON in the first place.</p>\n<p>In Ruby/Sinatra with&nbsp;<a href=\"http://project-voldemort.com/\">Voldemort</a>, generating JSON to go directly in a protovis chart looks like this (leave my Ruby alone):</p>\n<blockquote>\n<p>get &rsquo;/experience/:title&rsquo; do |title|</p>\n<p>&nbsp;&nbsp;experience = experience_client.get(title)</p>\n<p>&nbsp;&nbsp;values = []</p>\n<p>&nbsp;&nbsp;experience['by_years&rsquo;].each do |i|</p>\n<p>&nbsp;&nbsp; &nbsp;values &lt;&lt; {'x&rsquo; =&gt; i['start_years&rsquo;], 'y&rsquo; =&gt; i['total&rsquo;]}</p>\n<p>&nbsp;&nbsp;end</p>\n<p>&nbsp;&nbsp;JSON.generate(values)</p>\n<p>end</p>\n</blockquote>\n<p><strong>Step 4</strong>) Construct a single, light-weight interface, that renders the keys into HTML/JS. &nbsp;Use visualization:&nbsp;<a href=\"http://vis.stanford.edu/protovis/\">Protovis</a>,&nbsp;<a href=\"http://raphaeljs.com/\">Raphael</a>,&nbsp;<a href=\"http://processingjs.org/\">ProcessingJS</a>, etc. &nbsp;Add HTML links between records.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm2.static.flickr.com/1354/5103245691_26ea3ed91f_z.jpg\">External image</div></p>\n<p><strong>Result:</strong>&nbsp;Using batch processing, a key/value store, and light web and visualization frameworks&hellip; you made one simple type of record and an interface for it that enables endless exploration. &nbsp;I call that tremendous bang for the buck, and the technology stack helps you along the way. &nbsp;It is opinionated, as though this is the kind of thing you are supposed to be doing because there is such little&nbsp;impedance between the model and view.</p>\n<p>In contrast to relational database systems, Hadoop and NoSQL facilitates graph centric interfaces and enable graph-centric exploration and thinking. &nbsp;</p>\n<p>A record in a table is no longer the base unit. &nbsp;Tables aren&rsquo;t real. &nbsp;Graphs are real. &nbsp;Take note.</p>", "content_raw": "<p>My first startup was called Lucision. \u00a0Thats Lucid + Decision.</p>\n<p>(Never name your startup something weird or clever unless it rolls off the tongue. \u00a0It was like naming a kid\u00a0<a href=\"http://en.wikipedia.org/wiki/The_Outsiders_(novel)\">Soda Pop</a>. \u00a0If you don\u2019t know what I mean, go listen to\u00a0<a href=\"http://www.azlyrics.com/lyrics/johnnycash/aboynamedsue.html\">A Boy Named Sue</a>. \u00a0Nobody could remember or pronounce \u2018Lucision,\u2019 and I suffered misunderstanding on sales calls for two years because of it.)</p>\n<p>In its first iteration, Lucision aimed to turn court cases into\u00a0<a href=\"http://en.wikipedia.org/wiki/Decision_tree\">decision trees</a>\u00a0or\u00a0<a href=\"http://en.wikipedia.org/wiki/State_diagram\">state diagrams</a>. \u00a0Most legal cases are predictable, boilerplate stuff, so firms handle many at once, can\u2019t remember them, and have to recreate the state of each in their head when they work on them. \u00a0A lawyer friend sketched out a state chart of an eviction on a napkin at the Disco Diner in Atlanta at 2AM, and I was sold. \u00a0I spent a lot of time in legal libraries and I took a job doing IT for her law firm while working for my father building the farmhouse I would later live in. \u00a0I saved up money, and moved to Goa to focus on building a hot prototype. \u00a0I was a Perl hacker and had some bad habits, so it was\u00a0fortunate\u00a0that a computer science PhD was living next door. \u00a0We became friends, and he tutored me. \u00a0I read Design Patterns (and later recovered from it) and Object Oriented Analysis and Design, and built a graph-based document management system using Eclipse.</p>\n<p>Two years ago a friend gave a presentation on Cascading and Hadoop, and why I should care. \u00a0He convinced me. \u00a0I read the\u00a0<a href=\"http://research.yahoo.com/files/paper_5.pdf\">PigPen paper</a>\u00a0and decided to\u00a0<a href=\"http://github.com/rjurney/Cloud-Stenography\">productize</a>\u00a0it with\u00a0<a href=\"http://neyric.github.com/wireit/\">WireIT</a>. \u00a0Thats when I realized I was into graphs in a big way.</p>\n<p>I learned graph theory and read up on network flows. \u00a0I learned graph layouts. \u00a0I solved analytic problems with interactive graphs in\u00a0<a href=\"http://processing.org/\">Processing</a>. \u00a0Graphs, graphs, graphs! \u00a0<span>I became obsessed with the\u00a0<a href=\"http://www.googlewonderwheel.com/\"><span class=\"s1\">Wonder Wheel</span></a>. \u00a0</span></p>\n<p class=\"p1\">Which brings us full circle to yesterday, where I think I identified a design pattern: Data-Driven Recursive Interfaces. \u00a0</p>\n<p class=\"p1\"><strong>Step 1</strong>) Create interesting, inter-connected records. \u00a0This is your problem, but if you look at it the right way your data is probably a graph. \u00a0Most interesting data is. \u00a0I like to use\u00a0<a href=\"http://hadoop.apache.org/\">Hadoop</a>,\u00a0<a href=\"http://pig.apache.org/\">Pig</a>\u00a0and\u00a0<a href=\"http://www.scipy.org/\">Python</a>\u00a0to do this. \u00a0Shrink the big or medium data into summaries you can serve for people to consume directly.</p>\n<p class=\"p1\"><strong>Step 2</strong>) Store these records as objects in a key/value store, like so:</p>\n<p class=\"p1\">key =&gt; {property1, property2, links =&gt; [key1, key2, key3]}</p>\n<p class=\"p1\">Split records as properties increase and become complex to avoid deep nesting. \u00a0Or go at it as a document. \u00a0Both approaches are valid if they fit your data.</p>\n<p class=\"p1\"><strong>Step 3</strong>) Use a lightweight web framework like\u00a0<a href=\"http://www.sinatrarb.com/\">Sinatra</a>\u00a0to emit the key/value data as JSON, or use a key/value store that returns JSON in the first place.</p>\n<p class=\"p1\">In Ruby/Sinatra with\u00a0<a href=\"http://project-voldemort.com/\">Voldemort</a>, generating JSON to go directly in a protovis chart looks like this (leave my Ruby alone):</p>\n<blockquote>\n<p class=\"p1\">get \u2019/experience/:title\u2019 do |title|</p>\n<p class=\"p1\">\u00a0\u00a0experience = experience_client.get(title)</p>\n<p class=\"p1\">\u00a0\u00a0values = []</p>\n<p class=\"p1\">\u00a0\u00a0experience['by_years\u2019].each do |i|</p>\n<p class=\"p1\">\u00a0\u00a0 \u00a0values &lt;&lt; {'x\u2019 =&gt; i['start_years\u2019], 'y\u2019 =&gt; i['total\u2019]}</p>\n<p class=\"p1\">\u00a0\u00a0end</p>\n<p class=\"p1\">\u00a0\u00a0JSON.generate(values)</p>\n<p class=\"p1\">end</p>\n</blockquote>\n<p class=\"p1\"><strong>Step 4</strong>) Construct a single, light-weight interface, that renders the keys into HTML/JS. \u00a0Use visualization:\u00a0<a href=\"http://vis.stanford.edu/protovis/\">Protovis</a>,\u00a0<a href=\"http://raphaeljs.com/\">Raphael</a>,\u00a0<a href=\"http://processingjs.org/\">ProcessingJS</a>, etc. \u00a0Add HTML links between records.</p>\n<p class=\"p2\"><img height=\"360\" width=\"510\" src=\"http://farm2.static.flickr.com/1354/5103245691_26ea3ed91f_z.jpg\" align=\"middle\"></p>\n<p class=\"p1\"><strong>Result:</strong>\u00a0Using batch processing, a key/value store, and light web and visualization frameworks\u2026 you made one simple type of record and an interface for it that enables endless exploration. \u00a0I call that tremendous bang for the buck, and the technology stack helps you along the way. \u00a0It is opinionated, as though this is the kind of thing you are supposed to be doing because there is such little\u00a0impedance between the model and view.</p>\n<p class=\"p1\">In contrast to relational database systems, Hadoop and NoSQL facilitates graph centric interfaces and enable graph-centric exploration and thinking. \u00a0</p>\n<p class=\"p1\">A record in a table is no longer the base unit. \u00a0Tables aren\u2019t real. \u00a0Graphs are real. \u00a0Take note.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "3257282059"}}], "date": "2011-02-12 20:32:23 GMT", "slug": "data-driven-recursive-interfaces-for-graph-data", "blog_name": "rjurney", "summary": "Data-Driven Recursive Interfaces for Graph Data", "can_reblog": true}, {"body": "<p>It takes a lot of skills to build successful analytic products. \u00a0(<a href=\"http://www.linkedin.com/in/bradfordcross\">Bradford Cross</a>\u00a0<a href=\"http://measuringmeasures.com/blog/2010/7/2/research-driven-startups.html\">outlined the process well</a>). \u00a0The roles, defined in a spectrum from customer to researcher might look like this, although the continuum is not strictly speaking accurate (click to enlarge):</p>\n<p><a href=\"http://farm2.static.flickr.com/1389/5105430385_2e1f8e9230_b.jpg\"><img height=\"66\" width=\"512\" src=\"http://farm2.static.flickr.com/1389/5105430385_2e1f8e9230_b.jpg\" align=\"middle\"/></a></p>\n<p>Note that customer participation during the entire process is not optional if you&rsquo;re trying to make money.</p>\n<p>In a big company, you might see one person occupying each of these roles. \u00a0Of course, as team size increases\u00a0<a href=\"http://en.wikipedia.org/wiki/The_Mythical_Man-Month\">communication overhead</a>\u00a0rises and rapid release becomes impossible. \u00a0This can be mitigated by assigning only three people to a product at a time who&rsquo;s skills cover most of these areas, and lending them expert resources in areas they are short, only as needed.</p>\n<p><a href=\"http://farm2.static.flickr.com/1067/5105430391_d418a77072_b.jpg\"><img height=\"78\" width=\"512\" src=\"http://farm2.static.flickr.com/1067/5105430391_d418a77072_b.jpg\" align=\"middle\"/></a></p>\n<p>Analytic products are such a such a\u00a0multidisciplinary\u00a0undertaking that in a data startup a founding team is at minimum three people. \u00a0Ideally all are founders. \u00a0There are probably exceptions, but that is the minimum number of bodies required to flesh out all these areas with passionate people who share the vision and are deeply invested in the success of the company. \u00a0Someone needs to be good at and enjoy each of these roles.</p>\n<p>Of course, the split doesn&rsquo;t have to look like that. \u00a0It could look many ways:</p>\n<p><a href=\"http://farm2.static.flickr.com/1413/5105430397_bfabdd4904_b.jpg\"><img height=\"103\" width=\"512\" src=\"http://farm2.static.flickr.com/1413/5105430397_bfabdd4904_b.jpg\" align=\"middle\"/></a></p>\n<p>In the second configuration, one of you is the customer. \u00a0That is ideal because you are building for the guy &rsquo;<a href=\"http://steveblank.com/\">on the next bench</a>,&rsquo; (Steve Blank&rsquo;s phrase, refers to the next\u00a0soldering\u00a0bench and the fact that silicon valley always worked this way until quite recently) but it doesn&rsquo;t replace\u00a0<a href=\"http://steveblank.com/category/customer-development/\">customer development</a>.</p>\n<p>The third configuration is more eclectic. \u00a0The point being that there is no right answer, but you&rsquo;d better have these bases covered.</p>\n<p>For an analytics product, this is the customer development team. \u00a0Nobody is in charge and everyone participates. \u00a0Build a minimal v0.1 inside of one month that expresses your core insight and some key feature of the data. \u00a0Then drive, fly or swim to a real customer and introduce them to your application in person. \u00a0Give them access and keep them clicking each alpha release. \u00a0Log everything. \u00a0Monitor and evolve your metrics. \u00a0If you lose your alpha users, pivot.</p>\n<p>As\u00a0<a href=\"http://www.dhamma.org/en/goenka.shtml\">S.N. Goenka</a>\u00a0says at the end of a\u00a0<a href=\"http://en.wikipedia.org/wiki/Vipassan%C4%81\">Vipassana</a>\u00a0session&hellip; &ldquo;you are bound to be successful, bound to be successful&hellip;&rdquo; (Note: not affiliated with Goenka, but dug my first retreat).</p>", "liked": false, "followed": false, "reblog_key": "DvBDQaVZ", "reblog": {"comment": "<p>It takes a lot of skills to build successful analytic products. \u00a0(<a href=\"http://www.linkedin.com/in/bradfordcross\">Bradford Cross</a>\u00a0<a href=\"http://measuringmeasures.com/blog/2010/7/2/research-driven-startups.html\">outlined the process well</a>). \u00a0The roles, defined in a spectrum from customer to researcher might look like this, although the continuum is not strictly speaking accurate (click to enlarge):</p>\n<p><a href=\"http://farm2.static.flickr.com/1389/5105430385_2e1f8e9230_b.jpg\"><img height=\"66\" width=\"512\" src=\"http://farm2.static.flickr.com/1389/5105430385_2e1f8e9230_b.jpg\" align=\"middle\"></a></p>\n<p>Note that customer participation during the entire process is not optional if you\u2019re trying to make money.</p>\n<p>In a big company, you might see one person occupying each of these roles. \u00a0Of course, as team size increases\u00a0<a href=\"http://en.wikipedia.org/wiki/The_Mythical_Man-Month\">communication overhead</a>\u00a0rises and rapid release becomes impossible. \u00a0This can be mitigated by assigning only three people to a product at a time who\u2019s skills cover most of these areas, and lending them expert resources in areas they are short, only as needed.</p>\n<p><a href=\"http://farm2.static.flickr.com/1067/5105430391_d418a77072_b.jpg\"><img height=\"78\" width=\"512\" src=\"http://farm2.static.flickr.com/1067/5105430391_d418a77072_b.jpg\" align=\"middle\"></a></p>\n<p>Analytic products are such a such a\u00a0multidisciplinary\u00a0undertaking that in a data startup a founding team is at minimum three people. \u00a0Ideally all are founders. \u00a0There are probably exceptions, but that is the minimum number of bodies required to flesh out all these areas with passionate people who share the vision and are deeply invested in the success of the company. \u00a0Someone needs to be good at and enjoy each of these roles.</p>\n<p>Of course, the split doesn\u2019t have to look like that. \u00a0It could look many ways:</p>\n<p><a href=\"http://farm2.static.flickr.com/1413/5105430397_bfabdd4904_b.jpg\"><img height=\"103\" width=\"512\" src=\"http://farm2.static.flickr.com/1413/5105430397_bfabdd4904_b.jpg\" align=\"middle\"></a></p>\n<p>In the second configuration, one of you is the customer. \u00a0That is ideal because you are building for the guy \u2019<a href=\"http://steveblank.com/\">on the next bench</a>,\u2019 (Steve Blank\u2019s phrase, refers to the next\u00a0soldering\u00a0bench and the fact that silicon valley always worked this way until quite recently) but it doesn\u2019t replace\u00a0<a href=\"http://steveblank.com/category/customer-development/\">customer development</a>.</p>\n<p>The third configuration is more eclectic. \u00a0The point being that there is no right answer, but you\u2019d better have these bases covered.</p>\n<p>For an analytics product, this is the customer development team. \u00a0Nobody is in charge and everyone participates. \u00a0Build a minimal v0.1 inside of one month that expresses your core insight and some key feature of the data. \u00a0Then drive, fly or swim to a real customer and introduce them to your application in person. \u00a0Give them access and keep them clicking each alpha release. \u00a0Log everything. \u00a0Monitor and evolve your metrics. \u00a0If you lose your alpha users, pivot.</p>\n<p>As\u00a0<a href=\"http://www.dhamma.org/en/goenka.shtml\">S.N. Goenka</a>\u00a0says at the end of a\u00a0<a href=\"http://en.wikipedia.org/wiki/Vipassan%C4%81\">Vipassana</a>\u00a0session\u2026 \u201cyou are bound to be successful, bound to be successful\u2026\u201d (Note: not affiliated with Goenka, but dug my first retreat).</p>", "tree_html": ""}, "can_send_in_message": true, "id": 3257262188, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Analytic Product Teams", "tags": [], "post_url": "http://datasyndrome.com/post/3257262188/analytic-product-teams", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y329U1i", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1297542660, "note_count": 0, "trail": [{"content": "<p>It takes a lot of skills to build successful analytic products. &nbsp;(<a href=\"http://www.linkedin.com/in/bradfordcross\">Bradford Cross</a>&nbsp;<a href=\"http://measuringmeasures.com/blog/2010/7/2/research-driven-startups.html\">outlined the process well</a>). &nbsp;The roles, defined in a spectrum from customer to researcher might look like this, although the continuum is not strictly speaking accurate (click to enlarge):</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm2.static.flickr.com/1389/5105430385_2e1f8e9230_b.jpg\">External image</div></p>\n<p>Note that customer participation during the entire process is not optional if you&rsquo;re trying to make money.</p>\n<p>In a big company, you might see one person occupying each of these roles. &nbsp;Of course, as team size increases&nbsp;<a href=\"http://en.wikipedia.org/wiki/The_Mythical_Man-Month\">communication overhead</a>&nbsp;rises and rapid release becomes impossible. &nbsp;This can be mitigated by assigning only three people to a product at a time who&rsquo;s skills cover most of these areas, and lending them expert resources in areas they are short, only as needed.</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm2.static.flickr.com/1067/5105430391_d418a77072_b.jpg\">External image</div></p>\n<p>Analytic products are such a such a&nbsp;multidisciplinary&nbsp;undertaking that in a data startup a founding team is at minimum three people. &nbsp;Ideally all are founders. &nbsp;There are probably exceptions, but that is the minimum number of bodies required to flesh out all these areas with passionate people who share the vision and are deeply invested in the success of the company. &nbsp;Someone needs to be good at and enjoy each of these roles.</p>\n<p>Of course, the split doesn&rsquo;t have to look like that. &nbsp;It could look many ways:</p>\n<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm2.static.flickr.com/1413/5105430397_bfabdd4904_b.jpg\">External image</div></p>\n<p>In the second configuration, one of you is the customer. &nbsp;That is ideal because you are building for the guy &rsquo;<a href=\"http://steveblank.com/\">on the next bench</a>,&rsquo; (Steve Blank&rsquo;s phrase, refers to the next&nbsp;soldering&nbsp;bench and the fact that silicon valley always worked this way until quite recently) but it doesn&rsquo;t replace&nbsp;<a href=\"http://steveblank.com/category/customer-development/\">customer development</a>.</p>\n<p>The third configuration is more eclectic. &nbsp;The point being that there is no right answer, but you&rsquo;d better have these bases covered.</p>\n<p>For an analytics product, this is the customer development team. &nbsp;Nobody is in charge and everyone participates. &nbsp;Build a minimal v0.1 inside of one month that expresses your core insight and some key feature of the data. &nbsp;Then drive, fly or swim to a real customer and introduce them to your application in person. &nbsp;Give them access and keep them clicking each alpha release. &nbsp;Log everything. &nbsp;Monitor and evolve your metrics. &nbsp;If you lose your alpha users, pivot.</p>\n<p>As&nbsp;<a href=\"http://www.dhamma.org/en/goenka.shtml\">S.N. Goenka</a>&nbsp;says at the end of a&nbsp;<a href=\"http://en.wikipedia.org/wiki/Vipassan%C4%81\">Vipassana</a>&nbsp;session&hellip; &ldquo;you are bound to be successful, bound to be successful&hellip;&rdquo; (Note: not affiliated with Goenka, but dug my first retreat).</p>", "content_raw": "<p>It takes a lot of skills to build successful analytic products. \u00a0(<a href=\"http://www.linkedin.com/in/bradfordcross\">Bradford Cross</a>\u00a0<a href=\"http://measuringmeasures.com/blog/2010/7/2/research-driven-startups.html\">outlined the process well</a>). \u00a0The roles, defined in a spectrum from customer to researcher might look like this, although the continuum is not strictly speaking accurate (click to enlarge):</p>\n<p><a href=\"http://farm2.static.flickr.com/1389/5105430385_2e1f8e9230_b.jpg\"><img height=\"66\" width=\"512\" src=\"http://farm2.static.flickr.com/1389/5105430385_2e1f8e9230_b.jpg\" align=\"middle\"></a></p>\n<p>Note that customer participation during the entire process is not optional if you\u2019re trying to make money.</p>\n<p>In a big company, you might see one person occupying each of these roles. \u00a0Of course, as team size increases\u00a0<a href=\"http://en.wikipedia.org/wiki/The_Mythical_Man-Month\">communication overhead</a>\u00a0rises and rapid release becomes impossible. \u00a0This can be mitigated by assigning only three people to a product at a time who\u2019s skills cover most of these areas, and lending them expert resources in areas they are short, only as needed.</p>\n<p><a href=\"http://farm2.static.flickr.com/1067/5105430391_d418a77072_b.jpg\"><img height=\"78\" width=\"512\" src=\"http://farm2.static.flickr.com/1067/5105430391_d418a77072_b.jpg\" align=\"middle\"></a></p>\n<p>Analytic products are such a such a\u00a0multidisciplinary\u00a0undertaking that in a data startup a founding team is at minimum three people. \u00a0Ideally all are founders. \u00a0There are probably exceptions, but that is the minimum number of bodies required to flesh out all these areas with passionate people who share the vision and are deeply invested in the success of the company. \u00a0Someone needs to be good at and enjoy each of these roles.</p>\n<p>Of course, the split doesn\u2019t have to look like that. \u00a0It could look many ways:</p>\n<p><a href=\"http://farm2.static.flickr.com/1413/5105430397_bfabdd4904_b.jpg\"><img height=\"103\" width=\"512\" src=\"http://farm2.static.flickr.com/1413/5105430397_bfabdd4904_b.jpg\" align=\"middle\"></a></p>\n<p>In the second configuration, one of you is the customer. \u00a0That is ideal because you are building for the guy \u2019<a href=\"http://steveblank.com/\">on the next bench</a>,\u2019 (Steve Blank\u2019s phrase, refers to the next\u00a0soldering\u00a0bench and the fact that silicon valley always worked this way until quite recently) but it doesn\u2019t replace\u00a0<a href=\"http://steveblank.com/category/customer-development/\">customer development</a>.</p>\n<p>The third configuration is more eclectic. \u00a0The point being that there is no right answer, but you\u2019d better have these bases covered.</p>\n<p>For an analytics product, this is the customer development team. \u00a0Nobody is in charge and everyone participates. \u00a0Build a minimal v0.1 inside of one month that expresses your core insight and some key feature of the data. \u00a0Then drive, fly or swim to a real customer and introduce them to your application in person. \u00a0Give them access and keep them clicking each alpha release. \u00a0Log everything. \u00a0Monitor and evolve your metrics. \u00a0If you lose your alpha users, pivot.</p>\n<p>As\u00a0<a href=\"http://www.dhamma.org/en/goenka.shtml\">S.N. Goenka</a>\u00a0says at the end of a\u00a0<a href=\"http://en.wikipedia.org/wiki/Vipassan%C4%81\">Vipassana</a>\u00a0session\u2026 \u201cyou are bound to be successful, bound to be successful\u2026\u201d (Note: not affiliated with Goenka, but dug my first retreat).</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "3257262188"}}], "date": "2011-02-12 20:31:00 GMT", "slug": "analytic-product-teams", "blog_name": "rjurney", "summary": "Analytic Product Teams", "can_reblog": true}, {"body": "<p><img align=\"middle\" src=\"http://farm2.static.flickr.com/1226/5144521000_f233b6073b.jpg\" width=\"500\" height=\"375\"/></p>\n<p>Wherever the image came from of a productive hacker being a vitamin D deficient couch\u00a0potato, fueled entirely by Ramen and Jolt, it needs to die.</p>\n<p>I slept until I wasn&rsquo;t tired and hacked until I couldn&rsquo;t focus.</p>\n<p>Then I surfed south Linda Mar above. \u00a0There were soft, crumbly overhead sets, and I didn&rsquo;t get one ride. \u00a0But I got lots of paddling in before stumbling to shore through rocks and kelp.</p>\n<p>Now my mind is clear. I&rsquo;m riding an endorphin high. I&rsquo;ve got many more hours of hacking in me. \u00a0</p>\n<p>Human beings were not made to sit in chairs for twelve hours at a stretch pushing buttons while staring at LCDs. \u00a0Get up, go <strong>outside</strong>, move around, and come back. \u00a0You&rsquo;ll get more done. \u00a0As George Clinton said, <a href=\"http://en.wikipedia.org/wiki/Free_Your_Mind..._and_Your_Ass_Will_Follow\">&lsquo;Free your ass, and your mind will follow.&rsquo;</a></p>\n<p>Note: <em>The gym does not count</em>. \u00a0You are made to exercise under the sun surrounded by nature, not\u00a0fluorescent\u00a0lights and clinking\u00a0dumbbells. \u00a0<strong>Go outside.</strong></p>\n<p>Update (via\u00a0<a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">skm</a> on Hacker News): <a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">Exercise grows neurons</a>.</p>", "liked": false, "followed": false, "reblog_key": "bNvyyUeQ", "reblog": {"comment": "<p><img align=\"middle\" src=\"http://farm2.static.flickr.com/1226/5144521000_f233b6073b.jpg\" width=\"500\" height=\"375\"></p>\n<p>Wherever the image came from of a productive hacker being a vitamin D deficient couch\u00a0potato, fueled entirely by Ramen and Jolt, it needs to die.</p>\n<p>I slept until I wasn\u2019t tired and hacked until I couldn\u2019t focus.</p>\n<p>Then I surfed south Linda Mar above. \u00a0There were soft, crumbly overhead sets, and I didn\u2019t get one ride. \u00a0But I got lots of paddling in before stumbling to shore through rocks and kelp.</p>\n<p>Now my mind is clear. I\u2019m riding an endorphin high. I\u2019ve got many more hours of hacking in me. \u00a0</p>\n<p>Human beings were not made to sit in chairs for twelve hours at a stretch pushing buttons while staring at LCDs. \u00a0Get up, go <strong>outside</strong>, move around, and come back. \u00a0You\u2019ll get more done. \u00a0As George Clinton said, <a href=\"http://en.wikipedia.org/wiki/Free_Your_Mind..._and_Your_Ass_Will_Follow\">\u2018Free your ass, and your mind will follow.\u2019</a></p>\n<p>Note: <em>The gym does not count</em>. \u00a0You are made to exercise under the sun surrounded by nature, not\u00a0fluorescent\u00a0lights and clinking\u00a0dumbbells. \u00a0<strong>Go outside.</strong></p>\n<p>Update (via\u00a0<a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">skm</a> on Hacker News): <a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">Exercise grows neurons</a>.</p>", "tree_html": ""}, "can_send_in_message": true, "id": 1474842339, "display_avatar": true, "can_reply": true, "can_like": false, "title": "Exercise More to Hack Better", "tags": [], "post_url": "http://datasyndrome.com/post/1474842339/exercise-more-to-hack-better", "recommended_source": null, "state": "published", "short_url": "https://tmblr.co/ZbIO5y1Nw4xZ", "type": "text", "recommended_color": null, "format": "html", "timestamp": 1288830480, "note_count": 20, "trail": [{"content": "<p><div class=\"external-image-wrapper\" data-loading-text=\"Loading...\" data-src=\"http://farm2.static.flickr.com/1226/5144521000_f233b6073b.jpg\">External image</div></p>\n<p>Wherever the image came from of a productive hacker being a vitamin D deficient couch&nbsp;potato, fueled entirely by Ramen and Jolt, it needs to die.</p>\n<p>I slept until I wasn&rsquo;t tired and hacked until I couldn&rsquo;t focus.</p>\n<p>Then I surfed south Linda Mar above. &nbsp;There were soft, crumbly overhead sets, and I didn&rsquo;t get one ride. &nbsp;But I got lots of paddling in before stumbling to shore through rocks and kelp.</p>\n<p>Now my mind is clear. I&rsquo;m riding an endorphin high. I&rsquo;ve got many more hours of hacking in me. &nbsp;</p>\n<p>Human beings were not made to sit in chairs for twelve hours at a stretch pushing buttons while staring at LCDs. &nbsp;Get up, go <strong>outside</strong>, move around, and come back. &nbsp;You&rsquo;ll get more done. &nbsp;As George Clinton said, <a href=\"http://en.wikipedia.org/wiki/Free_Your_Mind..._and_Your_Ass_Will_Follow\">&lsquo;Free your ass, and your mind will follow.&rsquo;</a></p>\n<p>Note: <em>The gym does not count</em>. &nbsp;You are made to exercise under the sun surrounded by nature, not&nbsp;fluorescent&nbsp;lights and clinking&nbsp;dumbbells. &nbsp;<strong>Go outside.</strong></p>\n<p>Update (via&nbsp;<a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">skm</a> on Hacker News): <a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">Exercise grows neurons</a>.</p>", "content_raw": "<p><img align=\"middle\" src=\"http://farm2.static.flickr.com/1226/5144521000_f233b6073b.jpg\" width=\"500\" height=\"375\"></p>\n<p>Wherever the image came from of a productive hacker being a vitamin D deficient couch\u00a0potato, fueled entirely by Ramen and Jolt, it needs to die.</p>\n<p>I slept until I wasn\u2019t tired and hacked until I couldn\u2019t focus.</p>\n<p>Then I surfed south Linda Mar above. \u00a0There were soft, crumbly overhead sets, and I didn\u2019t get one ride. \u00a0But I got lots of paddling in before stumbling to shore through rocks and kelp.</p>\n<p>Now my mind is clear. I\u2019m riding an endorphin high. I\u2019ve got many more hours of hacking in me. \u00a0</p>\n<p>Human beings were not made to sit in chairs for twelve hours at a stretch pushing buttons while staring at LCDs. \u00a0Get up, go <strong>outside</strong>, move around, and come back. \u00a0You\u2019ll get more done. \u00a0As George Clinton said, <a href=\"http://en.wikipedia.org/wiki/Free_Your_Mind..._and_Your_Ass_Will_Follow\">\u2018Free your ass, and your mind will follow.\u2019</a></p>\n<p>Note: <em>The gym does not count</em>. \u00a0You are made to exercise under the sun surrounded by nature, not\u00a0fluorescent\u00a0lights and clinking\u00a0dumbbells. \u00a0<strong>Go outside.</strong></p>\n<p>Update (via\u00a0<a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">skm</a> on Hacker News): <a href=\"http://well.blogs.nytimes.com/2009/09/16/what-sort-of-exercise-can-make-you-smarter/\">Exercise grows neurons</a>.</p>", "is_current_item": true, "blog": {"can_be_followed": true, "name": "rjurney", "share_likes": true, "share_following": false, "theme": {"title_font_weight": "bold", "title_color": "#444444", "header_bounds": "", "title_font": "Gibson", "link_color": "#529ECC", "header_image_focused": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "show_description": true, "show_header_image": true, "header_stretch": true, "body_font": "Helvetica Neue", "show_title": true, "header_image_scaled": "https://assets.tumblr.com/images/default_header/optica_pattern_08_focused_v3.png?_v=f0f055039bb6136b9661cf2227b535c2", "avatar_shape": "square", "show_avatar": true, "background_color": "#FAFAFA", "header_image": "https://assets.tumblr.com/images/default_header/optica_pattern_08.png?_v=f0f055039bb6136b9661cf2227b535c2"}, "active": true}, "is_root_item": true, "post": {"id": "1474842339"}}], "date": "2010-11-04 00:28:00 GMT", "slug": "exercise-more-to-hack-better", "blog_name": "rjurney", "summary": "Exercise More to Hack Better", "can_reblog": true}]